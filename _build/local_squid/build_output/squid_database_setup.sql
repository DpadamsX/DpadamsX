------------------------------------------------------------ Database Setup------------------------------------------------------------ See PgSource_Build to regenerate this script.-- Pre-flight:-- Delete the database by hand, if it exists.-- Note: May be able to skip this step in PG 13 because of the new WITH (FORCE) argument on DROP DATABASE.-- Post-run:-- After running all of the code here, check for errors.-- If everything is okay, set up and insert the the unit tests. You'll want PgSource_BuildUnitTestSetup for this step.-- This isn't quite ready for RDS as search path and grants are only grabbing the local versions.-- But I couldn't get psql working through SSH anyway.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:_build:local_squid:database_setup:drop_create_database.script_only.sql-- WITH (FORCE) needed, not supported until PG 13.-- DROP DATABASE IF EXISTS squid WITH (FORCE);-- Ah...need to sort out CONNECT at this point. Another day.-- Yeah, do this next line manually in psql or SQLPro, etc.-- CREATE DATABASE squid;------------------------------------------- Schemas-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:schemas:schemas_create.sql-- Log in as rds_super for this on Amazon.----------------------------------------------------------- public----------------------------------------------------------- Hard to secure, get rid of it.DROP SCHEMA IF EXISTS public;----------------------------------------------------------- ascendco---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS ascendco    AUTHORIZATION user_admin;COMMENT ON SCHEMA ascendco    IS 'This is our internal data.';----------------------------------------------------------- api---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS api    AUTHORIZATION group_admins;COMMENT ON SCHEMA api    IS 'This is a view-only, regulated access point for external clients.';----------------------------------------------------------- api_queries---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS api_queries    AUTHORIZATION group_admins;COMMENT ON SCHEMA api_queries    IS 'Query functions in their own API.';----------------------------------------------------------- analytics---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS analytics    AUTHORIZATION group_admins;COMMENT ON SCHEMA analytics    IS 'This is a storehouse for analytic and summary data.';----------------------------------------------------------- dba---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS dba    AUTHORIZATION group_admins;COMMENT ON SCHEMA dba    IS 'DBA-oriented scripts and resources.';----------------------------------------------------------- domains---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS domains    AUTHORIZATION group_admins;COMMENT ON SCHEMA domains    IS 'Custom DOMAIN definition for use by tables and functions.';----------------------------------------------------------- extensions---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS extensions    AUTHORIZATION group_admins;COMMENT ON SCHEMA extensions    IS 'This is a convenience schema to make extension loading and search_path resolution simpler to manage.';----------------------------------------------------------- etl---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS etl    AUTHORIZATION group_admins;COMMENT ON SCHEMA etl    IS 'ETL work zone for cleanups and such.';----------------------------------------------------------- event_triggers---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS event_triggers    AUTHORIZATION group_admins;COMMENT ON SCHEMA event_triggers    IS 'DDL change event triggers are stored here.';----------------------------------------------------------- passthrough---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS passthrough    AUTHORIZATION group_admins;COMMENT ON SCHEMA passthrough    IS 'This is a view-only, regulated access point for external clients drawing data extracted from packed records.';----------------------------------------------------------- text_analysis---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS text_analysis    AUTHORIZATION group_admins;COMMENT ON SCHEMA text_analysis    IS 'Text analysis tables and tools.';----------------------------------------------------------- tools---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS tools    AUTHORIZATION group_admins;COMMENT ON SCHEMA tools    IS 'General purpose scripts and resources.';----------------------------------------------------------- types---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS types    AUTHORIZATION group_admins;COMMENT ON SCHEMA tools    IS 'Custom type declarations for use by tables and functions.';----------------------------------------------------------- types_plus---------------------------------------------------------CREATE SCHEMA IF NOT EXISTS types_plus    AUTHORIZATION user_admin;COMMENT ON SCHEMA types_plus    IS 'Custom views and types for row insertion. This is where the Postgres part of our push plumbing is implemented';------------------------------------------- Extensions-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:extensions:extensions_create.local.sqlCREATE EXTENSION IF NOT EXISTS amcheck SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS btree_gin SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS citext SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS fuzzystrmatch SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS pg_stat_statements SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS pg_trgm SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS pgcrypto SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS pgstattuple SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS pldbgapi SCHEMA extensions;  -- Debugger isn't supported on RDS :(CREATE EXTENSION IF NOT EXISTS plpgsql SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS postgres_fdw SCHEMA extensions;CREATE EXTENSION IF NOT EXISTS tablefunc SCHEMA extensions;-- A few more extensions are installed on RDS, via a distinct setup file.-- CREATE EXTENSION IF NOT EXISTS dict_xsyn SCHEMA extensions;-- CREATE EXTENSION IF NOT EXISTS log_fdw SCHEMA extensions; -- RDS only-- CREATE EXTENSION IF NOT EXISTS pg_repack SCHEMA extensions; -- RDS only-- CREATE EXTENSION IF NOT EXISTS pg_similarity SCHEMA extensions; -- RDS only-- pg_cron, RDS only, special setup steps required.------------------------------------------- search_path-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:search_paths:search_path_rebuild.local.sql-- Log in as postgres to run this script.-- Cleanup any modifications made on the DATABASE level.ALTER DATABASE squid RESET search_path;-- Cleanup any modifications made on the USER level specifically on squidALTER USER postgres IN DATABASE squid RESET search_path;ALTER USER rds_super IN DATABASE squid RESET search_path;ALTER USER user_admin IN DATABASE squid RESET search_path;ALTER USER user_bender IN DATABASE squid RESET search_path;ALTER USER user_change_structure IN DATABASE squid RESET search_path;ALTER USER user_cleanup IN DATABASE squid RESET search_path;ALTER USER user_domo_pull IN DATABASE squid RESET search_path;ALTER USER user_iceberg IN DATABASE squid RESET search_path;ALTER USER user_iceberg_remote IN DATABASE squid RESET search_path;ALTER USER user_leviathan IN DATABASE squid RESET search_path;ALTER USER user_reporting IN DATABASE squid RESET search_path;ALTER USER user_saws IN DATABASE squid RESET search_path;ALTER USER user_sonar IN DATABASE squid RESET search_path;-- Set globally for the cluster (all databases) as we've got the same schemas everywhere.ALTER USER postgres SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough, analytics, dba;ALTER USER rds_super SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough, analytics, dba;ALTER USER user_admin SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough, analytics, dba;ALTER USER user_bender SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough, analytics, dba;ALTER USER user_change_structure SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough, analytics, dba;ALTER USER user_cleanup SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough, analytics, dba;ALTER USER user_domo_pull SET search_path TO api, api_queries, domains, extensions, tools, types, types_plus, passthrough;ALTER USER user_iceberg SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough;ALTER USER user_iceberg_remote SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough;ALTER USER user_leviathan SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough;ALTER USER user_reporting SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough;ALTER USER user_saws SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough;ALTER USER user_sonar SET search_path TO api, api_queries, ascendco, domains, extensions, tools, types, types_plus, passthrough;------------------------------------------- Domains-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:bigint_not_negative.sql---------------------------- bigint_non_negative--------------------------DROP DOMAIN IF EXISTS domains.bigint_non_negative;CREATE DOMAIN domains.bigint_non_negative AS	bigint	NOT NULL	CHECK (value >= 0);COMMENT ON DOMAIN domains.bigint_non_negative IS	'The number must be 0 or greater';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:citext_not_empty.sql-------------------------- citext_not_empty------------------------DROP DOMAIN IF EXISTS domains.citext_not_empty;CREATE DOMAIN domains.citext_not_empty AS	citext	NOT NULL CHECK (value <> '');COMMENT ON DOMAIN domains.citext_not_empty IS	'The string must not be empty';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:day_name.sql-------------------------- day_name------------------------DROP DOMAIN IF EXISTS domains.day_name;CREATE DOMAIN domains.day_name AS	citext	NOT NULL	CONSTRAINT day_name_legal_values		CHECK(      		VALUE IN (      		    'Sunday',				'Monday',				'Tuesday',				'Wednesday',				'Thursday',				'Friday',				'Saturday'      		)  	 );COMMENT ON DOMAIN domains.day_name IS	'Valid full day names in English.';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:decimal_score.sql-------------------------- decimal_score------------------------DROP DOMAIN IF EXISTS domains.decimal_score;CREATE DOMAIN domains.decimal_score AS	DECIMAL(9,6)	NOT NULL;COMMENT ON DOMAIN domains.decimal_score IS	'###.###### precision decimal value, without NULLs';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:integer_non_negative.sql---------------------------- integer_non_negative--------------------------DROP DOMAIN IF EXISTS domains.integer_non_negative;CREATE DOMAIN domains.integer_non_negative AS	integer	NOT NULL	CHECK (value >= 0);COMMENT ON DOMAIN domains.integer_non_negative IS	'The number must be 0 or greater';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:smallint_not_negative.sql---------------------------- smallint_non_negative--------------------------DROP DOMAIN IF EXISTS domains.smallint_non_negative;CREATE DOMAIN domains.smallint_non_negative AS	smallint	NOT NULL	CHECK (value >= 0);COMMENT ON DOMAIN domains.smallint_non_negative IS	'The number must be 0 or greater';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:test_outcome.sql-------------------------- test_outcome------------------------DROP DOMAIN IF EXISTS domains.test_outcome;CREATE DOMAIN domains.test_outcome AS	citext	NOT NULL	CONSTRAINT test_outcome_legal_values		CHECK(      		VALUE IN ('Pass','Warning','Fail')  	 );COMMENT ON DOMAIN domains.test_outcome IS	'The test_outcome must be pass, warning, or fail, case-insensitive.';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:text_not_empty.sql-------------------------- text_not_empty------------------------DROP DOMAIN IF EXISTS domains.text_not_empty;CREATE DOMAIN domains.text_not_empty AS	text	NOT NULL	CHECK (value <> '');COMMENT ON DOMAIN domains.text_not_empty IS	'The string must not be empty';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:domains:user_name.sql-------------------------- user_name------------------------DROP DOMAIN IF EXISTS domains.user_name;CREATE DOMAIN domains.user_name AS	citext	NOT NULL	CONSTRAINT user_name_legal_values		CHECK(      		VALUE IN (      		    'postgres',				'rds_super',				'user_bender',				'user_change_structure',				'user_cleanup',				'user_domo_pull',				'user_iceberg',				'user_iceberg_remote',				'user_leviathan',				'user_reporting',				'user_saws',				'user_sonar'      		)  	 );COMMENT ON DOMAIN domains.user_name IS	'Valid user_name role names.';--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:ddl_event_log.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.ddl_event_log CASCADE;CREATE TABLE IF NOT EXISTS dba.ddl_event_log (	id uuid NOT NULL DEFAULT extensions.gen_random_uuid(),	event_timestamp timestamptz NOT NULL DEFAULT clock_timestamp(), -- The timestamp at the time the command runs.	classid oid, --            CREATE, ALTER, DELETE	objid oid, --              CREATE, ALTER, DELETE	objsubid integer, --       CREATE, ALTER, DELETE	command_tag text, --       CREATE, ALTER           <- Same value as TG_TAG event_trigger variable.	is_temporary bool, --                     DELETE	normal bool, --                           DELETE	original bool, --                         DELETE	in_extension bool, --      CREATE, ALTER	object_identity text, --   CREATE, ALTER, DELETE	object_name text, --       CREATE, ALTER, DELETE	object_type text, --       CREATE, ALTER, DELETE	schema_name text, --       CREATE, ALTER, DELETE	address_args text[], --                   DELETE	address_names text[], --                  DELETE	trigger_event text); --    CREATE, ALTER, DELETE	-- object_source text);    --        CREATE, ALTER via JOIN on pg_proc. So, not views, tables, etc. Not working. Badly not working.ALTER TABLE dba.ddl_event_log	ADD CONSTRAINT ddl_event_log_id_pkey    PRIMARY KEY (id);ALTER TABLE dba.ddl_event_log	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None needed at the moment.-------------------------------------- Add triggers-------------------------------------- None needed at the moment, but this might change to auto-populate and dirty custom_function.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:event_triggers:on_ddl_create_or_alter.sql------------------------------------------------------ CREATE FUNCTION on_ddl_create_or_alter----------------------------------------------------DROP FUNCTION IF EXISTS event_triggers.on_ddl_create_or_alter() CASCADE;CREATE FUNCTION event_triggers.on_ddl_create_or_alter()        RETURNS event_trigger AS$BODY$BEGININSERT INTO dba.ddl_event_log (			classid,			objid,			objsubid,			command_tag,			in_extension,			object_identity,			object_type,			schema_name,			trigger_event) --,			-- object_source)	SELECT	ec.classid,			ec.objid,			ec.objsubid,			ec.command_tag,			ec.in_extension,			ec.object_identity,			ec.object_type,			ec.schema_name,			TG_EVENT			-- ddl_get_object_source(ec.object_type,ec.objid)       FROM pg_event_trigger_ddl_commands() AS ec  LEFT JOIN pg_proc on pg_proc.oid = ec.objid      WHERE TG_TAG IS NOT NULL AND            command_tag NOT IN ('GRANT','REVOKE','ALTER DEFAULT PRIVILEGES');      -- Unclear why some are null, seems to be on low-level rewrites?  ¬Ø\_(„ÉÑ)_/¬ØEND$BODY$	LANGUAGE plpgsql;-- The code above defines the function, but does *not* build the event_trigger binding.-- That code is handled in a distinct operation.-- The object_source field population code call to ddl_get_object_source isn't working right,-- don't really need it, setting it aside for now.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:event_triggers:on_ddl_drop.sql------------------------------------------------------ CREATE FUNCTION on_ddl_drop----------------------------------------------------DROP FUNCTION IF EXISTS event_triggers.on_ddl_drop() CASCADE;CREATE FUNCTION event_triggers.on_ddl_drop()        RETURNS event_trigger AS$BODY$BEGININSERT INTO dba.ddl_event_log (			  classid,			  objid,			  objsubid,			  is_temporary,			  normal,			  original,			  object_identity,			  object_name,			  object_type,			  schema_name,			  address_args,			  address_names,			  trigger_event)	  SELECT ec.classid,			  ec.objid,			  ec.objsubid,			  ec.is_temporary,			  ec.normal,			  ec.original,			  ec.object_identity,			  ec.object_name,			  ec.object_type,			  ec.schema_name,			  ec.address_args,			  ec.address_names,			  TG_EVENT       FROM pg_event_trigger_dropped_objects() AS ec  LEFT JOIN pg_proc on pg_proc.oid = ec.objid;END$BODY$	LANGUAGE plpgsql;-- The code above defines the function, but does *not* build the event_trigger binding.-- That code is handled in a distinct operation.------------------------------------------- Event Triggers------------------------------------------- These get imported earlier.------------------------------------------- Types-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types:text_id.sqlCREATE TYPE types.text_id AS (    text citext,    id uuid);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types:text_text.sqlCREATE TYPE types.text_text AS (    text citext,    id   citext);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:trigger_functions:trigger_function_log_deletion_count.sqlCREATE OR REPLACE FUNCTION ascendco.trigger_function_log_deletion_count()	RETURNS triggerAS $BODY$DECLAREdeleted_count int := (select count(*) from deleted_rows);BEGINIF deleted_count > 0 THEN	   insert into ascendco.deletion_log				   (operation_name,				   schema_name,				   table_name,				   deleted_count)			 select TG_OP,					TG_TABLE_SCHEMA,					TG_TABLE_NAME,					deleted_count;END IF;	RETURN NULL;END;$BODY$	LANGUAGE plpgsql;ALTER FUNCTION ascendco.trigger_function_log_deletion_count ()	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:trigger_functions:trigger_function_log_truncation_count.sqlCREATE OR REPLACE FUNCTION ascendco.trigger_function_log_truncation_count()    RETURNS triggerAS $BODY$DECLARE  deleted_count int := 0;BEGIN/*I had:EXECUTE 'select count(1) from ' || TG_TABLE_NAME into deleted_count;If there are identical table names in different schemas could go wonky:https://stackoverflow.com/questions/57193314/what-is-the-easiest-way-to-get-the-number-of-rows-affected-in-an-after-truncate/The solution offered in that thread doesn't quite work, but EXECUTE FORMAT (query) INTO does work, as listed below.*/EXECUTE FORMAT('SELECT count(1) FROM %s', TG_RELID::regclass)   INTO deleted_count;   IF deleted_count > 0 THEN	   insert into deletion_log				  (operation_name,				   schema_name,				   table_name,				   deleted_count)			select TG_OP,				   TG_TABLE_SCHEMA,				   TG_TABLE_NAME,				   deleted_count;    END IF;    RETURN NULL;END;$BODY$	LANGUAGE plpgsql;ALTER FUNCTION ascendco.trigger_function_log_truncation_count ()	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:trigger_functions:trigger_function_update_last_updated_dts.sqlCREATE OR REPLACE FUNCTION ascendco.trigger_function_update_last_updated_dts()RETURNS TRIGGERAS $BODY$BEGIN  NEW.last_updated_dts = NOW(); -- Now *IS* a STABLE function, it's safe to use in a STABLE UDF.  RETURN NEW;END;$BODY$	LANGUAGE plpgsql STABLE;ALTER FUNCTION ascendco.trigger_function_update_last_updated_dts	OWNER TO user_bender;------------------------------------------- Trigger Functions------------------------------------------------------------------------------------ Dictionaries-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:dictionaries:simple_skip.sql---------------------------------------- Define the dictionary--------------------------------------CREATE TEXT SEARCH DICTIONARY ascendco.simple_skip_dictionary (    TEMPLATE = pg_catalog.simple,    STOPWORDS = english);---------------------------------------- Create a text search configuration--------------------------------------CREATE TEXT SEARCH CONFIGURATION ascendco.simple_skip (COPY = simple);ALTER  TEXT SEARCH CONFIGURATION ascendco.simple_skip   ALTER MAPPING FOR asciiword WITH ascendco.simple_skip_dictionary;  -- 1, 'Word, all ASCII'--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:minutes_old.sqlCREATE OR REPLACE FUNCTION api.minutes_old (dts timestamptz)  RETURNS pg_catalog.int4AS $BODY$SELECT ((date_part('epoch'::text, (now() - dts)))::integer / 60)$BODY$  LANGUAGE sql STABLE  COST 100;ALTER FUNCTION api.minutes_old (timestamptz)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:convert_ib_timezone_name.sqlCREATE OR REPLACE FUNCTION api.convert_ib_timezone_name (tz_name_in citext)     RETURNS citext AS$BODY$-- IB uses custom names, convert these to standard tz names.SELECTCASE WHEN tz_name_in = 'Arizona'  THEN 'US/Arizona'::citext     WHEN tz_name_in = 'Central'  THEN 'US/Central'::citext     WHEN tz_name_in = 'Eastern'  THEN 'US/Eastern'::citext     WHEN tz_name_in = 'Mountain' THEN 'US/Mountain'::citext     WHEN tz_name_in = 'Pacific'  THEN 'US/Pacific'::citext     WHEN tz_name_in = 'Western'  THEN 'US/Pacific'::citext  -- IB uses 'Western' instead of 'Pacific'     ELSE 'UTC'::citextEND$BODY$  LANGUAGE SQL  IMMUTABLE;COMMENT ON FUNCTION api.convert_ib_timezone_name (citext) IS'Convert a custom IB time zone name, like ''Central'', to a standard name Postgres understands, like ''US/Central''.';ALTER FUNCTION api.convert_ib_timezone_name (citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:count_rows.sqlCREATE OR REPLACE FUNCTION tools.count_rows (schema text, tablename text)	RETURNS pg_catalog.int4 	AS $BODY$DECLAREresult integer;query varchar;BEGINquery := 'SELECT count(1) FROM ' || schema || '.' || tablename;execute query into result;return result;END;$BODY$	LANGUAGE plpgsql 	VOLATILE	COST 100;	ALTER FUNCTION tools.count_rows (text, text) 	OWNER TO user_bender;	--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:get_current_user.sqlCREATE OR REPLACE FUNCTION tools.get_current_user()	RETURNS pg_catalog.text 	AS $BODY$SELECT current_user::text; $BODY$  LANGUAGE sql VOLATILE  COST 100;ALTER FUNCTION tools.get_current_user ()	OWNER TO user_bender;  ------------------------------------------- Tables-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:api:hour_bin.sql-------------------------------------- Define table-------------------------------------- NOTE: Should rewrite code to use generate_series() instead. Maybe.BEGIN;DROP TABLE IF EXISTS api.hour_bin CASCADE;CREATE TABLE IF NOT EXISTS api.hour_bin (	id uuid NOT NULL DEFAULT extensions.gen_random_uuid (),	bin_hour smallint NOT NULL DEFAULT NULL, 	bin_number smallint NOT NULL DEFAULT NULL, 	bin_label citext NOT NULL DEFAULT NULL,	bin_group citext NOT NULL DEFAULT 'Four hour blocks');ALTER TABLE api.hour_bin	ADD CONSTRAINT hour_bin_id_pkey    PRIMARY KEY (id);COMMENT ON TABLE api.hour_bin IS 	'LEFT JOIN against this table to group datetime values by intervals. Alternatively, use generate_series() to create your bin list on-the-fly.';ALTER TABLE api.hour_bin	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Nope. Postgres won't even bother with an index for searches on such a tiny table.-- Note: You always need an index for a unique constraint. PG defines that automatically for the PRIMARY.-------------------------------------- Add triggers-------------------------------------- None for this table.-------------------------------------- Add seed data------------------------------------INSERT INTO api.hour_bin (id, bin_hour, bin_number, bin_label, bin_group)     VALUES ('d9700433-51bc-40fe-b443-2cc4ff0751e8',  0, 1, 'Midnight to 4:00 AM', 'Four hour blocks'),           ('c1db1974-1b37-4107-96b9-fba23924d3d1',  1, 1, 'Midnight to 4:00 AM', 'Four hour blocks'),           ('01c2b5d4-b522-4a6f-b01f-28210f7ca7cf',  2, 1, 'Midnight to 4:00 AM', 'Four hour blocks'),           ('ace6757e-1792-44e9-a693-16e0139c7003',  3, 1, 'Midnight to 4:00 AM', 'Four hour blocks'),                      ('df08b137-f59d-408a-99fe-4fe099b08527',  4, 2, '4:00 AM to 8:00 AM', 'Four hour blocks'),           ('bfb952b0-7e30-4d29-a8ab-9cd82c51772d',  5, 2, '4:00 AM to 8:00 AM', 'Four hour blocks'),           ('e6e8d233-714f-47d2-9287-0f518ea90018',  6, 2, '4:00 AM to 8:00 AM', 'Four hour blocks'),           ('c7705830-1520-46ba-85bb-f7a72febbf2c',  7, 2, '4:00 AM to 8:00 AM', 'Four hour blocks'),                      ('cd5f798a-bf50-44ce-b7f3-fd5d7ad955d9',  8, 3, '8:00 AM to 12:00 Noon', 'Four hour blocks'),           ('c5157a0f-1210-4442-8d90-df801a725fc3',  9, 3, '8:00 AM to 12:00 Noon', 'Four hour blocks'),           ('4c895082-1366-41c3-a95d-1932f3a5317a', 10, 3, '8:00 AM to 12:00 Noon', 'Four hour blocks'),           ('106de712-0e3a-402a-8aa9-abd5f4ec0006', 11, 3, '8:00 AM to 12:00 Noon', 'Four hour blocks'),                      ('016f27ab-4e84-4689-bda1-f11187468f9e', 12, 4, 'Noon to 4:00 PM', 'Four hour blocks'),           ('cf7e4484-67fa-45b8-a27d-af352f9a1dd2', 13, 4, 'Noon to 4:00 PM', 'Four hour blocks'),           ('ff32141d-fb42-4bc9-ba46-45be4b99c9e5', 14, 4, 'Noon to 4:00 PM', 'Four hour blocks'),           ('5a187a42-c236-422d-8dbb-03bfddf23b0f', 15, 4, 'Noon to 4:00 PM', 'Four hour blocks'),                      ('9b3d6b18-f59b-4ff9-a1f7-dd394234b52e', 16, 5, '4:00 PM to 8:00 PM', 'Four hour blocks'),           ('bf983094-649a-4b3e-8287-6430062660bd', 17, 5, '4:00 PM to 8:00 PM', 'Four hour blocks'),           ('d8da5228-734f-42cd-8491-1fa0d0546d24', 18, 5, '4:00 PM to 8:00 PM', 'Four hour blocks'),           ('88979e7a-86a5-4179-96b3-1518e808c7f7', 19, 5, '4:00 PM to 8:00 PM', 'Four hour blocks'),                      ('688adc56-dbd3-40a8-828e-2cd808044f06', 20, 6, '8:00 PM to Midnight', 'Four hour blocks'),           ('3f3e4397-0f51-4762-a203-43d11a3d557d', 21, 6, '8:00 PM to Midnight', 'Four hour blocks'),           ('a2a8b328-56e1-4069-b29a-7af92e31a67a', 22, 6, '8:00 PM to Midnight', 'Four hour blocks'),           ('53149ae3-2f80-4e7f-bd36-4ab2eb4f686a', 23, 6, '8:00 PM to Midnight', 'Four hour blocks');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:hour_bin_get_bin.sqlCREATE OR REPLACE FUNCTION api.hour_bin_get_bin (hour_number int4, bin_group extensions.citext='Four hour blocks'::citext)  RETURNS pg_catalog.int2AS $BODY$SELECT bin_numberFROM hour_binWHERE bin_hour = $1 AND bin_group = $2$BODY$  LANGUAGE sql STABLE  COST 100;ALTER FUNCTION api.hour_bin_get_bin (int4, extensions.citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:hour_bin_get_bin_label.sqlCREATE OR REPLACE FUNCTION api.hour_bin_get_bin_label (hour_number int4, bin_group extensions.citext='Four hour blocks'::citext)  RETURNS extensions.citextAS $BODY$SELECT bin_labelFROM hour_binWHERE bin_hour = $1 AND bin_group = $2$BODY$  LANGUAGE sql STABLE  COST 100;ALTER FUNCTION api.hour_bin_get_bin_label (int4, extensions.citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:hour_bin_get_bin_label.sqlCREATE OR REPLACE FUNCTION api.hour_bin_get_bin_label (hour_number int4, bin_group extensions.citext='Four hour blocks'::citext)  RETURNS extensions.citextAS $BODY$SELECT bin_labelFROM hour_binWHERE bin_hour = $1 AND bin_group = $2$BODY$  LANGUAGE sql STABLE  COST 100;ALTER FUNCTION api.hour_bin_get_bin_label (int4, extensions.citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:hour_bin_get_bin.sqlCREATE OR REPLACE FUNCTION api.hour_bin_get_bin (hour_number int4, bin_group extensions.citext='Four hour blocks'::citext)  RETURNS pg_catalog.int2AS $BODY$SELECT bin_numberFROM hour_binWHERE bin_hour = $1 AND bin_group = $2$BODY$  LANGUAGE sql STABLE  COST 100;ALTER FUNCTION api.hour_bin_get_bin (int4, extensions.citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:deletion_log.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.deletion_log CASCADE;CREATE TABLE IF NOT EXISTS ascendco.deletion_log (	id uuid NOT NULL DEFAULT extensions.gen_random_uuid(),	deletion_dts timestamptz NOT NULL DEFAULT now(),	client_address inet DEFAULT inet_client_addr(),	user_name text NOT NULL DEFAULT get_current_user(),    schema_name text DEFAULT NULL,	table_name  text NOT NULL DEFAULT NULL,	operation_name  text NOT NULL DEFAULT 'unspecified',	deleted_count integer NOT NULL DEFAULT 0);ALTER TABLE ascendco.deletion_log	ADD CONSTRAINT deletion_log_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.deletion_log	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None at this time.-------------------------------------- Add triggers-------------------------------------- None at this time.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:data_file_info.sql-------------------------------------- Define table------------------------------------BEGIN; DROP TABLE IF EXISTS ascendco.data_file_info CASCADE; CREATE TABLE ascendco.data_file_info(    id uuid NOT NULL,    last_updated_dts timestamptz NOT NULL DEFAULT now(),    server_name_ citext NOT NULL DEFAULT NULL,    app_name citext NOT NULL DEFAULT NULL,    app_version citext NOT NULL DEFAULT NULL,    shell_version citext NOT NULL DEFAULT NULL,    sync_version citext NOT NULL DEFAULT NULL,    iam_type citext NOT NULL DEFAULT NULL,    compiled boolean NOT NULL DEFAULT false,    merged boolean NOT NULL DEFAULT false,    type_of_4d citext NOT NULL DEFAULT NULL,    version_of_4d citext NOT NULL DEFAULT NULL,    machine_name citext NOT NULL DEFAULT NULL,    platform_description citext NOT NULL DEFAULT NULL,    os_tz_name citext NOT NULL DEFAULT NULL,    iam jsonb NOT NULL DEFAULT '{}'::jsonb,    table_stats jsonb NOT NULL DEFAULT '{}'::jsonb     );ALTER TABLE ascendco.data_file_info    ADD CONSTRAINT data_file_info_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.data_file_info	OWNER TO user_change_structure; COMMIT;-------------------------------------- Build indexes-------------------------------------- Not so much, don't have enough data for indexes to be useful. (The planner will ignore them anyway.)-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_data_file_info_after_delete	AFTER DELETE	ON ascendco.data_file_info	REFERENCING OLD TABLE AS deleted_rows 	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_data_file_info_before_truncate 	BEFORE TRUNCATE	ON ascendco.data_file_info	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();CREATE TRIGGER trigger_data_file_info_before_update 	BEFORE UPDATE	ON ascendco.data_file_info	FOR EACH ROW	EXECUTE PROCEDURE ascendco.trigger_function_update_last_updated_dts();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:calendar.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE if exists ascendco.calendar CASCADE;CREATE TABLE ascendco.calendar(  id               uuid      NOT NULL DEFAULT NULL PRIMARY KEY, -- Hand-rolling UUIDs in advance, that's why this is set, not geneated.  calendar_name    citext    NOT NULL DEFAULT NULL UNIQUE,  week_starts_on   day_name  NOT NULL DEFAULT NULL, -- day_name is a custom domain, works as a type.  description      citext    NOT NULL DEFAULT '');ALTER TABLE ascendco.calendar	OWNER TO user_change_structure;-------------------------------------- Build indexes-------------------------------------- None needed. PG automatically builds a unique b-tree on the PRIMARY KEY id field.-------------------------------------- Add triggers-------------------------------------- None for this table. Cascading delete built into foreign keys from child tables.-------------------------------------- Manual Permissions for now------------------------------------GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.calendar TO rds_super;GRANT SELECT ON ascendco.calendar TO user_reporting;GRANT SELECT ON ascendco.calendar TO user_iceberg;GRANT SELECT ON ascendco.calendar TO user_iceberg_remote;GRANT SELECT ON ascendco.calendar TO user_saws;GRANT SELECT ON ascendco.calendar TO user_sonar;GRANT SELECT ON ascendco.calendar TO user_leviathan;GRANT SELECT ON ascendco.calendar TO user_change_structure;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:calendar_year.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE if exists ascendco.calendar_year CASCADE;CREATE TABLE ascendco.calendar_year(  id                       uuid      NOT NULL DEFAULT extensions.gen_random_uuid() PRIMARY KEY,  calendar_id              uuid      NOT NULL DEFAULT NULL,  fiscal_year_name         citext    NOT NULL DEFAULT NULL, -- Text? Academic and financial years commony split calendar years.  fiscal_year_abbr         citext    NOT NULL DEFAULT NULL, -- Useful in week names and other labels, like "2020" of "FY19-20".  first_date_in_year       date      NOT NULL DEFAULT NULL,  last_date_in_year        date      NOT NULL DEFAULT NULL,  days_in_year             int2      NOT NULL DEFAULT NULL,  weeks_in_year            int2      NOT NULL DEFAULT NULL,  first_day_of_week_usa    int2      NOT NULL DEFAULT NULL, -- 1-7 day numbers, Sunday-Saturday, like 4D  first_day_of_week_iso    int2      NOT NULL DEFAULT NULL, -- 1-7 day numbers, Monday-Sunday  first_day_of_week_name   citext    NOT NULL DEFAULT NULL,  week_start_offset        integer DEFAULT 1 -- 1 for a Sunday start, 0 for a Monday week start.  );ALTER TABLE ascendco.calendar_year	ADD CONSTRAINT calendar_year_calendar_fk	FOREIGN KEY (calendar_id) REFERENCES calendar(id)	ON DELETE CASCADE;ALTER TABLE ascendco.calendar_year	ADD CONSTRAINT calendar_year_unique_name    UNIQUE (calendar_id, fiscal_year_name);ALTER TABLE ascendco.calendar_year	ADD CONSTRAINT calendar_year_unique_abbr    UNIQUE (calendar_id, fiscal_year_abbr);ALTER TABLE ascendco.calendar_year	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None needed right now, not enough data.-------------------------------------- Define trigger functions-------------------------------------- In PG 12 we can use generated columns instead.CREATE OR REPLACE FUNCTION ascendco.trigger_function_calendar_year_before_upsert()  RETURNS triggerAS $BODY$BEGIN	NEW.first_day_of_week_usa := extract (dow from NEW.first_date_in_year) +1; -- 1-7, Sunday-Saturday, USA style.	NEW.first_day_of_week_iso := extract (isodow from NEW.first_date_in_year); -- 1-7, Monday-Sunday, ISO style. RETURN NEW;END$BODY$  LANGUAGE plpgsql VOLATILE  COST 100;ALTER FUNCTION ascendco.trigger_function_calendar_year_before_upsert	OWNER TO user_bender;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER calendar_year_before_upsert	BEFORE INSERT OR UPDATE	ON ascendco.calendar_year	FOR EACH ROW	EXECUTE PROCEDURE trigger_function_calendar_year_before_upsert();-------------------------------------- Manual Permissions for now------------------------------------GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.calendar_year TO rds_super;GRANT SELECT ON ascendco.calendar_year TO user_reporting;GRANT SELECT ON ascendco.calendar_year TO user_iceberg;GRANT SELECT ON ascendco.calendar_year TO user_iceberg_remote;GRANT SELECT ON ascendco.calendar_year TO user_saws;GRANT SELECT ON ascendco.calendar_year TO user_sonar;GRANT SELECT ON ascendco.calendar_year TO user_leviathan;GRANT SELECT ON ascendco.calendar_year TO user_change_structure;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:calendar_day.sql-------------------------------------- Define table-------------------------------------- Adapted from-- https://dev.to/duffn/creating-a-date-dimension-table-in-postgresql-5gjpBEGIN;DROP TABLE if exists ascendco.calendar_day CASCADE;CREATE TABLE ascendco.calendar_day(  id                               citext    NOT NULL DEFAULT NULL PRIMARY KEY,  -- calendar_year_id + YYYYMMDD  calendar_id                      uuid      NOT NULL DEFAULT NULL,  calendar_year_id                 uuid      NOT NULL DEFAULT NULL,  date_actual                      date      NOT NULL DEFAULT NULL,  epoch                            int8      NOT NULL DEFAULT NULL,  day_suffix                       citext    NOT NULL DEFAULT NULL,  day_name                         citext    NOT NULL DEFAULT NULL,  day_name_abbreviated             citext    NOT NULL DEFAULT NULL,  day_of_week_usa                  integer   NOT NULL DEFAULT NULL,  -- 1-7 day numbers, Sunday-Saturday, like 4D.  day_of_week_iso                  integer   NOT NULL DEFAULT NULL,  -- 1-7 day numbers, Monday-Sunday  day_of_month_actual              integer   NOT NULL DEFAULT NULL,  day_of_quarter_iso               integer   NOT NULL DEFAULT NULL,  day_of_year_actual               integer   NOT NULL DEFAULT NULL,  day_of_year_fiscal               integer   NOT NULL DEFAULT NULL,  week_of_month_actual             integer   NOT NULL DEFAULT NULL,  week_of_year_actual              integer   NOT NULL DEFAULT NULL,  -- 24  week_of_year_fiscal_name         citext    NOT NULL DEFAULT NULL,  -- Week 24 2020  week_of_year_fiscal              citext    NOT NULL DEFAULT NULL,  -- 2020-24  week_of_year_iso                 citext    NOT NULL DEFAULT NULL,  -- 2020-24  month_actual                     integer   NOT NULL DEFAULT NULL,  month_actual_name                citext    NOT NULL DEFAULT NULL,  month_actual_name_abbreviated    citext    NOT NULL DEFAULT NULL,  month_fiscal                     integer   NOT NULL DEFAULT NULL,  month_fiscal_name                citext    NOT NULL DEFAULT NULL,  month_fiscal_name_abbreviated    citext    NOT NULL DEFAULT NULL,  quarter_actual                   integer   NOT NULL DEFAULT NULL,  quarter_actual_name              citext    NOT NULL DEFAULT NULL,  quarter_fiscal                   integer   NOT NULL DEFAULT NULL,  quarter_fiscal_name              citext    NOT NULL DEFAULT NULL,  year_actual                      integer   NOT NULL DEFAULT NULL,  -- year_fiscal_name is pulled via a join from fiscal_year.fiscal_year_name  -- year_fiscal_abbr is pulled via a join from fiscal_year.fiscal_year_abbr  first_date_of_week                date      NOT NULL DEFAULT NULL,  last_date_of_week                 date      NOT NULL DEFAULT NULL,  first_date_of_month               date      NOT NULL DEFAULT NULL,  last_date_of_month                date      NOT NULL DEFAULT NULL,  first_date_of_quarter             date      NOT NULL DEFAULT NULL,  last_date_of_quarter              date      NOT NULL DEFAULT NULL,  first_date_of_year_actual         date      NOT NULL DEFAULT NULL,  last_date_of_year_actual          date      NOT NULL DEFAULT NULL,  first_date_of_year_fiscal         date      NOT NULL DEFAULT NULL,  last_date_of_year_fiscal          date      NOT NULL DEFAULT NULL,  mmyyyyy                           citext    NOT NULL DEFAULT NULL,  mmddyyyy                          citext    NOT NULL DEFAULT NULL,  ddmmyyyyy                         citext    NOT NULL DEFAULT NULL,  weekend                           boolean   NOT NULL DEFAULT NULL);ALTER TABLE ascendco.calendar_day	ADD CONSTRAINT calendar_day_calendar_year_fk	FOREIGN KEY (calendar_year_id) REFERENCES calendar_year(id)	ON DELETE CASCADE;ALTER TABLE ascendco.calendar_day	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- CREATE INDEX calendar_day_date_actual_idx--  ON ascendco.calendar_day(date_actual);-------------------------------------- Define trigger functions-------------------------------------- In PG 12 we can use generated columns instead.CREATE OR REPLACE FUNCTION ascendco.trigger_function_calendar_day_before_insert()  RETURNS triggerAS $BODY$BEGIN	NEW.id := NEW.calendar_id || '.' || TO_CHAR(NEW.date_actual, 'YYYY-MM-DD'); RETURN NEW;END$BODY$  LANGUAGE plpgsql VOLATILE  COST 100;ALTER FUNCTION ascendco.trigger_function_calendar_day_before_insert	OWNER TO user_bender;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER calendar_day_before_insert	BEFORE INSERT	ON ascendco.calendar_day	FOR EACH ROW	EXECUTE PROCEDURE trigger_function_calendar_day_before_insert();-------------------------------------- Manual Permissions for now------------------------------------GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.calendar_day TO rds_super;GRANT SELECT ON ascendco.calendar_day TO user_reporting;GRANT SELECT ON ascendco.calendar_day TO user_iceberg;GRANT SELECT ON ascendco.calendar_day TO user_iceberg_remote;GRANT SELECT ON ascendco.calendar_day TO user_saws;GRANT SELECT ON ascendco.calendar_day TO user_sonar;GRANT SELECT ON ascendco.calendar_day TO user_leviathan;GRANT SELECT ON ascendco.calendar_day TO user_change_structure;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:hsys.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.hsys CASCADE;CREATE TABLE IF NOT EXISTS ascendco.hsys (	id uuid NOT NULL DEFAULT NULL,	marked_for_deletion boolean NOT NULL DEFAULT false,	name_ citext NOT NULL DEFAULT NULL,	sonar_client_version citext NOT NULL DEFAULT '',	sonar_server_version citext NOT NULL DEFAULT '',	sonar_browser_version citext NOT NULL DEFAULT '');ALTER TABLE ascendco.hsys	ADD CONSTRAINT hsys_id_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.hsys	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Nope. Postgres won't even bother with an index for searches on such a tiny table.-- Note: You always need an index for a unique constraint. PG defines that automatically for the PRIMARY.-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_hsys_after_delete	AFTER DELETE	ON ascendco.hsys	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_hsys_before_truncate	BEFORE TRUNCATE	ON ascendco.hsys	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- GRANTS------------------------------------GRANT SELECT, UPDATE ON ascendco.hsys TO user_leviathan;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:facility.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.facility CASCADE;CREATE TABLE IF NOT EXISTS ascendco.facility (    id                                  uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    hsys_id                             uuid          NOT NULL DEFAULT NULL,	calendar_id                         uuid          NOT NULL DEFAULT '21c27277-3aa4-4396-9293-c342cc693adc'::uuid, -- Hard-coded ID of the standard US calendar definition in the calendar table.    production_label_form_id            uuid          NOT NULL DEFAULT NULL,    permanent_label_form_id             uuid          NOT NULL DEFAULT NULL,    missing_inst_label_form_id          uuid          NOT NULL DEFAULT NULL,    facility_location_label_form_id     uuid          NOT NULL DEFAULT NULL,    sterilizer_label_form_id            uuid          NOT NULL DEFAULT NULL,    user_badge_label_form_id            uuid          NOT NULL DEFAULT NULL,    workstation_label_form_id           uuid          NOT NULL DEFAULT NULL,    default_spd_facility_id             uuid          NOT NULL DEFAULT NULL,    created_dts                         timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                         timestamp     NOT NULL DEFAULT 'epoch',    sonar_auto_logout_minutes           integer       NOT NULL DEFAULT 0,    sonar_auto_logout_dialog_minutes    integer       NOT NULL DEFAULT 0,    num_ors                             integer       NOT NULL DEFAULT 0,    sonar_go_live_date                  date          NOT NULL DEFAULT NULL,    marked_for_deletion                 boolean       NOT NULL DEFAULT false,    is_count_sheet_source_truth         boolean       NOT NULL DEFAULT false,    hide_doc_names_for_stats            boolean       NOT NULL DEFAULT false,    is_item_master_live                 boolean       NOT NULL DEFAULT false,    is_sonar_live                       boolean       NOT NULL DEFAULT false,    sterilizer_print_at_sterilizing     boolean       NOT NULL DEFAULT false,    sterilizer_print_at_cooling         boolean       NOT NULL DEFAULT false,    sterilizer_print_at_released        boolean       NOT NULL DEFAULT false,    can_set_all_found_in_assembly       boolean       NOT NULL DEFAULT false,    name_                               citext        NOT NULL DEFAULT NULL,    their_id                            citext        NOT NULL DEFAULT NULL,    created_by                          citext        NOT NULL DEFAULT NULL,    updated_by                          citext        NOT NULL DEFAULT NULL,    reporting_name                      citext        NOT NULL DEFAULT NULL,    label_name                          citext        NOT NULL DEFAULT NULL,    tz_name                             citext        NOT NULL DEFAULT NULL,    tz_name_pg                          citext        GENERATED ALWAYS AS (convert_ib_timezone_name(tz_name)) STORED, -- Convert IB names like "Western" to standard names, like "US/Pacific".    sonar_name_full                     citext        NOT NULL DEFAULT NULL,    sonar_count_sheet_form_name         citext        NOT NULL DEFAULT NULL,    sterilize_alert_level               citext        NOT NULL DEFAULT NULL,    sonar_scanner_stop_char             citext        NOT NULL DEFAULT NULL,    emr_location_name                   citext        NOT NULL DEFAULT NULL,    sonar_features                      jsonb         NOT NULL DEFAULT '{}'::jsonb,    interfaces                          jsonb         NOT NULL DEFAULT '{}'::jsonb,    needs_scheduling                    jsonb         NOT NULL DEFAULT '{}'::jsonb,    analytics_prefs                     jsonb         NOT NULL DEFAULT '{}'::jsonb);ALTER TABLE ascendco.facility	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX facility_hsys_id_ix_gin          ON ascendco.facility       USING GIN (hsys_id);CREATE INDEX facility_marked_for_deletion_ix_gin          ON ascendco.facility       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.facility    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_facility_after_delete            AFTER DELETE               ON ascendco.facility      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_facility_before_truncate            BEFORE TRUNCATE               ON ascendco.facility         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility TO user_change_structure;GRANT SELECT ON ascendco.facility TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.facility TO user_iceberg;GRANT SELECT ON ascendco.facility TO user_iceberg_remote;GRANT SELECT ON ascendco.facility TO user_saws;GRANT SELECT ON ascendco.facility TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:outlier_rule.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.outlier_rule CASCADE;CREATE TABLE IF NOT EXISTS ascendco.outlier_rule (	id uuid NOT NULL DEFAULT extensions.gen_random_uuid(),	schema_name text NOT NULL DEFAULT NULL,	table_name text NOT NULL DEFAULT NULL,	column_name text NOT NULL DEFAULT NULL,	threshold integer,	set_to integer);ALTER TABLE ascendco.outlier_rule	ADD CONSTRAINT outlier_rule_pkey    PRIMARY KEY (schema_name,table_name,column_name);ALTER TABLE ascendco.outlier_rule	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE UNIQUE INDEX outlier_rule_id_unique	ON outlier_rule (id);ALTER TABLE ascendco.outlier_rule	ADD CONSTRAINT outlier_rule_id_unique 	UNIQUE USING INDEX outlier_rule_id_unique;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_outlier_rule_after_delete	AFTER DELETE	ON ascendco.outlier_rule	REFERENCING OLD TABLE AS deleted_rows 	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_outlier_rule_before_truncate	BEFORE TRUNCATE	ON ascendco.outlier_rule	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:record_changes_log.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.record_changes_log CASCADE;CREATE TABLE ascendco.record_changes_log (	id uuid NOT NULL,	table_number int4 NOT NULL DEFAULT 0,	record_id uuid NOT NULL,	updated_dts timestamptz(6) NOT NULL DEFAULT '-infinity'::timestamp with time zone,	app_type extensions.citext COLLATE pg_catalog.default NOT NULL,	machine_name extensions.citext COLLATE pg_catalog.default NOT NULL,	updated_by extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.record_changes_log	ADD CONSTRAINT record_changes_log_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.record_changes_log	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX record_changes_log_record_id_ix_btree	ON ascendco.record_changes_log	USING btree (record_id pg_catalog.uuid_ops ASC NULLS LAST);-------------------------------------- Set default CLUSTER option------------------------------------ALTER TABLE ascendco.record_changes_log	CLUSTER ON record_changes_log_record_id_ix_btree;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_record_changes_log_after_delete	AFTER DELETE	ON ascendco.record_changes_log	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_record_changes_log_before_truncate	BEFORE TRUNCATE	ON ascendco.record_changes_log	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:domo_passthrough.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.domo_passthrough CASCADE;CREATE TABLE IF NOT EXISTS ascendco.domo_passthrough (	id uuid NOT NULL DEFAULT extensions.gen_random_uuid() PRIMARY KEY,  -- Random unique UUID becuase that's our convention.	source_id	   uuid         NOT NULL DEFAULT NULL, -- The main source of the data, like [SterilizerLoad]ID	hsys_id        uuid         NOT NULL DEFAULT '00000000000000000000000000000000',	facility_id    uuid         NOT NULL DEFAULT '00000000000000000000000000000000',	view_version   integer      NOT NULL DEFAULT NULL, -- Used to future-proof changes to the JSONB (data) format when expanded for Domo.	dataset_name   text         NOT NULL DEFAULT NULL, -- The Domo DataSet this record is meant for.	key_supplement citext       NOT NULL DEFAULT '', -- Wor when source_id alone is not enough to distinguish the row within the data set.	data           jsonb        NOT NULL DEFAULT '{}', -- The data itself, packed into JSON. Each row in PG is one row in the DataSet.	from_dts       timestamp    NOT NULL DEFAULT 'epoch'::TIMESTAMP,	to_dts         timestamp    NOT NULL DEFAULT 'epoch'::TIMESTAMP,	created_dts    timestamptz  NOT NULL DEFAULT 'NOW()',-- This extra constraint blocks the same basic row from appearing twice in the same DataSet.-- Like, [SterilizerLoad]ID in the same DataSet redundantly. Postgres' UPSERT syntax uses-- constraints by name, so setting things up this way makes things really simple.CONSTRAINT domo_passthrough_key_unique	UNIQUE (source_id, dataset_name, key_supplement));ALTER TABLE ascendco.domo_passthrough	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- The following speeds up finding the right rows for a Domo pull, at least a bit.CREATE INDEX passthrough_dataset_name_and_version_ix_btree     ON ascendco.domo_passthrough (dataset_name, view_version);-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_domo_passthrough_after_delete	AFTER DELETE	ON ascendco.domo_passthrough	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_domo_passthrough_before_truncate	BEFORE TRUNCATE ON ascendco.domo_passthrough	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:focus.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.focus CASCADE;CREATE TABLE IF NOT EXISTS ascendco.focus (	scase_id uuid NOT NULL DEFAULT NULL,	hsys_id uuid NOT NULL DEFAULT NULL,	facility_id uuid NOT NULL DEFAULT NULL,	sched_dts timestamp NOT NULL DEFAULT TIMESTAMP 'epoch',	facility_name citext NOT NULL DEFAULT NULL,	or_name citext NOT NULL DEFAULT NULL,	case_seq citext NOT NULL DEFAULT NULL,	desc_ citext NOT NULL DEFAULT NULL,	status citext NOT NULL DEFAULT NULL,	transport_from citext NOT NULL DEFAULT NULL,	surgeon_name citext NOT NULL DEFAULT NULL,	proc_name citext NOT NULL DEFAULT NULL,	when_ citext NOT NULL DEFAULT NULL,CONSTRAINT focus_id_pkey    PRIMARY KEY (scase_id));ALTER TABLE ascendco.focus	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX focus_hsys_id_ix_btree	ON ascendco.focus	USING btree (hsys_id pg_catalog.uuid_ops ASC NULLS LAST);	CREATE INDEX focus_facility_id_ix_btree	ON ascendco.focus	USING btree (facility_id pg_catalog.uuid_ops ASC NULLS LAST);-------------------------------------- Add triggers-------------------------------------- None at the moment.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:text_collection.sql-------------------------------------- Define text_collection table------------------------------------DROP TABLE IF EXISTS ascendco.text_collection CASCADE;CREATE TABLE IF NOT EXISTS ascendco.text_collection (	id                uuid         NOT NULL DEFAULT extensions.gen_random_uuid(),    collection_name   citext       NOT NULL DEFAULT '',    added_dts         timestamptz  NOT NULL DEFAULT NOW()::timestamptz,	facility_id       uuid         NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000'::uuid,    retain            boolean      NOT NULL DEFAULT false); -- Skip true rows when purging old data.ALTER TABLE ascendco.text_collection	ADD CONSTRAINT text_collection_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.text_collection	SET UNLOGGED;/*This is a good place for a temoprary table, as the cleanup happens automatically when you drop the connection.For now, I want to keep the ability to spot-check the strings while I'm developing. Maybe I'll switch totemporary tables later. For now, I'm going with UNLOGGED as at least it clears out some overhead on INSERTand DELETE, one of the benefits of temporary tables.https://www.depesz.com/2011/01/03/waiting-for-9-1-unlogged-tables/https://blog.nukomeet.com/faster-inserts-how-to-increase-postgresql-write-performance-24d76bd56f75List all unlogged tables within the current database.SELECT relname FROM pg_class WHERE relpersistence = 'u';*/-------------------------------------- Build indexes-------------------------------------- If a name/label is included, it should be unique.CREATE UNIQUE INDEX text_collection_name_idx	ON ascendco.text_collection (collection_name)	WHERE (collection_name <> '');-------------------------------------- Add triggers-------------------------------------- Nope, this is pretty much a one-and-done table, don't care about tracking deletes, etc.-------------------------------------- Add GRANTS-------------------------------------- Not normal, jamming these in for my quick tests.GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection TO user_reporting;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection TO user_iceberg;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection TO user_change_structure;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection TO user_sonar;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:activity.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.activity;CREATE TABLE IF NOT EXISTS ascendco.activity (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    facility_id                     uuid          NOT NULL DEFAULT NULL,    facility_activities_id          uuid          NOT NULL DEFAULT NULL,    web_user_id                     uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    start_dts                       timestamp     NOT NULL DEFAULT 'epoch',    done_dts                        timestamp     NOT NULL DEFAULT 'epoch',    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    duration_seconds                integer       NOT NULL DEFAULT 0,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    other_desc                      citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.activity	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX activity_facility_id_ix_btree          ON ascendco.activity       USING btree (facility_id);CREATE INDEX activity_facility_activities_id_ix_btree          ON ascendco.activity       USING btree (facility_activities_id);CREATE INDEX activity_web_user_id_ix_btree          ON ascendco.activity       USING btree (web_user_id);CREATE INDEX activity_last_updated_by_data_file_id_ix_gin          ON ascendco.activity       USING GIN (last_updated_by_data_file_id);CREATE INDEX activity_created_dts_ix_btree          ON ascendco.activity       USING btree (created_dts);CREATE INDEX activity_marked_for_deletion_ix_gin          ON ascendco.activity       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.activity    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_activity_after_delete            AFTER DELETE               ON ascendco.activity      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_activity_before_truncate            BEFORE TRUNCATE               ON ascendco.activity         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.activity TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.activity TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.activity TO user_change_structure;GRANT SELECT ON ascendco.activity TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.activity TO user_iceberg;GRANT SELECT ON ascendco.activity TO user_iceberg_remote;GRANT SELECT ON ascendco.activity TO user_saws;GRANT SELECT ON ascendco.activity TO user_leviathan;GRANT SELECT, INSERT, UPDATE ON ascendco.activity TO user_sonar;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:analytic_productivity.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.analytic_productivity CASCADE;CREATE TABLE IF NOT EXISTS ascendco.analytic_productivity (    id uuid NOT NULL DEFAULT NULL,    pg_con_id integer GENERATED BY        DEFAULT AS IDENTITY UNIQUE,        data_file_id uuid NOT NULL DEFAULT NULL,        marked_for_deletion boolean NOT NULL DEFAULT FALSE,        hsys_id uuid NOT NULL DEFAULT NULL,        facility_id uuid NOT NULL DEFAULT NULL,        facility_location_id uuid NOT NULL DEFAULT NULL,        specialty_id uuid NOT NULL DEFAULT NULL,        item_type_id uuid NOT NULL DEFAULT NULL,        user_name citext NOT NULL DEFAULT NULL,        inv_name citext NOT NULL DEFAULT NULL,        item_name citext NOT NULL DEFAULT NULL,        tray_or_pack citext NOT NULL DEFAULT NULL,        num_inst integer NOT NULL DEFAULT 0,        assembly_minutes integer NOT NULL DEFAULT 0,        pause_minutes integer NOT NULL DEFAULT 0,        points integer NOT NULL DEFAULT 0,        points_per_hour double precision NOT NULL DEFAULT '0',        assembly_hour double precision NOT NULL DEFAULT '0',        pause_hour double precision NOT NULL DEFAULT '0',        start_utc timestamptz NOT NULL DEFAULT '-infinity',        start_local timestamptz NOT NULL DEFAULT '-infinity',        end_utc timestamptz NOT NULL DEFAULT '-infinity',        end_local timestamptz NOT NULL DEFAULT '-infinity');ALTER TABLE ascendco.analytic_productivity    ADD CONSTRAINT analytic_productivity_id_pkey PRIMARY KEY (id);ALTER TABLE ascendco.analytic_productivity OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX analytic_productivity_facility_id_ix_fkey ON ascendco.analytic_productivity (facility_id);CREATE INDEX analytic_productivity_hsys_id_ix_fkey ON ascendco.analytic_productivity (hsys_id);CREATE INDEX analytic_productivity_item_type_id_ix_fkey ON ascendco.analytic_productivity (item_type_id);CREATE INDEX analytic_productivity_marked_for_deletion_ix_bgin ON ascendco.analytic_productivityUSING GIN (marked_for_deletion)WHERE    marked_for_deletion = TRUE;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_analytic_productivity_after_delete    AFTER DELETE    ON ascendco.analytic_productivity	REFERENCING OLD TABLE AS deleted_rows    FOR EACH STATEMENT    EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count ();CREATE TRIGGER trigger_analytic_productivity_before_truncate    BEFORE TRUNCATE    ON ascendco.analytic_productivity    FOR EACH STATEMENT    EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count ();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:analytic_scan.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.analytic_scan CASCADE;CREATE TABLE IF NOT EXISTS ascendco.analytic_scan (	id uuid NOT NULL DEFAULT NULL,	pg_con_id integer GENERATED BY DEFAULT AS IDENTITY UNIQUE,	data_file_id uuid NOT NULL DEFAULT NULL,	marked_for_deletion boolean NOT NULL DEFAULT false,	hsys_id uuid NOT NULL DEFAULT NULL,	facility_id uuid NOT NULL DEFAULT NULL,	facility_location_id uuid NOT NULL DEFAULT NULL,	specialty_id uuid NOT NULL DEFAULT NULL,	scanned_type citext NOT NULL DEFAULT NULL,	associated_to citext NOT NULL DEFAULT NULL,	user_name citext NOT NULL DEFAULT NULL,	inv_name citext NOT NULL DEFAULT 0,	num_inst integer NOT NULL DEFAULT 0,	tray_or_pack citext NOT NULL DEFAULT NULL,	item_name citext NOT NULL DEFAULT NULL,	location_description citext NOT NULL DEFAULT '',	scan_time_utc_dts timestamptz NOT NULL DEFAULT '-infinity',	scan_time_local_dts timestamptz NOT NULL DEFAULT '-infinity');ALTER TABLE ascendco.analytic_scan	ADD CONSTRAINT analytic_scan_id_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.analytic_scan  ALTER COLUMN associated_to	SET STATISTICS 200;ALTER TABLE ascendco.analytic_scan	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX analytic_scan_facility_id_ix_fkey	ON ascendco.analytic_scan	USING btree(facility_id pg_catalog.uuid_ops ASC NULLS LAST);-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_analytic_scan_after_delete	AFTER DELETE	ON ascendco.analytic_scan	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_analytic_scan_before_truncate	BEFORE TRUNCATE	ON ascendco.analytic_scan	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:analytic_sterilizer_load.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.analytic_sterilizer_load CASCADE;CREATE TABLE IF NOT EXISTS ascendco.analytic_sterilizer_load (	id uuid NOT NULL DEFAULT NULL,	marked_for_deletion boolean NOT NULL DEFAULT false,--	pg_con_id integer GENERATED BY DEFAULT AS IDENTITY UNIQUE,	data_file_id uuid NOT NULL DEFAULT NULL,	sterilize_method_id uuid NOT NULL DEFAULT NULL,	sterilize_params_id uuid NOT NULL DEFAULT NULL,	sterilizer_id uuid NOT NULL DEFAULT NULL,	facility_id uuid NOT NULL DEFAULT NULL,	web_user_id uuid NOT NULL DEFAULT NULL,	status_building_dts timestamptz NOT NULL DEFAULT '-infinity',	status_building_local_dts timestamptz NOT NULL DEFAULT '-infinity',	status_done_dts timestamptz NOT NULL DEFAULT '-infinity',	status_done_local_dts timestamptz NOT NULL DEFAULT '-infinity',	status citext NOT NULL DEFAULT NULL,	is_iuss boolean NOT NULL DEFAULT NULL,	instruments_count integer NOT NULL DEFAULT NULL,	packs_count integer NOT NULL DEFAULT NULL,	trays_count integer NOT NULL DEFAULT NULL);ALTER TABLE ascendco.analytic_sterilizer_load	ADD CONSTRAINT analytic_sterilizer_load_id_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.analytic_sterilizer_load	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX analytic_sterilizer_load_facility_id_ix_fkey	ON ascendco.analytic_sterilizer_load	USING btree(facility_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_load_instruments_count_ix_btree	ON ascendco.analytic_sterilizer_load	USING btree(instruments_count pg_catalog.int4_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_load_packs_count_ix_btree	ON ascendco.analytic_sterilizer_load	USING btree(packs_count pg_catalog.int4_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_load_sterilize_params_id_ix_fkey	ON ascendco.analytic_sterilizer_load	USING btree(sterilize_params_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_load_sterilizer_id_ix_fkey	ON ascendco.analytic_sterilizer_load	USING btree(sterilizer_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_load_trays_count_count_ix_btree	ON ascendco.analytic_sterilizer_load	USING btree(trays_count pg_catalog.int4_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_load_web_user_id_ix_fkey	ON ascendco.analytic_sterilizer_load	USING btree(web_user_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_marked_for_deletion_ix_bgin	ON ascendco.analytic_sterilizer_load	USING gin(marked_for_deletion extensions.bool_ops)	WHERE marked_for_deletion = true;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_analytic_sterilizer_load_after_delete	AFTER DELETE	ON ascendco.analytic_sterilizer_load	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_analytic_sterilizer_load_before_truncate	BEFORE TRUNCATE	ON ascendco.analytic_sterilizer_load	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:analytic_sterilizer_loadinv.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.analytic_sterilizer_loadinv CASCADE;CREATE TABLE IF NOT EXISTS ascendco.analytic_sterilizer_loadinv (	id uuid NOT NULL DEFAULT NULL,	data_file_id uuid NOT NULL DEFAULT NULL,	marked_for_deletion boolean NOT NULL DEFAULT false,	facility_id uuid NOT NULL DEFAULT NULL,	hsys_id uuid NOT NULL DEFAULT NULL,	inv_id uuid NOT NULL DEFAULT NULL,	item_id uuid NOT NULL DEFAULT NULL,	item_type_id uuid NOT NULL DEFAULT NULL,	speciality_id uuid NOT NULL DEFAULT NULL,	sterilize_method_id uuid NOT NULL DEFAULT NULL,	sterilize_params_id uuid NOT NULL DEFAULT NULL,	sterilizer_id uuid NOT NULL DEFAULT NULL,	sterilizerload_id uuid NOT NULL DEFAULT NULL,	web_user_id uuid NOT NULL DEFAULT NULL,	inv_name_provided citext NOT NULL DEFAULT NULL,	is_iuss boolean NOT NULL DEFAULT '0',	num_inst integer NOT NULL DEFAULT 0,	qty integer NOT NULL DEFAULT 0,	category citext NOT NULL DEFAULT NULL,	clinic_dept_name citext NOT NULL DEFAULT NULL,	processing_seconds integer NOT NULL DEFAULT 0,	done_dts timestamptz NOT NULL DEFAULT '-infinity',	done_local_dts timestamptz NOT NULL DEFAULT '-infinity',	status citext NOT NULL DEFAULT NULL);ALTER TABLE ascendco.analytic_sterilizer_loadinv	ADD CONSTRAINT analytic_sterilizer_loadinv_id_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.analytic_sterilizer_loadinv	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX analytic_sterilizer_loadinv_facility_id_ix_btree	ON ascendco.analytic_sterilizer_loadinv	USING btree(facility_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_loadinv_item_type_id_ix_btree	ON ascendco.analytic_sterilizer_loadinv	USING btree(item_type_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_loadinv_marked_for_deletion_ix_bgin	ON ascendco.analytic_sterilizer_loadinv	USING gin(marked_for_deletion extensions.bool_ops)	WHERE marked_for_deletion = true;CREATE INDEX analytic_sterilizer_loadinv_sterilize_params_id_ix_btree	ON ascendco.analytic_sterilizer_loadinv	USING btree(sterilize_params_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_loadinv_sterilizer_id_ix_btree	ON ascendco.analytic_sterilizer_loadinv	USING btree(sterilizer_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX analytic_sterilizer_loadinv_web_user_id_ix_btree	ON ascendco.analytic_sterilizer_loadinv	USING btree(web_user_id pg_catalog.uuid_ops ASC NULLS LAST);-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_analytic_sterilizer_loadinv_after_delete	AFTER DELETE	ON ascendco.analytic_sterilizer_loadinv	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_analytic_sterilizer_loadinv_before_truncate	BEFORE TRUNCATE	ON ascendco.analytic_sterilizer_loadinv	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:analytic_work.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.analytic_work;CREATE TABLE IF NOT EXISTS ascendco.analytic_work (--  Standard IDs    id                       uuid             NOT NULL DEFAULT NULL,    hsys_id                  uuid             NOT NULL DEFAULT NULL,    facility_id              uuid             NOT NULL DEFAULT NULL,    inv_id                   uuid             NOT NULL DEFAULT NULL,    user_id                  uuid             NOT NULL DEFAULT NULL,--  Source IDs, only one of which is populated at a time. Or not...we'll see how it works out.    activity_id              uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',    assembly_id              uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',    q_event_id               uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',    scan_id                  uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',    scase_id                 uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',    scase_inv_id             uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',    sterilizer_load_id       uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',    sterilizer_loadinv_id    uuid             NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',--  Data points    start_dts                timestamp        NOT NULL DEFAULT 'epoch',    end_dts                  timestamp        NOT NULL DEFAULT 'epoch',    start_local_dts          timestamp        NOT NULL DEFAULT 'epoch',    end_local_dts            timestamp        NOT NULL DEFAULT 'epoch',    duration                 decimal (12,2)   NOT NULL DEFAULT 0,    missing_inst             int4             NOT NULL DEFAULT 0,    num_inst                 int4             NOT NULL DEFAULT 0,    num_items                int4             NOT NULL DEFAULT 0,    points                   int4             NOT NULL DEFAULT 0,    num_packs                int4             NOT NULL DEFAULT 0,    num_trays                int4             NOT NULL DEFAULT 0,    marked_for_deletion      boolean          NOT NULL DEFAULT false,    activity                 citext           NOT NULL DEFAULT '',    description              citext           NOT NULL DEFAULT '',    date_time                citext           NOT NULL DEFAULT '',  -- Custm 03/29 09:23 AM format of *clock time*, calcualted in 4D. For Domo, I guess.    key_supplement           citext           NOT NULL DEFAULT ''   -- sterilizer_load may set a value here to make id (sterilizer_load.id) unique in this table.);ALTER TABLE ascendco.analytic_work  ADD CONSTRAINT analytic_work_pk    PRIMARY KEY (id, key_supplement);ALTER TABLE ascendco.analytic_work	OWNER TO user_change_structure;-------------------------------------- Partitions-------------------------------------- We're only expecting a few million rows a year, which suggests not needed.-- But....I wonder. The rows are pretty wide. Well, time will tell and,-- if necessary, we can retrofit partitions. A bit painful but possible. — DPA-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.For example, facility_id and hsys_id are both in this table.If you know the facility_id, the hsys_id is always going to be predictable.facility is 'functionally dependent' on hsys, or 100% correlated.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound.-- Add indexes, when and as needed. Keep an eye out for *effecdtive partial indexes*. The table-- is likely going to be big enough (row counts and widths) to make it important. — DPA-- Compact, partial index that inlcudes only the rows marked for deletion. Sweet!CREATE INDEX analytic_work_marked_for_deletion_ix_gin          ON ascendco.analytic_work       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.analytic_work    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_analytic_work_after_delete            AFTER DELETE               ON ascendco.analytic_work      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_analytic_work_before_truncate            BEFORE TRUNCATE               ON ascendco.analytic_work         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.analytic_work TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.analytic_work TO user_cleanup;GRANT SELECT ON ascendco.analytic_work TO user_reporting;GRANT SELECT ON ascendco.analytic_work TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.analytic_work TO user_iceberg;GRANT SELECT ON ascendco.analytic_work TO user_iceberg_remote;GRANT SELECT ON ascendco.analytic_work TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.analytic_work TO user_sonar;GRANT SELECT ON ascendco.analytic_work TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:assembly_prods.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.assembly_prods CASCADE;CREATE TABLE IF NOT EXISTS ascendco.assembly_prods (    id                       uuid          NOT NULL DEFAULT NULL,    data_file_id             uuid          NOT NULL DEFAULT NULL,    assembly_id              uuid          NOT NULL DEFAULT NULL,    item_prod_id             uuid          NOT NULL DEFAULT NULL,    created_dts              timestamp     NOT NULL DEFAULT 'epoch',    updated_dts              timestamp     NOT NULL DEFAULT 'epoch',    updated_date             date          NOT NULL DEFAULT NULL, -- Generated in insert function as updated_date::date    target                   integer       NOT NULL DEFAULT 0,    found_                   integer       NOT NULL DEFAULT 0,    repair                   integer       NOT NULL DEFAULT 0,    backup                   integer       NOT NULL DEFAULT 0,    actual                   integer       NOT NULL DEFAULT 0,    assembly_pos             integer       NOT NULL DEFAULT 0,    prev_actual_for_audit    integer       NOT NULL DEFAULT 0,    broken                   integer       NOT NULL DEFAULT 0,    marked_for_deletion      boolean       NOT NULL DEFAULT false,    created_by               citext        NOT NULL DEFAULT NULL,    updated_by               citext        NOT NULL DEFAULT NULL,    prod_alert_text_ack      citext        NOT NULL DEFAULT NULL,    audit_events             jsonb         NOT NULL DEFAULT '{}'::jsonb,    PRIMARY KEY (updated_date, id)) PARTITION BY RANGE (updated_date);ALTER TABLE ascendco.assembly_prods	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound.-- Each partition (table) will include its own B-tree on assembly_id.-- The INCLUDE clause adds the marked_for_deletion field to the index,-- enabling a search to succeed with an index-only scan...'cause we're-- always discarding those soft-deleted rows.CREATE INDEX assembly_prods_assembly_id_covering_idx	ON assembly_prods (assembly_id)	INCLUDE (marked_for_deletion);/* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX assembly_prods_assembly_id_ix_btree          ON ascendco.assembly_prods       USING btree (assembly_id);CREATE INDEX assembly_prods_marked_for_deletion_ix_gin          ON ascendco.assembly_prods       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- Build partitions------------------------------------/*Using a function in the insert handler function to generate the partition_key,an int4 extract of yyyy-mm. From there, using a value list partitioning setup.Could use range partitions, but, in this case, list is a bit easier to follow.And, woah. First off, check this thread:https://stackoverflow.com/questions/66847389/partitioning-on-a-uuid-in-postgres-12-or-13Erwin Brandstetter is s total legend. If he says it, it's about 99.999999% likely to be true. Not an exaggeration.Okay, but a lot of rules:* You can't partition on a generated column.* You can't partition on an expression, and still have a PRIMARY KEY.* It sure seems like you need the partition key in the primary key. The definition above is as minimal as I could make it.So, to get this all to work, I'm populating updated_date in types_plus.insert_assembly_prods_v1(insert_assembly_prods_v1[]);Bit of a drag as that makes bulk import and manual entry pretty much impossible.Note on ranges:Ranges in Postgres partitions are [from, to), where [] indicates *inclusive* and () includes *exclusive*.Eh? As in "is the start/end value included in the range?" The behavior of [from, to) would liie this in anormal query >= From and < To. Notice < To, not <= To. For setting up patitions on dates, this is super convenient,as you don't have to get the ragged month end dates right, just specify the first day of the month after.This makes it easy to create gapless, non-overlapping ranges.Note that Postgres checks the partitions, and alerts you to overlaps. It does not mention gaps in lists...maybe not ranges either. That's what DEFAULT is for, and I've got a task to check that defaults are empty. If you want to visually inspect your definitions, start from here:select relkind,relname,pg_get_expr(c.relpartbound, c.oid, true)  from pg_class cwhere relname like 'assembly_prods%'  and relkind = 'r' -- 'r' = "ordinary tables". In this case, that's the partitions. The parent table is relkind of 'p'. order by relname*/-- 2015CREATE TABLE assembly_prods_y2015 PARTITION OF assembly_prods    FOR VALUES FROM ('2015-01-01') TO ('2016-01-01'); -- Acts as "include dates from Jan 1, 2015 through December 31, 2015'.-- 2016CREATE TABLE assembly_prods_y2016_m010203 PARTITION OF assembly_prods    FOR VALUES FROM ('2016-01-01') TO ('2016-04-01');CREATE TABLE assembly_prods_y2016_m040506 PARTITION OF assembly_prods    FOR VALUES FROM ('2016-04-01') TO ('2016-07-01');CREATE TABLE assembly_prods_y2016_m070809 PARTITION OF assembly_prods    FOR VALUES FROM ('2016-07-01') TO ('2016-10-01');CREATE TABLE assembly_prods_y2016_m101112 PARTITION OF assembly_prods    FOR VALUES FROM ('2016-10-01') TO ('2017-01-01');-- 2017CREATE TABLE assembly_prods_y2017_m010203 PARTITION OF assembly_prods    FOR VALUES FROM ('2017-01-01') TO ('2017-04-01');CREATE TABLE assembly_prods_y2017_m040506 PARTITION OF assembly_prods    FOR VALUES FROM ('2017-04-01') TO ('2017-07-01');CREATE TABLE assembly_prods_y2017_m070809 PARTITION OF assembly_prods    FOR VALUES FROM ('2017-07-01') TO ('2017-10-01');CREATE TABLE assembly_prods_y2017_m101112 PARTITION OF assembly_prods    FOR VALUES FROM ('2017-10-01') TO ('2018-01-01');-- 2018CREATE TABLE assembly_prods_y2018_m010203 PARTITION OF assembly_prods    FOR VALUES FROM ('2018-01-01') TO ('2018-04-01');CREATE TABLE assembly_prods_y2018_m040506 PARTITION OF assembly_prods    FOR VALUES FROM ('2018-04-01') TO ('2018-07-01');CREATE TABLE assembly_prods_y2018_m070809 PARTITION OF assembly_prods    FOR VALUES FROM ('2018-07-01') TO ('2018-10-01');CREATE TABLE assembly_prods_y2018_m101112 PARTITION OF assembly_prods    FOR VALUES FROM ('2018-10-01') TO ('2019-01-01');-- 2019CREATE TABLE assembly_prods_y2019_m010203 PARTITION OF assembly_prods    FOR VALUES FROM ('2019-01-01') TO ('2019-04-01');CREATE TABLE assembly_prods_y2019_m040506 PARTITION OF assembly_prods    FOR VALUES FROM ('2019-04-01') TO ('2019-07-01');CREATE TABLE assembly_prods_y2019_m070809 PARTITION OF assembly_prods    FOR VALUES FROM ('2019-07-01') TO ('2019-10-01');CREATE TABLE assembly_prods_y2019_m101112 PARTITION OF assembly_prods    FOR VALUES FROM ('2019-10-01') TO ('2020-01-01');-- 2020CREATE TABLE assembly_prods_y2020_m010203 PARTITION OF assembly_prods    FOR VALUES FROM ('2020-01-01') TO ('2020-04-01');CREATE TABLE assembly_prods_y2020_m040506 PARTITION OF assembly_prods    FOR VALUES FROM ('2020-04-01') TO ('2020-07-01');CREATE TABLE assembly_prods_y2020_m070809 PARTITION OF assembly_prods    FOR VALUES FROM ('2020-07-01') TO ('2020-10-01');CREATE TABLE assembly_prods_y2020_m101112 PARTITION OF assembly_prods    FOR VALUES FROM ('2020-10-01') TO ('2021-01-01');-- 2021CREATE TABLE assembly_prods_y2021_m010203 PARTITION OF assembly_prods    FOR VALUES FROM ('2021-01-01') TO ('2021-04-01');CREATE TABLE assembly_prods_y2021_m040506 PARTITION OF assembly_prods    FOR VALUES FROM ('2021-04-01') TO ('2021-07-01');CREATE TABLE assembly_prods_y2021_m070809 PARTITION OF assembly_prods    FOR VALUES FROM ('2021-07-01') TO ('2021-10-01');CREATE TABLE assembly_prods_y2021_m101112 PARTITION OF assembly_prods    FOR VALUES FROM ('2021-10-01') TO ('2022-01-01');-- Default-- Need to add more partitions before the next year, or the'll spill into the default partition.-- See pgPartition_CheckDefaults for code we can use to automatically check for default-- partitions with unexpected records.CREATE TABLE ascendco.assembly_prods_default partition of assembly_prods DEFAULT;-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.assembly_prods    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_assembly_prods_after_delete            AFTER DELETE               ON ascendco.assembly_prods      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_assembly_prods_before_truncate            BEFORE TRUNCATE               ON ascendco.assembly_prods         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.assembly_prods TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.assembly_prods TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.assembly_prods TO user_change_structure;GRANT SELECT ON ascendco.assembly_prods TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.assembly_prods TO user_iceberg;GRANT SELECT ON ascendco.assembly_prods TO user_iceberg_remote;GRANT SELECT ON ascendco.assembly_prods TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.assembly_prods TO user_sonar;GRANT SELECT ON ascendco.assembly_prods TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:assembly.sql-------------------------------------- Define table-------------------------------------- What's with the crazy field order? Saving space. We rarely need this data, and there's a lot of it.-- I'll set up a view with a more natural column order.-- https://ascendco.atlassian.net/wiki/spaces/SON/pages/666501123/Arranging+Fields+to+Optimize+Disk+SpaceBEGIN;DROP TABLE IF EXISTS ascendco.assembly CASCADE;CREATE TABLE IF NOT EXISTS ascendco.assembly (	id uuid NOT NULL DEFAULT NULL,	data_file_id uuid NOT NULL DEFAULT NULL,	created_by_user_id uuid NOT NULL DEFAULT NULL,	done_by_user_id uuid NOT NULL DEFAULT NULL,	facility_location_id uuid NOT NULL DEFAULT NULL,	inv_id uuid NOT NULL DEFAULT NULL,	last_updated_by_data_file_id uuid NOT NULL DEFAULT NULL,	updated_by_user_id uuid NOT NULL DEFAULT NULL,	marked_for_deletion boolean NOT NULL DEFAULT false,	is_complete boolean NOT NULL DEFAULT '0',	is_quick_turn boolean NOT NULL DEFAULT '0',	con_id integer NOT NULL DEFAULT 0,	created_by citext NOT NULL DEFAULT NULL,	difficulty integer NOT NULL DEFAULT 0,	quantity integer NOT NULL DEFAULT 0,	sequence_no integer NOT NULL DEFAULT 0,	num_inst integer NOT NULL DEFAULT 0,	points integer NOT NULL DEFAULT 0,	done_dts timestamptz NOT NULL DEFAULT '-infinity',	created_dts timestamptz NOT NULL DEFAULT '-infinity',	updated_dts timestamptz NOT NULL DEFAULT '-infinity',	missing_list citext NOT NULL DEFAULT NULL,	priority citext NOT NULL DEFAULT NULL,	production_ref citext NOT NULL DEFAULT '',	status citext NOT NULL DEFAULT NULL,	updated_by citext NOT NULL DEFAULT NULL);ALTER TABLE ascendco.assembly	ADD CONSTRAINT assembly_id_pkey    PRIMARY KEY (id);    ALTER TABLE ascendco.assembly	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Not adding many indexes. The id field gets a unique B-tree index by default since it's set as PRIMARY KEY.-- We can define more indexes, when needed for queries.-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_assembly_after_delete 	AFTER DELETE 	ON ascendco.assembly	REFERENCING OLD TABLE AS deleted_rows 	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();	CREATE TRIGGER trigger_assembly_before_truncate	BEFORE TRUNCATE ON ascendco.assembly	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:clinic.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.clinic CASCADE;CREATE TABLE IF NOT EXISTS ascendco.clinic (    id                     uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    hsys_id                uuid          NOT NULL DEFAULT NULL,    created_dts            timestamp     NOT NULL DEFAULT 'epoch',    updated_dts            timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion    boolean       NOT NULL DEFAULT false,    receive_at_clinic      boolean       NOT NULL DEFAULT false,    name_                  citext        NOT NULL DEFAULT NULL,    created_by             citext        NOT NULL DEFAULT NULL,    updated_by             citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.clinic	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too. Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX clinic_hsys_id_ix_gin          ON ascendco.clinic       USING GIN (hsys_id);CREATE INDEX clinic_marked_for_deletion_ix_gin          ON ascendco.clinic       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.clinic    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_clinic_after_delete            AFTER DELETE               ON ascendco.clinic      REFERENCING OLD TABLE AS deleted_rows          FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_clinic_before_truncate            BEFORE TRUNCATE               ON ascendco.clinic         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.clinic TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.clinic TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.clinic TO user_change_structure;GRANT SELECT ON ascendco.clinic TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.clinic TO user_iceberg;GRANT SELECT ON ascendco.clinic TO user_iceberg_remote;GRANT SELECT ON ascendco.clinic TO user_saws;GRANT SELECT ON ascendco.clinic TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.clinic TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:domo_dataset.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.domo_dataset CASCADE;CREATE TABLE IF NOT EXISTS ascendco.domo_dataset (	id uuid NOT NULL DEFAULT NULL,	dataset_name citext NOT NULL DEFAULT NULL,	rows_count integer NOT NULL DEFAULT 0,	columns_count integer NOT NULL DEFAULT 0,	created_at_dts timestamptz NOT NULL DEFAULT '-infinity',	updated_at_dts timestamptz NOT NULL DEFAULT '-infinity',	late_threshold_minutes integer NOT NULL DEFAULT 0);ALTER TABLE ascendco.domo_dataset	ADD CONSTRAINT domo_dataset_id_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.domo_dataset	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Nope. Postgres won't even bother with an index for searches on such a tiny table.-- Note: You always need an index for a unique constraint. PG defines that automatically for the PRIMARY.-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_domo_dataset_after_delete	AFTER DELETE	ON ascendco.domo_dataset	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_domo_dataset_before_truncate	BEFORE TRUNCATE	ON ascendco.domo_dataset	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now------------------------------------GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.domo_dataset TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.domo_dataset TO user_cleanup;GRANT SELECT ON ascendco.domo_dataset TO user_reporting;GRANT SELECT ON ascendco.domo_dataset TO user_iceberg;GRANT SELECT ON ascendco.domo_dataset TO user_iceberg_remote;GRANT SELECT ON ascendco.domo_dataset TO user_saws;GRANT SELECT ON ascendco.domo_dataset TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.domo_dataset TO user_leviathan;GRANT SELECT ON ascendco.domo_dataset TO user_change_structure;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:error_code.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.error_code CASCADE;CREATE TABLE ascendco.error_code(    errcode     citext  NOT NULL DEFAULT NULL,    description citext  NOT NULL DEFAULT NULL);ALTER TABLE ascendco.error_code    ADD CONSTRAINT error_code_pkey    PRIMARY KEY (errcode);ALTER TABLE ascendco.error_code	OWNER TO user_change_structure;COMMENT ON TABLE ascendco.error_code IS	'Custom errcode definitions.';COMMIT;-------------------------------------- Build indexes-------------------------------------- Not so much, don't have enough data for indexes to be useful. (The planner will ignore them anyway.)-------------------------------------- Add triggers-------------------------------------- Don't care about tracking deletes, etc.-------------------------------------- Manual Permissions for now------------------------------------GRANT SELECT, INSERT, UPDATE, DELETE ON error_code TO rds_super;GRANT SELECT ON error_code TO user_reporting;GRANT SELECT ON error_code TO user_iceberg;GRANT SELECT ON error_code TO user_iceberg_remote;GRANT SELECT ON error_code TO user_saws;GRANT SELECT ON error_code TO user_sonar;GRANT SELECT ON error_code TO user_leviathan;GRANT SELECT ON error_code TO user_change_structure;-------------------------------------- Seed------------------------------------INSERT INTO ascendco.error_code (errcode, description)     VALUES     	 ('KC001','Patch has been run before.'),     	 ('KC100','Bad string selector parameter value.'),     	 ('KC101','Empty string parameter value.'),     	 ('KC200', 'Numeric parameter value is too low.'),     	 ('KC201', 'Numeric parameter value is too high.'),     	 ('KC202', 'Numeric parameter value is out of range.'),     	 ('KC300', 'Lookkup ID not found.'),     	 ('KC400', 'From is later than to.'),     	 ('KC401', 'Date range looks wrong.')   ON CONFLICT(errcode) DO UPDATE      SET description = EXCLUDED.description;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:facility_activities.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.facility_activities CASCADE;CREATE TABLE IF NOT EXISTS ascendco.facility_activities (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    facility_id                     uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion             boolean       NOT NULL DEFAULT false,    name_                           citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.facility_activities	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX facility_activities_facility_id_ix_btree          ON ascendco.facility_activities       USING btree (facility_id);CREATE INDEX facility_activities_last_updated_by_data_file_id_ix_gin          ON ascendco.facility_activities       USING GIN (last_updated_by_data_file_id);CREATE INDEX facility_activities_marked_for_deletion_ix_gin          ON ascendco.facility_activities       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.facility_activities    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_facility_activities_after_delete            AFTER DELETE               ON ascendco.facility_activities      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_facility_activities_before_truncate            BEFORE TRUNCATE               ON ascendco.facility_activities         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility_activities TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility_activities TO user_cleanup;GRANT SELECT ON ascendco.facility_activities TO user_reporting;GRANT SELECT ON ascendco.facility_activities TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.facility_activities TO user_iceberg;GRANT SELECT ON ascendco.facility_activities TO user_iceberg_remote;GRANT SELECT ON ascendco.facility_activities TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.facility_activities TO user_sonar;GRANT SELECT ON ascendco.facility_activities TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:facility_department.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.facility_department CASCADE;CREATE TABLE IF NOT EXISTS ascendco.facility_department (    id                       uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    facility_id              uuid          NOT NULL DEFAULT NULL,    their_id                 uuid          NOT NULL DEFAULT NULL,    created_dts              timestamp     NOT NULL DEFAULT 'epoch',    updated_dts              timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion      boolean       NOT NULL DEFAULT false,    is_available_in_sonar    boolean       NOT NULL DEFAULT false,    receive_at_dept          boolean       NOT NULL DEFAULT false,    is_from_emr              boolean       NOT NULL DEFAULT false,    name_                    citext        NOT NULL DEFAULT NULL,    created_by               citext        NOT NULL DEFAULT NULL,    updated_by               citext        NOT NULL DEFAULT NULL,    label_name               citext        NOT NULL DEFAULT NULL,    inv_audit                citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.facility_department	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too. Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX facility_department_facility_id_ix_gin          ON ascendco.facility_department       USING GIN (facility_id);CREATE INDEX facility_department_marked_for_deletion_ix_gin          ON ascendco.facility_department       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;CREATE INDEX facility_department_is_available_in_sonar_ix_gin          ON ascendco.facility_department       USING GIN (is_available_in_sonar);*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.facility_department    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_facility_department_after_delete            AFTER DELETE               ON ascendco.facility_department      REFERENCING OLD TABLE AS deleted_rows          FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_facility_department_before_truncate            BEFORE TRUNCATE               ON ascendco.facility_department         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility_department TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility_department TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility_department TO user_change_structure;GRANT SELECT ON ascendco.facility_department TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.facility_department TO user_iceberg;GRANT SELECT ON ascendco.facility_department TO user_iceberg_remote;GRANT SELECT ON ascendco.facility_department TO user_saws;GRANT SELECT ON ascendco.facility_department TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.facility_department TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:facility_location.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.facility_location CASCADE;CREATE TABLE IF NOT EXISTS ascendco.facility_location (	id uuid NOT NULL DEFAULT NULL,	marked_for_deletion boolean NOT NULL DEFAULT false,	facility_id uuid NOT NULL DEFAULT NULL,	type_ citext NOT NULL DEFAULT NULL,	name_ citext NOT NULL DEFAULT NULL);ALTER TABLE ascendco.facility_location	ADD CONSTRAINT facility_location_id_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.facility_location	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_facility_location_after_delete	AFTER DELETE	ON ascendco.facility_location	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_facility_location_before_truncate	BEFORE TRUNCATE	ON ascendco.facility_location	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:form_template.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.form_template CASCADE;CREATE TABLE IF NOT EXISTS ascendco.form_template (    id                     uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    created_dts            timestamp     NOT NULL DEFAULT 'epoch',    updated_dts            timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion    boolean       NOT NULL DEFAULT false,    name_                  citext        NOT NULL DEFAULT NULL,    comments_              citext        NOT NULL DEFAULT NULL,    updated_by             citext        NOT NULL DEFAULT NULL,    created_by             citext        NOT NULL DEFAULT NULL,    form_definition        jsonb         NOT NULL DEFAULT '{}'::jsonb);ALTER TABLE ascendco.form_template	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too. Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX form_template_marked_for_deletion_ix_gin          ON ascendco.form_template       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.form_template    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_form_template_after_delete            AFTER DELETE               ON ascendco.form_template      REFERENCING OLD TABLE AS deleted_rows          FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_form_template_before_truncate            BEFORE TRUNCATE               ON ascendco.form_template         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.form_template TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.form_template TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.form_template TO user_change_structure;GRANT SELECT ON ascendco.form_template TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.form_template TO user_iceberg;GRANT SELECT ON ascendco.form_template TO user_iceberg_remote;GRANT SELECT ON ascendco.form_template TO user_saws;GRANT SELECT ON ascendco.form_template TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.form_template TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:iceberg_table.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.iceberg_table CASCADE;CREATE TABLE ascendco.iceberg_table(    table_number int4 NOT NULL DEFAULT NULL,    table_name citext NOT NULL DEFAULT NULL);ALTER TABLE ascendco.iceberg_table    ADD CONSTRAINT iceberg_table_pkey    PRIMARY KEY (table_number);ALTER TABLE ascendco.iceberg_table	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Not so much, don't have enough data for indexes to be useful. (The planner will ignore them anyway.)-------------------------------------- Add triggers-------------------------------------- Not needed, this is basically a static lookup table.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:inv.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.inv;CREATE TABLE IF NOT EXISTS ascendco.inv (    id                             uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    item_id                        uuid          NOT NULL DEFAULT NULL,    item_arch_id                   uuid          NOT NULL DEFAULT NULL,    facility_location_id           uuid          NOT NULL DEFAULT NULL,    standard_faclity_id            uuid          NOT NULL DEFAULT NULL,    store_at_facility_id           uuid          NOT NULL DEFAULT NULL,    created_dts                    timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                    timestamp     NOT NULL DEFAULT 'epoch',    serial_no_as_of_dts            timestamp     NOT NULL DEFAULT 'epoch',    qty                            integer       NOT NULL DEFAULT 0,    flow                           integer       NOT NULL DEFAULT 0,    flow_long                      integer       NOT NULL DEFAULT 0,    par                            integer       NOT NULL DEFAULT 0,    last_seen_date                 date          NOT NULL DEFAULT NULL,    their_next_repair_date         date          NOT NULL DEFAULT NULL,    last_sterilized_date           date          NOT NULL DEFAULT NULL,    repair_last_repair_date        date          NOT NULL DEFAULT NULL,    marked_for_deletion            boolean       NOT NULL DEFAULT false,    is_found                       boolean       NOT NULL DEFAULT false,    is_go_live_perm_printed        boolean       NOT NULL DEFAULT false,    is_facility_loc_inherited      boolean       NOT NULL DEFAULT false,    is_contents_incomplete         boolean       NOT NULL DEFAULT false,    is_deactivated                 boolean       NOT NULL DEFAULT false,    needs_repair                   boolean       NOT NULL DEFAULT false,    is_searched_but_not_found      boolean       NOT NULL DEFAULT false,    is_wrong_loc                   boolean       NOT NULL DEFAULT false,    is_handwritten_label           boolean       NOT NULL DEFAULT false,    is_sleeping                    boolean       NOT NULL DEFAULT false,    category                       citext        NOT NULL DEFAULT NULL,    their_name                     citext        NOT NULL DEFAULT NULL,    their_id                       citext        NOT NULL DEFAULT NULL,    their_location                 citext        NOT NULL DEFAULT NULL,    created_by                     citext        NOT NULL DEFAULT NULL,    updated_by                     citext        NOT NULL DEFAULT NULL,    their_id_scrubbed              citext        NOT NULL DEFAULT NULL,    crossing_status                citext        NOT NULL DEFAULT NULL,    inv_no                         citext        NOT NULL DEFAULT NULL,    their_raw_name                 citext        NOT NULL DEFAULT NULL,    comments_                      citext        NOT NULL DEFAULT NULL,    their_bar_code                 citext        NOT NULL DEFAULT NULL,    loc_rack                       citext        NOT NULL DEFAULT NULL,    loc_row                        citext        NOT NULL DEFAULT NULL,    loc_bin                        citext        NOT NULL DEFAULT NULL,    loc_note                       citext        NOT NULL DEFAULT NULL,    serial_no                      citext        NOT NULL DEFAULT NULL,    data_cleanse_classification    citext        NOT NULL DEFAULT NULL,    repair_next_due                citext        NOT NULL DEFAULT NULL,    repair_last_repaired_by        citext        NOT NULL DEFAULT NULL,    msgs                           jsonb         NOT NULL DEFAULT '{}'::jsonb);ALTER TABLE ascendco.inv	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX inv_item_id_ix_btree          ON ascendco.inv       USING btree (item_id);CREATE INDEX inv_item_arch_id_ix_btree          ON ascendco.inv       USING btree (item_arch_id);CREATE INDEX inv_facility_location_id_ix_gin          ON ascendco.inv       USING GIN (facility_location_id);CREATE INDEX inv_serial_no_as_of_dts_ix_btree          ON ascendco.inv       USING btree (serial_no_as_of_dts);CREATE INDEX inv_their_next_repair_date_ix_btree          ON ascendco.inv       USING btree (their_next_repair_date);CREATE INDEX inv_last_sterilized_date_ix_btree          ON ascendco.inv       USING btree (last_sterilized_date);CREATE INDEX inv_marked_for_deletion_ix_gin          ON ascendco.inv       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;CREATE INDEX inv_is_found_ix_gin          ON ascendco.inv       USING GIN (is_found);CREATE INDEX inv_is_deactivated_ix_gin          ON ascendco.inv       USING GIN (is_deactivated);CREATE INDEX inv_is_searched_but_not_found_ix_gin          ON ascendco.inv       USING GIN (is_searched_but_not_found);CREATE INDEX inv_their_bar_code_ix_btree          ON ascendco.inv       USING btree (their_bar_code);CREATE INDEX inv_serial_no_ix_btree          ON ascendco.inv       USING btree (serial_no);CREATE INDEX inv_data_cleanse_classification_ix_btree          ON ascendco.inv       USING btree (data_cleanse_classification);*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.inv    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_inv_after_delete            AFTER DELETE               ON ascendco.inv      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_inv_before_truncate            BEFORE TRUNCATE               ON ascendco.inv         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.inv TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.inv TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.inv TO user_change_structure;GRANT SELECT ON ascendco.inv TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.inv TO user_iceberg;GRANT SELECT ON ascendco.inv TO user_iceberg_remote;GRANT SELECT ON ascendco.inv TO user_saws;GRANT SELECT ON ascendco.inv TO user_sonar;GRANT SELECT, INSERT, UPDATE ON ascendco.inv TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:item_arch.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.item_arch CASCADE;CREATE TABLE IF NOT EXISTS ascendco.item_arch (    id                     uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    facility_id            uuid          NOT NULL DEFAULT NULL,    clinic_id              uuid          NOT NULL DEFAULT NULL,    created_dts            timestamp     NOT NULL DEFAULT 'epoch',    updated_dts            timestamp     NOT NULL DEFAULT 'epoch',    previous_as_of         date          NOT NULL DEFAULT NULL,    marked_for_deletion    boolean       NOT NULL DEFAULT false,    is_current             boolean       NOT NULL DEFAULT false,    name_                  citext        NOT NULL DEFAULT NULL,    type_                  citext        NOT NULL DEFAULT NULL,    created_by             citext        NOT NULL DEFAULT NULL,    updated_by             citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.item_arch	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too. Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX item_arch_facility_id_ix_btree          ON ascendco.item_arch       USING btree (facility_id);CREATE INDEX item_arch_clinic_id_ix_btree          ON ascendco.item_arch       USING btree (clinic_id);CREATE INDEX item_arch_marked_for_deletion_ix_gin          ON ascendco.item_arch       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.item_arch    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_item_arch_after_delete            AFTER DELETE               ON ascendco.item_arch      REFERENCING OLD TABLE AS deleted_rows          FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_item_arch_before_truncate            BEFORE TRUNCATE               ON ascendco.item_arch         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.item_arch TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.item_arch TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.item_arch TO user_change_structure;GRANT SELECT ON ascendco.item_arch TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.item_arch TO user_iceberg;GRANT SELECT ON ascendco.item_arch TO user_iceberg_remote;GRANT SELECT ON ascendco.item_arch TO user_saws;GRANT SELECT ON ascendco.item_arch TO user_sonar;GRANT SELECT, INSERT, UPDATE ON ascendco.item_arch TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:item_type.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.item_type CASCADE;CREATE TABLE IF NOT EXISTS ascendco.item_type (	id uuid NOT NULL DEFAULT NULL,	marked_for_deletion boolean NOT NULL DEFAULT false,	name_ citext NOT NULL DEFAULT NULL);ALTER TABLE ascendco.item_type	ADD CONSTRAINT item_type_id_pkey    PRIMARY KEY (id);    ALTER TABLE ascendco.item_type	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Nope. Postgres won't even bother with an index for searches on such a tiny table.-- Note: You always need an index for a unique constraint. PG defines that automatically for the PRIMARY.-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_item_type_after_delete	AFTER DELETE	ON ascendco.item_type	REFERENCING OLD TABLE AS deleted_rows 	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_item_type_before_truncate	BEFORE TRUNCATE	ON ascendco.item_type	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:item.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.item;CREATE TABLE IF NOT EXISTS ascendco.item (    id                                uuid                 NOT NULL DEFAULT NULL PRIMARY KEY,    item_arch_id                      uuid                 NOT NULL DEFAULT NULL,    facility_specialty_id             uuid                 NOT NULL DEFAULT NULL,    item_uu_id_across_item_archs      uuid                 NOT NULL DEFAULT NULL,    inv_responsible_user_id           uuid                 NOT NULL DEFAULT NULL,    facility_department_id            uuid                 NOT NULL DEFAULT NULL,    specialty_id                      uuid                 NOT NULL DEFAULT NULL,    sup_id                            uuid                 NOT NULL DEFAULT NULL,    dr_people_id                      uuid                 NOT NULL DEFAULT NULL,    item_type_id                      uuid                 NOT NULL DEFAULT NULL,    item_master_link_id               uuid                 NOT NULL DEFAULT NULL,    facility_location_id              uuid                 NOT NULL DEFAULT NULL,    clinic_id                         uuid                 NOT NULL DEFAULT NULL,    hsys_tag_id                       uuid                 NOT NULL DEFAULT NULL,    name_copied_from_prod_id          uuid                 NOT NULL DEFAULT NULL,    created_dts                       timestamp            NOT NULL DEFAULT 'epoch',    updated_dts                       timestamp            NOT NULL DEFAULT 'epoch',    named_dts                         timestamp            NOT NULL DEFAULT 'epoch',    needs_sched_sync_as_of_dts        timestamp            NOT NULL DEFAULT 'epoch',    weight_lb                         double precision     NOT NULL DEFAULT NULL,    qty                               integer              NOT NULL DEFAULT 0,    flow                              integer              NOT NULL DEFAULT 0,    flow_long                         integer              NOT NULL DEFAULT 0,    max_processed_one_day             integer              NOT NULL DEFAULT 0,    par                               integer              NOT NULL DEFAULT 0,    assembly_difficulty               integer              NOT NULL DEFAULT 0,    num_inst                          integer              NOT NULL DEFAULT 0,    repair_every_x                    integer              NOT NULL DEFAULT 0,    their_qty                         integer              NOT NULL DEFAULT 0,    replace_every_x_cycles            integer              NOT NULL DEFAULT 0,    marked_for_deletion               boolean              NOT NULL DEFAULT false,    is_name_finalized                 boolean              NOT NULL DEFAULT false,    ignore_for_optimization           boolean              NOT NULL DEFAULT false,    name_needs_review                 boolean              NOT NULL DEFAULT false,    is_vendor_data                    boolean              NOT NULL DEFAULT false,    is_deactivated                    boolean              NOT NULL DEFAULT false,    is_name_copied_from_prod          boolean              NOT NULL DEFAULT false,    is_custom_sort                    boolean              NOT NULL DEFAULT false,    inv_has_implants                  boolean              NOT NULL DEFAULT false,    sync_to_other_software_systems    boolean              NOT NULL DEFAULT false,    has_implants                      boolean              NOT NULL DEFAULT false,    is_label_abbr                     boolean              NOT NULL DEFAULT false,    is_in_data_cleanse_scope          boolean              NOT NULL DEFAULT false,    hide_specialty_in_name            boolean              NOT NULL DEFAULT false,    hide_hsys_tag_in_name             boolean              NOT NULL DEFAULT false,    is_small_set                      boolean              NOT NULL DEFAULT false,    is_conflict_check                 boolean              NOT NULL DEFAULT false,    dont_print_count_sheet            boolean              NOT NULL DEFAULT false,    is_generic_pack                   boolean              NOT NULL DEFAULT false,    is_flexible_scope                 boolean              NOT NULL DEFAULT false,    is_robotic                        boolean              NOT NULL DEFAULT false,    is_imlink_locked                  boolean              NOT NULL DEFAULT false,    is_not_tracked_by_inv_no          boolean              NOT NULL DEFAULT false,    requires_leak_test                boolean              NOT NULL DEFAULT false,    is_assembly_critical              boolean              NOT NULL DEFAULT false,    their_name                        citext               NOT NULL DEFAULT NULL,    inv_status                        citext               NOT NULL DEFAULT NULL,    opt_status                        citext               NOT NULL DEFAULT NULL,    created_by                        citext               NOT NULL DEFAULT NULL,    updated_by                        citext               NOT NULL DEFAULT NULL,    old_names                         citext               NOT NULL DEFAULT NULL,    their_serial_no                   citext               NOT NULL DEFAULT NULL,    name_desc                         citext               NOT NULL DEFAULT NULL,    name_                             citext               NOT NULL DEFAULT NULL,    their_id                          citext               NOT NULL DEFAULT NULL,    decon_special_instructions        citext               NOT NULL DEFAULT NULL,    named_by                          citext               NOT NULL DEFAULT NULL,    needs_review_notes                citext               NOT NULL DEFAULT NULL,    vendor_tray_type                  citext               NOT NULL DEFAULT NULL,    sterilization_method              citext               NOT NULL DEFAULT NULL,    priority                          citext               NOT NULL DEFAULT NULL,    category                          citext               NOT NULL DEFAULT NULL,    packaging_type                    citext               NOT NULL DEFAULT NULL,    packaging_notes                   citext               NOT NULL DEFAULT NULL,    their_packaging_type              citext               NOT NULL DEFAULT NULL,    assembly_special_instructions     citext               NOT NULL DEFAULT NULL,    sterilize_special_instructions    citext               NOT NULL DEFAULT NULL,    label_name_abbr                   citext               NOT NULL DEFAULT NULL,    their_location                    citext               NOT NULL DEFAULT NULL,    count_sheet_status                citext               NOT NULL DEFAULT NULL,    requested_by                      citext               NOT NULL DEFAULT NULL,    rack_row_bin_note                 citext               NOT NULL DEFAULT NULL,    standardization_status            citext               NOT NULL DEFAULT NULL,    repair_every_x_type               citext               NOT NULL DEFAULT NULL,    their_base_barcode                citext               NOT NULL DEFAULT NULL,    their_key                         citext               NOT NULL DEFAULT NULL,    stuff                             jsonb                NOT NULL DEFAULT '{}'::jsonb);ALTER TABLE ascendco.item	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too. Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX item_item_arch_id_ix_btree          ON ascendco.item       USING btree (item_arch_id);CREATE INDEX item_facility_specialty_id_ix_gin          ON ascendco.item       USING GIN (facility_specialty_id);CREATE INDEX item_inv_responsible_user_id_ix_gin          ON ascendco.item       USING GIN (inv_responsible_user_id);CREATE INDEX item_facility_department_id_ix_gin          ON ascendco.item       USING GIN (facility_department_id);CREATE INDEX item_specialty_id_ix_gin          ON ascendco.item       USING GIN (specialty_id);CREATE INDEX item_item_type_id_ix_gin          ON ascendco.item       USING GIN (item_type_id);CREATE INDEX item_item_master_link_id_ix_btree          ON ascendco.item       USING btree (item_master_link_id);CREATE INDEX item_facility_location_id_ix_btree          ON ascendco.item       USING btree (facility_location_id);CREATE INDEX item_clinic_id_ix_btree          ON ascendco.item       USING btree (clinic_id);CREATE INDEX item_hsys_tag_id_ix_gin          ON ascendco.item       USING GIN (hsys_tag_id);CREATE INDEX item_name_copied_from_prod_id_ix_gin          ON ascendco.item       USING GIN (name_copied_from_prod_id);CREATE INDEX item_created_dts_ix_btree          ON ascendco.item       USING btree (created_dts);CREATE INDEX item_needs_sched_sync_as_of_dts_ix_btree          ON ascendco.item       USING btree (needs_sched_sync_as_of_dts);CREATE INDEX item_repair_every_x_ix_gin          ON ascendco.item       USING GIN (repair_every_x);CREATE INDEX item_replace_every_x_cycles_ix_gin          ON ascendco.item       USING GIN (replace_every_x_cycles);CREATE INDEX item_marked_for_deletion_ix_gin          ON ascendco.item       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;CREATE INDEX item_is_name_finalized_ix_gin          ON ascendco.item       USING GIN (is_name_finalized);CREATE INDEX item_is_deactivated_ix_gin          ON ascendco.item       USING GIN (is_deactivated);CREATE INDEX item_is_name_copied_from_prod_ix_gin          ON ascendco.item       USING GIN (is_name_copied_from_prod);CREATE INDEX item_has_implants_ix_gin          ON ascendco.item       USING GIN (has_implants);CREATE INDEX item_is_in_data_cleanse_scope_ix_gin          ON ascendco.item       USING GIN (is_in_data_cleanse_scope);CREATE INDEX item_their_name_ix_btree          ON ascendco.item       USING btree (their_name);CREATE INDEX item_name_ix_btree          ON ascendco.item       USING btree (name_);CREATE INDEX item_their_id_ix_btree          ON ascendco.item       USING btree (their_id);CREATE INDEX item_vendor_tray_type_ix_gin          ON ascendco.item       USING GIN (vendor_tray_type);CREATE INDEX item_category_ix_gin          ON ascendco.item       USING GIN (category);CREATE INDEX item_count_sheet_status_ix_gin          ON ascendco.item       USING GIN (count_sheet_status);*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.item    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_item_after_delete            AFTER DELETE               ON ascendco.item      REFERENCING OLD TABLE AS deleted_rows          FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_item_before_truncate            BEFORE TRUNCATE               ON ascendco.item         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.item TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.item TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.item TO user_change_structure;GRANT SELECT ON ascendco.item TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.item TO user_iceberg;GRANT SELECT ON ascendco.item TO user_iceberg_remote;GRANT SELECT ON ascendco.item TO user_saws;GRANT SELECT ON ascendco.item TO user_sonar;GRANT SELECT, INSERT, UPDATE ON ascendco.item TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:loaner_case.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.loaner_case CASCADE;CREATE TABLE IF NOT EXISTS ascendco.loaner_case (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    loaner_id                       uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    case_dts                        timestamp     NOT NULL DEFAULT 'epoch',    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion             boolean       NOT NULL DEFAULT false,    surgeon                         citext        NOT NULL DEFAULT NULL,    desc_                           citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.loaner_case	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX loaner_case_loaner_id_ix_btree          ON ascendco.loaner_case       USING btree (loaner_id);CREATE INDEX loaner_case_last_updated_by_data_file_id_ix_gin          ON ascendco.loaner_case       USING GIN (last_updated_by_data_file_id);CREATE INDEX loaner_case_marked_for_deletion_ix_gin          ON ascendco.loaner_case       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.loaner_case    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_loaner_case_after_delete            AFTER DELETE               ON ascendco.loaner_case      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_loaner_case_before_truncate            BEFORE TRUNCATE               ON ascendco.loaner_case         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner_case TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner_case TO user_cleanup;GRANT SELECT ON ascendco.loaner_case TO user_reporting;GRANT SELECT ON ascendco.loaner_case TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.loaner_case TO user_iceberg;GRANT SELECT ON ascendco.loaner_case TO user_iceberg_remote;GRANT SELECT ON ascendco.loaner_case TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.loaner_case TO user_sonar;GRANT SELECT ON ascendco.loaner_case TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:loaner_item.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.loaner_item CASCADE;CREATE TABLE IF NOT EXISTS ascendco.loaner_item (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    loaner_id                       uuid          NOT NULL DEFAULT NULL,    item_id                         uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    qty                             integer       NOT NULL DEFAULT 0,    pickup_qty                      integer       NOT NULL DEFAULT 0,    left_behind_qty                 integer       NOT NULL DEFAULT 0,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.loaner_item	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX loaner_item_loaner_id_ix_btree          ON ascendco.loaner_item       USING btree (loaner_id);CREATE INDEX loaner_item_item_id_ix_btree          ON ascendco.loaner_item       USING btree (item_id);CREATE INDEX loaner_item_last_updated_by_data_file_id_ix_gin          ON ascendco.loaner_item       USING GIN (last_updated_by_data_file_id);CREATE INDEX loaner_item_marked_for_deletion_ix_gin          ON ascendco.loaner_item       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.loaner_item    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_loaner_item_after_delete            AFTER DELETE               ON ascendco.loaner_item      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_loaner_item_before_truncate            BEFORE TRUNCATE               ON ascendco.loaner_item         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner_item TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner_item TO user_cleanup;GRANT SELECT ON ascendco.loaner_item TO user_reporting;GRANT SELECT ON ascendco.loaner_item TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.loaner_item TO user_iceberg;GRANT SELECT ON ascendco.loaner_item TO user_iceberg_remote;GRANT SELECT ON ascendco.loaner_item TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.loaner_item TO user_sonar;GRANT SELECT ON ascendco.loaner_item TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:loaner_iteminv.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.loaner_iteminv CASCADE;CREATE TABLE IF NOT EXISTS ascendco.loaner_iteminv (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    loaner_item_id                  uuid          NOT NULL DEFAULT NULL,    inv_id                          uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion             boolean       NOT NULL DEFAULT false,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.loaner_iteminv	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX loaner_iteminv_loaner_item_id_ix_btree          ON ascendco.loaner_iteminv       USING btree (loaner_item_id);CREATE INDEX loaner_iteminv_inv_id_ix_btree          ON ascendco.loaner_iteminv       USING btree (inv_id);CREATE INDEX loaner_iteminv_last_updated_by_data_file_id_ix_gin          ON ascendco.loaner_iteminv       USING GIN (last_updated_by_data_file_id);CREATE INDEX loaner_iteminv_marked_for_deletion_ix_gin          ON ascendco.loaner_iteminv       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.loaner_iteminv    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_loaner_iteminv_after_delete            AFTER DELETE               ON ascendco.loaner_iteminv      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_loaner_iteminv_before_truncate            BEFORE TRUNCATE               ON ascendco.loaner_iteminv         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner_iteminv TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner_iteminv TO user_cleanup;GRANT SELECT ON ascendco.loaner_iteminv TO user_reporting;GRANT SELECT ON ascendco.loaner_iteminv TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.loaner_iteminv TO user_iceberg;GRANT SELECT ON ascendco.loaner_iteminv TO user_iceberg_remote;GRANT SELECT ON ascendco.loaner_iteminv TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.loaner_iteminv TO user_sonar;GRANT SELECT ON ascendco.loaner_iteminv TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:loaner.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.loaner CASCADE;CREATE TABLE IF NOT EXISTS ascendco.loaner (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    sup_id                          uuid          NOT NULL DEFAULT NULL,    rep_id                          uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    facility_id                     uuid          NOT NULL DEFAULT NULL,    s_case_id                       uuid          NOT NULL DEFAULT NULL,    drop_off_dts                    timestamp     NOT NULL DEFAULT 'epoch',    pickup_dts                      timestamp     NOT NULL DEFAULT 'epoch',    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    datetime_local                  timestamp     NOT NULL DEFAULT 'epoch',    num_items                       integer       NOT NULL DEFAULT 0,    is_printed                      boolean       NOT NULL DEFAULT false,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    notes                           citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL,    status                          citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.loaner	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX loaner_sup_id_ix_gin          ON ascendco.loaner       USING GIN (sup_id);CREATE INDEX loaner_rep_id_ix_gin          ON ascendco.loaner       USING GIN (rep_id);CREATE INDEX loaner_last_updated_by_data_file_id_ix_gin          ON ascendco.loaner       USING GIN (last_updated_by_data_file_id);CREATE INDEX loaner_facility_id_ix_gin          ON ascendco.loaner       USING GIN (facility_id);CREATE INDEX loaner_marked_for_deletion_ix_gin          ON ascendco.loaner       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.loaner    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_loaner_after_delete            AFTER DELETE               ON ascendco.loaner      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_loaner_before_truncate            BEFORE TRUNCATE               ON ascendco.loaner         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.loaner TO user_cleanup;GRANT SELECT ON ascendco.loaner TO user_reporting;GRANT SELECT ON ascendco.loaner TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.loaner TO user_iceberg;GRANT SELECT ON ascendco.loaner TO user_iceberg_remote;GRANT SELECT ON ascendco.loaner TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.loaner TO user_sonar;GRANT SELECT ON ascendco.loaner TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:need.sql-------------------------------------- Define table------------------------------------/*Column order tweaked a bit with Column Tetris search fromhttps://www.2ndquadrant.com/en/blog/on-rocks-and-sand/Not neeed in this table, but I want to keep the structure parallel(ish) toneed_history, where keeping row sizes doesn *does* matter. -- DPA*/BEGIN;DROP TABLE IF EXISTS ascendco.need CASCADE;CREATE TABLE IF NOT EXISTS ascendco.need (	id uuid NOT NULL DEFAULT NULL,	hsys_id uuid NOT NULL DEFAULT NULL,	facility_id uuid NOT NULL DEFAULT NULL,	item_id uuid NOT NULL DEFAULT NULL,	percent_down double precision NOT NULL DEFAULT NULL,	created_dts timestamptz NOT NULL DEFAULT NOW(),	next_case_dts timestamp NOT NULL DEFAULT TIMESTAMP 'epoch',	flow integer NOT NULL DEFAULT NULL,	qty_circulation integer NOT NULL DEFAULT NULL,	qty_ready_everywhere integer NOT NULL DEFAULT NULL,	qty_ready_here integer NOT NULL DEFAULT NULL,	qty_sched_everywhere integer NOT NULL DEFAULT NULL,	qty_sched_here integer NOT NULL DEFAULT NULL,	qty_sterile_everywhere integer NOT NULL DEFAULT NULL,	qty_sterile_here integer NOT NULL DEFAULT NULL,	qty_suggest_sterilize integer NOT NULL DEFAULT NULL,	qty_total integer NOT NULL DEFAULT NULL,	ready_vs_need_defecit integer NOT NULL DEFAULT NULL,	sched_sort integer NOT NULL DEFAULT NULL,	sort_rank integer NOT NULL DEFAULT NULL,	suggest_transport boolean NOT NULL DEFAULT NULL,	next_needed citext NOT NULL DEFAULT NULL,	or_name citext NOT NULL DEFAULT NULL,	status citext NOT NULL DEFAULT NULL,	status_sort citext NOT NULL DEFAULT NULL,	when_ citext NOT NULL DEFAULT NULL,    qty_here integer NOT NULL DEFAULT 0);ALTER TABLE ascendco.need	ADD CONSTRAINT need_id_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.need	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX need_facility_id_ix_fkey	ON ascendco.need (facility_id); -- Not sure if this will be useful, it depends how big the table is.-- need_history dropped for now. We can revisit it, once Welsh has a think about what to include.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:outlier_change.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.outlier_change CASCADE;CREATE TABLE IF NOT EXISTS ascendco.outlier_change (	id uuid NOT NULL DEFAULT NULL,	outlier_rule_id uuid NOT NULL DEFAULT NULL,	value_was bigint NOT NULL DEFAULT NULL,	set_to bigint NOT NULL DEFAULT NULL,	change_count bigint NOT NULL DEFAULT 0,	last_changed_dts timestamptz NOT NULL DEFAULT NOW());ALTER TABLE ascendco.outlier_change	ADD CONSTRAINT outlier_change_pkey    PRIMARY KEY (id, outlier_rule_id);/*ALTER TABLE ascendco.outlier_change	ADD CONSTRAINT outlier_rule_fkey	FOREIGN KEY (outlier_rule_id)	REFERENCES ascendco.outlier_rule (id)	ON DELETE CASCADE	ON UPDATE NO ACTION;*/ALTER TABLE ascendco.outlier_change	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Nope. Postgres won't even bother with an index for searches on such a tiny table.-- Note: You always need an index for a unique constraint. PG defines that automatically for the PRIMARY.-- Note: If this table gets bigger, and we search on it, we may find we can use an index.-------------------------------------- Trigger function-------------------------------------- Function defined here as the function isn't used elsewhere:CREATE OR REPLACE FUNCTION ascendco.trigger_function_outlier_upsert()  RETURNS triggerAS $BODY$BEGIN    NEW.last_changed_dts := NOW();	NEW.change_count     := COALESCE(OLD.change_count,0) + 1;    RETURN NEW;    		 -- important!END;$BODY$	LANGUAGE plpgsql VOLATILE	COST 100;ALTER FUNCTION ascendco.trigger_function_outlier_upsert	OWNER TO user_bender;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_outlier_change_before_upsert	BEFORE INSERT OR UPDATE	ON ascendco.outlier_change	FOR EACH ROW	EXECUTE PROCEDURE ascendco.trigger_function_outlier_upsert();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:productivity_detail.sqlBEGIN;-- This destroys ALL partitions automatically, even without a CASCADE clause.DROP TABLE IF EXISTS ascendco.productivity_detail CASCADE;CREATE TABLE IF NOT EXISTS ascendco.productivity_detail (	id                         uuid      NOT NULL DEFAULT NULL, -- Based on source record ID, such as [Scan]ID or [Activity]ID.	data_file_id               uuid      NOT NULL DEFAULT NULL,	user_id                    uuid      NOT NULL DEFAULT NULL,	facility_id                uuid      NOT NULL DEFAULT NULL,	start_time_dts             timestamp NOT NULL DEFAULT '-infinity',	source_record_row_counter  int4      NOT NULL DEFAULT NULL, -- Based on source record ID, such as [Scan]ID or [Activity]ID.	source_table_number        integer   NOT NULL DEFAULT 0,  -- IceBerg table number for [Scan], [Assembly] and so on. Useful to count contributing rows, may be useful for subpartitions.	start_date                 date      NOT NULL DEFAULT NULL,	assembly_inst              integer   NOT NULL DEFAULT 0,	assembly_pack              integer   NOT NULL DEFAULT 0,	assembly_tray              integer   NOT NULL DEFAULT 0,	assembly_points            integer   NOT NULL DEFAULT 0,	assembly_seconds_trays     integer   NOT NULL DEFAULT 0,	assembly_seconds_overall   integer   NOT NULL DEFAULT 0,	pause_seconds              integer   NOT NULL DEFAULT 0,	duration_seconds           integer   NOT NULL DEFAULT 0,	placeholder_row            boolean   NOT NULL DEFAULT false,	description                citext    NOT NULL DEFAULT NULL,	year_and_month             text      NOT NULL DEFAULT NULL, -- YYYY-MM for partition. This is calculated by the insert function(s). Long story.	time_label                 citext    NOT NULL DEFAULT NULL,	duration                   citext    NOT NULL DEFAULT NULL,	pause_time                 citext    NOT NULL DEFAULT NULL,	activity                   citext    NOT NULL DEFAULT NULL,	user_label                 citext    NOT NULL DEFAULT NULL,-- Reminder: id values come from the various source tables in IB. The upsert writes over matches ON CONFLICT with this ID.-- Note: You *must* include the partition key in the primary key. It's a rule.CONSTRAINT productivity_detail_id_pkey    PRIMARY KEY (id,source_record_row_counter,year_and_month)) PARTITION BY LIST (year_and_month);CREATE INDEX productivity_detail_year_and_month_ix_btree	ON ascendco.productivity_detail(year_and_month);CREATE INDEX productivity_detail_facility_id_ix_btree	ON ascendco.productivity_detail(facility_id);ALTER TABLE ascendco.productivity_detail	OWNER TO user_change_structure;-- Build out 2020 completely.CREATE TABLE ascendco.productivity_detail_2020_01 partition of productivity_detail FOR VALUES IN ('2020-01');CREATE TABLE ascendco.productivity_detail_2020_02 partition of productivity_detail FOR VALUES IN ('2020-02');CREATE TABLE ascendco.productivity_detail_2020_03 partition of productivity_detail FOR VALUES IN ('2020-03');CREATE TABLE ascendco.productivity_detail_2020_04 partition of productivity_detail FOR VALUES IN ('2020-04');CREATE TABLE ascendco.productivity_detail_2020_05 partition of productivity_detail FOR VALUES IN ('2020-05');CREATE TABLE ascendco.productivity_detail_2020_06 partition of productivity_detail FOR VALUES IN ('2020-06');CREATE TABLE ascendco.productivity_detail_2020_07 partition of productivity_detail FOR VALUES IN ('2020-07');CREATE TABLE ascendco.productivity_detail_2020_08 partition of productivity_detail FOR VALUES IN ('2020-08');CREATE TABLE ascendco.productivity_detail_2020_09 partition of productivity_detail FOR VALUES IN ('2020-09');CREATE TABLE ascendco.productivity_detail_2020_10 partition of productivity_detail FOR VALUES IN ('2020-10');CREATE TABLE ascendco.productivity_detail_2020_11 partition of productivity_detail FOR VALUES IN ('2020-11');CREATE TABLE ascendco.productivity_detail_2020_12 partition of productivity_detail FOR VALUES IN ('2020-12');-- Build out 2021 completely.CREATE TABLE ascendco.productivity_detail_2021_01 partition of productivity_detail FOR VALUES IN ('2021-01');CREATE TABLE ascendco.productivity_detail_2021_02 partition of productivity_detail FOR VALUES IN ('2021-02');CREATE TABLE ascendco.productivity_detail_2021_03 partition of productivity_detail FOR VALUES IN ('2021-03');CREATE TABLE ascendco.productivity_detail_2021_04 partition of productivity_detail FOR VALUES IN ('2021-04');CREATE TABLE ascendco.productivity_detail_2021_05 partition of productivity_detail FOR VALUES IN ('2021-05');CREATE TABLE ascendco.productivity_detail_2021_06 partition of productivity_detail FOR VALUES IN ('2021-06');CREATE TABLE ascendco.productivity_detail_2021_07 partition of productivity_detail FOR VALUES IN ('2021-07');CREATE TABLE ascendco.productivity_detail_2021_08 partition of productivity_detail FOR VALUES IN ('2021-08');CREATE TABLE ascendco.productivity_detail_2021_09 partition of productivity_detail FOR VALUES IN ('2021-09');CREATE TABLE ascendco.productivity_detail_2021_10 partition of productivity_detail FOR VALUES IN ('2021-10');CREATE TABLE ascendco.productivity_detail_2021_11 partition of productivity_detail FOR VALUES IN ('2021-11');CREATE TABLE ascendco.productivity_detail_2021_12 partition of productivity_detail FOR VALUES IN ('2021-12');-- Need to add more partitions before the next year, or the'll spill into the default partition.-- See pgPartition_CheckDefaults for code we can use to automatically check for default-- partitions with unexpected records.CREATE TABLE ascendco.productivity_detail_default partition of productivity_detail DEFAULT;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:push_log.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.push_log CASCADE;CREATE TABLE IF NOT EXISTS ascendco.push_log (	id uuid NOT NULL DEFAULT extensions.gen_random_uuid(),	push_dts timestamptz NOT NULL DEFAULT now(),	pushed_by text DEFAULT get_current_user(),	data_file_id uuid NOT NULL DEFAULT NULL,	ib_table_number integer NOT NULL DEFAULT 0,	ib_table_name citext NOT NULL DEFAULT NULL,	records_count integer NOT NULL DEFAULT 0);ALTER TABLE ascendco.push_log	ADD CONSTRAINT push_log_id_pkey    PRIMARY KEY (id);ALTER TABLE ascendco.push_log	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX push_log_data_file_id_ix_btree	ON ascendco.push_log	USING btree (data_file_id pg_catalog.uuid_ops ASC NULLS LAST);CREATE INDEX push_log_ib_table_name_ix_btree	ON ascendco.push_log	USING btree (ib_table_name COLLATE pg_catalog.default extensions.citext_ops ASC NULLS LAST);CREATE INDEX push_log_push_dts_ix_btree	ON ascendco.push_log	USING btree (push_dts pg_catalog.timestamptz_ops ASC NULLS LAST);-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_push_log_after_delete	AFTER DELETE	ON ascendco.push_log	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_push_log_before_truncate	BEFORE TRUNCATE	ON ascendco.push_log	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:q_audit_step.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.q_audit_step CASCADE;CREATE TABLE IF NOT EXISTS ascendco.q_audit_step (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    hsys_id                         uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    sort                            integer       NOT NULL DEFAULT 0,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    qsub_type_id_audit              citext        NOT NULL DEFAULT NULL,    step                            citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL,    qsub_type_id_event              citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.q_audit_step	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äö√Ñ√Æ DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX q_audit_step_hsys_id_ix_gin          ON ascendco.q_audit_step       USING GIN (hsys_id);CREATE INDEX q_audit_step_qsub_type_id_audit_ix_gin          ON ascendco.q_audit_step       USING GIN (qsub_type_id_audit);CREATE INDEX q_audit_step_marked_for_deletion_ix_gin          ON ascendco.q_audit_step       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;CREATE INDEX q_audit_step_last_updated_by_data_file_id_ix_gin          ON ascendco.q_audit_step       USING GIN (last_updated_by_data_file_id);*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.q_audit_step    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_q_audit_step_after_delete            AFTER DELETE               ON ascendco.q_audit_step      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_q_audit_step_before_truncate            BEFORE TRUNCATE               ON ascendco.q_audit_step         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_audit_step TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_audit_step TO user_cleanup;GRANT SELECT ON ascendco.q_audit_step TO user_reporting;GRANT SELECT ON ascendco.q_audit_step TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.q_audit_step TO user_iceberg;GRANT SELECT ON ascendco.q_audit_step TO user_iceberg_remote;GRANT SELECT ON ascendco.q_audit_step TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.q_audit_step TO user_sonar;GRANT SELECT ON ascendco.q_audit_step TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:q_event_audit_step.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.q_event_audit_step CASCADE;CREATE TABLE IF NOT EXISTS ascendco.q_event_audit_step (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    qevent_id                       uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    qaudit_step_id                  uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    sort                            integer       NOT NULL DEFAULT 0,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    is_coached                      boolean       NOT NULL DEFAULT false,    step                            citext        NOT NULL DEFAULT NULL,    status                          citext        NOT NULL DEFAULT NULL,    notes                           citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL,    qsub_type_id_event              citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.q_event_audit_step	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX q_event_audit_step_qevent_id_ix_btree          ON ascendco.q_event_audit_step       USING btree (qevent_id);CREATE INDEX q_event_audit_step_last_updated_by_data_file_id_ix_gin          ON ascendco.q_event_audit_step       USING GIN (last_updated_by_data_file_id);CREATE INDEX q_event_audit_step_marked_for_deletion_ix_gin          ON ascendco.q_event_audit_step       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;CREATE INDEX q_event_audit_step_is_coached_ix_gin          ON ascendco.q_event_audit_step       USING GIN (is_coached);CREATE INDEX q_event_audit_step_status_ix_gin          ON ascendco.q_event_audit_step       USING GIN (status);*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.q_event_audit_step    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_q_event_audit_step_after_delete            AFTER DELETE               ON ascendco.q_event_audit_step      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_q_event_audit_step_before_truncate            BEFORE TRUNCATE               ON ascendco.q_event_audit_step         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_event_audit_step TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_event_audit_step TO user_cleanup;GRANT SELECT ON ascendco.q_event_audit_step TO user_reporting;GRANT SELECT ON ascendco.q_event_audit_step TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.q_event_audit_step TO user_iceberg;GRANT SELECT ON ascendco.q_event_audit_step TO user_iceberg_remote;GRANT SELECT ON ascendco.q_event_audit_step TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.q_event_audit_step TO user_sonar;GRANT SELECT ON ascendco.q_event_audit_step TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:q_event_person.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.q_event_person CASCADE;CREATE TABLE IF NOT EXISTS ascendco.q_event_person (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    web_user_id                     uuid          NOT NULL DEFAULT NULL,    qevent_id                       uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    is_accountable                  boolean       NOT NULL DEFAULT false,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    send_email                      boolean       NOT NULL DEFAULT false,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL,    role_                           citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.q_event_person	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX q_event_person_web_user_id_ix_gin          ON ascendco.q_event_person       USING GIN (web_user_id);CREATE INDEX q_event_person_qevent_id_ix_btree          ON ascendco.q_event_person       USING btree (qevent_id);CREATE INDEX q_event_person_last_updated_by_data_file_id_ix_gin          ON ascendco.q_event_person       USING GIN (last_updated_by_data_file_id);CREATE INDEX q_event_person_marked_for_deletion_ix_gin          ON ascendco.q_event_person       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.q_event_person    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_q_event_person_after_delete            AFTER DELETE               ON ascendco.q_event_person      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_q_event_person_before_truncate            BEFORE TRUNCATE               ON ascendco.q_event_person         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_event_person TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_event_person TO user_cleanup;GRANT SELECT ON ascendco.q_event_person TO user_reporting;GRANT SELECT ON ascendco.q_event_person TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.q_event_person TO user_iceberg;GRANT SELECT ON ascendco.q_event_person TO user_iceberg_remote;GRANT SELECT ON ascendco.q_event_person TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.q_event_person TO user_sonar;GRANT SELECT ON ascendco.q_event_person TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:q_event.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.q_event CASCADE;CREATE TABLE IF NOT EXISTS ascendco.q_event (    id                              uuid                 NOT NULL DEFAULT NULL PRIMARY KEY,    qtype_id                        uuid                 NOT NULL DEFAULT NULL,    qsub_type_id                    uuid                 NOT NULL DEFAULT NULL,    inv_id                          uuid                 NOT NULL DEFAULT NULL,    scan_id                         uuid                 NOT NULL DEFAULT NULL,    status_reported_by_user_id      uuid                 NOT NULL DEFAULT NULL,    status_investigating_user_id    uuid                 NOT NULL DEFAULT NULL,    status_done_user_id             uuid                 NOT NULL DEFAULT NULL,    or_surgeon_people_id            uuid                 NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid                 NOT NULL DEFAULT NULL,    facility_id                     uuid                 NOT NULL DEFAULT NULL,    status_when_user_id             uuid                 NOT NULL DEFAULT NULL,    assembly_id                     uuid                 NOT NULL DEFAULT NULL,    status_reported_dts             timestamp            NOT NULL DEFAULT 'epoch',    status_investigating_dts        timestamp            NOT NULL DEFAULT 'epoch',    status_done_dts                 timestamp            NOT NULL DEFAULT 'epoch',    created_dts                     timestamp            NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp            NOT NULL DEFAULT 'epoch',    status_when_dts                 timestamp            NOT NULL DEFAULT 'epoch',    datetime_local                  timestamp            NOT NULL DEFAULT 'epoch',    or_delay_minutes                double precision     NOT NULL DEFAULT NULL,    marked_for_deletion             boolean              NOT NULL DEFAULT false,    assembly_audit_prods            boolean              NOT NULL DEFAULT false,    is_process_problem              boolean              NOT NULL DEFAULT false,    is_data_problem                 boolean              NOT NULL DEFAULT false,    is_coached                      boolean              NOT NULL DEFAULT false,    desc_                           citext               NOT NULL DEFAULT NULL,    status                          citext               NOT NULL DEFAULT NULL,    status_reported_by_name         citext               NOT NULL DEFAULT NULL,    status_investigating_name       citext               NOT NULL DEFAULT NULL,    status_done_name                citext               NOT NULL DEFAULT NULL,    or_room                         citext               NOT NULL DEFAULT NULL,    or_delay_type                   citext               NOT NULL DEFAULT NULL,    created_by                      citext               NOT NULL DEFAULT NULL,    updated_by                      citext               NOT NULL DEFAULT NULL,    status_when_name                citext               NOT NULL DEFAULT NULL,    notes                           citext               NOT NULL DEFAULT NULL);ALTER TABLE ascendco.q_event	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX q_event_qtype_id_ix_gin          ON ascendco.q_event       USING GIN (qtype_id);CREATE INDEX q_event_qsub_type_id_ix_gin          ON ascendco.q_event       USING GIN (qsub_type_id);CREATE INDEX q_event_scan_id_ix_btree          ON ascendco.q_event       USING btree (scan_id);CREATE INDEX q_event_last_updated_by_data_file_id_ix_gin          ON ascendco.q_event       USING GIN (last_updated_by_data_file_id);CREATE INDEX q_event_facility_id_ix_gin          ON ascendco.q_event       USING GIN (facility_id);CREATE INDEX q_event_marked_for_deletion_ix_gin          ON ascendco.q_event       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;CREATE INDEX q_event_is_coached_ix_gin          ON ascendco.q_event       USING GIN (is_coached);CREATE INDEX q_event_status_ix_gin          ON ascendco.q_event       USING GIN (status);*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.q_event    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_q_event_after_delete            AFTER DELETE               ON ascendco.q_event      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_q_event_before_truncate            BEFORE TRUNCATE               ON ascendco.q_event         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_event TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_event TO user_cleanup;GRANT SELECT ON ascendco.q_event TO user_reporting;GRANT SELECT ON ascendco.q_event TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.q_event TO user_iceberg;GRANT SELECT ON ascendco.q_event TO user_iceberg_remote;GRANT SELECT ON ascendco.q_event TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.q_event TO user_sonar;GRANT SELECT ON ascendco.q_event TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:q_level.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.q_level CASCADE;CREATE TABLE IF NOT EXISTS ascendco.q_level (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    hsys_id                         uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    level_                          integer       NOT NULL DEFAULT 0,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    name_                           citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL,    ascendco_name                   citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.q_level	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX q_level_last_updated_by_data_file_id_ix_gin          ON ascendco.q_level       USING GIN (last_updated_by_data_file_id);CREATE INDEX q_level_marked_for_deletion_ix_gin          ON ascendco.q_level       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.q_level    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_q_level_after_delete            AFTER DELETE               ON ascendco.q_level      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_q_level_before_truncate            BEFORE TRUNCATE               ON ascendco.q_level         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_level TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_level TO user_cleanup;GRANT SELECT ON ascendco.q_level TO user_reporting;GRANT SELECT ON ascendco.q_level TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.q_level TO user_iceberg;GRANT SELECT ON ascendco.q_level TO user_iceberg_remote;GRANT SELECT ON ascendco.q_level TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.q_level TO user_sonar;GRANT SELECT ON ascendco.q_level TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:q_subtype.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.q_subtype CASCADE;CREATE TABLE IF NOT EXISTS ascendco.q_subtype (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    qtype_id                        uuid          NOT NULL DEFAULT NULL,    qlevel_id                       uuid          NOT NULL DEFAULT NULL,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    hsys_id                         uuid          NOT NULL DEFAULT NULL,    facility_id                     uuid          NOT NULL DEFAULT NULL,    facility_group_id               uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    is_available_in_decon           boolean       NOT NULL DEFAULT false,    marked_for_deletion             boolean       NOT NULL DEFAULT false,    is_active                       boolean       NOT NULL DEFAULT false,    is_for_inv                      boolean       NOT NULL DEFAULT false,    is_available_in_assembly        boolean       NOT NULL DEFAULT false,    name_                           citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL,    ascendco_name                   citext        NOT NULL DEFAULT NULL,    type_                           citext        NOT NULL DEFAULT NULL,    available_for                   citext        NOT NULL DEFAULT NULL,    item_type_ids                   jsonb         NOT NULL DEFAULT '{}'::jsonb);ALTER TABLE ascendco.q_subtype	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.For example, facility_id and hsys_id are both in this table.If you know the facility_id, the hsys_id is always going to be predictable.facility is 'functionally dependent' on hsys, or 100% correlated.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX q_subtype_last_updated_by_data_file_id_ix_gin          ON ascendco.q_subtype       USING GIN (last_updated_by_data_file_id);CREATE INDEX q_subtype_hsys_id_ix_gin          ON ascendco.q_subtype       USING GIN (hsys_id);CREATE INDEX q_subtype_marked_for_deletion_ix_gin          ON ascendco.q_subtype       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.q_subtype    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_q_subtype_after_delete            AFTER DELETE               ON ascendco.q_subtype      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_q_subtype_before_truncate            BEFORE TRUNCATE               ON ascendco.q_subtype         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_subtype TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_subtype TO user_cleanup;GRANT SELECT ON ascendco.q_subtype TO user_reporting;GRANT SELECT ON ascendco.q_subtype TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.q_subtype TO user_iceberg;GRANT SELECT ON ascendco.q_subtype TO user_iceberg_remote;GRANT SELECT ON ascendco.q_subtype TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.q_subtype TO user_sonar;GRANT SELECT ON ascendco.q_subtype TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:q_type.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.q_type CASCADE;CREATE TABLE IF NOT EXISTS ascendco.q_type (    id                              uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    last_updated_by_data_file_id    uuid          NOT NULL DEFAULT NULL,    hsys_id                         uuid          NOT NULL DEFAULT NULL,    created_dts                     timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                     timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion             boolean       NOT NULL DEFAULT false,    is_active                       boolean       NOT NULL DEFAULT false,    name_                           citext        NOT NULL DEFAULT NULL,    created_by                      citext        NOT NULL DEFAULT NULL,    updated_by                      citext        NOT NULL DEFAULT NULL,    ascendco_name                   citext        NOT NULL DEFAULT NULL,    type_                           citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.q_type	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX q_type_last_updated_by_data_file_id_ix_gin          ON ascendco.q_type       USING GIN (last_updated_by_data_file_id);CREATE INDEX q_type_marked_for_deletion_ix_gin          ON ascendco.q_type       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.q_type    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_q_type_after_delete            AFTER DELETE               ON ascendco.q_type      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_q_type_before_truncate            BEFORE TRUNCATE               ON ascendco.q_type         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_type TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.q_type TO user_cleanup;GRANT SELECT ON ascendco.q_type TO user_reporting;GRANT SELECT ON ascendco.q_type TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON ascendco.q_type TO user_iceberg;GRANT SELECT ON ascendco.q_type TO user_iceberg_remote;GRANT SELECT ON ascendco.q_type TO user_saws;GRANT SELECT, INSERT, UPDATE ON ascendco.q_type TO user_sonar;GRANT SELECT ON ascendco.q_type TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:rcl_check.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.rcl_check;CREATE TABLE ascendco.rcl_check (	id uuid NOT NULL,	production int8,	leviathan int8);ALTER TABLE ascendco.rcl_check 	ADD CONSTRAINT rcl_check_pkey 	PRIMARY KEY (id);ALTER TABLE ascendco.rcl_check	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Not at this time.-------------------------------------- Add triggers-------------------------------------- No triggers for this table.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:rcl_id.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.rcl_id;CREATE TABLE ascendco.rcl_id (	id uuid NOT NULL,	source extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.rcl_id 	ADD CONSTRAINT rcl_id_pkey 	PRIMARY KEY (id, source);ALTER TABLE ascendco.rcl_id	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Not at this time.-------------------------------------- Add triggers-------------------------------------- No triggers for this table.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:record_changes_log_detail.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.record_changes_log_detail;CREATE TABLE ascendco.record_changes_log_detail (	id uuid NOT NULL DEFAULT gen_random_uuid(),	record_changes_log_id uuid NOT NULL,	record_id uuid,	field_name extensions.citext COLLATE pg_catalog.default NOT NULL,	old_value extensions.citext COLLATE pg_catalog.default NOT NULL,	new_value extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.record_changes_log_detail	ADD CONSTRAINT record_changes_log_detail_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.record_changes_log_detail	ADD CONSTRAINT fk_record_changes_log_detail_to_record_changes_log	FOREIGN KEY (record_changes_log_id)		REFERENCES ascendco.record_changes_log (id)		ON DELETE CASCADE		ON UPDATE NO ACTION;ALTER TABLE ascendco.record_changes_log_detail	OWNER TO user_change_structure;COMMENT ON TABLE ascendco.record_changes_log_detail IS	'The record_id field is populated in the BEFORE INSERT trigger and validated for NOT NULL in the AFTER INSERT';COMMIT;-------------------------------------- Build indexes------------------------------------/*CREATE INDEX record_changes_log_detail_field_name_ix_btree	ON ascendco.record_changes_log_detail	USING btree (field_name COLLATE pg_catalog.default extensions.citext_ops ASC NULLS LAST);CREATE INDEX record_changes_log_detail_old_value_hash_ix_btree	ON ascendco.record_changes_log_detail	USING btree (hashtext(old_value::text) pg_catalog.int4_ops ASC NULLS LAST);CREATE INDEX record_changes_log_detail_old_value_ix_btree	ON ascendco.record_changes_log_detail	USING btree ((left(old_value::text, 1024)::citext) COLLATE pg_catalog.default extensions.citext_pattern_ops ASC NULLS LAST);CREATE INDEX record_changes_log_detail_old_value_ix_tgrm	ON ascendco.record_changes_log_detail	USING GIN (old_value COLLATE pg_catalog.default extensions.gin_trgm_ops);CREATE INDEX record_changes_log_detail_old_value_tsv_gin	ON ascendco.record_changes_log_detail	USING GIN (to_tsvector('simple_skip'::regconfig, old_value::text) pg_catalog.tsvector_ops);*/CREATE INDEX record_changes_log_id_ix_fkey	ON ascendco.record_changes_log_detail	USING btree (record_changes_log_id pg_catalog.uuid_ops ASC NULLS LAST);-------------------------------------- Define trigger functions------------------------------------CREATE OR REPLACE FUNCTION ascendco.trigger_function_record_changes_log_detail_before_insert()  RETURNS triggerAS $BODY$BEGIN	NEW.record_id := rcl_get_record_id (NEW.record_changes_log_id); RETURN NEW;END$BODY$  LANGUAGE plpgsql VOLATILE  COST 100;ALTER FUNCTION ascendco.trigger_function_record_changes_log_detail_before_insert	OWNER TO user_bender;CREATE OR REPLACE FUNCTION ascendco.trigger_function_record_changes_log_detail_after_insert()RETURNS trigger AS$BODY$BEGIN   IF NEW.record_id IS NULL THEN			RAISE EXCEPTION 'ERROR:  null value in column record_id violates not-null constraint';   END IF;	 RETURN NEW;END$BODY$  LANGUAGE plpgsql VOLATILE  COST 100;ALTER FUNCTION ascendco.trigger_function_record_changes_log_detail_after_insert	OWNER TO user_bender;CREATE OR REPLACE FUNCTION ascendco.trigger_function_record_changes_log_detail_stop_duplicates()  RETURNS triggerAS $BODY$BEGINIF EXISTS (SELECT 1 FROM record_changes_log_detail           WHERE (           	record_changes_log_id,           	hashtext(field_name || old_value || new_value))             =             (NEW.record_changes_log_id,           	hashtext(NEW.field_name || NEW.old_value || NEW.new_value))) THEN   RETURN NULL;END IF;RETURN NEW;END$BODY$	LANGUAGE plpgsql;COMMENT ON FUNCTION ascendco.trigger_function_record_changes_log_detail_stop_duplicates() IS 'Buggy parse in push code in IB, blocking duplicates in an old-fashioned way. Eventually, want to clear the duplicates and add a UNIQUE constraint.';ALTER FUNCTION ascendco.trigger_function_record_changes_log_detail_stop_duplicates	OWNER TO user_bender;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_record_changes_log_detail_after_insert	AFTER INSERT	ON ascendco.record_changes_log_detail	FOR EACH ROW	EXECUTE PROCEDURE ascendco.trigger_function_record_changes_log_detail_after_insert();CREATE TRIGGER trigger_record_changes_log_detail_before_insert	BEFORE INSERT	ON ascendco.record_changes_log_detail	FOR EACH ROW	EXECUTE PROCEDURE ascendco.trigger_function_record_changes_log_detail_before_insert();CREATE TRIGGER trigger_record_changes_log_detail_before_upsert	BEFORE INSERT OR UPDATE	ON record_changes_log_detail	FOR EACH ROW	EXECUTE PROCEDURE trigger_function_record_changes_log_detail_stop_duplicates();CREATE TRIGGER trigger_record_changes_log_detail_after_delete	AFTER DELETE	ON ascendco.record_changes_log_detail	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_record_changes_log_detail_before_truncate	BEFORE TRUNCATE	ON ascendco.record_changes_log_detail	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:rep.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.rep CASCADE;CREATE TABLE IF NOT EXISTS ascendco.rep (    id                     uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    user_id                uuid          NOT NULL DEFAULT NULL,    hsys_id                uuid          NOT NULL DEFAULT NULL,    sup_id                 uuid          NOT NULL DEFAULT NULL,    created_dts            timestamp     NOT NULL DEFAULT 'epoch',    updated_dts            timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion    boolean       NOT NULL DEFAULT false,    name_                  citext        NOT NULL DEFAULT NULL,    phone                  citext        NOT NULL DEFAULT NULL,    email                  citext        NOT NULL DEFAULT NULL,    created_by             citext        NOT NULL DEFAULT NULL,    updated_by             citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.rep	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX rep_hsys_id_ix_gin          ON ascendco.rep       USING GIN (hsys_id);CREATE INDEX rep_sup_id_ix_gin          ON ascendco.rep       USING GIN (sup_id);CREATE INDEX rep_marked_for_deletion_ix_gin          ON ascendco.rep       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.rep    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_rep_after_delete            AFTER DELETE               ON ascendco.rep      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_rep_before_truncate            BEFORE TRUNCATE               ON ascendco.rep         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.rep TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.rep TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.rep TO user_change_structure;GRANT SELECT ON ascendco.rep TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.rep TO user_iceberg;GRANT SELECT ON ascendco.rep TO user_iceberg_remote;GRANT SELECT ON ascendco.rep TO user_saws;GRANT SELECT ON ascendco.rep TO user_leviathan;GRANT SELECT, INSERT, UPDATE ON ascendco.rep TO user_sonar;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:row_compare.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.row_compare;CREATE TABLE ascendco.row_compare (  id uuid NOT NULL,  hash_1 int8,  hash_2 int8,  hashes_match bool,  table_name text COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.row_compare	ADD CONSTRAINT row_compare_pkey	PRIMARY KEY (id, table_name);ALTER TABLE ascendco.row_compare	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes------------------------------------CREATE INDEX row_compare_fail	ON ascendco.row_compare	USING btree ((hashes_match = false) pg_catalog.bool_ops ASC NULLS LAST);-------------------------------------- Trigger function-------------------------------------- Function defined here as the function isn't used elsewhere:CREATE OR REPLACE FUNCTION ascendco.trigger_function_row_compare_upsert()  RETURNS trigger AS$BODY$BEGIN	IF  NEW.hash_1 = NULL OR	    NEW.hash_2 = NULL THEN	    RETURN NEW; -- Don't do the comparison, hash_1 hasn't been populated yet.	ELSE-- Do the comparison. The point of this is to avoid constantly thrashing the expression index.	   NEW.hashes_match := NEW.hash_1 = NEW.hash_2;      RETURN NEW;     -- important!   END IF;END;$BODY$  LANGUAGE plpgsql VOLATILE  COST 100;ALTER FUNCTION ascendco.trigger_function_row_compare_upsert	OWNER TO user_bender;-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_row_compare_before_upsert	BEFORE INSERT OR UPDATE	ON ascendco.row_compare	FOR EACH ROW	EXECUTE PROCEDURE ascendco.trigger_function_row_compare_upsert();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:specialty.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.specialty;CREATE TABLE ascendco.specialty (	id uuid NOT NULL,	marked_for_deletion bool NOT NULL DEFAULT false,	data_file_id uuid NOT NULL,	name_ extensions.citext COLLATE pg_catalog.default NOT NULL,	name_short extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.specialty	ADD CONSTRAINT specialty_id_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.specialty	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_specialty_after_delete	AFTER DELETE	ON ascendco.specialty	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_specialty_before_truncate	BEFORE TRUNCATE	ON ascendco.specialty	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:stat_facility.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.stat_facility;CREATE TABLE ascendco.stat_facility  (	id uuid NOT NULL,	date_ date NOT NULL,	category extensions.citext COLLATE pg_catalog.default NOT NULL,	item_type extensions.citext COLLATE pg_catalog.default NOT NULL,	stat_type extensions.citext COLLATE pg_catalog.default NOT NULL,	is_most_recent bool NOT NULL,	in_data_cleanse_scope bool NOT NULL,	facility_id uuid NOT NULL,	hsys_id uuid NOT NULL,	items_inactive int4 NOT NULL,	items_count int4 NOT NULL,	items_qty int4 NOT NULL,	items_inventoried int4 NOT NULL,	items_to_inventory int4 NOT NULL,	items_named int4 NOT NULL,	items_to_name int4 NOT NULL,	inst_qty int4 NOT NULL,	items_has_loc int4 NOT NULL,	items_missing_locs int4 NOT NULL,	item_prods_count int4 NOT NULL,	item_prods_missing_part_nos_thier int4 NOT NULL,	item_prods_missing_vendors_thier int4 NOT NULL,	item_prods_dr_pref int4 NOT NULL,	item_prods_critical int4 NOT NULL,	item_prods_not_linked int4 NOT NULL,	item_prods_missing_part_nos int4 NOT NULL,	item_prods_missing_vendors int4 NOT NULL,	item_prods_cant_determine int4 NOT NULL,	item_prods_linked int4 NOT NULL,	sup_prods_count int4 NOT NULL,	sups_count int4 NOT NULL,	prods_count int4 NOT NULL,	prods_with_pic int4 NOT NULL,	prods_without_pic int4 NOT NULL,	item_prods_verified int4 NOT NULL,	item_prods_expert_linked int4 NOT NULL,	item_prods_dup_names_their int4 NOT NULL,	item_prods_dup_names int4 NOT NULL,	prods_named int4 NOT NULL,	part_nos_fixed int4 NOT NULL,	invs_inactive int4 NOT NULL,	invs_count int4 NOT NULL,	invs_found int4 NOT NULL,	emr_items_count int4 NOT NULL,	emr_items_linked int4 NOT NULL,	emr_items_matches_their_name int4 NOT NULL,	emr_items_matches_our_name int4 NOT NULL,	emr_items_no_match_their_name int4 NOT NULL,	emr_items_no_match_our_name int4 NOT NULL,	emr_items_dups int4 NOT NULL);ALTER TABLE ascendco.stat_facility 	ADD CONSTRAINT stat_facility_pkey 	PRIMARY KEY (id);ALTER TABLE ascendco.stat_facility 	OWNER TO user_change_structure;	COMMIT;-------------------------------------- Build indexes-------------------------------------- None defined yet.-------------------------------------- Add triggers-------------------------------------- No triggers for this table.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:sterilize_method.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.sterilize_method;CREATE TABLE ascendco.sterilize_method  (	id uuid NOT NULL,	marked_for_deletion bool NOT NULL DEFAULT false,	data_file_id uuid NOT NULL,	name_ extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.sterilize_method	ADD CONSTRAINT sterilize_method_id_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.sterilize_method	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_sterilize_method_after_delete	AFTER DELETE	ON ascendco.sterilize_method	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_sterilize_method_before_truncate	BEFORE TRUNCATE	ON ascendco.sterilize_method	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:sterilize_params.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.sterilize_params;CREATE TABLE ascendco.sterilize_params  (	id uuid NOT NULL,	marked_for_deletion bool NOT NULL DEFAULT false,	data_file_id uuid NOT NULL,	hsys_id uuid NOT NULL,	sterilize_method_id uuid NOT NULL,	name_ extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.sterilize_params 	ADD CONSTRAINT sterilize_params_id_pkey 	PRIMARY KEY (id);ALTER TABLE ascendco.sterilize_params 	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Nope. Postgres won't even bother with an index for searches on such a tiny table.-- Note: You always need an index for a unique constraint. PG defines that automatically for the PRIMARY.-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_sterilize_params_after_delete	AFTER DELETE	ON ascendco.sterilize_params	REFERENCING OLD TABLE AS deleted_rows 	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_sterilize_params_before_truncate	BEFORE TRUNCATE	ON ascendco.sterilize_params	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:sterilizer_load.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.sterilizer_load;CREATE TABLE ascendco.sterilizer_load  (	id uuid NOT NULL,	data_file_id uuid NOT NULL,	sterilize_method_id uuid NOT NULL,	sterilize_params_id uuid NOT NULL,	sterilizer_id uuid NOT NULL,	created_dts timestamptz(6) NOT NULL DEFAULT '-infinity'::timestamp with time zone,	status_building_dts timestamptz(6) NOT NULL DEFAULT '-infinity'::timestamp with time zone,	status_sterilizing_dts timestamptz(6) NOT NULL DEFAULT '-infinity'::timestamp with time zone,	status_cooling_dts timestamptz(6) NOT NULL DEFAULT '-infinity'::timestamp with time zone,	status_done_dts timestamptz(6) NOT NULL DEFAULT '-infinity'::timestamp with time zone,	utcoffset_seconds int4 NOT NULL DEFAULT 0,	marked_for_deletion bool NOT NULL DEFAULT false,	load_no extensions.citext COLLATE pg_catalog.default NOT NULL,	notes extensions.citext COLLATE pg_catalog.default NOT NULL,	failed_notes extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.sterilizer_load	ADD CONSTRAINT sterilizer_load_id_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.sterilizer_load	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_sterilizer_load_after_delete	AFTER DELETE	ON ascendco.sterilizer_load	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_sterilizer_load_before_truncate	BEFORE TRUNCATE	ON ascendco.sterilizer_load	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:sterilizer_log.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.sterilizer_log;CREATE TABLE ascendco.sterilizer_log  (	id uuid NOT NULL,	log_type extensions.citext COLLATE pg_catalog.default NOT NULL,	summary_json jsonb NOT NULL DEFAULT '{}'::jsonb,	log_xml xml NOT NULL,	data_file_id uuid DEFAULT '00000000-0000-0000-0000-000000000000'::uuid);ALTER TABLE ascendco.sterilizer_log 	ADD CONSTRAINT sterilizer_log_id_pkey 	PRIMARY KEY (id);ALTER TABLE ascendco.sterilizer_log 	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None yet.-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_sterilizer_log_after_delete	AFTER DELETE	ON ascendco.sterilizer_log	REFERENCING OLD TABLE AS deleted_rows 	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_sterilizer_log_before_truncate	BEFORE TRUNCATE	ON ascendco.sterilizer_log	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:sterilizer.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.sterilizer;CREATE TABLE ascendco.sterilizer  (	id uuid NOT NULL,	marked_for_deletion bool NOT NULL DEFAULT false,	data_file_id uuid NOT NULL,	facility_id uuid NOT NULL,	sterilize_method_id uuid NOT NULL,	name_ extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.sterilizer 	ADD CONSTRAINT sterilizer_id_pkey 	PRIMARY KEY (id);ALTER TABLE ascendco.sterilizer 	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- Nope. Postgres won't even bother with an index for searches on such a tiny table.-- Note: You always need an index for a unique constraint. PG defines that automatically for the PRIMARY.-------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_sterilizer_after_delete	AFTER DELETE	ON ascendco.sterilizer	REFERENCING OLD TABLE AS deleted_rows 	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_sterilizer_before_truncate	BEFORE TRUNCATE	ON ascendco.sterilizer	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:sup_parent.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.sup_parent CASCADE;CREATE TABLE IF NOT EXISTS ascendco.sup_parent (    id                     uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    created_dts            timestamp     NOT NULL DEFAULT 'epoch',    updated_dts            timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion    boolean       NOT NULL DEFAULT false,    name_                  citext        NOT NULL DEFAULT NULL,    created_by             citext        NOT NULL DEFAULT NULL,    updated_by             citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.sup_parent	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too. Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX sup_parent_marked_for_deletion_ix_gin          ON ascendco.sup_parent       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.sup_parent    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_sup_parent_after_delete            AFTER DELETE               ON ascendco.sup_parent      REFERENCING OLD TABLE AS deleted_rows          FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_sup_parent_before_truncate            BEFORE TRUNCATE               ON ascendco.sup_parent         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup_parent TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup_parent TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup_parent TO user_change_structure;GRANT SELECT ON ascendco.sup_parent TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.sup_parent TO user_iceberg;GRANT SELECT ON ascendco.sup_parent TO user_iceberg_remote;GRANT SELECT ON ascendco.sup_parent TO user_saws;GRANT SELECT ON ascendco.sup_parent TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup_parent TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:sup.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.sup CASCADE;CREATE TABLE IF NOT EXISTS ascendco.sup (    id                          uuid          NOT NULL DEFAULT NULL PRIMARY KEY,    custom_facility_id          uuid          NOT NULL DEFAULT NULL,    sup_parent_id               uuid          NOT NULL DEFAULT NULL,    created_dts                 timestamp     NOT NULL DEFAULT 'epoch',    updated_dts                 timestamp     NOT NULL DEFAULT 'epoch',    marked_for_deletion         boolean       NOT NULL DEFAULT false,    is_custom_by_facility       boolean       NOT NULL DEFAULT false,    is_available_for_loaners    boolean       NOT NULL DEFAULT false,    name_                       citext        NOT NULL DEFAULT NULL,    created_by                  citext        NOT NULL DEFAULT NULL,    updated_by                  citext        NOT NULL DEFAULT NULL,    short_name                  citext        NOT NULL DEFAULT NULL);ALTER TABLE ascendco.sup	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too. Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äî DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound./* Indexing trade-offs are different in 4D and Postgres.It pays to be a bit conservative about adding indexes in Postgres, wait and see what you need.CREATE INDEX sup_custom_facility_id_ix_gin          ON ascendco.sup       USING GIN (custom_facility_id);CREATE INDEX sup_marked_for_deletion_ix_gin          ON ascendco.sup       USING GIN (marked_for_deletion extensions.bool_ops)       WHERE marked_for_deletion = true;CREATE INDEX sup_is_custom_by_facility_ix_gin          ON ascendco.sup       USING GIN (is_custom_by_facility);CREATE INDEX sup_is_available_for_loaners_ix_gin          ON ascendco.sup       USING GIN (is_available_for_loaners);*/-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE ascendco.sup    CLUSTER ON ***index name to cluster by here.***;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_sup_after_delete            AFTER DELETE               ON ascendco.sup      REFERENCING OLD TABLE AS deleted_rows          FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_sup_before_truncate            BEFORE TRUNCATE               ON ascendco.sup         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup TO user_change_structure;GRANT SELECT ON ascendco.sup TO user_reporting;-- Adjustable user permissions:GRANT SELECT ON ascendco.sup TO user_iceberg;GRANT SELECT ON ascendco.sup TO user_iceberg_remote;GRANT SELECT ON ascendco.sup TO user_saws;GRANT SELECT ON ascendco.sup TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON ascendco.sup TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:text_collection_item.sql-------------------------------------- Define text_collection_item table------------------------------------DROP TABLE IF EXISTS ascendco.text_collection_item;CREATE TABLE IF NOT EXISTS ascendco.text_collection_item (	collection_id    uuid        NOT NULL DEFAULT NULL,  -- Shared by all strings in the same collection.	text             citext      NOT NULL DEFAULT '',	source_id        citext      NOT NULL DEFAULT ''); -- Optional. May be a UUID, doesn't have to be.ALTER TABLE ascendco.text_collection_item	SET UNLOGGED;ALTER TABLE ascendco.text_collection_item	ADD CONSTRAINT text_collection_item_pkey    PRIMARY KEY (collection_id,text);ALTER TABLE ascendco.text_collection_item	ADD CONSTRAINT text_collection_item_parent_fkey	FOREIGN KEY (collection_id)	REFERENCES ascendco.text_collection (id)	ON DELETE CASCADE	ON UPDATE NO ACTION;ALTER TABLE ascendco.text_collection_item	OWNER TO user_change_structure;/*This is a good place for a temoprary table, as the cleanup happens automatically when you drop the connection.For now, I want to keep the ability to spot-check the strings while I'm developing. Maybe I'll switch totemporary tables later. For now, I'm going with UNLOGGED as at least it clears out some overhead on INSERTand DELETE, one of the benefits of temporary tables.https://www.depesz.com/2011/01/03/waiting-for-9-1-unlogged-tables/https://blog.nukomeet.com/faster-inserts-how-to-increase-postgresql-write-performance-24d76bd56f75List all unlogged tables within the current database.SELECT relname FROM pg_class WHERE relpersistence = 'u';*/-------------------------------------- Build indexes-------------------------------------- Magic GiST index for K-NN search.-- Note: As of PG 13, you can now set the GiST "signature length" in gist_trgm_ops. The deafult is 12 bytes.-- https://www.postgresql.org/docs/13/pgtrgm.html#id-1.11.7.40.5-- https://postgrespro.co.il/blog/gist-index-and-siglen/CREATE INDEX text_collection_item_text_ix_tgrm_gist	ON ascendco.text_collection_item	USING gist(text COLLATE pg_catalog.default extensions.gist_trgm_ops(siglen=64));-------------------------------------- Add triggers-------------------------------------- Nope, this is pretty much a one-and-done table, don't care about tracking deletes, etc.-------------------------------------- Add GRANTS-------------------------------------- Not normal, jamming these in for my quick tests.GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection_item TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection_item TO user_reporting;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection_item TO user_iceberg;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection_item TO user_change_structure;GRANT SELECT, INSERT, UPDATE, DELETE ON text_collection_item TO user_sonar;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:web_user.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS ascendco.web_user;CREATE TABLE ascendco.web_user  (	id uuid NOT NULL,	marked_for_deletion bool NOT NULL DEFAULT false,    is_sonar_ascendco_support bool NOT NULL DEFAULT false,    data_file_id uuid NOT NULL,	username extensions.citext COLLATE pg_catalog.default NOT NULL,	role_ extensions.citext COLLATE pg_catalog.default NOT NULL,	name_first extensions.citext COLLATE pg_catalog.default NOT NULL,	name_last extensions.citext COLLATE pg_catalog.default NOT NULL,	hsys_id uuid NOT NULL,	name_full extensions.citext COLLATE pg_catalog.default NOT NULL);ALTER TABLE ascendco.web_user	ADD CONSTRAINT web_user_id_pkey	PRIMARY KEY (id);ALTER TABLE ascendco.web_user	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------------------------------------------- Add triggers------------------------------------CREATE TRIGGER trigger_web_user_after_delete	AFTER DELETE	ON ascendco.web_user	REFERENCING OLD TABLE AS deleted_rows	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();CREATE TRIGGER trigger_web_user_before_truncate	BEFORE TRUNCATE	ON ascendco.web_user	FOR EACH STATEMENT	EXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:patch_log.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.patch_log;CREATE TABLE IF NOT EXISTS dba.patch_log (	id             uuid         NOT NULL DEFAULT extensions.gen_random_uuid(),	patch_dts      timestamptz  NOT NULL DEFAULT now(), -- The timestamp of the transaction you're in.    server_address citext       NOT NULL DEFAULT inet_server_addr()::citext,    database_name  citext       NOT NULL DEFAULT current_database()::citext,    pg_version     citext       NOT NULL DEFAULT version()::citext,    user_name      user_name    NOT NULL DEFAULT current_user::user_name, -- user_name is a custom domain.    patch_name     citext_not_empty      NOT NULL DEFAULT NULL,    description    citext_not_empty      NOT NULL DEFAULT NULL,    patch_hash     text_not_empty        NOT NULL DEFAULT NULL);ALTER TABLE dba.patch_log	ADD CONSTRAINT patch_log_id_pkey    PRIMARY KEY (id);ALTER TABLE dba.patch_log	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None needed at the moment.-------------------------------------- Add triggers-------------------------------------- None needed at the moment, but this might change to auto-populate and dirty custom_function.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:test_case.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.test_case CASCADE;CREATE TABLE IF NOT EXISTS dba.test_case (    id                       uuid NOT NULL DEFAULT extensions.gen_random_uuid(),    added_dts                timestamptz                    NOT NULL DEFAULT now(), -- The timestamp of the transaction you're in.    object_class             citext_not_empty               NOT NULL DEFAULT NULL,    object_schema            citext_not_empty               NOT NULL DEFAULT NULL,    object_name              citext_not_empty               NOT NULL DEFAULT NULL,    function_signature       citext                         NOT NULL DEFAULT '',    test_name                citext_not_empty               NOT NULL DEFAULT NULL,    test_code                text_not_empty                 NOT NULL DEFAULT NULL,    setup_code               citext                         NOT NULL DEFAULT '',    teardown_code            citext                         NOT NULL DEFAULT '',    expected_response        citext                         NOT NULL DEFAULT '',    expected_error           citext                         NOT NULL DEFAULT '',    expected_outcome         test_outcome                   NOT NULL DEFAULT NULL,   -- Custom domain allowing 'pass', 'warning', 'fail', case-blind.    response_type            citext_not_empty               NOT NULL DEFAULT '',     -- text, numeric, record, JSON, like that.    comparison_options       jsonb                          NOT NULL DEFAULT '{"case":"blind"}'::jsonb,    run_as                   user_name[]                    NOT NULL DEFAULT NULL,   -- array of representative users to test as, checked against the user_name DOMAIN.    modifies_data            bool                           NOT NULL DEFAULT false,    rds_only                 bool                           NOT NULL DEFAULT false);ALTER TABLE dba.test_case    ADD CONSTRAINT test_case_id_pkey    PRIMARY KEY (id);ALTER TABLE dba.test_case	ADD CONSTRAINT test_case_unique_signature	UNIQUE (object_class,object_schema,object_name,function_signature,test_name);ALTER TABLE dba.test_case    OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None needed at the moment.-------------------------------------- Add triggers-------------------------------------- None needed at the moment, but this might change to auto-populate and dirty custom_function.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:test_result.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.test_result CASCADE;CREATE TABLE IF NOT EXISTS dba.test_result (	id               uuid          NOT NULL DEFAULT extensions.gen_random_uuid(),	test_case_id     uuid          NOT NULL DEFAUlT NULL, -- Need to declare as a FK.    patch_log_id     uuid,         -- Optional.	result_dts       timestamptz   NOT NULL DEFAULT now(), -- The timestamp of the transaction you're in.    test_passed      bool          NOT NULL DEFAULT false,    server_address   citext        NOT NULL DEFAULT inet_server_addr()::citext,    database_name    citext        NOT NULL DEFAULT current_database()::citext,    pg_version       citext        NOT NULL DEFAULT version()::citext,    user_name        user_name     NOT NULL DEFAULT current_user::user_name, -- user_name is a custom domain.    actual_response  citext        NOT NULL DEFAULT '',    actual_error     citext        NOT NULL DEFAULT '',    actual_outcome   test_outcome, -- Custom DOMAIN based on citext that only accepts the values pass, warning, or fail, case-insensitive.    diagnostics      citext        NOT NULL DEFAULT '',    summary          citext        NOT NULL DEFAULT '',    results_json     jsonb         NOT NULL DEFAULT '{}'::jsonb);ALTER TABLE dba.test_result	ADD CONSTRAINT test_result_id_pkey    PRIMARY KEY (id);ALTER TABLE dba.test_result	ADD CONSTRAINT test_result_case_and_user_unique    UNIQUE (test_case_id,user_name);ALTER TABLE dba.test_result	ADD CONSTRAINT test_result_test_case_fk	FOREIGN KEY (test_case_id)	REFERENCES dba.test_case (id)	ON DELETE CASCADE	ON UPDATE NO ACTION;ALTER TABLE dba.test_result	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None needed at the moment.-------------------------------------- Add triggers-------------------------------------- None needed at the moment, but this might change to auto-populate and dirty custom_function.--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:push_target.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.push_target CASCADE;CREATE TABLE IF NOT EXISTS dba.push_target (    id                int8       GENERATED ALWAYS AS IDENTITY PRIMARY KEY,    unique_path       citext     NOT NULL DEFAULT NULL UNIQUE,    schema_name       citext     NOT NULL DEFAULT NULL,    target_name       citext     NOT NULL DEFAULT NULL,    qualified_name    citext     GENERATED ALWAYS AS (schema_name || '.' || target_name) STORED, -- Qualified name for tables, not for passthroughs.    target_type       citext     NOT NULL DEFAULT NULL);ALTER TABLE dba.push_target	OWNER TO user_change_structure;COMMENT ON TABLE dba.push_target IS'Server-side table to consolidate target strings, linked back to push_audit logs by a server-side integer key. Not directly pushed from IB/Sonar. All INSERTs on this table come from the insert-handling Postgres functions for push_audit.';-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äö√Ñ√Æ DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound.-- Note: Postgres automatically creates a UNIQUE B-tree for columns marked UNIQUE.-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE dba.push_target    CLUSTER ON ***index name to cluster by here;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_push_target_after_delete            AFTER DELETE               ON dba.push_target      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_push_target_before_truncate            BEFORE TRUNCATE               ON dba.push_target         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON dba.push_target TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON dba.push_target TO user_cleanup;GRANT SELECT, INSERT, UPDATE ON dba.push_target TO user_reporting;GRANT SELECT, INSERT, UPDATE ON dba.push_target TO user_change_structure;-- Adjustable user permissions:GRANT SELECT, INSERT, UPDATE ON dba.push_target TO user_iceberg;GRANT SELECT, INSERT, UPDATE ON dba.push_target TO user_iceberg_remote;GRANT SELECT, INSERT, UPDATE ON dba.push_target TO user_saws;GRANT SELECT, INSERT, UPDATE ON dba.push_target TO user_sonar;GRANT SELECT, INSERT, UPDATE ON dba.push_target TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:push_audit.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.push_audit CASCADE;-- Why the peculiar column order? column_tetris('push_audit').-- https://ascendco.atlassian.net/wiki/spaces/SON/pages/666501123/Arranging+Fields+to+Optimize+Disk+Space-- This is a potentially large table, and worth some fuss to make more efficient.CREATE TABLE IF NOT EXISTS dba.push_audit (    data_file_id                   uuid            NOT NULL DEFAULT NULL,    start_local_dts                timestamp       NOT NULL DEFAULT 'epoch',    end_local_dts                  timestamp       NOT NULL DEFAULT 'epoch',    end_utc_dts                    timestamp       NOT NULL DEFAULT 'epoch',    inserted_utc_dts               timestamptz     NOT NULL DEFAULT timezone('utc', clock_timestamp()),    id                             int4            GENERATED ALWAYS AS IDENTITY PRIMARY KEY, -- Unique, int-4 (longint in 4D) ID. Works like a con_id for us.    duration_seconds               int4            NOT NULL DEFAULT 0,    records_count                  int4            NOT NULL DEFAULT 0,    target_id                      int8            NOT NULL DEFAULT 0,                       -- Links to dba.push_target which holds schema, name, path, and target type.    version_number                 int2            NOT NULL DEFAULT 0,    error_occurred                 boolean         NOT NULL DEFAULT false,    client_user_name               citext          NOT NULL DEFAULT '',                     -- A client-side user name, if you like.    inserted_by                    citext          NOT NULL DEFAULT get_current_user(),     -- PG user name, which may be something like a data pump utility user name.    push_method_name               citext          NOT NULL DEFAULT '',                     -- Client side label attribute, helps with debugging.    error_text                     citext          NOT NULL DEFAULT '');ALTER TABLE dba.push_audit ADD CONSTRAINT   push_audit_push_target_fk   FOREIGN KEY (target_id)   REFERENCES dba.push_target (id)   ON DELETE CASCADE;ALTER TABLE dba.push_audit	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äö√Ñ√Æ DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound.-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE dba.push_audit    CLUSTER ON ***index name to cluster by here;*/-------------------------------------- Add triggers------------------------------------   CREATE TRIGGER trigger_push_audit_after_delete            AFTER DELETE               ON dba.push_audit      REFERENCING OLD TABLE AS deleted_rows         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_deletion_count();  CREATE TRIGGER trigger_push_audit_before_truncate            BEFORE TRUNCATE               ON dba.push_audit         FOR EACH STATEMENTEXECUTE PROCEDURE ascendco.trigger_function_log_truncation_count();-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users...and few extra INSERT and UPDATE blessings.GRANT SELECT, INSERT, UPDATE, DELETE ON dba.push_audit TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON dba.push_audit TO user_cleanup;GRANT SELECT, INSERT, UPDATE ON dba.push_audit TO user_reporting;GRANT SELECT, INSERT, UPDATE ON dba.push_audit TO user_change_structure;-- Adjustable user permissions:GRANT SELECT, INSERT, UPDATE ON dba.push_audit TO user_iceberg;GRANT SELECT, INSERT, UPDATE ON dba.push_audit TO user_iceberg_remote;GRANT SELECT, INSERT, UPDATE ON dba.push_audit TO user_saws;GRANT SELECT, INSERT, UPDATE ON dba.push_audit TO user_sonar;GRANT SELECT, INSERT, UPDATE ON dba.push_audit TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:target_count.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.target_count CASCADE;-- Why the peculiar column order? column_tetris('target_count').-- https://ascendco.atlassian.net/wiki/spaces/SON/pages/666501123/Arranging+Fields+to+Optimize+Disk+Space-- This is a potentially large table, and worth some fuss to make more efficient.CREATE TABLE IF NOT EXISTS dba.target_count (    hsys_id              uuid         NOT NULL DEFAULT NULL,    records_count        int4         NOT NULL DEFAULT 0,    count_date           date         NOT NULL DEFAULT current_date,    count_dts            timestamp    NOT NULL DEFAULT now(),    qualified_name       citext       NOT NULL DEFAULT NULL);ALTER TABLE dba.target_count ADD CONSTRAINT   target_count_pk   PRIMARY KEY (hsys_id, qualified_name, count_date);ALTER TABLE dba.target_count	OWNER TO user_change_structure;-------------------------------------- Build statistics------------------------------------/*The Postgres ANALYZE system function collects statistics about each table and column. These valuesare used by the query planner to help generate probabilistic cost estimates for various query plans.When the plans are based on misleading stats, you can have poor performance. Stats can be reconfiguredon a row-by-row basis, and some special extended statistics are supported too.Custom and extended statistics are typically added after we've been accumulating data for some time.See PgBuildStatistics_Extended in IB to declare new statistics objects. For more background, seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/1723695105/*/-------------------------------------- ANALYZE options-------------------------------------- Placholder and reminder for now. ANALYZE and AUTOVACUUM tunings are *core* Postgres DBA-- skills. But, for the minute, we're not running into trouble. I'm chipping away af figuring-- out when to tune, and how, and when not to tune. ‚Äö√Ñ√Æ DPA-------------------------------------- Build indexes-------------------------------------- Note: Postgres automatically creates a UNIQUE B-tree for the PRIMARY KEY, simple or compound.-------------------------------------- CLUSTER------------------------------------/*Code stub/reminder about CLUSTERing. Not a hard topic, but too big to write up here. Notes and links:https://ascendco.atlassian.net/wiki/spaces/SON/pages/356679683/ALTER TABLE dba.target_count    CLUSTER ON ***index name to cluster by here;*/-------------------------------------- Add triggers-------------------------------------- None for now.-------------------------------------- Manual Permissions for now-------------------------------------- Standard permissions for utility/admin users:GRANT SELECT, INSERT, UPDATE, DELETE ON dba.target_count TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON dba.target_count TO user_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE ON dba.target_count TO user_reporting;GRANT SELECT ON dba.target_count TO user_change_structure;-- Adjustable user permissions:GRANT SELECT ON dba.target_count TO user_iceberg;GRANT SELECT ON dba.target_count TO user_iceberg_remote;GRANT SELECT ON dba.target_count TO user_saws;GRANT SELECT ON dba.target_count TO user_sonar;GRANT SELECT, INSERT, UPDATE, DELETE ON dba.target_count TO user_leviathan;COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:dba:view_catalog.sql-------------------------------------- Define table------------------------------------BEGIN;DROP TABLE IF EXISTS dba.view_catalog;CREATE TABLE IF NOT EXISTS dba.view_catalog (	schema_name    citext  NOT NULL DEFAULT NULL,    view_name      citext  NOT NULL DEFAULT NULL,    description    citext  NOT NULL DEFAULT NULL,    domo_dataset   citext  NOT NULL DEFAULT NULL);ALTER TABLE dba.view_catalog	ADD CONSTRAINT view_catalog_id_pkey    PRIMARY KEY (schema_name,view_name);COMMENT ON TABLE dba.view_catalog IS	'Searchable descriptions of useful views. It''s all text, no validation of names, OIDs, etc.';ALTER TABLE dba.view_catalog	OWNER TO user_change_structure;COMMIT;-------------------------------------- Build indexes-------------------------------------- None needed at the moment.-------------------------------------- Add triggers-------------------------------------- None needed at the moment, but this might change to auto-populate and dirty custom_function.-------------------------------------- Add GRANTS-------------------------------------- Not normal, jamming these in for my quick tests.GRANT SELECT, INSERT, UPDATE, DELETE ON view_catalog TO rds_super;GRANT SELECT, INSERT, UPDATE, DELETE ON view_catalog TO user_reporting;GRANT SELECT, INSERT, UPDATE, DELETE ON view_catalog TO user_iceberg;GRANT SELECT, INSERT, UPDATE, DELETE ON view_catalog TO user_change_structure;GRANT SELECT, INSERT, UPDATE, DELETE ON view_catalog TO user_sonar;-------------------------------------------------- Register view------------------------------------------------------------------------------------------- Functions-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:domo_passthrough_expand.sqlDROP FUNCTION IF EXISTS api.domo_passthrough_expand (text, jsonb);CREATE FUNCTION api.domo_passthrough_expand(type_name text, packed_data jsonb)	RETURNS SETOF record AS$BODY$BEGIN    RETURN QUERY EXECUTE FORMAT   'select *      from jsonb_populate_recordset(null::%1$I, %2$I) as expanded_data;',           type_name,           packed_data;END;$BODY$LANGUAGE plpgsql STABLE;ALTER FUNCTION api.domo_passthrough_expand(text, jsonb) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:hour_number.sqlCREATE OR REPLACE FUNCTION api.hour_number(dts timestamptz)  RETURNS pg_catalog.int2 AS$BODY$/* day numbers are 0-6 and hours are 0-23 in postgres. this function shifts those to 1-7 and 1-24,   and gives you the hour-in-the-week result. so 12:30 am sunday night is 1, 1:00 sunday night is 2	 1:00 monday night is 25, and so on. */select ((extract(dow from dts) + 1) * 24 +	   (extract (hour from dts) + 1)) ::int2$BODY$  LANGUAGE sql STABLE;ALTER function api.hour_number (timestamptz)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:pg_stat_statements.sqlCREATE OR REPLACE FUNCTION api.pg_stat_statements()RETURNS SETOF extensions.pg_stat_statementsAS $BODY$SELECT * FROM pg_stat_statements;$BODY$LANGUAGE sqlSECURITY DEFINER;ALTER FUNCTION api.pg_stat_statements()OWNER TO rds_super;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:productivity_user.sqlDROP FUNCTION IF EXISTS api.productivity_user (uuid, date, date, uuid);CREATE OR REPLACE FUNCTION api.productivity_user (    facility_id   uuid,    from_date     date,    to_date       date,    user_id       uuid)RETURNS TABLE (	  schema_name citext,	  view_name   citext) AS$BODY$-- DECLAREBEGIN-- The parameter types screen out most bad inputs, but it's still possible to screw up the start-end range. A few quick checks.IF from_date > to_date THEN  RAISE EXCEPTION USING     message = 'Invalid date range: ' || from_date::text || ' to ' || to_date::text,     hint = 'The from date is later than the to date.',     errcode = 'KC400'; -- Custom code, see the error_code table.END IF;END$BODY$LANGUAGE plpgsql STABLE;COMMENT ON FUNCTION api.productivity_user (uuid, date, date, uuid) IS'Pass in a facility ID, from date, to date, and a user ID to get back matching sent records.';ALTER function api.productivity_user (uuid, date, date, uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:push_log_count_since.sqlCREATE OR REPLACE FUNCTION api.push_log_count_since (since_dts timestamptz)	RETURNS TABLE(		days_ago int8,		table_name extensions.citext,		server_name extensions.citext,		push_count int8)AS $BODY$DECLARE-- Subtract two timestamptz values, get an interval, pull out just the days.   days_ago bigint := date_part('day', now()::timestamptz - since_dts)::bigint;BEGINRETURN QUERY    SELECT days_ago,           ib_table_name as table_name,           data_file_info.server_name_ as server_name,           count(*) as push_count      FROM ascendco.push_log      JOIN ascendco.data_file_info on (data_file_info.id = push_log.data_file_id)     WHERE push_log.push_dts >= since_dts  GROUP BY ib_table_name,           data_file_info.server_name_  ORDER BY ib_table_name,           data_file_info.server_name_           ;END;$BODY$  LANGUAGE plpgsql STABLE SECURITY DEFINER  COST 100  ROWS 1000;ALTER FUNCTION api.push_log_count_since (timestamptz)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:api:push_log_sum_since.sqlCREATE OR REPLACE FUNCTION api.push_log_sum_since (since_dts timestamptz)	RETURNS TABLE(		days_ago int8,		table_name extensions.citext,		server_name extensions.citext,		push_sum int8)AS $BODY$DECLARE-- Subtract two timestamptz values, get an interval, pull out just the days.   days_ago bigint := date_part('day', now()::timestamptz - since_dts)::bigint;BEGINRETURN QUERY    SELECT days_ago,           ib_table_name as table_name,           data_file_info.server_name_ as server_name,           sum(push_log.records_count) as push_sum      FROM ascendco.push_log      JOIN ascendco.data_file_info on (data_file_info.id = push_log.data_file_id)     WHERE push_log.push_dts >= since_dts  GROUP BY ib_table_name,           data_file_info.server_name_  ORDER BY ib_table_name,           data_file_info.server_name_           ;END;$BODY$  LANGUAGE plpgsql STABLE SECURITY DEFINER  COST 100  ROWS 1000;ALTER FUNCTION api.push_log_sum_since (timestamptz)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:calendar_get_fiscal_week.sql-- select * from calendar_get_fiscal_week('2020-01-08'::date, '2020-01-01'::date) -- 2CREATE OR REPLACE FUNCTION ascendco.calendar_get_fiscal_week (	date_in date,	first_date_of_fiscal_year_in date)RETURNS integerAS $BODY$SELECT ((date_in - first_date_of_fiscal_year_in) / 7 ) +1$BODY$	LANGUAGE sql VOLATILE	COST 100;ALTER FUNCTION ascendco.calendar_get_fiscal_week (date, date)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:activity_for_facility.plpgsqlDROP FUNCTION IF EXISTS     ascendco.activity_for_facility (uuid);CREATE OR REPLACE FUNCTION  ascendco.activity_for_facility (in_facility_id uuid)RETURNS TABLE (    activity_id          uuid,    hsys_name            citext,    facility_name        citext,    server_name          citext,    start_dts            timestamp,    done_dts             timestamp,    duration_seconds     int4,    updated_dts          timestamp,    marked_for_deletion  boolean,    other_desc           citext,    user_name            citext,    created_dts          timestamp,    created_by           citext,    updated_by           citext)LANGUAGE plpgsql STABLE -- RETURN QUERY is a PL/PgSQL thing...AS $BODY$BEGINRETURN QUERYSELECT activity.id                                             AS activity_id,       coalesce(hsys.name_, 'Unknown')                         AS hsys_name,       coalesce(facility.name_, 'Unknown')                     AS facility_name,       coalesce(facility_activities.name_, 'Unknown')          AS activity_name,       coalesce(data_file_info.server_name_, 'Unknown')        AS server_name,       activity.start_dts,       activity.done_dts,       activity.duration_seconds,       activity.updated_dts,       activity.marked_for_deletion,       activity.other_desc,       coalesce(web_user.name_full, 'Unknown')                 AS user_name,       activity.created_dts,       activity.created_by,       activity.updated_by--   Note: activity doesn't have hsys_id, you neeed to load facility, and get the hsys_id from there.     FROM activityLEFT JOIN facility_activities  ON facility_activities.id   = activity.facility_activities_idLEFT JOIN web_user             ON web_user.id              =  activity.web_user_idLEFT JOIN data_file_info       ON data_file_info.id        =  activity.last_updated_by_data_file_idLEFT JOIN facility             ON facility.id              =  activity.facility_idLEFT JOIN hsys                 ON hsys.id                  =  facility.hsys_idWHERE activity.facility_id = in_facility_id;END$BODY$;COMMENT ON FUNCTION ascendco.activity_for_facility (uuid) IS'Pass in a facility_id and get back a list of activity records.';ALTER FUNCTION ascendco.activity_for_facility (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:activity_for_facility.sqlDROP FUNCTION IF EXISTS     ascendco.activity_for_facility (uuid);CREATE OR REPLACE FUNCTION  ascendco.activity_for_facility (in_facility_id uuid)RETURNS TABLE (    activity_id          uuid,    hsys_name            citext,    facility_id          uuid,    facility_name        citext,    activity_name        citext,    server_name          citext,    start_dts            timestamp,    done_dts             timestamp,    duration_seconds     int4,    updated_dts          timestamp,    marked_for_deletion  boolean,    other_desc           citext,    user_name            citext,    created_dts          timestamp,    created_by           citext,    updated_by           citext)LANGUAGE sql STABLEAS $BODY$SELECT activity.id                                             AS activity_id,       coalesce(hsys.name_, 'Unknown')                         AS hsys_name,       facility.id,       coalesce(facility.name_, 'Unknown')                     AS facility_name,       coalesce(facility_activities.name_, 'Unknown')          AS activity_name,       coalesce(data_file_info.server_name_, 'Unknown')        AS server_name,       activity.start_dts,       activity.done_dts,       activity.duration_seconds,       activity.updated_dts,       activity.marked_for_deletion,       activity.other_desc,       coalesce(web_user.name_full, 'Unknown')                 AS user_name,       activity.created_dts,       activity.created_by,       activity.updated_by--   Note: activity doesn't have hsys_id, you neeed to load facility, and get the hsys_id from there.     FROM activityLEFT JOIN facility_activities  ON facility_activities.id   = activity.facility_activities_idLEFT JOIN web_user             ON web_user.id              =  activity.web_user_idLEFT JOIN data_file_info       ON data_file_info.id        =  activity.last_updated_by_data_file_idLEFT JOIN facility             ON facility.id              =  activity.facility_idLEFT JOIN hsys                 ON hsys.id                  =  facility.hsys_idWHERE activity.facility_id = in_facility_id;$BODY$;COMMENT ON FUNCTION ascendco.activity_for_facility (uuid) IS'Pass in a facility_id and get back a list of activity records.';ALTER FUNCTION ascendco.activity_for_facility (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:calendar_add.sqlCREATE OR REPLACE FUNCTION ascendco.calendar_add (     id_in               uuid, -- Pre-build UUIDs to share around the system. That's why this is passed, not generated.     calendar_name_in    citext,     week_starts_on_in   day_name,     description_in      citext DEFAULT ''     )RETURNS uuid AS$BODY$DELETE from calendar WHERE id = id_in; -- CASCADE delete flows through to related child tables.INSERT INTO calendar  (id, calendar_name, week_starts_on, description)            VALUES    (id_in, calendar_name_in, week_starts_on_in, description_in)            RETURNING id; -- The RETURNING clauses is a very cool Postgres extension to SQL. It should be in the standards.$BODY$  LANGUAGE sql;ALTER function ascendco.calendar_add (uuid, citext,day_name, citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:calendar_generate_year_of_days.sql-- select * from calendar_generate_year_of_days ('FY 2020','2020','2019-12-29'::date,'2020-12-26'::date,1);DROP FUNCTION IF EXISTS ascendco.calendar_generate_year_of_days (text_not_empty, text_not_empty, date, date, integer);CREATE OR REPLACE FUNCTION ascendco.calendar_generate_year_of_days (     fiscal_year_name_in            text_not_empty,     fiscal_year_abbr_in            text_not_empty,     first_date_of_fiscal_year_in   date,     last_date_of_fiscal_year_in    date,     week_start_offset              integer DEFAULT 1 -- 1 for a Sunday start, 0 for a Monday week start.     )-- calendar_day fields, apaart from ids and lookkup values. Eh?-- Want to be able to generate a year _without_ a table, or into a table.RETURNS TABLE (  date_actual                 date,  epoch                       int8,  day_suffix                  citext,  day_name                    citext,  day_name_abbreviated        citext,  day_of_week_usa             integer,  -- 1-7 day numbers, Sunday-Saturday, like 4D.  day_of_week_iso             integer,  -- 1-7 day numbers, Monday-Sunday  day_of_month_actual         integer,  day_of_quarter_iso          integer,  day_of_year_actual          integer,  day_of_year_fiscal          integer,  week_of_month_actual        integer,  week_of_year_actual         integer,    -- 24  week_of_year_fiscal_name    citext,  -- Week 24 2020  week_of_year_fiscal         citext,  -- 2020-24  week_of_year_iso            citext,  -- 2020-W20-5  month_actual                integer,  month_actual_name                  citext,  month_actual_name_abbreviated      citext,  month_fiscal                integer,  month_fiscal_name                  citext,  month_fiscal_name_abbreviated      citext,  quarter_actual              integer,  quarter_actual_name         citext,  quarter_fiscal              integer,  quarter_fiscal_name         citext,  year_actual                 integer,  -- year_fiscal is pulled from the input parameter here, and by lookup when working with the calendar_day table.  first_date_of_week          date,  last_date_of_week           date,  first_date_of_month         date,  last_date_of_month          date,  first_date_of_quarter       date,  last_date_of_quarter        date,  first_date_of_year_actual   date,  last_date_of_year_actual    date,  first_date_of_year_fiscal   date,  last_date_of_year_fiscal    date,  mmyyyyy                     citext,  mmddyyyy                    citext,  ddmmyyyyy                   citext,  weekend                     boolean)AS $BODY$DECLARE   days_in_year_calculated integer := last_date_of_fiscal_year_in - first_date_of_fiscal_year_in +1;BEGIN-- The parameter types screen out most bad inputs, but it's still possible to screw up the start-end range. A few quick checks.IF first_date_of_fiscal_year_in > last_date_of_fiscal_year_in THEN  RAISE EXCEPTION USING     message = 'Invalid date range: ' || first_date_of_fiscal_year_in::text || ' to ' || last_date_of_fiscal_year_in::text,     hint = 'The first day in the year is later than the last day in the year.',     errcode = 'KC400'; -- Custom code, see the error_code table.END IF;IF days_in_year_calculated < 364 OR days_in_year_calculated > 371 THEN  RAISE EXCEPTION USING     message = 'Invalid date range: '  || first_date_of_fiscal_year_in::text || ' to ' || last_date_of_fiscal_year_in::text,     hint =  days_in_year_calculated::text || ' days in the fiscal year.' || '. fiscal years are expected to have 52 or 53 weeks for 364 or 371 days',     errcode = 'KC401'; -- Custom code, see the error_code table.END IF;RETURN QUERYSELECT	datum                                                           AS date_actual,	EXTRACT(EPOCH FROM datum)::int8                                 AS epoch,-- Note: TO_CHAR ("string" to us 4D folk) argument fm/FM = Fill Mode. Which means "strip padding." Eh?	TO_CHAR(datum, 'fmDDth')::citext                                AS day_suffix,	TO_CHAR(datum, 'fmDay')::citext                                 AS day_name,	TO_CHAR(datum, 'fmDy') ::citext                                 AS day_name_abbreviated,	(EXTRACT(DOW FROM datum) + 1)::integer                          AS day_of_week_usa,     -- 1-7 for Sunday-Monday, like 4D.	(EXTRACT(ISODOW FROM datum))::integer                           AS day_of_week_iso,     -- 1-7 for Monday-Sunday.	(EXTRACT(DAY FROM datum))::integer                              AS day_of_month_actual,	(datum - DATE_TRUNC('quarter', datum)::DATE + 1)::integer       AS day_of_quarter_iso,	(EXTRACT(DOY FROM datum))::integer                              AS day_of_year_actual,	(datum - first_date_of_fiscal_year_in +1)::integer              AS day_of_year_fiscal,	TO_CHAR(datum, 'W')::integer                                    AS week_of_month_actual,	TO_CHAR(datum,'WW')::integer                                    AS week_of_year_actual,	-- OMG! This next lines really are *horrible*. Want Abbr-00 format. Yeah, maybe there's a simpler way, maybe this *is* the simpler way.	CONCAT('Week ', to_char(calendar_get_fiscal_week(datum, first_date_of_fiscal_year_in),'fm00')::citext, ' ', fiscal_year_abbr_in)::citext  AS week_of_year_fiscal_name,	CONCAT(fiscal_year_abbr_in, '-', to_char(calendar_get_fiscal_week(datum, first_date_of_fiscal_year_in),'fm00')::citext)::citext  AS week_of_year_fiscal,	(EXTRACT(ISOYEAR FROM datum) || TO_CHAR(datum, '"-W"IW-') || EXTRACT(ISODOW FROM datum))::citext                      AS week_of_year_iso,	(EXTRACT(MONTH FROM datum))::integer                            AS month_actual,	TO_CHAR(datum, 'Month')::citext                                 AS month_actual_name,	TO_CHAR(datum, 'Mon')::citext                                   AS month_actual_name_abbreviated,    calendar_get_fiscal_month (datum, first_date_of_fiscal_year_in) AS month_fiscal, -- Redundnat data with different column names for convenience	TO_CHAR(datum, 'Month')::citext                                 AS month_fiscal_name,	TO_CHAR(datum, 'Mon')::citext                                   AS month_fiscal_name_abbreviated,	(EXTRACT(QUARTER FROM datum))::integer                          AS quarter_actual,	CASE	   WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'::citext	   WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'::citext	   WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'::citext	   WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'::citext	   ELSE ''::citext	END                                                                 AS quarter_actual_name,	((datum - first_date_of_fiscal_year_in +1) / (7 * 13) +1)::integer  AS quarter_fiscal,	CASE	   WHEN (datum - first_date_of_fiscal_year_in +1) / (7 * 13) +1 = 1 THEN 'First'::citext	   WHEN (datum - first_date_of_fiscal_year_in +1) / (7 * 13) +1 = 2 THEN 'Second'::citext	   WHEN (datum - first_date_of_fiscal_year_in +1) / (7 * 13) +1 = 3 THEN 'Third'::citext	   WHEN (datum - first_date_of_fiscal_year_in +1) / (7 * 13) +1 = 4 THEN 'Fourth'::citext	   ELSE ''::citext	END                                                                 AS quarter_fiscal_name,	(EXTRACT(ISOYEAR FROM datum))::integer AS year_actual,  -- calendar year	datum + (week_start_offset     - EXTRACT(ISODOW FROM datum))::int   AS first_date_of_week,	datum + (week_start_offset + 6 - EXTRACT(ISODOW FROM datum))::int   AS last_date_of_week,	datum + (1 - EXTRACT(DAY FROM datum))::INT                          AS first_date_of_month,	(DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE     AS last_date_of_month,	DATE_TRUNC('quarter', datum)::DATE                                  AS first_date_of_quarter,    (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE   AS last_date_of_quarter,	TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD')         AS first_date_of_year_actual,	TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD')         AS last_date_of_year_actual,	first_date_of_fiscal_year_in                                        AS first_date_of_year_fiscal,	last_date_of_fiscal_year_in                                         AS last_date_of_year_fiscal,	TO_CHAR(datum, 'mmyyyyy')::citext                                   AS mmyyyyy,	TO_CHAR(datum, 'mmddyyyy')::citext                                  AS mmddyyyy,	TO_CHAR(datum, 'ddmmyyyyy')::citext                                 AS ddmmyyyyy,	CASE	   WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE	   ELSE FALSE	END AS weekend-- Synthesize a list of dates. This is then run against each line in the SELECT above,-- and the result is inserted into calendar_date.FROM (SELECT first_date_of_fiscal_year_in + SEQUENCE.DAY AS datum      FROM GENERATE_SERIES(0, days_in_year_calculated -1 ) AS SEQUENCE (DAY)      GROUP BY SEQUENCE.DAY) DQORDER BY 1;RAISE NOTICE 'fiscal_year_name_in: %', fiscal_year_name_in;END$BODY$  LANGUAGE plpgsql;ALTER function ascendco.calendar_generate_year_of_days (text_not_empty, text_not_empty, date, date, integer)    OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:calendar_get_fiscal_month.sql--  select * from calendar_get_fiscal_month('2020-04-30'::date, '2020-01-01'::date) -- 5CREATE OR REPLACE FUNCTION ascendco.calendar_get_fiscal_month (	date_in date,	first_date_of_fiscal_year_in date)RETURNS integerAS $BODY$DECLARE    fiscal_week integer  := calendar_get_fiscal_week (date_in, first_date_of_fiscal_year_in);    fiscal_month integer := 0;BEGINSELECTCASE WHEN fiscal_week <  5 THEN  1	 WHEN fiscal_week <  9 THEN  2	 WHEN fiscal_week < 14 THEN  3	 WHEN fiscal_week < 18 THEN  4	 WHEN fiscal_week < 22 THEN  5	 WHEN fiscal_week < 27 THEN  6	 WHEN fiscal_week < 32 THEN  7	 WHEN fiscal_week < 35 THEN  8	 WHEN fiscal_week < 40 THEN  9	 WHEN fiscal_week < 44 THEN 10	 WHEN fiscal_week < 48 THEN 11	 ELSE                       12END INTO fiscal_month;RETURN fiscal_month;END;$BODY$	LANGUAGE plpgsql VOLATILE	COST 100;ALTER FUNCTION ascendco.calendar_get_fiscal_month (date, date)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:calendar_insert_year_of_days.sql/*It would be better to pass in calendar_year.id, and look everything else up.As it stands, I couldn't get it to work with a subquery, CTE, or CTE + LATERAL.https://stackoverflow.com/questions/37670995/postgresql-cte-records-as-parameters-to-functionSo, some bit of remedial (intermediate+) Postgres that I don't know. I'll figure it outeventually, as I keep running into this issue of "passing lookup values into function parameters."*/CREATE OR REPLACE FUNCTION ascendco.calendar_insert_year_of_days (    calendar_id_in          uuid,    calendar_year_id_in     uuid,    fiscal_year_name_in     text,    fiscal_year_abbr_in     text,    first_date_in_year_in   date,    last_date_in_year_in    date,    week_start_offset       integer    )RETURNS voidAS $BODY$BEGININSERT INTO calendar_day (            calendar_id,            calendar_year_id,            date_actual,            epoch,            day_suffix,            day_name,            day_name_abbreviated,            day_of_week_usa,            day_of_week_iso,            day_of_month_actual,            day_of_quarter_iso,            day_of_year_actual,            day_of_year_fiscal,            week_of_month_actual,            week_of_year_actual,            week_of_year_fiscal_name,            week_of_year_fiscal,            week_of_year_iso,            month_actual,            month_actual_name,            month_actual_name_abbreviated,            month_fiscal,            month_fiscal_name,            month_fiscal_name_abbreviated,            quarter_actual,            quarter_actual_name,            quarter_fiscal,            quarter_fiscal_name,            year_actual,            first_date_of_week,            last_date_of_week,            first_date_of_month,            last_date_of_month,            first_date_of_quarter,            last_date_of_quarter,            first_date_of_year_actual,            last_date_of_year_actual,            first_date_of_year_fiscal,            last_date_of_year_fiscal,            mmyyyyy,            mmddyyyy,            ddmmyyyyy,            weekend         )     SELECT calendar_id_in,            calendar_year_id_in,            date_actual,            epoch,            day_suffix,            day_name,            day_name_abbreviated,            day_of_week_usa,            day_of_week_iso,            day_of_month_actual,            day_of_quarter_iso,            day_of_year_actual,            day_of_year_fiscal,            week_of_month_actual,            week_of_year_actual,            week_of_year_fiscal_name,            week_of_year_fiscal,            week_of_year_iso,            month_actual,            month_actual_name,            month_actual_name_abbreviated,            month_fiscal,            month_fiscal_name,            month_fiscal_name_abbreviated,            quarter_actual,            quarter_actual_name,            quarter_fiscal,            quarter_fiscal_name,            year_actual,            first_date_of_week,            last_date_of_week,            first_date_of_month,            last_date_of_month,            first_date_of_quarter,            last_date_of_quarter,            first_date_of_year_actual,            last_date_of_year_actual,            first_date_of_year_fiscal,            last_date_of_year_fiscal,            mmyyyyy,            mmddyyyy,            ddmmyyyyy,            weekend     from  calendar_generate_year_of_days (                  fiscal_year_name_in,                  fiscal_year_abbr_in,                  first_date_in_year_in,                  last_date_in_year_in,                  week_start_offset)      order by date_actual;RETURN; -- void/NULLEND$BODY$	LANGUAGE plpgsql;ALTER function ascendco.calendar_insert_year_of_days (uuid, uuid, text, text, date, date, integer)    OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:calendar_year_add.sqlCREATE OR REPLACE FUNCTION ascendco.calendar_year_add (     calendar_id_in          uuid,     fiscal_year_name_in     citext,     fiscal_year_abbr_in     citext,     first_date_in_year_in   date,     last_date_in_year_in    date,     week_start_offset       integer DEFAULT 1 -- 1 for a Sunday start, 0 for a Monday week start.     )RETURNS citext AS$BODY$DECLARE   calendar_year_id_out                             uuid;   -- Returned by INSERT below.   days_in_year_calculated            int2      :=  last_date_in_year_in - first_date_in_year_in + 1;   weeks_in_year_calculated           int2      :=  days_in_year_calculated/7;   first_day_of_week_usa_calculated   int2      :=  extract (dow from first_date_in_year_in) + 1;  -- 1-7, Sunday-Monday, US convention.   first_day_of_week_iso_calclated    int2      :=  extract (isodow from first_date_in_year_in); -- 1-7, Monday-Saturday, ISO convention.-- Note: TO_CHAR adds a space after the day name, that's what the regex is about. See-- https://stackoverflow.com/questions/22699535/trim-trailing-spaces-with-postgresql   first_day_of_week_name_calculated  day_name  :=  regexp_replace(to_char (first_date_in_year_in, 'Day') , '\s+$', ''); -- Sunday-Monday. day_name is a custom domain (type+rules).BEGIN-- The parameter types screen out most bad inputs, but it's still possible to screw up the start-end range. A few quick checks.IF first_date_in_year_in > last_date_in_year_in THEN  RAISE EXCEPTION USING     message = 'Invalid date range: ' || first_date_in_year_in::text || ' to ' || last_date_in_year_in::text,     hint = 'The first day in the year is later than the last day in the year.',     errcode = 'KC400'; -- Custom code, see the error_code table.END IF;IF days_in_year_calculated < 364 OR days_in_year_calculated > 371 THEN  RAISE EXCEPTION USING     message = 'Invalid date range: '  || first_date_in_year_in::text || ' to ' || last_date_in_year_in::text,     hint =  days_in_year_calculated::text || ' days in the fiscal year. fiscal years are expected to have 52 or 53 weeks for 364 or 371 days total.',     errcode = 'KC401'; -- Custom code, see the error_code table.END IF;DELETE FROM ascendco.calendar_year      WHERE calendar_id = calendar_id_in  -- CASCADE delete flows through to related child tables.        AND fiscal_year_name = fiscal_year_name_in;INSERT INTO calendar_year  (calendar_id,                            fiscal_year_name,                            fiscal_year_abbr,                            first_date_in_year,                            last_date_in_year,                            days_in_year,                            weeks_in_year,                            first_day_of_week_usa,                            first_day_of_week_iso,                            first_day_of_week_name,                            week_start_offset)                    VALUES (calendar_id_in,                            fiscal_year_name_in,                            fiscal_year_abbr_in,                            first_date_in_year_in,                            last_date_in_year_in,                            days_in_year_calculated,                            weeks_in_year_calculated,                            first_day_of_week_usa_calculated,                            first_day_of_week_iso_calclated,                            first_day_of_week_name_calculated,                            week_start_offset)--  The RETURNING clauses is a very cool Postgres extension to SQL. It should be in the standards.--  The ID is set in the table definition on INSERT as a generated UUID.            RETURNING id into calendar_year_id_out;-- PERFORM instead of SELECT to discard the result.-- The records are still created, they're just not returned by this function.PERFORM calendar_insert_year_of_days(        calendar_id_in,        calendar_year_id_out,        fiscal_year_name_in,        fiscal_year_abbr_in,        first_date_in_year_in,        last_date_in_year_in,        week_start_offset);RETURN calendar_year_id_out;END$BODY$  LANGUAGE plpgsql;ALTER function ascendco.calendar_year_add (uuid, citext, citext, date, date, integer)    OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:clear_deleted_records.sql/* This code is built in IceBerg by PgBuild_ClearDeletedRecords. It reads the pgIOMap definitions to see which table(s) haveauto-delete enabled. Do *not* update this method by hand!Use PgBuild_ClearDeletedRecords on Dev to change the rules.After that, push the code to the Postgres database. The point here is to define the rules in Dev and enforcethem universally on Postgres. See:https://ascendco.atlassian.net/wiki/spaces/SON/pages/767459342/Deleting+Records+on+Postgres*/CREATE OR REPLACE FUNCTION ascendco.clear_deleted_records()  RETURNS SETOF pg_catalog.void AS $BODY$BEGIN     DELETE FROM ascendco.analytic_productivity WHERE marked_for_deletion = true;     ANALYZE  ascendco.analytic_productivity;     DELETE FROM ascendco.analytic_sterilizer_load WHERE marked_for_deletion = true;     ANALYZE  ascendco.analytic_sterilizer_load;     DELETE FROM ascendco.analytic_sterilizer_loadinv WHERE marked_for_deletion = true;     ANALYZE  ascendco.analytic_sterilizer_loadinv;     DELETE FROM ascendco.item_type WHERE marked_for_deletion = true;     ANALYZE  ascendco.item_type;     DELETE FROM ascendco.specialty WHERE marked_for_deletion = true;     ANALYZE  ascendco.specialty;     DELETE FROM ascendco.sterilize_method WHERE marked_for_deletion = true;     ANALYZE  ascendco.sterilize_method;END;$BODY$  LANGUAGE plpgsql VOLATILE  COST 100  ROWS 1000;  ALTER FUNCTION ascendco.clear_deleted_records() 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:facility_get_id.sqlCREATE OR REPLACE FUNCTION ascendco.facility_get_id (facility_name_in citext)     RETURNS uuidLANGUAGE sql STABLEAS$BODY$SELECT coalesce(    (SELECT id FROM ascendco.facility WHERE name_ = facility_name_in),    '00000000-0000-0000-0000-000000000000'::uuid);$BODY$;COMMENT ON FUNCTION ascendco.facility_get_id (citext) IS'Pass in a facility name and get back its ID, or a pseudo-null UUID.';ALTER FUNCTION ascendco.facility_get_id (citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:facility_get_name.sqlCREATE OR REPLACE FUNCTION ascendco.facility_get_name (facility_id_in uuid)     RETURNS citextLANGUAGE sql STABLEAS$BODY$-- Need to put the select as an expression *inside* the COALESCE, or else it never fires on NULL. D'oh!-- Not the same in a straight select for Reasons That I Do Not Undestand.-- https://stackoverflow.com/questions/65973653/SELECT coalesce((SELECT name_ FROM ascendco.facility WHERE id = facility_id_in),'');$BODY$;COMMENT ON FUNCTION ascendco.facility_get_name (uuid) IS'Pass in a facility ID and get back its name.';ALTER FUNCTION ascendco.facility_get_name (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:find_outliers.sqlCREATE OR REPLACE FUNCTION ascendco.find_outliers (	table_name text,	field_name text,	frequency_threshold int4,	value_threshold int4)RETURNS TABLE (	value_ int4,	frequency_percentile int4,	value_percentile int4)AS $BODY$BEGIN	RETURN QUERY EXECUTE 'withfrequency_counts as (   select ' ||  field_name || '::INT as value_,          count(*) as frequency              from ' || table_name || '			  where ' ||  field_name || ' > 0	      group by 1	      order by 2),frequency_percentiles as (   select *,         ntile(100) over (order by frequency asc) as frequency_percentile,         ntile(100) over (order by value_ asc) as value_percentile	  from frequency_counts)select value_,       frequency_percentile,       value_percentile  from frequency_percentiles   where frequency_percentile < ' || frequency_threshold || '  and         value_ >         (select value_          from frequency_counts          where value_percentile > ' || value_threshold || '          limit 1)order by 1,2,3';END;$BODY$  LANGUAGE plpgsql VOLATILE  COST 100  ROWS 1000;ALTER FUNCTION ascendco.find_outliers (text, text, int4, int4)	OWNER TO user_reporting;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:find_rare_and_large.sqlCREATE OR REPLACE FUNCTION ascendco.find_rare_and_large (	table_name text,	field_name text,	frequency_threshold int4,	value_threshold int4,	target_server text default 'All')RETURNS TABLE (	value_ int4,	frequency int4,	frequency_percentile int4,	value_percentile int4)AS $BODY$BEGINIF (target_server = 'All') THEN    RETURN QUERY EXECUTE '	with frequency_counts as (	  select ' || quote_ident(field_name) || '::INT as value_,	   	      count(*) as frequency	    from ' || quote_ident(table_name) || '	   where ' || quote_ident(field_name) || ' > 0	group by 1	order by 2),	frequency_percentiles as (	  select *,	         ntile(100) over (order by frequency asc) as frequency_percentile,	         ntile(100) over (order by value_ asc) as value_percentile	   from frequency_counts)	select value_,	       frequency::INT,	       frequency_percentile,	       value_percentile	  from frequency_percentiles	   where frequency_percentile < $3 and	         value_ >	         (select value_	          from frequency_counts	          where value_percentile > $4	          limit 1)	order by 1,2,3'	using  table_name, field_name, frequency_threshold, value_threshold;ELSE    RETURN QUERY EXECUTE '	with frequency_counts as (	  select ' || quote_ident(field_name) || '::INT as value_,	   	      count(*) as frequency	    from ' || quote_ident(table_name) || ' 	inner join data_file_info on (data_file_info.id = ' || quote_ident(table_name) || '.data_file_id)	   where ' || quote_ident(field_name) || ' > 0 and	         data_file_info.server_name_ = $5	group by 1	order by 2),	frequency_percentiles as (	  select *,	         ntile(100) over (order by frequency asc) as frequency_percentile,	         ntile(100) over (order by value_ asc) as value_percentile	   from frequency_counts)	select value_,	       frequency::INT,	       frequency_percentile,	       value_percentile	  from frequency_percentiles	   where frequency_percentile < $3 and	         value_ >	         (select value_	          from frequency_counts	          where value_percentile >$4	          limit 1)	order by 1,2,3'	using  table_name, field_name, frequency_threshold, value_threshold, target_server;END IF;END;$BODY$	LANGUAGE plpgsql VOLATILE	COST 100	ROWS 1000;ALTER FUNCTION ascendco.find_rare_and_large(text,text,int,int,text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:form_template_get_name.sqlCREATE OR REPLACE FUNCTION ascendco.form_template_get_name (id_in uuid)     RETURNS citext AS$BODY$-- Need to put the select as an expression *inside* the COALESCE, or else it never fires on NULL. D'oh!-- Not the same in a straight select for Reasons That I Do Not Undestand.-- https://stackoverflow.com/questions/65973653/SELECT coalesce((SELECT name_ FROM ascendco.form_template WHERE id = id_in),'');$BODY$  LANGUAGE SQL;ALTER FUNCTION ascendco.form_template_get_name (uuid)	OWNER TO user_reporting;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:hsys_get_facility_ids.sqlCREATE OR REPLACE FUNCTION ascendco.hsys_get_facility_ids (hsys_id_in uuid)     RETURNS TABLE (facility_id uuid)LANGUAGE SQL STABLEAS$BODY$select id from facility where hsys_id = hsys_id_in;$BODY$;COMMENT ON FUNCTION ascendco.hsys_get_facility_ids (uuid) IS'Pass in a hsys ID and get back the IDs of all of its facilities.';ALTER FUNCTION ascendco.hsys_get_facility_ids (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:hsys_get_id_by_facility_id.sqlCREATE OR REPLACE FUNCTION ascendco.hsys_get_id_by_facility_id (facility_id_in uuid)     RETURNS uuidLANGUAGE sql STABLEAS$BODY$SELECT coalesce(    (SELECT hsys_id FROM ascendco.facility WHERE id = facility_id_in),    '00000000-0000-0000-0000-000000000000'::uuid);$BODY$;COMMENT ON FUNCTION ascendco.hsys_get_id_by_facility_id (uuid) IS'Pass in a facility ID name and get back its parent hsys ID, or a pseudo-null UUID.';ALTER FUNCTION ascendco.hsys_get_id_by_facility_id (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:hsys_get_id.sqlCREATE OR REPLACE FUNCTION ascendco.hsys_get_id (hsys_name_in citext)     RETURNS uuidLANGUAGE sql STABLEAS$BODY$SELECT coalesce(    (SELECT id FROM ascendco.hsys WHERE name_ = hsys_name_in),    '00000000-0000-0000-0000-000000000000'::uuid);$BODY$;COMMENT ON FUNCTION ascendco.hsys_get_id (citext) IS'Pass in a hsys name and get back its ID, or a pseudo-null UUID.';ALTER FUNCTION ascendco.hsys_get_id (citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:hsys_get_name_by_facility_id.sqlCREATE OR REPLACE FUNCTION ascendco.hsys_get_name_by_facility_id (facility_id_in uuid)     RETURNS citextLANGUAGE sql STABLEAS$BODY$SELECT coalesce(	(SELECT name_ FROM ascendco.hsys WHERE id = (select hsys_id  from facility where id = facility_id_in)),	'');$BODY$;COMMENT ON FUNCTION ascendco.hsys_get_name_by_facility_id (uuid) IS'Pass in a facility ID and get back the related hsys name.';ALTER FUNCTION ascendco.hsys_get_name_by_facility_id (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:hsys_get_name.sqlCREATE OR REPLACE FUNCTION ascendco.hsys_get_name (hsys_id_in uuid)     RETURNS citextLANGUAGE sql STABLEAS$BODY$-- Need to put the select as an expression *inside* the COALESCE, or else it never fires on NULL. D'oh!-- Not the same in a straight select for Reasons That I Do Not Undestand.-- https://stackoverflow.com/questions/65973653/SELECT coalesce((SELECT name_ FROM ascendco.hsys WHERE id = hsys_id_in),'');$BODY$;COMMENT ON FUNCTION ascendco.hsys_get_name (uuid) IS'Pass in a hsys ID and get back its name.';ALTER FUNCTION ascendco.hsys_get_name (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:inv_getdesc.sqlCREATE OR REPLACE FUNCTION ascendco.inv_getdesc (	inv_id_in        uuid,  -- Because this is declared as a uuid, the routine won't even run with an empty string, etc.	item_name_in     citext DEFAULT NULL)  -- Default NULL to make it possible to figure out if $2 was passed.RETURNS citextLANGUAGE plpgsql STABLE -- STABLE instead of VOLATILE for speed. Safe, in this case, as we're not changing the DB, or calling any kind of random function.COST 100AS $BODY$---------------------------------------------------------------------------- Set up the variables---------------------------------------------------------------------------DECLARE    final_out citext := '';    v_inv_id        uuid   := '00000000-0000-0000-0000-000000000000';    v_inv_no        citext := '';    v_item_id       uuid   := '00000000-0000-0000-0000-000000000000';    v_their_name    citext := '';    v_serial_no     citext := '';    v_item_name     citext := '';  -- Gets either $2 or lookup value.    v_description   citext := '';BEGIN    final_out := '';---------------------------------------------------------------------------- Load the necessary inv and item data, either from params or search----------------------------------------------------------------------------- No matter what, we need some details out of inv. Use COALESCE to avoid NULL checks later in the routine.    SELECT COALESCE (         id, '00000000-0000-0000-0000-000000000000'),           COALESCE (     inv_no,  ''),           COALESCE (    item_id, '00000000-0000-0000-0000-000000000000'),           COALESCE ( their_name, ''),           COALESCE (  serial_no, '')      INTO v_inv_id,           v_inv_no,           v_item_id,           v_their_name,           v_serial_no      FROM ascendco.inv      WHERE id = inv_id_in; -- Reminder: It's impossible to run this routine without a valid-looking UUID in $1. PG won't even try.-- Three term COALESCE ($2, subquery, '') to get either a name from $2, a lookup value, or an empty string, if all else fails.-- This may be subtly different from the 4D original, which doesn't appear to look up on an empty input.v_item_name = COALESCE                (item_name_in,                (SELECT name_ FROM ascendco.item WHERE item.id = v_item_id),                '');IF (v_item_name = '') THEN    v_item_name := 'NotLinked ' || v_their_name;END IF;IF (v_inv_no <> '') THEN    v_description := v_item_name || ' - ' || v_inv_no;ELSE    v_description := v_item_name;END IF;IF (v_serial_no <> '') THEN    v_description := v_description || ' (' || v_serial_no || ')';END IF;-- Eh? For some reason, I could *not* get serial number to concatenate into final_out directly...had to go with intermediate variable.  ¬Ø\_(„ÉÑ)_/¬Øfinal_out := v_description;-- Bit of console-like reporting for debugging./*RAISE NOTICE 'value of inv_id_in :       %', inv_id_in;RAISE NOTICE 'value item_name_in :       %', item_name_in;RAISE NOTICE 'value of v_inv_id :        %', v_inv_id;RAISE NOTICE 'value of v_inv_no :        %', v_inv_no;RAISE NOTICE 'value of v_item_id :       %', v_item_id;RAISE NOTICE 'value of v_their_name :    %', v_their_name;RAISE NOTICE 'value of v_item_name :     %', v_item_name;RAISE NOTICE 'value of v_serial_no :     %', v_serial_no;RAISE NOTICE 'value of v_description :   %', v_description;RAISE NOTICE 'value of final_out :       %', final_out;*/RETURN final_out;END;$BODY$;COMMENT ON FUNCTION ascendco.inv_getdesc (uuid, citext) IS'This is a Postgres version of the Inv_GetDesc (InvID {;ItemName}) function in IB/Sonar.';ALTER FUNCTION ascendco.inv_getdesc (uuid, citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:outlier_fix.sqlDROP FUNCTION IF EXISTS ascendco.outlier_fix;CREATE OR REPLACE FUNCTION ascendco.outlier_fix ()RETURNS TABLE (	schema_name  text,	table_name   text,	column_name  text,	id           uuid,	value_was    bigint,	set_to       bigint,	change_count bigint)AS $BODY$DECLARE    rule record;    now_ timestamptz = NOW();BEGIN	FOR rule IN SELECT * FROM ascendco.outlier_rule LOOP		EXECUTE FORMAT (       'INSERT INTO outlier_change (						outlier_rule_id,						set_to,						id,						value_was)			   SELECT %6$L,						%5$s,						%2$I.id,						%2$I.%3$I			     FROM %1$I.%2$I			    WHERE %3$I > %4$s				   ON CONFLICT(id,outlier_rule_id) DO UPDATE SET					   value_was = EXCLUDED.value_was,					   set_to    = EXCLUDED.set_to          RETURNING outlier_rule_id,			          id,			          value_was,			          set_to			          change_count;			 UPDATE %1$I.%2$I			    SET %3$I = %5$s			  WHERE %3$I > %4$s;',				rule.schema_name,				rule.table_name,				rule.column_name,				rule.threshold,				rule.set_to,				rule.id);  END LOOP;  RETURN QUERY EXECUTE ('		SELECT outlier_rule.schema_name,              outlier_rule.table_name,              outlier_rule.column_name,              outlier_change.id,              outlier_change.value_was,              outlier_change.set_to,              outlier_change.change_count		  FROM outlier_change		  JOIN outlier_rule ON (outlier_rule.id = outlier_change.outlier_rule_id)		 WHERE last_changed_dts = $1')	USING now_;END;$BODY$	LANGUAGE plpgsql;ALTER FUNCTION ascendco.outlier_fix()	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:push_target_add_if_missing.sqlDROP FUNCTION IF EXISTS ascendco.push_target_add_if_missing(citext, citext, citext, citext);CREATE OR REPLACE FUNCTION ascendco.push_target_add_if_missing (     schema_name_in   citext,     target_name_in   citext,     unique_path_in   citext,     target_type_in   citext)RETURNS integer AS$BODY$DECLARE   id_out integer = 0;BEGIN-- Insert the value, if it's missing.INSERT INTO dba.push_target  (schema_name,    target_name,     unique_path,    target_type)                      VALUES (schema_name_in, target_name_in,  unique_path_in, target_type_in)                 ON CONFLICT DO NOTHING;-- The ID should be there, either historically or becase it was just added.     SELECT id       FROM dba.push_target      WHERE schema_name = schema_name_in        AND target_name = target_name_in        AND unique_path = unique_path_in        AND target_type = target_type_in       INTO id_out; return id_out as id;END$BODY$  LANGUAGE plpgsql;ALTER FUNCTION ascendco.push_target_add_if_missing(citext, citext, citext, citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:rcl_get_record_id.sqlCREATE OR REPLACE FUNCTION ascendco.rcl_get_record_id (rcl_id uuid)	RETURNS pg_catalog.uuidAS $BODY$SELECT record_id  FROM record_changes_log WHERE id = $1;$BODY$	LANGUAGE sql VOLATILE	COST 100;ALTER FUNCTION ascendco.rcl_get_record_id (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:system_analyze_after_deletions.sqlCREATE OR REPLACE FUNCTION ascendco.system_analyze_after_deletions()	RETURNS pg_catalog.voidAS $BODY$BEGIN	analyze ascendco.analytic_productivity;	analyze ascendco.analytic_sterilizer_load;	analyze ascendco.analytic_sterilizer_loadinv;	analyze ascendco.item_type;	analyze ascendco.specialty;	analyze ascendco.sterilize_method;END;$BODY$	LANGUAGE plpgsql VOLATILE	COST 100;ALTER FUNCTION ascendco.system_analyze_after_deletions()	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:system_delete_marked.sqlCREATE OR REPLACE FUNCTION ascendco.system_delete_marked()RETURNS table(    schema text,    table_name text,    count int)    AS $BODY$BEGINRETURN QUERY   select 'ascendco','analytic_productivity', deleted_count from table_delete_marked('ascendco.analytic_productivity') union all   select 'ascendco','analytic_sterilizer_load', deleted_count from table_delete_marked('ascendco.analytic_sterilizer_load') union all   select 'ascendco','analytic_sterilizer_loadinv', deleted_count from table_delete_marked('ascendco.analytic_sterilizer_loadinv') union all   select 'ascendco','item_type', deleted_count from table_delete_marked('ascendco.item_type') union all   select 'ascendco','specialty', deleted_count from table_delete_marked('ascendco.specialty') union all   select 'ascendco','sterilize_method', deleted_count from table_delete_marked('ascendco.sterilize_method');END;$BODY$	 LANGUAGE plpgsql;COMMENT ON FUNCTION ascendco.system_delete_marked() IS '/* This code is built in IceBerg by PgBuild_ClearDeletedRecords. It reads the pgIOMap definitions to see which table(s) haveauto-delete enabled. Do *not* update this method by hand!Use PgBuild_ClearDeletedRecords on Dev to change the rules.After that, push the code to the Postgres database. The point here is to define the rules in Dev and enforcethem universally on Postgres. See:https://ascendco.atlassian.net/wiki/spaces/SON/pages/767459342/Deleting+Records+on+Postgres*/';ALTER FUNCTION ascendco.system_delete_marked() 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:table_delete_marked.sqlCREATE OR REPLACE FUNCTION ascendco.table_delete_marked (table_name regclass, out deleted_count int)	RETURNS intAS $BODY$DECLARE	schema_name_text text := (select relnamespace::regnamespace::text							from pg_catalog.pg_class						   where oid = table_name);   table_name_text  text := table_name::text;BEGIN/* Woah! What's happening? EXECUTE? Yes, concatenation is safe here because table_nameis ::regclass, not text. The regclass magic type is designed to be injection proof.For more involved work, see format(), quote_ident(), and commentary/docs on dynamic SQLgenerally. It's all be thought through well. Also seehttps://ascendco.atlassian.net/wiki/spaces/SON/pages/767459342/Deleting+Records+on+Postgres*/	EXECUTE 'delete from ' || schema_name_text || '.' || table_name_text || ' where marked_for_deletion = true;';	GET DIAGNOSTICS deleted_count = ROW_COUNT;END;$BODY$	LANGUAGE plpgsql;ALTER FUNCTION ascendco.table_delete_marked (regclass, out int)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:ascendco:work_get_source_name.sqlCREATE OR REPLACE FUNCTION ascendco.work_get_source_name (activity_in citext)RETURNS citextLANGUAGE sql IMMUTABLEAS $BODY$SELECTCASE WHEN activity_in =          'Activity'         THEN  'Activity'::citext	 WHEN activity_in =          'Assembly'         THEN  'Assembly'::citext	 WHEN activity_in =          'Collection Inv'   THEN  'CollectionInv'::citext	 WHEN activity_in =          'Sterilize Inv'    THEN  'SterilizerLoad_Inv'::citext -- Catch this first, pattern below would catch it .	 WHEN left(activity_in,9) =  'Sterilize'        THEN  'SterilizerLoad'::citext	 WHEN activity_in =          'Case Cart'        THEN  'Scan'::citext	 WHEN activity_in =          'Decon Receiving'  THEN  'Scan'::citext	 WHEN activity_in =          'Decon Sink'       THEN  'Scan'::citext	 WHEN activity_in =          'Deliver Inv'      THEN  'Scan'::citext	 ELSE                                                 ('Unknown ' || activity_in)::citextEND as source_name_out;$BODY$;COMMENT ON FUNCTION ascendco.work_get_source_name (citext) IS'Translate activity descriptions back to the source IB table. In IB, the activity tags are set in PgIO_Work_xxx_ToObj methods.';ALTER FUNCTION ascendco.work_get_source_name (citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:check_if_patch_has_been_run_before.sqlCREATE OR REPLACE FUNCTION dba.check_if_patch_has_been_run_before (patch_name_in text) RETURNS booleanAS $BODY$DECLARE  row_count int8;BEGINSELECT count(*) INTO row_count  FROM patch_log WHERE patch_name = patch_name_in;IF (row_count = 0) THEN  RETURN false;ELSE  RAISE EXCEPTION USING	 message = 'Patch has been run before',	 hint = 'Patches should be run in order, and may not be reapplied.',	 errcode = 'KC001'; -- Custom code for 'Patch has been run before.'END IF;END;$BODY$  LANGUAGE plpgsql VOLATILE  COST 100;ALTER FUNCTION dba.check_if_patch_has_been_run_before (text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:column_tetris.sql/* Table_in is a 'regclass'. It's a way of avoiding SQL injection problems,not that there is a chance of that here. (No dynamic SQL.) The really nicepart is that you can pass in table_name or schema_name.table_name this wayand either work magically.*/CREATE OR REPLACE FUNCTION dba.column_tetris (table_in regclass)	RETURNS table (	  column_name           text,	  type_name             text,	  type_align            text,	  alignment_description text,	  type_length           int2,	  suggestioned_position int8,	  current_position      int2	)AS $BODY$   SELECT a.attname::text  AS column_name,          t.typname::text  AS type_name,          t.typalign::text AS type_align,          CASE             WHEN typalign = 'c' THEN 'char alignment, no alignment needed'             WHEN typalign = 's' THEN 'short alignment, 2 bytes on most machines'             WHEN typalign = 'i' THEN 'int alignment, 4 bytes on most machines'             WHEN typalign = 'd' THEN 'double alignment, 8 bytes on many machines, but by no means all'             ELSE 'Unexpected typalign ' || typalign			END AS alignment_description,          t.typlen   AS type_length,          ROW_NUMBER () OVER (ORDER BY t.typlen DESC,a.attname) as suggested_position,          a.attnum   AS currrent_position     FROM pg_class c     JOIN pg_attribute a ON (a.attrelid = c.oid)     JOIN pg_type t ON (t.oid = a.atttypid)    WHERE c.relname = table_in::name AND          a.attnum >= 0 ORDER BY t.typlen DESC,a.attname;$BODY$	LANGUAGE sql;COMMENT ON FUNCTION dba.column_tetris (regclass) IS '/*Adapted from this excellent blob post:https://blog.2ndquadrant.com/on-rocks-and-sand/*/';ALTER FUNCTION dba.column_tetris (regclass)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:explain_this.sqlCREATE OR REPLACE FUNCTION dba.explain_this(IN l_query text, OUT explain json)  RETURNS SETOF pg_catalog.json   AS $BODY$BEGIN  RETURN QUERY EXECUTE 'explain (format json) ' || l_query;END;$BODY$  LANGUAGE plpgsql VOLATILE STRICT SECURITY DEFINER  COST 100  ROWS 1000;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:field_data_profile.sqlCREATE OR REPLACE FUNCTION dba.field_data_profile (table_name text, field_name text)  RETURNS TABLE (  	distinct_value extensions.citext,   	page_correlation float4,   	field_cardinality int8,   	rows_count int8,   	value_frequency int8,   	selectivity numeric,   	proportion_chart text)   	AS $BODY$BEGINRETURN QUERY EXECUTE 'with table_estimate as (select correlation  from pg_stats   where tablename = ''' || table_name || ''' and         attname   = ''' || field_name || '''),          distinct_values as  (select distinct ' || quote_ident(field_name) || '::citext as distinct_value,         count(*) as frequency     from ' || quote_ident(table_name) || ' group by ' || quote_ident(field_name) || '),  row_figures as  (select count(*) as rows_count     from ' || quote_ident(table_name) || ') select  distinct_values.distinct_value,        table_estimate.correlation as page_correlation,        (select count(*) as field_cardinality from distinct_values),		 row_figures.rows_count,		 distinct_values.frequency as value_frequency,          round((distinct_values.frequency::decimal / row_figures.rows_count::decimal),3) as value_selectivity,        repeat(' || quote_literal('‚ñÄ') || ', ((distinct_values.frequency::decimal / row_figures.rows_count::decimal)*100)::int) as proportion_chart           from distinct_values,        table_estimate,        row_figures        '    	using  table_name, field_name;END;$BODY$  LANGUAGE plpgsql VOLATILE  COST 100  ROWS 1000;  ALTER FUNCTION dba.field_data_profile(text, text)	OWNER TO user_bender;  --Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:numeric_field_analysis.sqlDROP FUNCTION IF EXISTS dba.numeric_field_analysis(text,text);-- This is going to be a bit slow as it has to grind through the data...not all of which is indexed.CREATE OR REPLACE FUNCTION dba.numeric_field_analysis (table_name_in text, field_name text)  RETURNS TABLE (	table_name text, 	column_name text, 	min int4, 	max int4, 	avg float4, 	variance float4, 	stddev float4,     stddev_1_above float4,    stddev_1_below float4,    stddev_2_above float4,    stddev_2_below float4,    stddev_3_above float4,    stddev_3_below float4,    stddev_4_above float4,    stddev_4_below float4,    stddev_5_above float4,    stddev_5_below float4,	q1 float4, 	q2 float4, 	q3 float4, 	p95 float4, 	iqr float4,		stddev_1_above_count int4,	stddev_1_above_min float4,	stddev_1_above_max float4,	stddev_1_below_count int4,	stddev_1_below_min float4,	stddev_1_below_max float4,	stddev_2_above_count int4,	stddev_2_above_min float4,	stddev_2_above_max float4,	stddev_2_below_count int4,	stddev_2_below_min float4,	stddev_2_below_max float4,	stddev_3_above_count int4,	stddev_3_above_min float4,	stddev_3_above_max float4,	stddev_3_below_count int4,	stddev_3_below_min float4,	stddev_3_below_max float4,	stddev_4_above_count int4,	stddev_4_above_min float4,	stddev_4_above_max float4,	stddev_4_below_count int4,	stddev_4_below_min float4,	stddev_4_below_max float4,	stddev_5_above_count int4,	stddev_5_above_min float4,	stddev_5_above_max float4,	stddev_5_below_count int4,	stddev_5_below_min float4,	stddev_5_below_max float4,	q3_count int4,	q3_min float4,	q3_max float4,		p95_count int4,	p95_min float4,	p95_max float4,		p99_count int4,	p99_min float4,	p99_max	float4)	AS $BODY$  BEGIN    RETURN QUERY EXECUTE        'with 	overall_stats as 	(select *	   from numeric_field_stats(' || quote_literal(table_name_in) || ',' || quote_literal(field_name) || ')	 ), 	q3_stats as 	(select count(*)::int4 as q3_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as q3_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as q3_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select q3 from overall_stats)),  	stddev_stats as 	(select count(*)::int4 as stddev_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select stddev from overall_stats)),  	stddev_1_above_stats as 	(select count(*)::int4 as stddev_1_above_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_1_above_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_1_above_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select stddev_1_above from overall_stats)), 	stddev_1_below_stats as 	(select count(*)::int4 as stddev_1_below_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_1_below_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_1_below_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' <= (select stddev_1_below from overall_stats)), 	stddev_2_above_stats as 	(select count(*)::int4 as stddev_2_above_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_2_above_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_2_above_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select stddev_2_above from overall_stats)), 	stddev_2_below_stats as 	(select count(*)::int4 as stddev_2_below_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_2_below_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_2_below_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || '<= (select stddev_2_below from overall_stats)), 	stddev_3_above_stats as 	(select count(*)::int4 as stddev_3_above_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_3_above_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_3_above_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select stddev_3_above from overall_stats)), 	stddev_3_below_stats as 	(select count(*)::int4 as stddev_3_below_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_3_below_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_3_below_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' <= (select stddev_3_below from overall_stats)), 	stddev_4_above_stats as 	(select count(*)::int4 as stddev_4_above_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_4_above_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_4_above_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select stddev_4_above from overall_stats)), 	stddev_4_below_stats as 	(select count(*)::int4 as stddev_4_below_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_4_below_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_4_below_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' <= (select stddev_4_below from overall_stats)), 	stddev_5_above_stats as 	(select count(*)::int4 as stddev_5_above_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_5_above_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_5_above_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select stddev_5_above from overall_stats)), 	stddev_5_below_stats as 	(select count(*)::int4 as stddev_5_below_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as stddev_5_below_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as stddev_5_below_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' <= (select stddev_5_below from overall_stats)),	  	p95_stats as 	(select count(*)::int4 as p95_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as p95_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as p95_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select p95 from overall_stats)),	p99_stats as 	(select count(*)::int4 as p99_count,             coalesce(min(' || quote_ident(field_name) || '),0)::float4 as p99_min,             coalesce(max(' || quote_ident(field_name) || '),0)::float4 as p99_max		  	   from '|| quote_ident(table_name_in) || '	  where ' || quote_ident(field_name) || ' >= (select p99 from overall_stats))   	select overall_stats.table_name,           overall_stats.column_name,           overall_stats.min,           overall_stats.max,           overall_stats.avg,           overall_stats.variance,           overall_stats.stddev,           stddev_1_above,           stddev_1_below,           stddev_2_above,           stddev_2_below,           stddev_3_above,           stddev_3_below,           stddev_4_above,           stddev_4_below,           stddev_4_above,           stddev_5_below,                      overall_stats.q1,           overall_stats.q2,           overall_stats.q3,           overall_stats.p95,           overall_stats.iqr,           stddev_1_above_stats.stddev_1_above_count,           stddev_1_above_stats.stddev_1_above_min,           stddev_1_above_stats.stddev_1_above_max,           stddev_1_below_stats.stddev_1_below_count,           stddev_1_below_stats.stddev_1_below_min,           stddev_1_below_stats.stddev_1_below_max,           stddev_2_above_stats.stddev_2_above_count,           stddev_2_above_stats.stddev_2_above_min,           stddev_2_above_stats.stddev_2_above_max,           stddev_2_below_stats.stddev_2_below_count,           stddev_2_below_stats.stddev_2_below_min,           stddev_2_below_stats.stddev_2_below_max,           stddev_3_above_stats.stddev_3_above_count,           stddev_3_above_stats.stddev_3_above_min,           stddev_3_above_stats.stddev_3_above_max,           stddev_3_below_stats.stddev_3_below_count,           stddev_3_below_stats.stddev_3_below_min,           stddev_3_below_stats.stddev_3_below_max,           stddev_4_above_stats.stddev_4_above_count,           stddev_4_above_stats.stddev_4_above_min,           stddev_4_above_stats.stddev_4_above_max,           stddev_4_below_stats.stddev_4_below_count,           stddev_4_below_stats.stddev_4_below_min,           stddev_4_below_stats.stddev_4_below_max,           stddev_5_above_stats.stddev_5_above_count,           stddev_5_above_stats.stddev_5_above_min,           stddev_5_above_stats.stddev_5_above_max,           stddev_5_below_stats.stddev_5_below_count,           stddev_5_below_stats.stddev_5_below_min,           stddev_5_below_stats.stddev_5_below_max,                      q3_stats.q3_count,           q3_stats.q3_min,           q3_stats.q3_max,                      p95_stats.p95_count,           p95_stats.p95_min,           p95_stats.p95_max,                      p99_stats.p99_count,           p99_stats.p99_min,           p99_stats.p99_max      from overall_stats,           stddev_1_above_stats,           stddev_1_below_stats,           stddev_2_above_stats,           stddev_2_below_stats,           stddev_3_above_stats,           stddev_3_below_stats,           stddev_4_above_stats,           stddev_4_below_stats,           stddev_5_above_stats,           stddev_5_below_stats,           q3_stats,           p95_stats,           p99_stats'                                           USING table_name_in, field_name;	END;$BODY$  LANGUAGE plpgsql;ALTER FUNCTION dba.numeric_field_analysis (text, text) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:numeric_field_buckets.sqlDROP FUNCTION IF EXISTS dba.numeric_field_buckets(text,text,int4);-- Calculate a bunch of stats on a numeric field to help identify outliers.CREATE OR REPLACE FUNCTION dba.numeric_field_buckets (table_name_in text, field_name text, bucket_count int4)  RETURNS TABLE (	table_name text, 	column_name text, 	bucket int4,	min int4, 	max int4, 	count int8,	bar text)		AS $BODY$  BEGIN    RETURN QUERY EXECUTE    'with 	range_stats as	(select min(' || quote_ident(field_name) || '),			max(' || quote_ident(field_name) || ')			 		   from ' || quote_ident(table_name_in) || '),			histogram as	(select  '|| quote_literal(table_name_in) || ' as table_name,         	 '|| quote_literal(field_name)    || ' as column_name,			  width_bucket(num_inst, range_stats.min, range_stats.max, $3 - 1) as bucket,         	  min(' || quote_ident(field_name) || '),         	  max(' || quote_ident(field_name) || '),			  count(*) as frequency		    from ' || quote_ident(table_name_in) || ',			 range_stats	group by bucket    	order by bucket)		 select table_name,			column_name,			bucket,			min,			max,			frequency,			repeat ('|| quote_literal('‚ñá') || ',				   (frequency::float					 / max(frequency) over() * ($3 - 1) * 2)::int			) as bar	   from histogram'	    USING table_name, field_name, bucket_count;	END;$BODY$  LANGUAGE plpgsql;ALTER FUNCTION dba.numeric_field_buckets (text, text, int4) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:numeric_field_stats.sqlDROP FUNCTION IF EXISTS dba.numeric_field_stats(text,text);-- Calculate a bunch of stats on a numeric field to help identify outliers.CREATE OR REPLACE FUNCTION dba.numeric_field_stats (table_name_in text, field_name text)  RETURNS TABLE (	table_name text, 	column_name text, 	min int4, 	max int4, 	avg float4, 	variance float4, 	stddev float4,     stddev_1_above float4,    stddev_1_below float4,    stddev_2_above float4,    stddev_2_below float4,    stddev_3_above float4,    stddev_3_below float4,    stddev_4_above float4,    stddev_4_below float4,    stddev_5_above float4,    stddev_5_below float4,	q1 float4, 	q2 float4, 	q3 float4, 	p95 float4, 	p99 float4, 	iqr float4)	AS $BODY$  BEGIN    RETURN QUERY EXECUTE         'with 	 stats as	 (select  coalesce(min( ' || quote_ident(field_name) || '),0)::int4 as min,			  coalesce(max( ' || quote_ident(field_name) || '),0)::int4 as max,			  coalesce(avg( ' || quote_ident(field_name) || '),0)::float4 as avg,			  			  coalesce(variance(' || quote_ident(field_name) || '),0)::float4 as variance,			  coalesce(stddev(' || quote_ident(field_name) || '),0)::float4 as stddev,			  			  coalesce(percentile_cont(0.25) within group (order by ' || quote_ident(field_name) || ' asc),0)::float4 as q1,			  coalesce(percentile_cont(0.50) within group (order by ' || quote_ident(field_name) || ' asc),0)::float4 as q2,			  coalesce(percentile_cont(0.75) within group (order by ' || quote_ident(field_name) || ' asc),0)::float4 as q3,			  coalesce(percentile_cont(0.95) within group (order by ' || quote_ident(field_name) || ' asc),0)::float4 as p95,			  coalesce(percentile_cont(0.99) within group (order by ' || quote_ident(field_name) || ' asc),0)::float4 as p99	   from ' || quote_ident(table_name_in) || ')   	 select ' || quote_literal(table_name_in) || ' as table_name,         	' || quote_literal(field_name) || ' as column_name,             min,             max,             avg,             variance,             stddev,             avg + (stddev * 1)::float4 as stddev_1_above,             avg - (stddev * 1)::float4 as stddev_1_below,             avg + (stddev * 2)::float4 as stddev_2_above,             avg - (stddev * 2)::float4 as stddev_2_below,             avg + (stddev * 3)::float4 as stddev_3_above,             avg - (stddev * 3)::float4 as stddev_3_below,             avg + (stddev * 4)::float4 as stddev_4_above,             avg - (stddev * 4)::float4 as stddev_4_below,             avg + (stddev * 5)::float4 as stddev_5_above,             avg - (stddev * 5)::float4 as stddev_5_below,                          q1,             q2,             q3,             p95,             p99, 			(q3 - q1)::float4 as iqr				from stats'	    USING table_name, field_name;	END;$BODY$  LANGUAGE plpgsql;ALTER FUNCTION dba.numeric_field_stats (text, text) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:patch_log_insert.sqlCREATE OR REPLACE FUNCTION dba.patch_log_insert(	patch_name_in     citext,	description_in    citext,	patch_hash_in     text)RETURNS patch_logAS $BODY$INSERT INTO patch_log (	           patch_name,	           description,	           patch_hash)       VALUES (patch_name_in,	           description_in,	           patch_hash_in)       RETURNING *$BODY$	LANGUAGE sql;ALTER FUNCTION dba.patch_log_insert (citext,citext,text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:push_log_recent.sqlDROP FUNCTION IF EXISTS     dba.push_log_recent (citext,int4);CREATE OR REPLACE FUNCTION  dba.push_log_recent (       table_name_in  citext,       limit_in       int4   DEFAULT 20)RETURNS TABLE (         table_name     citext,         minutes_old    int4,         records_count  int4,         server_name    citext,         push_log_id    citext) -- Eh? I reformat it for 4D's UUID style.LANGUAGE plpgsql STABLEAS $BODY$BEGINRETURN QUERY   select push_log.ib_table_name,          minutes_old (push_log.push_dts) as minutes_old,          push_log.records_count,          coalesce(data_file_info.server_name_, 'Unknown server with ID ' || format_uuid(push_log.data_file_id))::citext AS server_name,          format_uuid (push_log.id)::citext AS push_log_id     from push_logleft join data_file_info on data_file_info.id = push_log.data_file_id    where ib_table_name = table_name_in  order by push_dts desc   limit limit_in;END$BODY$;COMMENT ON FUNCTION dba.push_log_recent (citext,int4) IS'Pass in a table name and an optional imit to get the most recent information back from ascendco.push_log.';ALTER FUNCTION dba.push_log_recent (citext,int4)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:show_database_rights.sqlCREATE OR REPLACE FUNCTION dba.show_database_rights(d_name text)	RETURNS TABLE(		database_name text, 		user_name name, 		connect text, 		"create" text, 		temporary text)		AS $BODY$  	select d_name,				 u.usename,         CASE WHEN has_database_privilege(u.usename, 'nautilus', 'connect') = TRUE then 'X' ELSE ' ' END AS connect,         CASE WHEN has_database_privilege(u.usename, 'nautilus', 'create') = TRUE then 'X' ELSE ' ' END AS create,         CASE WHEN has_database_privilege(u.usename, 'nautilus', 'temporary') = TRUE then 'X' ELSE ' ' END AS temporary				  	from  pg_user u	order by u.usename;$BODY$	LANGUAGE sql	STABLE;ALTER FUNCTION dba.show_database_rights(text) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:show_functions.sqlCREATE OR REPLACE FUNCTION dba.show_functions()  RETURNS TABLE(  	schema_name name,	function_name name,	function_type name,	function_owner name,	run_as text,	language name,	return_type name,	strict text,	returns_set text,	comment text)AS $BODY$ 	SELECT	n.nspname AS schema_name,	P.proname AS function_name,	typ.typname AS function_type,	pg_get_userbyid ( P.proowner ) AS function_owner,	CASE	WHEN P.prosecdef = TRUE THEN 'owner' ELSE 'invoker' END AS run_as,		l.lanname AS language,	typ.typname AS return_type,	CASE WHEN P.proisstrict = TRUE THEN 'True' ELSE 'False' END AS strict,	CASE WHEN P.proretset =   TRUE THEN 'True' ELSE 'False' END AS returns_set,	obj_description ( P.oid ) AS COMMENT FROM	pg_proc	P LEFT JOIN pg_type typ ON typ.oid = P.prorettype	LEFT JOIN pg_namespace typns ON typns.oid = typ.typnamespace	LEFT JOIN pg_namespace n ON n.oid = P.pronamespace	LEFT JOIN pg_language l ON l.oid = P.prolang	LEFT JOIN pg_user u ON P.proowner = u.usesysid	LEFT JOIN pg_database d ON d.datname = current_database () WHERE	P.prokind IN ('f','p') -- Function or Procedure	AND n.nspname <> 'information_schema' 	AND n.nspname <> 'pg_catalog' ORDER BY	n.nspname,	P.proname ASC 	$BODY$	LANGUAGE sql STABLE	COST 100	ROWS 1000;	ALTER FUNCTION dba.show_functions () 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:show_owners.sqlCREATE OR REPLACE FUNCTION dba.show_owners()  RETURNS TABLE(  	schema_name name,   	object_name name,  	owner_name name,  	object_type text)   	AS $BODY$SELECT 	   nsp.nspname AS object_schema,       cls.relname AS object_name,        rol.rolname AS owner_name,        case cls.relkind         WHEN 'r' THEN 'TABLE'         WHEN 'v' THEN 'VIEW'         WHEN 'm' THEN 'MATERIALIZED_VIEW'         WHEN 'i' THEN 'INDEX'         WHEN 'S' THEN 'SEQUENCE'         WHEN 'c' THEN 'TYPE'         ELSE cls.relkind::text       END AS object_typeFROM pg_class cls  JOIN pg_roles rol ON rol.oid = cls.relowner  JOIN pg_namespace nsp ON nsp.oid = cls.relnamespaceWHERE nsp.nspname NOT IN ('information_schema', 'pg_catalog') AND			nsp.nspname NOT LIKE 'pg_toast%'ORDER BY  nsp.nspname, cls.relname;$BODY$  LANGUAGE sql STABLE  COST 100  ROWS 1000;  ALTER FUNCTION dba.show_owners()	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:show_schema_rights.sqlCREATE OR REPLACE FUNCTION dba.show_schema_rights(s_name text)	RETURNS TABLE( 		schema_name text,  		user_name name,  		usage text,  		"create" text) 		AS $BODY$  	select s_name,				 u.usename,	         CASE WHEN has_schema_privilege(u.usename, s_name, 'usage') = TRUE then 'X' ELSE ' ' END AS usage,         CASE WHEN has_schema_privilege(u.usename, s_name, 'create') = TRUE then 'X' ELSE ' ' END AS create				  	from  pg_user u	order by u.usename;$BODY$	LANGUAGE sql	STABLE;ALTER FUNCTION dba.show_schema_rights(text) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:show_table_rights.sqlCREATE OR REPLACE FUNCTION dba.show_table_rights(t_name text)	RETURNS TABLE(		"Table_Name" name, 		"User_Name" name, 		"SELECT" text, 		"INSERT" text, 		"UPDATE" text, 		"DELETE" text, 		"TRUNCATE" text, 		"REFERENCES" text, 		"TRIGGER" text)AS $BODY$	SELECT 				t.tablename,        u.usename,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', t.tablename), 'select') = TRUE then 'X' ELSE ' ' END AS select,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', t.tablename), 'insert')= TRUE then 'X' ELSE ' ' END AS insert,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', t.tablename), 'update') = TRUE then 'X' ELSE ' ' END AS update,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', t.tablename), 'delete') = TRUE then 'X' ELSE ' ' END AS delete,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', t.tablename), 'truncate') = TRUE then 'X' ELSE ' ' END AS truncate,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', t.tablename), 'references') = TRUE then 'X' ELSE ' ' END AS references,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', t.tablename), 'trigger') = TRUE then 'X' ELSE ' ' END AS trigger					FROM    pg_tables t,         					pg_user u                 	WHERE	  t.tablename = t_name		ORDER BY u.usename;$BODY$	LANGUAGE sql	STABLE;ALTER FUNCTION dba.show_table_rights(text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:show_view_rights.sqlCREATE OR REPLACE FUNCTION dba.show_view_rights(v_name text)	RETURNS TABLE(		"View_Name" name,		"User_Name" name,		"SELECT" text,		"INSERT" text,		"UPDATE" text,		"DELETE" text,		"TRUNCATE" text,		"REFERENCES" text,		"TRIGGER" text)AS $BODY$	SELECT		v.viewname,        u.usename,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', v.viewname), 'select') = TRUE then 'X' ELSE ' ' END AS select,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', v.viewname), 'insert')= TRUE then 'X' ELSE ' ' END AS insert,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', v.viewname), 'update') = TRUE then 'X' ELSE ' ' END AS update,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', v.viewname), 'delete') = TRUE then 'X' ELSE ' ' END AS delete,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', v.viewname), 'truncate') = TRUE then 'X' ELSE ' ' END AS truncate,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', v.viewname), 'references') = TRUE then 'X' ELSE ' ' END AS references,        CASE WHEN has_table_privilege(u.usename, concat(schemaname, '.', v.viewname), 'trigger') = TRUE then 'X' ELSE ' ' END AS trigger	FROM    pg_views v,			pg_user u	WHERE	  v.viewname = v_name	ORDER BY u.usename;$BODY$	LANGUAGE sql	STABLE;ALTER FUNCTION dba.show_view_rights(text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:test_case_setup.sql-- Woah, *way* too hard to call this by hand, I'm setting up a test case setup screen in IB. -- DPA-- Earlier signatures here:DROP FUNCTION IF EXISTS dba.test_case_setup (citext, citext, citext, citext, citext, text, citext, citext, citext, jsonb, test_outcome, user_name[], bool);DROP FUNCTION IF EXISTS dba.test_case_setup (citext, citext, citext, citext, citext, text, citext, citext, citext, jsonb, test_outcome, user_name[], bool, citext, citext);CREATE OR REPLACE FUNCTION dba.test_case_setup (	object_class_in             citext,	object_schema_in            citext,	object_name_in              citext,	function_signature_in       citext,	test_name_in                citext,	test_code_in                text,	expected_response_in        citext,	expected_error_in           citext,	response_type_in            citext,	comparison_options_in       jsonb,	expected_outcome_in         test_outcome,	run_as_in                   user_name[],  -- array of users to run as. This is saved as a user_name[], which checks each value against a custom domain to detect bogus names.	modifies_data_in            bool DEFAULT true,	rds_only_in                 bool DEFAULT false,	setup_code_in               citext DEFAULT '',	teardown_code_in            citext DEFAULT '')RETURNS test_caseAS $BODY$INSERT INTO test_case (               object_class,               object_schema,               object_name,               function_signature,               test_name,               test_code,               expected_response,               expected_error,               response_type,               comparison_options,               expected_outcome,               run_as,               modifies_data,               rds_only,               setup_code,               teardown_code)       VALUES (               object_class_in,               object_schema_in,               object_name_in,               function_signature_in,               test_name_in,               test_code_in,               expected_response_in,               expected_error_in,               response_type_in,               comparison_options_in,               expected_outcome_in,               run_as_in,               modifies_data_in,               rds_only_in,               setup_code_in,               teardown_code_in)-- Using a synthetic uuid id field, but there's also a uniqueness check on-- object_class,object_schema,object_name,function_signature,test_name		ON CONFLICT ON CONSTRAINT test_case_unique_signature			DO UPDATE SET			   test_code               = test_code_in,			   expected_response       = expected_response_in,			   expected_error          = expected_error_in,			   response_type           = response_type_in,			   comparison_options      = comparison_options_in,			   expected_outcome        = expected_outcome_in,			   run_as                  = run_as_in,			   modifies_data           = modifies_data_in,			   rds_only                = rds_only_in,			   setup_code              = setup_code_in,			   teardown_code           = teardown_code_in       RETURNING *;$BODY$	LANGUAGE sql;ALTER FUNCTION dba.test_case_setup (citext, citext, citext, citext, citext, text, citext, citext, citext, jsonb, test_outcome, user_name[], bool,  bool, citext, citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:test_result_insert.sqlCREATE OR REPLACE FUNCTION dba.test_result_insert(	test_case_id_in    uuid,	test_passed_in     bool,	actual_outcome_in  test_outcome,	user_name_in       user_name,	patch_log_id_in    uuid   DEFAULT NULL,	actual_response_in citext DEFAULT '',	actual_error_in    citext DEFAULT '',	diagnostics_in     citext DEFAULT '',	summary_in         citext DEFAULT '',	results_json_in    jsonb  DEFAULT '{}'::jsonb)RETURNS test_resultAS $BODY$INSERT INTO test_result (	           test_case_id,	           actual_outcome,	           test_passed,	           patch_log_id,	           actual_response,	           actual_error,	           summary,	           diagnostics,	           results_json,	           user_name)       VALUES (test_case_id_in,	           actual_outcome_in,	           test_passed_in,	           patch_log_id_in,	           actual_response_in,	           actual_error_in,	           summary_in,	           diagnostics_in,	           results_json_in,	           user_name_in::user_name) -- user_name is a custom domain.		ON CONFLICT ON CONSTRAINT test_result_case_and_user_unique			DO UPDATE SET			   actual_outcome  = actual_outcome_in,               test_passed     = test_passed_in,               patch_log_id    = patch_log_id_in,               actual_response = actual_response_in,               actual_error    = actual_error_in,               summary         = summary_in,               diagnostics     = diagnostics_in,               results_json    = results_json_in,               user_name       = user_name_in::user_name -- user_name is a custom domain       RETURNING *$BODY$	LANGUAGE sql;ALTER FUNCTION dba.test_result_insert (uuid,bool,test_outcome,user_name,uuid,citext,citext,citext,citext,jsonb)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:view_get_column_descriptions.sql/*This version is gnarly looking, the Cool Kids say it's "faster" than a morestraightforward search on information_schema.columns. I've already writtenthe information_schema one, so I saved it out as a disabled script.*/CREATE OR REPLACE FUNCTION dba.view_get_column_descriptions (view_name_in text)	RETURNS TABLE(		"Position" int2,		"Name"     text,		"Type"     text		)AS $BODY$SELECT attnum                  AS "Position",       attname::text           AS "Name",       atttypid::regtype::text AS "Type"FROM   pg_attributeWHERE  attrelid = view_name_in::regclass AND    -- ::regclass is a magic casting and a Very Good Thing. You can       attnum > 0 AND       NOT attisdroppedORDER  BY attnum$BODY$	LANGUAGE sql	STABLE;ALTER FUNCTION dba.view_get_column_descriptions(text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:view_get_referenced_tables.sqlCREATE OR REPLACE FUNCTION dba.view_get_referenced_tables (view_name_in text)	RETURNS TABLE(		referenced_table text		)AS $BODY$  SELECT u.table_schema || '.' || u.table_name as referenced_table    FROM information_schema.view_table_usage u    JOIN information_schema.views v         ON  u.view_schema = v.table_schema         AND u.view_name = v.table_name   WHERE u.view_name = view_name_in::regclass::nameORDER BY u.view_schema,         u.view_name;$BODY$	LANGUAGE sql	STABLE;ALTER FUNCTION dba.view_get_referenced_tables(text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:view_register.sql-- Notice: This is a PROCEDURE, not a FUNCTION...no return value.-- You use CALL instead of SELECT to invoke a stored procedure.-- NOTE: It's all text below, no oid/regclass translation/validation, etc.-- This is a quick-and-dirty tool to make finding things simple for Welsh and William. -- DPACREATE OR REPLACE PROCEDURE dba.view_register (	schema_name_in     citext,	view_name_in       citext,	description_in     citext,	domo_dataset_in    citext DEFAULT '')AS $BODY$INSERT INTO dba.view_catalog (               schema_name,               view_name,               description,               domo_dataset)       VALUES (               schema_name_in,               view_name_in,               description_in,               domo_dataset_in)	ON CONFLICT ON CONSTRAINT view_catalog_id_pkey			DO UPDATE SET			   description   = description_in,			   domo_dataset  = domo_dataset_in$BODY$	LANGUAGE sql;ALTER PROCEDURE dba.view_register (citext, citext, citext, citext)	OWNER TO user_bender;-------------------------------------------------- Register view--------------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:dba:views_using_field.sqlCREATE OR REPLACE FUNCTION dba.views_using_field (    table_name  text,    column_name text)RETURNS table (	  schema_name citext,	  view_name   citext	)AS $BODY$SELECT pg_namespace.nspname::citext   AS schema_name,       pg_class.oid::regclass::citext AS view_name FROM pg_attribute   -- columns for the table JOIN pg_depend   -- objects that depend on the column   ON pg_depend.refobjsubid = pg_attribute.attnum  AND pg_depend.refobjid = pg_attribute.attrelid JOIN pg_rewrite  -- rules depending on the column   ON pg_rewrite.oid = pg_depend.objid JOIN pg_class    -- views for the rules   ON pg_class.oid = pg_rewrite.ev_class JOIN pg_namespace -- I added this is to include the schema_name in the output. -- DPA   ON pg_class.relnamespace  = pg_namespace.oidWHERE pg_class.relkind = 'v'    -- only interested in views  -- dependency must be a rule depending on a relation  AND pg_depend.classid     = 'pg_rewrite'::regclass  AND pg_depend.refclassid  = 'pg_class'::regclass  AND pg_depend.deptype     = 'n'    -- normal dependency  AND pg_attribute.attrelid = table_name::regclass  AND pg_attribute.attname  = column_name;$BODY$	LANGUAGE sql;COMMENT ON FUNCTION dba.views_using_field (text, text) IS '/*Adapted from this excellent blob post:https://www.cybertec-postgresql.com/en/tracking-view-dependencies-in-postgresql/*/';ALTER FUNCTION dba.views_using_field (text, text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:array_remove_element.sqlCREATE OR REPLACE FUNCTION tools.array_remove_element(anyarray, int)  RETURNS anyarray LANGUAGE sql IMMUTABLE AS'SELECT $1[:$2-1] || $1[$2+1:]';COMMENT ON FUNCTION tools.array_remove_element(anyarray, int) IS 'From the ever-helpful Erwin Brandstetter, renamed for our schema and idiom.https://dba.stackexchange.com/questions/94639/delete-array-element-by-index';ALTER FUNCTION tools.array_remove_element (anyarray, int) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:connection_snapshot_kvp.sqlCREATE OR REPLACE FUNCTION tools.connection_snapshot_kvp()  RETURNS TABLE(  	setting_name text,   	setting_value text)   	AS $BODY$DECLARE	search_path text;	BEGIN	 	 SELECT setting FROM pg_settings WHERE name='search_path' INTO search_path;	 SELECT 'user_name',current_user INTO setting_name,setting_value;				RETURN NEXT;	 SELECT 'session_user_name',session_user INTO setting_name,setting_value;		RETURN NEXT;	 SELECT 'role_nane',current_role INTO setting_name,setting_value;				RETURN NEXT;	 SELECT 'database_name',current_database() INTO setting_name,setting_value;		RETURN NEXT;	 SELECT 'server_version',version() INTO setting_name,setting_value;				RETURN NEXT;	 SELECT 'search_path',search_path INTO setting_name,setting_value;				RETURN NEXT;	 SELECT 'inet_client_addr',inet_client_addr() INTO setting_name,setting_value;	RETURN NEXT;	 SELECT 'inet_client_port',inet_client_port() INTO setting_name,setting_value;	RETURN NEXT;	 SELECT 'inet_server_addr',inet_server_addr() INTO setting_name,setting_value;	RETURN NEXT;	 SELECT 'inet_server_port',inet_server_port() INTO setting_name,setting_value;	RETURN NEXT;	 SELECT 'query',current_query() INTO setting_name,setting_value;				RETURN NEXT;END$BODY$  LANGUAGE plpgsql VOLATILE  COST 100  ROWS 1000;  ALTER FUNCTION tools.connection_snapshot_kvp ()	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:connection_snapshot.sqlCREATE OR REPLACE FUNCTION tools.connection_snapshot() 	RETURNS TABLE(		user_name text, 		session_user_name text,		role_nane text,		database_name text,		server_version text,		search_path text,		inet_client_addr inet,		inet_client_port integer,		inet_server_addr inet,		inet_server_port integer,		query text)AS $BODY$ BEGIN	 user_name := current_user;	 session_user_name := session_user;	 role_nane := current_role;	 database_name := current_database();	 server_version := version();	 	 SELECT setting FROM pg_settings WHERE name='search_path' INTO search_path;	 inet_client_addr := inet_client_addr();	 inet_client_port := inet_client_port();	 inet_server_addr := inet_server_addr();	 inet_server_port := inet_server_port();		 query := current_query();		 RETURN NEXT;END$BODY$  LANGUAGE plpgsql;ALTER FUNCTION tools.connection_snapshot() 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:count_rows_unqualified.sqlCREATE OR REPLACE FUNCTION tools.count_rows_unqualified (tablename text)	RETURNS pg_catalog.int4 	AS $BODY$DECLAREresult integer;query varchar;-- Man, don't use this code anywhere live...it needs to be rewritten to use quot_ident(), etc. to avoid injection.BEGINquery := 'SELECT count(1) FROM ' || tablename;execute query into result;return result;END;$BODY$	LANGUAGE plpgsql 	VOLATILE	COST 100;	ALTER FUNCTION tools.count_rows_unqualified (text) 	OWNER TO user_bender;	--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:dts_get_yyyy_mm_int.sql-- Thank you Erwin Brandstetter, dude's amazing.-- https://stackoverflow.com/questions/66847389/partitioning-on-a-uuid-in-postgres-12-or-13/66848699#66848699DROP FUNCTION IF EXISTS tools.dts_to_yyyy_mm_int (timestamp);CREATE FUNCTION tools.dts_to_yyyy_mm_int (timestamp)   RETURNS int4   LANGUAGE sql PARALLEL SAFE IMMUTABLE AS'SELECT (EXTRACT(year FROM $1) * 100 + EXTRACT(month FROM $1))::int';COMMENT ON FUNCTION tools.dts_to_yyyy_mm_int (timestamp) IS 'High-speed function to convert a timestamp without time zone to sortable yyyy-mm integer. This is ideal for partition keys.';ALTER FUNCTION tools.dts_to_yyyy_mm_int (timestamp)     OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:dynamic_pivot.sqlCREATE OR REPLACE FUNCTION tools.dynamic_pivot (central_query text, headers_query text) RETURNS refcursor  AS $BODY$DECLARE  left_column text;  header_column text;  value_column text;  h_value text;  headers_clause text;  query text;  j json;  r record;  curs refcursor;  i int:=1;BEGIN  -- find the column names of the source query  EXECUTE 'select row_to_json(_r.*) from (' ||  central_query || ') AS _r' into j;  FOR r in SELECT * FROM json_each_text(j)  LOOP    IF (i=1) THEN left_column := r.key;      ELSEIF (i=2) THEN header_column := r.key;      ELSEIF (i=3) THEN value_column := r.key;    END IF;    i := i+1;  END LOOP;  --  build the dynamic transposition query (based on the canonical model)  FOR h_value in EXECUTE headers_query  LOOP    headers_clause := concat(headers_clause,     format(chr(10)||',min(case when %I=%L then %I::text end) as %I',           header_column,	   h_value,	   value_column,	   h_value ));  END LOOP;  query := format('SELECT %I %s FROM (select *,row_number() over() as rn from (%s) AS _c) as _d GROUP BY %I order by min(rn)',           left_column,	   headers_clause,	   central_query,	   left_column);  -- open the cursor so the caller can FETCH right away  OPEN curs FOR execute query;  RETURN curs;END $BODY$ 	LANGUAGE plpgsql;COMMENT ON FUNCTION tools.dynamic_pivot (text, text) IS 'Woah! Thanks dude:https://postgresql.verite.pro/blog/2018/06/19/crosstab-pivot.html';ALTER FUNCTION tools.dynamic_pivot (text, text) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:format_uuid.sqlCREATE OR REPLACE FUNCTION tools.format_uuid(id uuid)	RETURNS textAS $BODY$SELECT UPPER(REPLACE(id::text,'-', ''));$BODY$  LANGUAGE sql;ALTER FUNCTION tools.format_uuid (uuid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:fuzzy_compare__test_bundle.sql/*bundle folder: fuzzy_compare_citext_citext_citext_citext_real_citextBuild date:   2020-05-14T05:21:06ZDescription:  Revised tests for fuzzy_compare()This script combines the following files into a single transaction:Test setup scripts:fuzzy_compare__Bad__Empty_base_string__tests.sqlfuzzy_compare__Bad__Handicap_too_high__tests.sqlfuzzy_compare__Bad__Handicap_too_low__tests.sqlfuzzy_compare__Good__Defaults__tests.sqlfuzzy_compare__Good__Empty_base_id__tests.sqlfuzzy_compare__Good__Empty_comparison_id__tests.sqlfuzzy_compare__Good__Empty_comparison_string__tests.sqlfuzzy_compare__Good__Empty_IDs__tests.sqlfuzzy_compare__Good__Handicap_set__tests.sql*/BEGIN;-- fuzzy_compare__Bad__Empty_base_string__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Bad: Empty base string', 'select * from fuzzy_compare('''',''Tray Finochietto Retractor'')', '', 'Error: KC101, ERROR:  A base string must be supplied.CONTEXT:  PL/pgSQL function fuzzy_compare(citext,citext,citext,citext,real,citext) line 197 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Bad__Handicap_too_high__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Bad: Handicap too high', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'',''Tray Finochietto Retractor'','''','''',2)', '', 'Error: KC202, ERROR:  handicap_factor value is out of range.HINT:  Value must be in the range 0-1.CONTEXT:  PL/pgSQL function fuzzy_compare(citext,citext,citext,citext,real,citext) line 214 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Bad__Handicap_too_low__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Bad: Handicap too low', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'',''Tray Finochietto Retractor'','''','''',-1)', '', 'Error: KC202, ERROR:  handicap_factor value is out of range.HINT:  Value must be in the range 0-1.CONTEXT:  PL/pgSQL function fuzzy_compare(citext,citext,citext,citext,real,citext) line 214 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Good__Defaults__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Good: Defaults', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'',''Tray Finochietto Retractor'')', '1 West Adult Finochietto Ret	Tray Finochietto Retractor			0.755719	monge_elkan_quadratic	0.514471	0.717267	0.375	0	0.645219	0.645219	0.428571	0.571111	0.755719	0.528254	0.712862	0.482759	0.375', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Good__Empty_base_id__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Good: Empty base_id', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'',''Tray Finochietto Retractor'','''',''comparison_id_here'')', '1 West Adult Finochietto Ret	Tray Finochietto Retractor		comparison_id_here	0.755719	monge_elkan_quadratic	0.514471	0.717267	0.375	0	0.645219	0.645219	0.428571	0.571111	0.755719	0.528254	0.712862	0.482759	0.375', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Good__Empty_comparison_id__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Good: Empty comparison_id', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'',''Tray Finochietto Retractor'',''base_id_here'','''')', '1 West Adult Finochietto Ret	Tray Finochietto Retractor	base_id_here		0.755719	monge_elkan_quadratic	0.514471	0.717267	0.375	0	0.645219	0.645219	0.428571	0.571111	0.755719	0.528254	0.712862	0.482759	0.375', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Good__Empty_comparison_string__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Good: Empty comparison string', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'','''')', '1 West Adult Finochietto Ret				0	none	0	0	0	0	0	0	0	0	0	0	0	0	0', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Good__Empty_IDs__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Good: Empty IDs', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'',''Tray Finochietto Retractor'','''','''')', '1 West Adult Finochietto Ret	Tray Finochietto Retractor			0.755719	monge_elkan_quadratic	0.514471	0.717267	0.375	0	0.645219	0.645219	0.428571	0.571111	0.755719	0.528254	0.712862	0.482759	0.375', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare__Good__Handicap_set__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare', '(citext, citext, citext, citext, real, citext)', 'fuzzy_compare: Good: Handicap set', 'select * from fuzzy_compare(''1 West Adult Finochietto Ret'',''Tray Finochietto Retractor'','''','''',.35)', '1 West Adult Finochietto Ret	Tray Finochietto Retractor			0.755719	monge_elkan_quadratic	0.513043	0.71627	0.375	0	0.645219	0.645219	0.428571	0.571111	0.755719	0.521111	0.705719	0.482759	0.375', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:fuzzy_compare_cross__test_bundle.sql/*bundle folder: fuzzy_compare_crossBuild date:   2020-05-14T04:50:05ZDescription:  Revised tests for fuzzy_compare_cross()This script combines the following files into a single transaction:Test setup scripts:fuzzy_compare_cross__Bad__Handicap_too_high__tests.sqlfuzzy_compare_cross__Bad__Handicap_too_low__tests.sqlfuzzy_compare_cross__Bad__Malformed_JSON_(missing_comma)__tests.sqlfuzzy_compare_cross__Bad__Method_winkler__tests.sqlfuzzy_compare_cross__Good__Defaults__tests.sqlfuzzy_compare_cross__Good__Handicap_set__tests.sqlfuzzy_compare_cross__Good__Method_jaro__tests.sqlfuzzy_compare_cross__Good__Method_jarowinkler__tests.sqlfuzzy_compare_cross__Good__Method_qgram__tests.sql*/BEGIN;-- fuzzy_compare_cross__Bad__Handicap_too_high__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Bad: Handicap too high', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 2);', '', 'Error: KC202, ERROR:  handicap_factor value is out of range.HINT:  Value must be in the range 0-1.CONTEXT:  PL/pgSQL function fuzzy_compare_cross(jsonb,jsonb,real,citext) line 20 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Bad__Handicap_too_low__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Bad: Handicap too low', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', -1);', '', 'Error: KC202, ERROR:  handicap_factor value is out of range.HINT:  Value must be in the range 0-1.CONTEXT:  PL/pgSQL function fuzzy_compare_cross(jsonb,jsonb,real,citext) line 20 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Bad__Malformed_JSON_(missing_comma)__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Bad: Malformed JSON (missing comma)', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"}	{"text":"Green Medium Special","id":"5"} ]'', );', '', 'Error: 42601, ERROR:  syntax error at or near ")"LINE 12: );         ^', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Bad__Method_winkler__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Bad: Method winkler', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''winkler'')', '', 'Error: KC300, ERROR:  Invalid distance measure name winklerHINT:  Valid methods are jaro, jarowinkler, and qgramCONTEXT:  PL/pgSQL function fuzzy_compare_cross(jsonb,jsonb,real,citext) line 10 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Good__Defaults__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Good: Defaults', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Fuzzy Green Bunny	Blue Small	1	4	0.730297	monge_elkan_quadratic	0.344271	0.586746	0	0	0.381046	0.381046	0.117647	0.533333	0.730297	0.533333	0.730297	0	0.035714Fuzzy Green Bunny	Green Medium Special	1	5	0.699206	monge_elkan_quadratic	0.377897	0.614733	0.1	0	0.498529	0.498529	0.1	0.488889	0.699206	0.428889	0.639206	0.243902	0.181818Small Red Squirrel	Red Large Special	2	3	0.849136	monge_elkan_quadratic	0.496845	0.704873	0.16129	0	0.651961	0.651961	0.277778	0.721032	0.849136	0.661032	0.789136	0.205128	0.16129Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087Small Red Squirrel	Green Medium Special	2	5	0.785702	monge_elkan_quadratic	0.432831	0.657899	0.026316	0	0.599158	0.599158	0.25	0.617328	0.785702	0.617328	0.785702	0.047619	0.026316', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Good__Handicap_set__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Good: Handicap set', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3);', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Fuzzy Green Bunny	Blue Small	1	4	0.730297	monge_elkan_quadratic	0.344271	0.586746	0	0	0.381046	0.381046	0.117647	0.533333	0.730297	0.533333	0.730297	0	0.035714Fuzzy Green Bunny	Green Medium Special	1	5	0.699206	monge_elkan_quadratic	0.377897	0.614733	0.1	0	0.498529	0.498529	0.1	0.488889	0.699206	0.428889	0.639206	0.243902	0.181818Small Red Squirrel	Red Large Special	2	3	0.849136	monge_elkan_quadratic	0.496845	0.704873	0.16129	0	0.651961	0.651961	0.277778	0.721032	0.849136	0.661032	0.789136	0.205128	0.16129Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087Small Red Squirrel	Green Medium Special	2	5	0.785702	monge_elkan_quadratic	0.432831	0.657899	0.026316	0	0.599158	0.599158	0.25	0.617328	0.785702	0.617328	0.785702	0.047619	0.026316', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Good__Method_jaro__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Good: Method jaro', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''jaro'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Fuzzy Green Bunny	Blue Small	1	4	0.730297	monge_elkan_quadratic	0.344271	0.586746	0	0	0.381046	0.381046	0.117647	0.533333	0.730297	0.533333	0.730297	0	0.035714Fuzzy Green Bunny	Green Medium Special	1	5	0.699206	monge_elkan_quadratic	0.377897	0.614733	0.1	0	0.498529	0.498529	0.1	0.488889	0.699206	0.428889	0.639206	0.243902	0.181818Small Red Squirrel	Red Large Special	2	3	0.849136	monge_elkan_quadratic	0.496845	0.704873	0.16129	0	0.651961	0.651961	0.277778	0.721032	0.849136	0.661032	0.789136	0.205128	0.16129Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087Small Red Squirrel	Green Medium Special	2	5	0.785702	monge_elkan_quadratic	0.432831	0.657899	0.026316	0	0.599158	0.599158	0.25	0.617328	0.785702	0.617328	0.785702	0.047619	0.026316', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Good__Method_jarowinkler__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Good: Method jarowinkler', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''jaro'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Fuzzy Green Bunny	Blue Small	1	4	0.730297	monge_elkan_quadratic	0.344271	0.586746	0	0	0.381046	0.381046	0.117647	0.533333	0.730297	0.533333	0.730297	0	0.035714Fuzzy Green Bunny	Green Medium Special	1	5	0.699206	monge_elkan_quadratic	0.377897	0.614733	0.1	0	0.498529	0.498529	0.1	0.488889	0.699206	0.428889	0.639206	0.243902	0.181818Small Red Squirrel	Red Large Special	2	3	0.849136	monge_elkan_quadratic	0.496845	0.704873	0.16129	0	0.651961	0.651961	0.277778	0.721032	0.849136	0.661032	0.789136	0.205128	0.16129Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087Small Red Squirrel	Green Medium Special	2	5	0.785702	monge_elkan_quadratic	0.432831	0.657899	0.026316	0	0.599158	0.599158	0.25	0.617328	0.785702	0.617328	0.785702	0.047619	0.026316', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_cross__Good__Method_qgram__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_cross', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_cross: Good: Method qgram', 'select *  from fuzzy_compare_cross(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''qgram'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.457516	jaro	0.097386	0.312067	0	0	0.457516	0.457516	0.058824	0	0	0	0	0	0Fuzzy Green Bunny	Blue Small	1	4	0.381046	jaro	0.147093	0.383527	0	0	0.381046	0.381046	0.117647	0.051282	0.226455	0.051282	0.226455	0	0.035714Fuzzy Green Bunny	Green Medium Special	1	5	0.57735	monge_elkan_quadratic	0.322415	0.567816	0.1	0	0.498529	0.498529	0.1	0.333333	0.57735	0.273333	0.51735	0.243902	0.181818Small Red Squirrel	Red Large Special	2	3	0.697741	monge_elkan_quadratic	0.419728	0.647864	0.16129	0	0.651961	0.651961	0.277778	0.486842	0.697741	0.426842	0.637741	0.205128	0.16129Small Red Squirrel	Blue Small	2	4	0.641689	monge_elkan_quadratic	0.411685	0.641627	0.26087	0	0.623148	0.623148	0.277778	0.411765	0.641689	0.336765	0.566689	0.375	0.26087Small Red Squirrel	Green Medium Special	2	5	0.599158	jaro	0.261287	0.511163	0.026316	0	0.599158	0.599158	0.25	0.153509	0.391802	0.153509	0.391802	0.047619	0.026316', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:fuzzy_compare_cross.sqlDROP FUNCTION IF EXISTS tools.fuzzy_compare_cross (jsonb, jsonb, real, citext);CREATE OR REPLACE FUNCTION tools.fuzzy_compare_cross (     base_jsonb_in                        jsonb,     comparison_jsonb_in                  jsonb,     handicap_factor_in                   real DEFAULT 0.3,     monge_elkan_similarity_method_in     citext DEFAULT 'jarowinkler')-- decimal_score is a custom domain (type) for ###.##### numbers.RETURNS TABLE (     base_text                             citext,     comparison_text                       citext,     base_id                               citext,     comparison_id                         citext,     highest_score                         decimal_score,     best_method                           citext,     avg_score                             decimal_score,     avg_quadratic_score                   decimal_score,     lowest_score                          decimal_score,     equality_check                        int4,     jaro_score                            decimal_score,     jaro_winkler_score                    decimal_score,     levenshtein_score                     decimal_score,     monge_elkan_score                     decimal_score,     monge_elkan_quadratic_score           decimal_score,     monge_elkan_handicap_score            decimal_score,     monge_elkan_quadratic_handicap_score  decimal_score,     qgram_score                           decimal_score,     trigram_score                         decimal_score)AS $BODY$BEGIN-------------------------------------------------------------- Safety checks for parameters stitched into the SQL.------------------------------------------------------------    monge_elkan_similarity_method_in  := lower(monge_elkan_similarity_method_in);	IF monge_elkan_similarity_method_in NOT IN ('jaro','jarowinkler','qgram') THEN		RAISE EXCEPTION USING			message = 'Invalid distance measure name ' || monge_elkan_similarity_method_in,			hint = 'Valid methods are jaro, jarowinkler, and qgram',			errcode = 'KC300'; -- Custom code for 'Bad lookup ID'.    END IF;-------------------------------------------------------------- Range/sanity checks on thresholds------------------------------------------------------------	IF handicap_factor_in < 0 OR handicap_factor_in > 1 THEN		RAISE EXCEPTION USING			message = 'handicap_factor value is out of range.',			hint = 'Value must be in the range 0-1.',			errcode = 'KC202'; -- Custom code for 'Numeric parameter value is too low'.    END IF;RETURN QUERYWITHbase_expanded AS ( select *   from jsonb_to_recordset(     base_jsonb_in)  AS base_unpacked (                 text citext,                 id citext) ),comparison_expanded AS ( select *   from jsonb_to_recordset(     comparison_jsonb_in)  AS comparison_unpacked (                 text citext,                 id citext) ),combined_lists AS (select base_expanded.text         AS base_text_x,       base_expanded.id           AS base_id_x,       comparison_expanded.text   AS comparison_text_x,       comparison_expanded.id     AS comparison_id_x  from base_expanded,       comparison_expanded),---------------------------------------------------------- Pull in the basic scores, and add some handicaps--------------------------------------------------------basic_scores AS (select base_text_x,       comparison_text_x,       base_id_x,       comparison_id_x,       (base_text_x = comparison_text_x)::int4                                              AS equality_check_x,       monge_elkan(base_text_x, comparison_text_x, monge_elkan_similarity_method_in)        AS monge_elkan_score_x,       sqrt(monge_elkan(base_text_x, comparison_text_x, monge_elkan_similarity_method_in))  AS monge_elkan_quadratic_score_x,       jaccard(base_text_x, comparison_text_x)                                              AS jaccard_coefficient_x,       jaccard(base_text_x, comparison_text_x) * handicap_factor_in                         AS jaccard_handicap_x,       qgram(base_text_x,comparison_text_x)                                                 AS qgram_score_x,       similarity(base_text_x,comparison_text_x)                                            AS trigram_score_x,       lev(base_text_x,comparison_text_x)                                                   AS levenshtein_score_x,       jaro(base_text_x,comparison_text_x)                                                  AS jaro_score_x,       jarowinkler(base_text_x,comparison_text_x)                                           AS jaro_winkler_score_x  from combined_lists),---------------------------------------------------------- Pull in the basic scores, and add some handicaps--------------------------------------------------------extended_scores AS (SELECT  base_text_x,        comparison_text_x,        base_id_x,        comparison_id_x,        equality_check_x,        jaro_score_x,        jaro_winkler_score_x,        levenshtein_score_x,        monge_elkan_score_x,        monge_elkan_quadratic_score_x,        (monge_elkan_score_x - jaccard_handicap_x) AS monge_elkan_handicap_score_x,        (monge_elkan_quadratic_score_x - jaccard_handicap_x) AS monge_elkan_quadratic_handicap_score_x,        jaccard_coefficient_x,        jaccard_handicap_x,        qgram_score_x,        trigram_score_x  FROM basic_scores),---------------------------------------------------------- Augment with overall stats on range of scores--------------------------------------------------------  score_stats AS (  SELECT base_text_x,         comparison_text_x,         base_id_x,         comparison_id_x,         equality_check_x,         jaro_score_x,         jaro_winkler_score_x,         levenshtein_score_x,         monge_elkan_score_x,         monge_elkan_quadratic_score_x,         monge_elkan_handicap_score_x,         monge_elkan_quadratic_handicap_score_x,         jaccard_coefficient_x,         jaccard_handicap_x,         qgram_score_x,         trigram_score_x,           GREATEST (           equality_check_x,           jaro_score_x,           jaro_winkler_score_x,           levenshtein_score_x,           monge_elkan_score_x,           monge_elkan_handicap_score_x,           monge_elkan_quadratic_score_x,           monge_elkan_quadratic_handicap_score_x,           qgram_score_x,           trigram_score_x) AS highest_score_x,-- Leave out equality_check_x out of LEAST and AVG scores. It's either 0 or 1, almost always 0.        LEAST (           jaro_score_x,           jaro_winkler_score_x,           levenshtein_score_x,           monge_elkan_score_x,           monge_elkan_handicap_score_x,           monge_elkan_quadratic_score_x,           monge_elkan_quadratic_handicap_score_x,           qgram_score_x,           trigram_score_x) AS lowest_score_x,         ((jaro_score_x +           jaro_winkler_score_x +           levenshtein_score_x +           monge_elkan_score_x +           monge_elkan_handicap_score_x +           monge_elkan_quadratic_score_x +           monge_elkan_quadratic_handicap_score_x +           qgram_score_x +           trigram_score_x) / 10) AS avg_score_x,           sqrt((jaro_score_x +           jaro_winkler_score_x +           levenshtein_score_x +           monge_elkan_score_x +           monge_elkan_handicap_score_x +           monge_elkan_quadratic_score_x +           monge_elkan_quadratic_handicap_score_x +           qgram_score_x +           trigram_score_x) / 10) AS avg_quadratic_score_x     FROM extended_scores        )---------------------------------------------------------- Final result: Get everything, along with the top score--------------------------------------------------------SELECT base_text_x,       comparison_text_x,       base_id_x,       comparison_id_x,       highest_score_x::decimal_score,        -- Ugh. Researching better methods for doing this part...and some of the others...bit too long.        -- In case of a tie, this code picks the first match.       CASE          WHEN highest_score_x = 0                                      THEN 'none'          WHEN highest_score_x = equality_check_x                       THEN 'equality_check'          WHEN highest_score_x = monge_elkan_score_x                    THEN 'monge_elkan'          WHEN highest_score_x = monge_elkan_handicap_score_x           THEN 'monge_elkan_handicap'          WHEN highest_score_x = monge_elkan_quadratic_score_x          THEN 'monge_elkan_quadratic'          WHEN highest_score_x = monge_elkan_quadratic_handicap_score_x THEN 'monge_elkan_quadratic_handicap'          WHEN highest_score_x = qgram_score_x                          THEN 'qgram'          WHEN highest_score_x = trigram_score_x                        THEN 'trigram'          WHEN highest_score_x = levenshtein_score_x                    THEN 'levenshtein'          WHEN highest_score_x = jaro_score_x                           THEN 'jaro'          WHEN highest_score_x = jaro_winkler_score_x                   THEN 'jaro_winkler'          WHEN highest_score_x = avg_score_x                            THEN 'avg'          WHEN highest_score_x = avg_quadratic_score_x                  THEN 'avg_quadratic'          ELSE 'Undefined'::citext        END AS best_method,       avg_score_x::decimal_score,       avg_quadratic_score_x::decimal_score,       lowest_score_x::decimal_score,       equality_check_x::int4,       jaro_score_x::decimal_score::decimal_score,       jaro_winkler_score_x::decimal_score,       levenshtein_score_x::decimal_score,       monge_elkan_score_x::decimal_score,       monge_elkan_quadratic_score_x::decimal_score,       monge_elkan_handicap_score_x::decimal_score,       monge_elkan_quadratic_handicap_score_x::decimal_score,       qgram_score_x::decimal_score,       trigram_score_x::decimal_score  FROM score_stats;END$BODY$LANGUAGE plpgsql;ALTER FUNCTION tools.fuzzy_compare_cross (jsonb, jsonb, real, citext)     OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:fuzzy_compare_pairwise__test_bundle.sql/*bundle folder: fuzzy_compare_pairwiseBuild date:   2020-05-14T05:00:18ZDescription:  Revised tests for fuzzy_compare_pairwise()This script combines the following files into a single transaction:Test setup scripts:fuzzy_compare_pairwise__Bad__Handicap_too_high__tests.sqlfuzzy_compare_pairwise__Bad__Handicap_too_low__tests.sqlfuzzy_compare_pairwise__Bad__Malformed_JSON_(missing_comma)__tests.sqlfuzzy_compare_pairwise__Bad__Method_winkler__tests.sqlfuzzy_compare_pairwise__Good__Defaults__tests.sqlfuzzy_compare_pairwise__Good__Handicap_set__tests.sqlfuzzy_compare_pairwise__Good__Method_jaro__tests.sqlfuzzy_compare_pairwise__Good__Method_jarowinkler__tests.sqlfuzzy_compare_pairwise__Good__Method_qgram__tests.sql*/BEGIN;-- fuzzy_compare_pairwise__Bad__Handicap_too_high__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Bad: Handicap too high', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 2);', '', 'Error: KC202, ERROR:  handicap_factor value is out of range.HINT:  Value must be in the range 0-1.CONTEXT:  PL/pgSQL function fuzzy_compare_pairwise(jsonb,jsonb,real,citext) line 20 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Bad__Handicap_too_low__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Bad: Handicap too low', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', -1);', '', 'Error: KC202, ERROR:  handicap_factor value is out of range.HINT:  Value must be in the range 0-1.CONTEXT:  PL/pgSQL function fuzzy_compare_pairwise(jsonb,jsonb,real,citext) line 20 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Bad__Malformed_JSON_(missing_comma)__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Bad: Malformed JSON (missing comma)', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"}	{"text":"Green Medium Special","id":"5"} ]'', );', '', 'Error: 42601, ERROR:  syntax error at or near ")"LINE 12: );         ^', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Bad__Method_winkler__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Bad: Method winkler', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''winkler'')', '', 'Error: KC300, ERROR:  Invalid distance measure name winklerHINT:  Valid methods are jaro, jarowinkler, and qgramCONTEXT:  PL/pgSQL function fuzzy_compare_pairwise(jsonb,jsonb,real,citext) line 10 at RAISE', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Good__Defaults__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Good: Defaults', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Good__Handicap_set__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Good: Handicap set', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3);', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Good__Method_jaro__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Good: Method jaro', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''jaro'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Good__Method_jarowinkler__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Good: Method jarowinkler', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''jaro'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.479197	monge_elkan_quadratic	0.239151	0.489031	0	0	0.457516	0.457516	0.058824	0.22963	0.479197	0.22963	0.479197	0	0Small Red Squirrel	Blue Small	2	4	0.726483	monge_elkan_quadratic	0.451847	0.672195	0.26087	0	0.623148	0.623148	0.277778	0.527778	0.726483	0.452778	0.651483	0.375	0.26087', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');-- fuzzy_compare_pairwise__Good__Method_qgram__tests.sqlselect * from test_case_setup('Function', 'ascendco', 'fuzzy_compare_pairwise', '(jsonb, jsonb, real, citext)', 'fuzzy_compare_pairwise: Good: Method qgram', 'select *  from fuzzy_compare_pairwise(''[	{"text":"Fuzzy Green Bunny","id":"1"},	{"text":"Small Red Squirrel","id":"2"} ]'',''[	{"text":"Red Large Special","id":"3"},	{"text":"Blue Small","id":"4"},	{"text":"Green Medium Special","id":"5"} ]'', 0.3,''qgram'');', 'Fuzzy Green Bunny	Red Large Special	1	3	0.457516	jaro	0.097386	0.312067	0	0	0.457516	0.457516	0.058824	0	0	0	0	0	0Small Red Squirrel	Blue Small	2	4	0.641689	monge_elkan_quadratic	0.411685	0.641627	0.26087	0	0.623148	0.623148	0.277778	0.411765	0.641689	0.336765	0.566689	0.375	0.26087', '', 'text', '{"comparator":"equals","column_order":"Ignore","case_sensitivity":"blind","whitespace_cleaning":"all","normalize_line_endings":true}', 'Pass', '{user_change_structure, user_iceberg}', FALSE, TRUE, '', '');COMMIT;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:fuzzy_compare_pairwise.sqlDROP FUNCTION IF EXISTS tools.fuzzy_compare_pairwise (jsonb, jsonb, real, citext);CREATE OR REPLACE FUNCTION tools.fuzzy_compare_pairwise (     base_jsonb_in                        jsonb,     comparison_jsonb_in                  jsonb,     handicap_factor_in                   real DEFAULT 0.3,     monge_elkan_similarity_method_in     citext DEFAULT 'jarowinkler')-- decimal_score is a custom domain (type) for ###.##### numbers.RETURNS TABLE (     base_text                             citext,     comparison_text                       citext,     base_id                               citext,     comparison_id                         citext,     highest_score                         decimal_score,     best_method                           citext,     avg_score                             decimal_score,     avg_quadratic_score                   decimal_score,     lowest_score                          decimal_score,     equality_check                        int4,     jaro_score                            decimal_score,     jaro_winkler_score                    decimal_score,     levenshtein_score                     decimal_score,     monge_elkan_score                     decimal_score,     monge_elkan_quadratic_score           decimal_score,     monge_elkan_handicap_score            decimal_score,     monge_elkan_quadratic_handicap_score  decimal_score,     qgram_score                           decimal_score,     trigram_score                         decimal_score)AS $BODY$BEGIN-------------------------------------------------------------- Safety checks for parameters stitched into the SQL.------------------------------------------------------------    monge_elkan_similarity_method_in  := lower(monge_elkan_similarity_method_in);    IF monge_elkan_similarity_method_in NOT IN ('jaro','jarowinkler','qgram') THEN        RAISE EXCEPTION USING            message = 'Invalid distance measure name ' || monge_elkan_similarity_method_in,            hint = 'Valid methods are jaro, jarowinkler, and qgram',            errcode = 'KC300'; -- Custom code for 'Bad lookup ID'.    END IF;-------------------------------------------------------------- Range/sanity checks on thresholds------------------------------------------------------------    IF handicap_factor_in < 0 OR handicap_factor_in > 1 THEN        RAISE EXCEPTION USING            message = 'handicap_factor value is out of range.',            hint = 'Value must be in the range 0-1.',            errcode = 'KC202'; -- Custom code for 'Numeric parameter value is too low'.    END IF;RETURN QUERYWITHbase_expanded AS (   SELECT * FROM jsonb_array_elements(base_jsonb_in::jsonb)       WITH ORDINALITY AS x(element, idx)),comparison_expanded AS (   SELECT * FROM jsonb_array_elements(comparison_jsonb_in::jsonb)       WITH ORDINALITY AS y(element, idx) ),-- Pairwise JOIN using ordinality-geneated index as the joining term.-- So, base element 1 to comaprison element 1, and so on.combined_lists AS (select base_expanded.element ->> 'text'        AS base_text_x,       base_expanded.element ->> 'id'          AS base_id_x,       comparison_expanded.element ->> 'text'  AS comparison_text_x,       comparison_expanded.element ->> 'id'    AS comparison_id_x  from base_expanded  join comparison_expanded ON (comparison_expanded.idx = base_expanded.idx)),---------------------------------------------------------- Pull in the basic scores, and add some handicaps--------------------------------------------------------basic_scores AS (select base_text_x,       comparison_text_x,       base_id_x,       comparison_id_x,       (base_text_x = comparison_text_x)::int4                                              AS equality_check_x,       monge_elkan(base_text_x, comparison_text_x,monge_elkan_similarity_method_in)         AS monge_elkan_score_x,       sqrt(monge_elkan(base_text_x, comparison_text_x, monge_elkan_similarity_method_in))  AS monge_elkan_quadratic_score_x,       jaccard(base_text_x,comparison_text_x)                                               AS jaccard_coefficient,       jaccard(base_text_x,comparison_text_x) * handicap_factor_in                          AS jaccard_handicap,       qgram(base_text_x,comparison_text_x)                                                 AS qgram_score_x,       similarity(base_text_x,comparison_text_x)                                            AS trigram_score_x,       lev(base_text_x,comparison_text_x)                                                   AS levenshtein_score_x,       jaro(base_text_x,comparison_text_x)                                                  AS jaro_score_x,       jarowinkler(base_text_x,comparison_text_x)                                           AS jaro_winkler_score_x  from combined_lists),---------------------------------------------------------- Pull in the basic scores, and add some handicaps--------------------------------------------------------extended_scores AS (SELECT  base_text_x,        comparison_text_x,        base_id_x,        comparison_id_x,        equality_check_x,        jaro_score_x::decimal_score,        jaro_winkler_score_x::decimal_score,        levenshtein_score_x::decimal_score,        monge_elkan_score_x::decimal_score,        monge_elkan_quadratic_score_x::decimal_score,        (monge_elkan_score_x - jaccard_handicap)::decimal_score AS monge_elkan_handicap_score_x,        (monge_elkan_quadratic_score_x - jaccard_handicap)::decimal_score AS monge_elkan_quadratic_handicap_score_x,        jaccard_coefficient,        jaccard_handicap,        qgram_score_x::decimal_score,        trigram_score_x::decimal_score  FROM basic_scores),---------------------------------------------------------- Augment with overall stats on range of scores--------------------------------------------------------  score_stats AS (  SELECT base_text_x,         comparison_text_x,         base_id_x,         comparison_id_x,         equality_check_x,         jaro_score_x,         jaro_winkler_score_x,         levenshtein_score_x,         monge_elkan_score_x,         monge_elkan_quadratic_score_x,         monge_elkan_handicap_score_x,         monge_elkan_quadratic_handicap_score_x,         jaccard_coefficient,         jaccard_handicap,         qgram_score_x,         trigram_score_x,           GREATEST (           equality_check_x,           jaro_score_x,           jaro_winkler_score_x,           levenshtein_score_x,           monge_elkan_score_x,           monge_elkan_handicap_score_x,           monge_elkan_quadratic_score_x,           monge_elkan_quadratic_handicap_score_x,           qgram_score_x,           trigram_score_x)::decimal_score AS highest_score_x,-- Leave out equality_check_x out of LEAST and AVG scores. It's either 0 or 1, almost always 0.        LEAST (           jaro_score_x,           jaro_winkler_score_x,           levenshtein_score_x,           monge_elkan_score_x,           monge_elkan_handicap_score_x,           monge_elkan_quadratic_score_x,           monge_elkan_quadratic_handicap_score_x,           qgram_score_x,           trigram_score_x)::decimal_score AS lowest_score_x,         ((jaro_score_x +           jaro_winkler_score_x +           levenshtein_score_x +           monge_elkan_score_x +           monge_elkan_handicap_score_x +           monge_elkan_quadratic_score_x +           monge_elkan_quadratic_handicap_score_x +           qgram_score_x +           trigram_score_x) / 10)::decimal_score AS avg_score_x,           sqrt((jaro_score_x +           jaro_winkler_score_x +           levenshtein_score_x +           monge_elkan_score_x +           monge_elkan_handicap_score_x +           monge_elkan_quadratic_score_x +           monge_elkan_quadratic_handicap_score_x +           qgram_score_x +           trigram_score_x) / 10)::decimal_score AS avg_quadratic_score_x     FROM extended_scores        )---------------------------------------------------------- Final result: Get everything, along with the top score--------------------------------------------------------SELECT base_text_x::citext,       comparison_text_x::citext,       base_id_x::citext,       comparison_id_x::citext,       highest_score_x,        -- Ugh. Researching better methods for doing this part...and some of the others...bit too long.        -- In case of a tie, this code picks the first match.       CASE          WHEN highest_score_x = 0 THEN 'none'          WHEN highest_score_x = equality_check_x                       THEN 'equality_check'          WHEN highest_score_x = monge_elkan_score_x                    THEN 'monge_elkan'          WHEN highest_score_x = monge_elkan_handicap_score_x           THEN 'monge_elkan_handicap'          WHEN highest_score_x = monge_elkan_quadratic_score_x          THEN 'monge_elkan_quadratic'          WHEN highest_score_x = monge_elkan_quadratic_handicap_score_x THEN 'monge_elkan_quadratic_handicap'          WHEN highest_score_x = qgram_score_x                          THEN 'qgram'          WHEN highest_score_x = trigram_score_x                        THEN 'trigram'          WHEN highest_score_x = levenshtein_score_x                    THEN 'levenshtein'          WHEN highest_score_x = jaro_score_x                           THEN 'jaro'          WHEN highest_score_x = jaro_winkler_score_x                   THEN 'jaro_winkler'          WHEN highest_score_x = avg_score_x                            THEN 'avg'          WHEN highest_score_x = avg_quadratic_score_x                  THEN 'avg_quadratic'          ELSE 'Undefined'::citext        END AS best_method_x,       avg_score_x,       avg_quadratic_score_x,       lowest_score_x,       equality_check_x,       jaro_score_x,       jaro_winkler_score_x,       levenshtein_score_x,       monge_elkan_score_x,       monge_elkan_quadratic_score_x,       monge_elkan_handicap_score_x,       monge_elkan_quadratic_handicap_score_x,       qgram_score_x,       trigram_score_x  FROM score_stats;END$BODY$LANGUAGE plpgsql;ALTER FUNCTION tools.fuzzy_compare_pairwise (jsonb, jsonb, real, citext)     OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:fuzzy_compare.sqlDROP FUNCTION IF EXISTS tools.fuzzy_compare (citext, citext, citext, citext, real, citext);-- decimal_score is a custom domain (type) for ###.##### numbers.CREATE OR REPLACE FUNCTION tools.fuzzy_compare (     base_text_in                         citext,     comparison_text_in                   citext,     base_id_in                           citext DEFAULT '',     comparison_id_in                     citext DEFAULT '',     handicap_factor_in                   float4 DEFAULT 0.3,     monge_elkan_similarity_method_in     citext DEFAULT 'jarowinkler')RETURNS TABLE (	base_text                             citext,	comparison_text                       citext,	base_id                               citext,	comparison_id                         citext,	highest_score                         decimal_score,	best_method                           citext,	avg_score                             decimal_score,	avg_quadratic_score                   decimal_score,	lowest_score                          decimal_score,	equality_check                        int4,	jaro_score                            decimal_score,    jaro_winkler_score                    decimal_score,	levenshtein_score                     decimal_score,	monge_elkan_score                     decimal_score,	monge_elkan_quadratic_score           decimal_score,	monge_elkan_handicap_score            decimal_score,	monge_elkan_quadratic_handicap_score  decimal_score,	qgram_score                           decimal_score,	trigram_score                         decimal_score)AS $BODY$DECLARE-------------------------------------------------------------- Setup query template, which you can RAISE NOTICE while .-- developing to see what's in it.------------------------------------------------------------sql text := 'WITHbasic_scores AS (  SELECT $1                           AS base_text,         $2                           AS comparison_text,         $3                           AS base_id,         $4                           AS comparison_id,         ($1 = $2)::int4              AS equality_check,         monge_elkan($1,$2,$6)        AS monge_elkan_score,         sqrt(monge_elkan($1,$2,$6))  AS monge_elkan_quadratic_score,         jaccard($1,$2)               AS jaccard_coefficient,         jaccard($1,$2) * $5          AS jaccard_handicap,         qgram($1,$2)                 AS qgram_score,         similarity($1,$2)            AS trigram_score,         word_similarity($1,$2)       AS word_score,         lev($1,$2)                   AS levenshtein_score,         jaro($1,$2)                  AS jaro_score,         jarowinkler($1,$2)           AS jaro_winkler_score),---------------------------------------------------------- Pull in the basic scores, and add some handicaps--------------------------------------------------------extended_scores AS (SELECT  base_text,        comparison_text,        base_id,        comparison_id,        equality_check,        jaro_score::decimal_score,        jaro_winkler_score::decimal_score,        levenshtein_score::decimal_score,        monge_elkan_score::decimal_score,        monge_elkan_quadratic_score::decimal_score,        (monge_elkan_score - jaccard_handicap)::decimal_score AS monge_elkan_handicap_score,        (monge_elkan_quadratic_score - jaccard_handicap)::decimal_score AS monge_elkan_quadratic_handicap_score,        jaccard_coefficient,        jaccard_handicap,        qgram_score::decimal_score,        trigram_score::decimal_score  FROM basic_scores),  score_stats AS (  SELECT GREATEST (           equality_check,           jaro_score,           jaro_winkler_score,           levenshtein_score,           monge_elkan_score,           monge_elkan_handicap_score,           monge_elkan_quadratic_score,           monge_elkan_quadratic_handicap_score,           qgram_score,           trigram_score)::decimal_score AS highest_score,-- Leave out equality_check out of LEAST and AVG scores. It''s either 0 or 1, almost always 0.        LEAST (           jaro_score,           jaro_winkler_score,           levenshtein_score,           monge_elkan_score,           monge_elkan_handicap_score,           monge_elkan_quadratic_score,           monge_elkan_quadratic_handicap_score,           qgram_score,           trigram_score)::decimal_score AS lowest_score,         ((jaro_score +           jaro_winkler_score +           levenshtein_score +           monge_elkan_score +           monge_elkan_handicap_score +           monge_elkan_quadratic_score +           monge_elkan_quadratic_handicap_score +           qgram_score +           trigram_score) / 10)::decimal_score AS avg_score,          sqrt((jaro_score +           jaro_winkler_score +           levenshtein_score +           monge_elkan_score +           monge_elkan_handicap_score +           monge_elkan_quadratic_score +           monge_elkan_quadratic_handicap_score +           qgram_score +           trigram_score ) / 10)::decimal_score AS avg_quadratic_score     FROM extended_scores        )---------------------------------------------------------- Final result: Get everything, along with the top score--------------------------------------------------------SELECT extended_scores.base_text,       extended_scores.comparison_text,       extended_scores.base_id,       extended_scores.comparison_id,       score_stats.highest_score,        -- Ugh. Researching better methods for doing this part...and some of the others...bit too long.        -- In case of a tie, this code picks the first match.       CASE          WHEN score_stats.highest_score = 0 THEN ''none''          WHEN score_stats.highest_score = equality_check THEN ''equality_check''          WHEN score_stats.highest_score = extended_scores.monge_elkan_score THEN ''monge_elkan''          WHEN score_stats.highest_score = extended_scores.monge_elkan_handicap_score THEN ''monge_elkan_handicap''          WHEN score_stats.highest_score = extended_scores.monge_elkan_quadratic_score THEN ''monge_elkan_quadratic''          WHEN score_stats.highest_score = extended_scores.monge_elkan_quadratic_handicap_score THEN ''monge_elkan_quadratic_handicap''          WHEN score_stats.highest_score = extended_scores.qgram_score THEN ''qgram''          WHEN score_stats.highest_score = extended_scores.trigram_score THEN ''trigram''          WHEN score_stats.highest_score = extended_scores.levenshtein_score THEN ''levenshtein''          WHEN score_stats.highest_score = extended_scores.jaro_score THEN ''jaro''          WHEN score_stats.highest_score = extended_scores.jaro_winkler_score THEN ''jaro_winkler''          WHEN score_stats.highest_score = score_stats.avg_score THEN ''avg''          WHEN score_stats.highest_score = score_stats.avg_quadratic_score THEN ''avg_quadratic''        ELSE ''Undefined''::citext END AS best_method,       score_stats.avg_score,       score_stats.avg_quadratic_score,       score_stats.lowest_score,       extended_scores.equality_check,       extended_scores.jaro_score,       extended_scores.jaro_winkler_score,       extended_scores.levenshtein_score,       extended_scores.monge_elkan_score,       extended_scores.monge_elkan_quadratic_score,       extended_scores.monge_elkan_handicap_score,       extended_scores.monge_elkan_quadratic_handicap_score,       extended_scores.qgram_score,       extended_scores.trigram_score  FROM extended_scores,       score_stats;';BEGIN-------------------------------------------------------------- Safety checks for parameters stitched into the SQL.------------------------------------------------------------	IF base_text_in = '' THEN		RAISE EXCEPTION USING			message = 'A base string must be supplied.',			errcode = 'KC101'; -- Custom code for 'Empty string parameter'.    END IF;    monge_elkan_similarity_method_in  := lower(monge_elkan_similarity_method_in);	IF monge_elkan_similarity_method_in NOT IN ('jaro','jarowinkler','qgram') THEN		RAISE EXCEPTION USING			message = 'Invalid distance measure name ''' || monge_elkan_similarity_method_in || '''',			hint = 'Valid methods are jaro, jarowinkler, and qgram',			errcode = 'KC300'; -- Custom code for 'Bad lookup ID'.    END IF;-------------------------------------------------------------- Range/sanity checks on thresholds------------------------------------------------------------	IF handicap_factor_in < 0 OR handicap_factor_in > 1 THEN		RAISE EXCEPTION USING			message = 'handicap_factor value is out of range.',			hint = 'Value must be in the range 0-1.',			errcode = 'KC202'; -- Custom code for 'Numeric parameter value is too low'.    END IF;-------------------------------------------------------------- If you've gotten this far, everything looks good. Run it!------------------------------------------------------------    RETURN QUERY EXECUTE sql    USING base_text_in,          comparison_text_in,          base_id_in,          comparison_id_in,          handicap_factor_in,          monge_elkan_similarity_method_in;END$BODY$LANGUAGE plpgsql;ALTER FUNCTION tools.fuzzy_compare (citext, citext, citext, citext, real, citext)     OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:fuzzy_match.sqlDROP FUNCTION IF EXISTS tools.fuzzy_match (citext, uuid, int4, citext, float4, int4);-- decimal_score is a custom domain (type) for ###.##### numbers.CREATE OR REPLACE FUNCTION tools.fuzzy_match (     base_text_in                        citext,     text_collection_id_in               uuid,     neighbors_to_check_max_in           int4   DEFAULT 25,     monge_elkan_similarity_method_in    citext DEFAULT 'jarowinkler',     neighbor_qgram_threshold_min_in     float4 DEFAULT 0.2,     result_rows_max_in                  int4   DEFAULT 25)RETURNS TABLE (     base_text                           citext,     neighbor_text                       citext,     neighbor_id                         citext, -- Might be a 3rd party ID, not one of our UUIDs.     neighbor_rank                       int4,     neighbors_count                     int4,     highest_score                       decimal_score,     best_method                         citext,     avg_score                           decimal_score,     avg_quadratic_score                 decimal_score,     equality_check                      int4,     jaro_score                          decimal_score,     jaro_winkler_score                  decimal_score,     monge_elkan_score                   decimal_score,     monge_elkan_quadratic_score         decimal_score,     qgram_score                         decimal_score,     trigram_score                       decimal_score)AS $BODY$DECLARE-------------------------------------------------------------- Setup query template, which you can RAISE NOTICE while .-- developing to see what's in it.------------------------------------------------------------sql text := 'WITHnear_neighbors AS (  select distinct on (text <-> $1) text AS neighbor_text,         $1                             AS base_text,         source_id                      AS neighbor_id    from text_collection_item   where collection_id = $2  limit $3),measures AS (  select *,         DENSE_RANK() OVER(ORDER BY qgram(base_text, neighbor_text) DESC) AS neighbor_rank,         (base_text = neighbor_text)::int4                                AS equality_check,         monge_elkan(base_text, neighbor_text, $4)                        AS monge_elkan_score,         sqrt(monge_elkan(base_text, neighbor_text, $4))                  AS monge_elkan_quadratic_score,         jaro (base_text, neighbor_text)                                  AS jaro_score,         jarowinkler (base_text, neighbor_text)                           AS jaro_winkler_score,         qgram(base_text, neighbor_text)                                  AS qgram_score,         similarity(base_text, neighbor_text)                             AS trigram_score  from near_neighbors), handicap AS (    select base_text,           neighbor_text,           neighbor_id,           neighbor_rank::int4,           count(*) OVER() AS neighbors_count, -- Weird-looking way to get a count out of near_neighbors.           equality_check,           CASE             WHEN monge_elkan_score = 1 AND equality_check = 0 THEN 0.95             ELSE monge_elkan_score           END AS monge_elkan_score,           CASE             WHEN monge_elkan_quadratic_score = 1 AND equality_check = 0 THEN 0.95             ELSE monge_elkan_quadratic_score           END AS monge_elkan_quadratic_score,           jaro_score,           jaro_winkler_score,           qgram_score,           trigram_score      from measures     where qgram_score >= $5 ),stats AS (  select *,        (handicap.monge_elkan_score +         handicap.monge_elkan_quadratic_score +         jaro_score +         jaro_winkler_score +         qgram_score +         trigram_score) / 6 AS avg_score    from handicap), calculations AS (  select *,         sqrt(avg_score) AS avg_quadratic_score,         greatest (           monge_elkan_score,           monge_elkan_quadratic_score,           avg_score,           sqrt(avg_score),           jaro_score,           jaro_winkler_score,           qgram_score,           trigram_score) AS highest_score from stats)-- Final query, pull it all together and selsort  select base_text,         neighbor_text,         neighbor_id,         neighbor_rank::int4,         neighbors_count::int4,         highest_score::decimal_score,         (CASE highest_score            WHEN equality_check              THEN ''equality''            WHEN monge_elkan_quadratic_score THEN ''monge_elkan_quadratic''            WHEN monge_elkan_score           THEN ''monge_elkan''            WHEN jaro_score                  THEN ''jaro''            WHEN jaro_winkler_score          THEN ''jaro_winkler''            WHEN qgram_score                 THEN ''qgram''            WHEN trigram_score               THEN ''trigram''            WHEN avg_score                   THEN ''avg''            WHEN avg_quadratic_score         THEN ''avg_quadratic''            ELSE ''Undefined''         END)::citext AS best_method,         avg_score::decimal_score,         avg_quadratic_score::decimal_score,         equality_check::int4,         jaro_score::decimal_score,         jaro_winkler_score::decimal_score,         monge_elkan_score::decimal_score,         monge_elkan_quadratic_score::decimal_score,         qgram_score::decimal_score,         trigram_score::decimal_score    from calculationsorder by highest_score               DESC,         equality_check              DESC,         monge_elkan_quadratic_score DESC,         monge_elkan_score           DESC,         jaro_score                  DESC,         jaro_winkler_score          DESC,         qgram_score                 DESC,         trigram_score               DESC  limit $6';BEGIN-------------------------------------------------------------- Existence check for the text_collection------------------------------------------------------------	IF NOT EXISTS (select 1 from text_collection where id = text_collection_id_in) THEN		RAISE EXCEPTION USING			message = 'text_collection not found with id = ''' || text_collection_id_in || '''',			errcode = 'KC100'; -- Custom code for 'Bad string selector parameter value'.    END IF;-------------------------------------------------------------- Safety checks for parameters stitched into the SQL.------------------------------------------------------------	IF base_text_in = '' THEN		RAISE EXCEPTION USING			message = 'A base string must be supplied.',			errcode = 'KC101'; -- Custom code for 'Empty string parameter'.    END IF;    monge_elkan_similarity_method_in  := lower(monge_elkan_similarity_method_in);	IF monge_elkan_similarity_method_in NOT IN ('jaro','jarowinkler','qgram') THEN		RAISE EXCEPTION USING			message = 'Invalid distance measure name ''' || monge_elkan_similarity_method_in || '''',			hint = 'Valid methods are jaro, jarowinkler, and qgram',			errcode = 'KC300'; -- Custom code for 'Bad lookup ID'.    END IF;-------------------------------------------------------------- Range/sanity checks on thresholds------------------------------------------------------------	IF neighbors_to_check_max_in < 1 THEN		RAISE EXCEPTION USING			message = 'neighbors_to_check_max value is too low.',			hint = 'Value must be 1 or higher.',			errcode = 'KC200'; -- Custom code for 'Numeric parameter value is too low'.    END IF;	IF result_rows_max_in < 1 THEN		RAISE EXCEPTION USING			message = 'result_rows_max value is too low.',			hint = 'Value must be 1 or higher.',			errcode = 'KC200'; -- Custom code for 'Numeric parameter value is too low'.    END IF;	IF neighbor_qgram_threshold_min_in < 0 OR neighbor_qgram_threshold_min_in > 1 THEN		RAISE EXCEPTION USING			message = 'neighbor_qgram_threshold_min value is out of range.',			hint = 'Value must be in the range 0-1.',			errcode = 'KC202'; -- Custom code for 'Numeric parameter value is too low'.    END IF;-------------------------------------------------------------- If you've gotten this far, everything looks good. Run it!------------------------------------------------------------    RETURN QUERY EXECUTE sql    USING base_text_in,          text_collection_id_in,          neighbors_to_check_max_in,          monge_elkan_similarity_method_in,          neighbor_qgram_threshold_min_in,          result_rows_max_in;END$BODY$LANGUAGE plpgsql STABLE;ALTER FUNCTION tools.fuzzy_match (citext, uuid, int4, citext, float4, int4)     OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:get_function_owner_name.sqlCREATE OR REPLACE FUNCTION tools.get_function_owner_name (function_oid oid)	RETURNS textAS $BODY$SELECT rolname::text   FROM pg_authid WHERE oid = (	 	SELECT pg_proc.proowner	 	  FROM pg_proc	 	 WHERE oid = function_oid	 	 )$BODY$  LANGUAGE sql;ALTER FUNCTION tools.get_function_owner_name (oid)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:get_session_timezone.sqlCREATE OR REPLACE FUNCTION tools.get_session_timezone()  RETURNS pg_catalog.text   AS $BODY$	SELECT current_setting('TIMEZONE'); $BODY$  LANGUAGE sql VOLATILE  COST 100;  ALTER FUNCTION tools.get_session_timezone()	OWNER TO user_bender;    --Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:interval_generator.sqlCREATE OR REPLACE FUNCTION tools.interval_generator(        start_ts timestamp with time zone,        end_ts timestamp with time zone,        round_interval interval)             RETURNS TABLE(            start_time timestamp with time zone,            end_time timestamp with time zone) as $$BEGINRETURN QUERY        select            (n)       start_time,            (n + round_interval) end_time        from generate_series(date_trunc('minute', start_ts), end_ts, round_interval) n;END$$LANGUAGE 'plpgsql';COMMENT ON FUNCTION tools.interval_generator (timestamptz, timestamptz, interval) IS '/* https://stackoverflow.com/questions/12045600/postgresql-sql-group-by-time-interval-with-arbitrary-accuracy-down-to-milli-sec*/';ALTER FUNCTION tools.interval_generator (timestamptz, timestamptz, interval) 	OWNER TO user_bender;	--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:monge_elkan.sqlDROP FUNCTION IF EXISTS tools.monge_elkan (text,text,text,boolean);DROP FUNCTION IF EXISTS tools.monge_elkan (text,text,text,boolean,boolean);CREATE OR REPLACE FUNCTION tools.monge_elkan (	base_text              text,	comparison_text        text,	distance_measure_name  text    DEFAULT 'jarowinkler',	handicap               boolean DEFAULT true,	lexize_strings         boolean DEFAULT false)RETURNS realAS $BODY$DECLARE  base_word                 text;  comparison_word           text;  score                     float8;  best_score                float8;  best_scores_sum           float8;  monge_elkan_score         real;  base_words_count          int4;  comparison_words_count    float8;  word_count_ratio          float8;  base_words_array          text[];  comparison_words_array    text[];BEGIN    distance_measure_name  := lower(distance_measure_name);	IF distance_measure_name NOT IN ('qgram','jaro','jarowinkler') THEN		RAISE EXCEPTION USING			message = 'Invalid distance measure name ''' || distance_measure_name || '''',			hint = 'Valid methods are jaro, jarowinkler, and qgram',			errcode = 'KC100'; -- Custom code for 'Bad string selector parameter value'.		RETURN -1;	END IF;    base_text       := lower(base_text);    comparison_text := lower(comparison_text);    IF lexize_strings = true THEN		select into base_words_array		            array_agg(word)			   from ts_stat('SELECT to_tsvector(''english'',quote_literal(base_text))');			select into comparison_words_array		            array_agg(word)			   from ts_stat('SELECT to_tsvector(''english'',quote_literal(comparison_text))');    ELSE		select into base_words_array			string_to_array(base_text, ' ');		select into comparison_words_array			string_to_array (comparison_text, ' ');	END IF;	base_words_count  := 0;	best_scores_sum   := 0;    monge_elkan_score := 0;	FOREACH base_word IN array base_words_array LOOP		base_words_count := base_words_count + 1; -- PL/PgSQL doesn't have ++. Who does that? ;-)		best_score:=0;   -- Eh? Why repeat the loop. Micro-optimization, or better.	 -- This way, the which-method-to-use test runs once, not once per loop.		IF distance_measure_name = 'jaro' THEN				FOREACH comparison_word IN array comparison_words_array LOOP							 score      := jaro (base_word, comparison_word);							 best_score := greatest(score, best_score);				END LOOP;	    ELSEIF distance_measure_name = 'jarowinkler' THEN				FOREACH comparison_word IN array comparison_words_array LOOP							 score      := jarowinkler (base_word, comparison_word);							 best_score := greatest(score, best_score);				END LOOP;		  ELSEIF distance_measure_name = 'qgram' THEN				FOREACH comparison_word IN array comparison_words_array LOOP							 score      := qgram (base_word, comparison_word);							 best_score := greatest(score, best_score);				END LOOP;			ELSE				RAISE EXCEPTION USING					message = 'Invalid distance measure name ''' || distance_measure_name || '''',					hint = 'Valid methods are jaro, jarowinkler, and qgram. Problem should have been caught earlier.',					errcode = 'KC100'; -- Custom code for 'Bad string selector parameter value'.		END IF;		best_scores_sum := 	best_scores_sum + best_score;	END LOOP;   comparison_words_count := array_length(comparison_words_array, 1);       -- Being very explicit here about avoiding zero division.   	IF base_words_count = 0 THEN		word_count_ratio := 0;	ELSEIF comparison_words_count = 0 THEN		word_count_ratio := 0;    ELSE        word_count_ratio := (base_words_count / comparison_words_count)::real;   END IF;    -- Being very explicit here about avoiding zero division.	IF best_scores_sum = 0 THEN		monge_elkan_score := 0;	ELSEIF base_words_count = 0 THEN		monge_elkan_score := 0;	ELSEIF comparison_words_count = 0 THEN		monge_elkan_score := 0;    ELSE		monge_elkan_score:= (best_scores_sum / base_words_count)::real;		IF handicap = true AND word_count_ratio <= .67 THEN		     monge_elkan_score := monge_elkan_score - 0.1;		END IF;    END IF;	RETURN monge_elkan_score;END$BODY$	LANGUAGE plpgsql STABLE;ALTER FUNCTION tools.monge_elkan (text, text,text, boolean, boolean)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:num2words.sql/*Want something like Python's num2words, hacking it in.https://pypi.org/project/num2words/The code here uses the cash_words function from the deprecated money data type.No mention of it for years in the docs, but it still works in PG 12.    select cash_words('24,120.10')returns    Twenty four thousand one hundred twenty dollars and ten centsPython gives you   twenty-four thousand, one hundred and twenty point oneThis routine gives you    twenty four thousand one hundred and twenty point tenSo, not *identical* to the Python, but close. The bad part are the trailing decimals.Right now, just using this the fuzzy match cleanups, so the differences may not matter.If we ever mix data from Python and Postgres operations then, yeah, not ideal.*/CREATE OR REPLACE FUNCTION tools.num2words(number_as_text_in text)	RETURNS textAS $BODY$DECLARE  words_out text;  number_as_money money; -- cash_words(money)...the deprecated type.BEGIN   number_as_money = number_as_text_in::money;   words_out = cash_words(number_as_money); -- cash_words(money), not cash_words(some kind of numeric or text)-- select cash_words('24,120.10'); -- Twenty four thousand one hundred twenty dollars and ten cents   words_out = replace(words_out, ' dollars','');   words_out = replace(words_out, ' dollar','');   words_out = replace(words_out, ' cents','');   words_out = replace(words_out, ' cent','');   words_out = replace(words_out, ' and ',' point ');   RETURN words_out;END$BODY$  LANGUAGE plpgsql;ALTER FUNCTION tools.num2words (text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:relkind_name.sqlCREATE OR REPLACE FUNCTION tools.relkind_name (relkind text, out relkind_name text)  RETURNS textAS $BODY$SELECT CASE  WHEN relkind = 'r' THEN 'table'  WHEN relkind = 'i' THEN 'index'  WHEN relkind = 'S' THEN 'sequence'  WHEN relkind = 't' THEN 'TOAST table'  WHEN relkind = 'v' THEN 'view'  WHEN relkind = 'm' THEN 'materialized view'  WHEN relkind = 'c' THEN 'composite type'  WHEN relkind = 'f' THEN 'foreign table'  WHEN relkind = 'p' THEN 'partitioned table'  WHEN relkind = 'I' THEN 'partitioned index'  ELSE 'Unexpected relkind ' || relkindEND;$BODY$ 	LANGUAGE sql;ALTER FUNCTION tools.relkind_name (relkind text, out relkind_name text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:row_count_estimate.sqlCREATE OR REPLACE FUNCTION tools.row_count_estimate (query text)	RETURNS bigintAS $BODY$DECLARE   plan jsonb;BEGIN   EXECUTE 'EXPLAIN (FORMAT JSON) ' || query INTO plan;   RETURN (plan->0->'Plan'->>'Plan Rows')::bigint;END;$BODY$	LANGUAGE plpgsql;ALTER FUNCTION tools.row_count_estimate (text) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:stats_agg.sql-- Copyright (c) 2018 Chucky Ellison <cme at freefour.com>-- Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation-- files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy,-- modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the-- Software is furnished to do so, subject to the following conditions:-- The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.-- THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE-- WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR-- COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,-- ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.-- based on code from John D. Cook's https://www.johndcook.com/blog/skewness_kurtosis/ with permission-- This routine copied from https://github.com/ellisonch/PostgreSQL-Stats-Aggregate/-- I moved this code into our tools schema, even the custom type. (DPA)-- Notes:-- All the math is done at double precision; can easily be changed to work with numeric or single, or whatever.-- Kurtosis and skewness are NOT corrected for statistical bias---------------------------------------------------- MAKE SURE you're not using any of these names!drop aggregate if exists tools.stats_agg(double precision);drop function if exists tools._stats_agg_accumulator(_stats_agg_accum_type, double precision);drop function if exists tools._stats_agg_finalizer(_stats_agg_accum_type);drop type if exists tools._stats_agg_result_type;drop type if exists tools._stats_agg_accum_type;create type tools._stats_agg_accum_type AS (	n bigint,	min double precision,	max double precision,	m1 double precision,	m2 double precision,	m3 double precision,	m4 double precision);create type tools._stats_agg_result_type AS (	count bigint,	min double precision,	max double precision,	mean double precision,	variance double precision,	skewness double precision,	kurtosis double precision);create or replace function tools._stats_agg_accumulator(_stats_agg_accum_type, double precision)returns tools._stats_agg_accum_type AS 'DECLARE	a ALIAS FOR $1;	x alias for $2;	n1 bigint;	delta double precision;	delta_n double precision;	delta_n2 double precision;	term1 double precision;BEGIN	n1 = a.n;	a.n = a.n + 1;	delta = x - a.m1;	delta_n = delta / a.n;	delta_n2 = delta_n * delta_n;	term1 = delta * delta_n * n1;	a.m1 = a.m1 + delta_n;	a.m4 = a.m4 + term1 * delta_n2 * (a.n*a.n - 3*a.n + 3) + 6 * delta_n2 * a.m2 - 4 * delta_n * a.m3;	a.m3 = a.m3 + term1 * delta_n * (a.n - 2) - 3 * delta_n * a.m2;	a.m2 = a.m2 + term1;	a.min = least(a.min, x);	a.max = greatest(a.max, x);	RETURN a;END;'language plpgsql;create or replace function tools._stats_agg_finalizer(_stats_agg_accum_type)returns tools._stats_agg_result_type AS 'BEGIN	RETURN row(		$1.n,		$1.min,		$1.max,		$1.m1,		$1.m2 / nullif(($1.n - 1.0), 0),		case when $1.m2 = 0 then null else sqrt($1.n) * $1.m3 / nullif(($1.m2 ^ 1.5), 0) end,		case when $1.m2 = 0 then null else $1.n * $1.m4 / nullif(($1.m2 * $1.m2) - 3.0, 0) end	);END;'language plpgsql;create aggregate tools.stats_agg(double precision) (	sfunc = tools._stats_agg_accumulator,	stype = tools._stats_agg_accum_type,	finalfunc = tools._stats_agg_finalizer,	initcond = '(0,,, 0, 0, 0, 0)');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:text_collection_get_id.sqlCREATE OR REPLACE FUNCTION tools.text_collection_get_id(name_in citext)	RETURNS uuidAS $BODY$SELECT coalesce(id, '00000000-0000-0000-0000-000000000000') AS id  FROM text_collection WHERE collection_name = name_in;$BODY$  LANGUAGE sql;ALTER FUNCTION tools.text_collection_get_id (citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:typcategory_name.sqlCREATE OR REPLACE FUNCTION tools.typcategory_name (typcategory text, out typcategory_name text)  RETURNS textAS $BODY$SELECT CASE  WHEN typcategory ='A' THEN 'Array'  WHEN typcategory ='B' THEN 'Boolean'  WHEN typcategory ='C' THEN 'Composite'  WHEN typcategory ='D' THEN 'Date/time'  WHEN typcategory ='E' THEN 'Enum'  WHEN typcategory ='G' THEN 'Geometric'  WHEN typcategory ='I' THEN 'Network address'  WHEN typcategory ='N' THEN 'Numeric'  WHEN typcategory ='P' THEN 'Pseudo-'  WHEN typcategory ='R' THEN 'Range'  WHEN typcategory ='S' THEN 'String'  WHEN typcategory ='T' THEN 'Timespan'  WHEN typcategory ='U' THEN 'User-defined'  WHEN typcategory ='V' THEN 'Bit-string'  WHEN typcategory ='X' THEN 'Unknown type'  ELSE 'Unexpected typcategory ' || typcategoryEND;$BODY$	LANGUAGE sql;ALTER FUNCTION tools.typcategory_name (typcategory text, out typcategory_name text) 	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:typtype_name.sqlCREATE OR REPLACE FUNCTION tools.typtype_name (typtype text, out typtype_name text)	RETURNS text	AS $BODY$SELECT CASE  WHEN typtype = 'b' THEN 'base'  WHEN typtype = 'c' THEN 'composite type'  WHEN typtype = 'd' THEN 'domain'  WHEN typtype = 'e' THEN 'enum'  WHEN typtype = 'p' THEN 'pseudo-type'  WHEN typtype = 'r' THEN 'range'  ELSE 'Unexpected typtype ' || typtypeEND;$BODY$	LANGUAGE sql;ALTER FUNCTION tools.typtype_name (typtype text, out typtype_name text)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:view_count_estimate.sqlCREATE OR REPLACE FUNCTION tools.view_count_estimate (view_id regclass)	RETURNS bigintAS $BODY$DECLARE   plan jsonb;BEGIN   EXECUTE 'EXPLAIN (FORMAT JSON) ' || pg_get_viewdef(view_id) INTO plan;   RETURN (plan->0->'Plan'->>'Plan Rows')::bigint;END;$BODY$	LANGUAGE plpgsql;ALTER FUNCTION tools.view_count_estimate (regclass)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:word_count.sqlCREATE OR REPLACE FUNCTION tools.word_count (text_in citext)RETURNS intAS $BODY$DECLARE  text_in_words_array   text[];  word_count            int4;BEGINselect into text_in_words_array	string_to_array(text_in, ' ');word_count := array_length(text_in_words_array, 1);RETURN word_count;END$BODY$	LANGUAGE plpgsql;ALTER FUNCTION tools.word_count (citext)	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:functions:tools:word_type.sqlCREATE OR REPLACE FUNCTION tools.word_type(word_in citext)	RETURNS citextAS $BODY$select description::citext  from ts_debug('simple', word_in)  limit 1 -- only the first word$BODY$  LANGUAGE sql;ALTER FUNCTION tools.word_type (citext)	OWNER TO user_bender;------------------------------------------- Procedures-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:procedures:ascendco:cleanup_fuzzy_text.sqlDROP PROCEDURE IF EXISTS ascendco.cleanup_fuzzy_text;CREATE PROCEDURE ascendco.cleanup_fuzzy_text ()AS $BODY$DELETE FROM ascendco.text_collection      WHERE added_dts < NOW() - INTERVAL '1 day'        AND retain = false;ANALYZE ascendco.text_collection;$BODY$    LANGUAGE SQL;COMMENT ON PROCEDURE ascendco.cleanup_fuzzy_text IS 'Clear out old, purgeable data in ascendco.text_collection.Note: This is a stored PROCEDURE, not a FUNCTION. CALL count_targets(), not SELECT count_targets().';ALTER PROCEDURE ascendco.cleanup_fuzzy_text ()   OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:procedures:dba:count_targets.sqlDROP PROCEDURE IF EXISTS dba.count_targets;CREATE PROCEDURE dba.count_targets ()AS $BODY$/*Capture daily row counts for targets of interest by hsys and target into dba.target_count:ascendco.analytic_productivityascendco.analytic_scanascendco.analytic_sterilizer_loadinvascendco.analytic_sterilizer_loadNote: This is a stored PROCEDURE, not a FUNCTION. CALL count_targets(), not SELECT count_targets().*/WITHraw_counts AS (---------------------------------------------------- ascendco.analytic_productivity--------------------------------------------------   select hsys_id,          count(*)                             as records_count,          'ascendco'                           as schema_name,          'analytic_productivity'              as target_name      from ascendco.analytic_productivity  group by 1 union all---------------------------------------------------- ascendco.analytic_scan--------------------------------------------------    select hsys_id,           count(*)                            as records_count,          'ascendco'                           as schema_name,          'analytic_scan'                      as target_name      from ascendco.analytic_scan  group by 1 union all---------------------------------------------------- ascendco.ascendco.analytic_sterilizer_loadinv--------------------------------------------------    select hsys_id,           count(*)                            as records_count,          'ascendco'                           as schema_name,          'analytic_sterilizer_loadinv'        as target_name      from ascendco.analytic_sterilizer_loadinv  group by 1 union all---------------------------------------------------- ascendco.ascendco.analytic_sterilizer_load---------------------------------------------------- ascendco.analytic_sterilizer_load doesn't have hsys_id. D'oh!-- Look it up through facility_id, which is present.    select facility.hsys_id,           count(*)                            as records_count,           'ascendco'                          as schema_name,           'analytic_sterilizer_load'          as target_name       from ascendco.analytic_sterilizer_load left join facility on facility.id = analytic_sterilizer_load.facility_id  group by 1),---------------------------------------------------- Clear out bogus results--------------------------------------------------cleaned_counts AS (    select *     from raw_counts    where hsys_id IS NOT NULL      and hsys_id <> '00000000-0000-0000-0000-000000000000')---------------------------------------------------- Put it all together-------------------------------------------------- INSERT INTO dba.target_count (               hsys_id,               qualified_name,               records_count,               count_date,               count_dts)        SELECT hsys_id,               concat (schema_name, '.', target_name),               records_count,               current_date,               now()         FROM cleaned_counts  ON CONFLICT ON CONSTRAINT target_count_pk  DO UPDATE SET               records_count = EXCLUDED.records_count,               count_date    = EXCLUDED.count_date,               count_dts     = EXCLUDED.count_dts;$BODY$    LANGUAGE SQL;COMMENT ON PROCEDURE dba.count_targets IS 'Capture daily row counts for targets of interest by hsys and target into dba.target_count.Note: This is a stored PROCEDURE, not a FUNCTION. CALL count_targets(), not SELECT count_targets().';ALTER PROCEDURE dba.count_targets ()   OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:procedures:dba:system_delete_marked_and_log.sqlCREATE OR REPLACE PROCEDURE ascendco.system_delete_marked_and_log_sp ()AS $BODY$BEGIN-- Execute configured auto-deletes and save results in a CTE.with deletion_results as (    SELECT *      FROM system_delete_marked()    )-- Take the results from the CTE where something actually got deleted and push them into deletion_log.INSERT INTO deletion_log (                  schema_name,                  table_name,                  operation_name,                  deleted_count)         SELECT  schema,                 table_name,                 'DELETE',                 count            FROM deletion_results           WHERE count > 0;-- ANALYZE modified tables.-- Note: We're in a stored procedure, there is no result returned. Use PERFORM on this function instead of SELECT.PERFORM system_analyze_after_deletions();END;$BODY$	LANGUAGE plpgsql;COMMENT ON PROCEDURE ascendco.system_delete_marked_and_log_sp() IS '/*The system_delete_marked stored procedure is generated by PgBuild_ClearDeletedRecords to includehard-coded references to tables where we do auto-cleanup.Leviathan periodically calls system_delete_marked_and_log_sp, this routine,to run whatever deletes are configured in system_delete_marked_and_log_sp.You can see this in the deletion_results CTE at the top of this function.The summaries of those deletions are then intserted into deltion_log in the main body of this function.Note: This is a stored PROCEDURE and is invoked with CALL, not SELECT.*/';ALTER PROCEDURE ascendco.system_delete_marked_and_log_sp()	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:activity_v1:activity_v1_combined.sql-- Create a view onto activity formatted as activity_v1.-- If activity changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_activity_v1.DROP VIEW IF EXISTS types_plus.activity_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.activity_v1 AS select id,        facility_id,        facility_activities_id,        web_user_id,        other_desc,        start_dts,        done_dts,        last_updated_by_data_file_id,        created_by,        created_dts,        updated_by,        updated_dts,        duration_seconds   from activity;ALTER TABLE types_plus.activity_v1    OWNER TO user_change_structure;-- Create a casting function to convert activity rows into the compound type format activity_v1.-- If activity changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.activity_to_v1 (activity_in activity)  RETURNS activity_v1AS $BODY$                   SELECT			activity_in.id,			activity_in.facility_id,			activity_in.facility_activities_id,			activity_in.web_user_id,			activity_in.other_desc,			activity_in.start_dts,			activity_in.done_dts,			activity_in.last_updated_by_data_file_id,			activity_in.created_by,			activity_in.created_dts,			activity_in.updated_by,			activity_in.updated_dts,			activity_in.duration_seconds               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.activity_to_v1 (activity_in activity)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert activity rows into the activity_v1 compound type format using the following syntax:-- select activity::activity_v1 from activityDROP CAST IF EXISTS (activity as activity_v1);CREATE CAST (activity as activity_v1) WITH FUNCTION types_plus.activity_to_v1(activity);-- Create a function to accept an array of rows formatted as activity_v1 for UPSERT into activity.DROP FUNCTION IF EXISTS types_plus.insert_activity_v1 (types_plus.activity_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_activity_v1 (data_in types_plus.activity_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO activity (			id,			facility_id,			facility_activities_id,			web_user_id,			other_desc,			start_dts,			done_dts,			last_updated_by_data_file_id,			created_by,			created_dts,			updated_by,			updated_dts,			duration_seconds)                  SELECT			rows_in.id,			rows_in.facility_id,			rows_in.facility_activities_id,			rows_in.web_user_id,			rows_in.other_desc,			rows_in.start_dts,			rows_in.done_dts,			rows_in.last_updated_by_data_file_id,			rows_in.created_by,			rows_in.created_dts,			rows_in.updated_by,			rows_in.updated_dts,			rows_in.duration_seconds                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			facility_id = EXCLUDED.facility_id,			facility_activities_id = EXCLUDED.facility_activities_id,			web_user_id = EXCLUDED.web_user_id,			other_desc = EXCLUDED.other_desc,			start_dts = EXCLUDED.start_dts,			done_dts = EXCLUDED.done_dts,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			created_by = EXCLUDED.created_by,			created_dts = EXCLUDED.created_dts,			updated_by = EXCLUDED.updated_by,			updated_dts = EXCLUDED.updated_dts,			duration_seconds = EXCLUDED.duration_seconds          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_activity_v1(types_plus.activity_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:activity_v2:activity_v2_combined.sql-- Create a view onto activity formatted as activity_v2.-- If activity changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_activity_v2.DROP VIEW IF EXISTS types_plus.activity_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.activity_v2 AS select id,        facility_id,        facility_activities_id,        web_user_id,        last_updated_by_data_file_id,        updated_dts,        created_dts,        done_dts,        start_dts,        duration_seconds,        marked_for_deletion,        other_desc,        created_by,        updated_by   from activity;ALTER TABLE types_plus.activity_v2    OWNER TO user_change_structure;-- Create a casting function to convert activity rows into the compound type format activity_v2.-- If activity changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.activity_to_v2 (activity_in activity)  RETURNS activity_v2AS $BODY$                   SELECT			activity_in.id,			activity_in.facility_id,			activity_in.facility_activities_id,			activity_in.web_user_id,			activity_in.last_updated_by_data_file_id,			activity_in.updated_dts,			activity_in.created_dts,			activity_in.done_dts,			activity_in.start_dts,			activity_in.duration_seconds,			activity_in.marked_for_deletion,			activity_in.other_desc,			activity_in.created_by,			activity_in.updated_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.activity_to_v2 (activity_in activity)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert activity rows into the activity_v2 compound type format using the following syntax:-- select activity::activity_v2 from activityDROP CAST IF EXISTS (activity as activity_v2);CREATE CAST (activity as activity_v2) WITH FUNCTION types_plus.activity_to_v2(activity);-- Create a function to accept an array of rows formatted as activity_v2 for UPSERT into activity.DROP FUNCTION IF EXISTS types_plus.insert_activity_v2 (types_plus.activity_v2[]);  CREATE OR REPLACE FUNCTION types_plus.insert_activity_v2 (data_in types_plus.activity_v2[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO activity (			id,			facility_id,			facility_activities_id,			web_user_id,			last_updated_by_data_file_id,			updated_dts,			created_dts,			done_dts,			start_dts,			duration_seconds,			marked_for_deletion,			other_desc,			created_by,			updated_by)                  SELECT			rows_in.id,			rows_in.facility_id,			rows_in.facility_activities_id,			rows_in.web_user_id,			rows_in.last_updated_by_data_file_id,			rows_in.updated_dts,			rows_in.created_dts,			rows_in.done_dts,			rows_in.start_dts,			rows_in.duration_seconds,			rows_in.marked_for_deletion,			rows_in.other_desc,			rows_in.created_by,			rows_in.updated_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			facility_id = EXCLUDED.facility_id,			facility_activities_id = EXCLUDED.facility_activities_id,			web_user_id = EXCLUDED.web_user_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			updated_dts = EXCLUDED.updated_dts,			created_dts = EXCLUDED.created_dts,			done_dts = EXCLUDED.done_dts,			start_dts = EXCLUDED.start_dts,			duration_seconds = EXCLUDED.duration_seconds,			marked_for_deletion = EXCLUDED.marked_for_deletion,			other_desc = EXCLUDED.other_desc,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_activity_v2(types_plus.activity_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:analytic_productivity_v1:analytic_productivity_v1_combined.sql-- Create a view onto analytic_productivity formatted as analytic_productivity_v1.-- If analytic_productivity changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_analytic_productivity_v1.DROP VIEW IF EXISTS types_plus.analytic_productivity_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.analytic_productivity_v1 AS select id,        data_file_id,        marked_for_deletion,        hsys_id,        facility_id,        facility_location_id,        specialty_id,        item_type_id,        user_name,        inv_name,        item_name,        tray_or_pack,        num_inst,        assembly_minutes,        pause_minutes,        points,        points_per_hour,        assembly_hour,        pause_hour,        start_utc,        start_local,        end_utc,        end_local   from analytic_productivity;ALTER TABLE types_plus.analytic_productivity_v1    OWNER TO user_change_structure;-- Create a casting function to convert analytic_productivity rows into the compound type format analytic_productivity_v1.-- If analytic_productivity changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.analytic_productivity_to_v1 (analytic_productivity_in analytic_productivity)  RETURNS analytic_productivity_v1AS $BODY$        SELECT			analytic_productivity_in.id,			analytic_productivity_in.data_file_id,			analytic_productivity_in.marked_for_deletion,			analytic_productivity_in.hsys_id,			analytic_productivity_in.facility_id,			analytic_productivity_in.facility_location_id,			analytic_productivity_in.specialty_id,			analytic_productivity_in.item_type_id,			analytic_productivity_in.user_name,			analytic_productivity_in.inv_name,			analytic_productivity_in.item_name,			analytic_productivity_in.tray_or_pack,			analytic_productivity_in.num_inst,			analytic_productivity_in.assembly_minutes,			analytic_productivity_in.pause_minutes,			analytic_productivity_in.points,			analytic_productivity_in.points_per_hour,			analytic_productivity_in.assembly_hour,			analytic_productivity_in.pause_hour,			analytic_productivity_in.start_utc,			analytic_productivity_in.start_local,			analytic_productivity_in.end_utc,			analytic_productivity_in.end_local$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.analytic_productivity_to_v1 (analytic_productivity_in analytic_productivity) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert analytic_productivity rows into the analytic_productivity_v1 compound type format using the following syntax:-- select analytic_productivity::analytic_productivity_v1 from analytic_productivityDROP CAST IF EXISTS (analytic_productivity as analytic_productivity_v1);CREATE CAST (analytic_productivity as analytic_productivity_v1) WITH FUNCTION types_plus.analytic_productivity_to_v1(analytic_productivity);-- Create a function to accept an array of rows formatted as analytic_productivity_v1 for UPSERT into analytic_productivity.DROP FUNCTION IF EXISTS types_plus.insert_analytic_productivity_v1 (types_plus.analytic_productivity_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_analytic_productivity_v1 (data_in types_plus.analytic_productivity_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO analytic_productivity (			id,			data_file_id,			marked_for_deletion,			hsys_id,			facility_id,			facility_location_id,			specialty_id,			item_type_id,			user_name,			inv_name,			item_name,			tray_or_pack,			num_inst,			assembly_minutes,			pause_minutes,			points,			points_per_hour,			assembly_hour,			pause_hour,			start_utc,			start_local,			end_utc,			end_local)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.hsys_id,			rows_in.facility_id,			rows_in.facility_location_id,			rows_in.specialty_id,			rows_in.item_type_id,			rows_in.user_name,			rows_in.inv_name,			rows_in.item_name,			rows_in.tray_or_pack,			rows_in.num_inst,			rows_in.assembly_minutes,			rows_in.pause_minutes,			rows_in.points,			rows_in.points_per_hour,			rows_in.assembly_hour,			rows_in.pause_hour,			rows_in.start_utc,			rows_in.start_local,			rows_in.end_utc,			rows_in.end_local        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			hsys_id = EXCLUDED.hsys_id,			facility_id = EXCLUDED.facility_id,			facility_location_id = EXCLUDED.facility_location_id,			specialty_id = EXCLUDED.specialty_id,			item_type_id = EXCLUDED.item_type_id,			user_name = EXCLUDED.user_name,			inv_name = EXCLUDED.inv_name,			item_name = EXCLUDED.item_name,			tray_or_pack = EXCLUDED.tray_or_pack,			num_inst = EXCLUDED.num_inst,			assembly_minutes = EXCLUDED.assembly_minutes,			pause_minutes = EXCLUDED.pause_minutes,			points = EXCLUDED.points,			points_per_hour = EXCLUDED.points_per_hour,			assembly_hour = EXCLUDED.assembly_hour,			pause_hour = EXCLUDED.pause_hour,			start_utc = EXCLUDED.start_utc,			start_local = EXCLUDED.start_local,			end_utc = EXCLUDED.end_utc,			end_local = EXCLUDED.end_local        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_analytic_productivity_v1(types_plus.analytic_productivity_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:analytic_scan_v1:analytic_scan_v1_combined.sql-- Create a view onto analytic_scan formatted as analytic_scan_v1.-- If analytic_scan changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_analytic_scan_v1.DROP VIEW IF EXISTS types_plus.analytic_scan_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.analytic_scan_v1 AS select id,        data_file_id,        marked_for_deletion,        hsys_id,        facility_id,        facility_location_id,        specialty_id,        scanned_type,        associated_to,        user_name,        inv_name,        num_inst,        tray_or_pack,        item_name,        scan_time_utc_dts,        scan_time_local_dts,        location_description   from analytic_scan;ALTER TABLE types_plus.analytic_scan_v1    OWNER TO user_change_structure;-- Create a casting function to convert analytic_scan rows into the compound type format analytic_scan_v1.-- If analytic_scan changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.analytic_scan_to_v1 (analytic_scan_in analytic_scan)  RETURNS analytic_scan_v1AS $BODY$        SELECT			analytic_scan_in.id,			analytic_scan_in.data_file_id,			analytic_scan_in.marked_for_deletion,			analytic_scan_in.hsys_id,			analytic_scan_in.facility_id,			analytic_scan_in.facility_location_id,			analytic_scan_in.specialty_id,			analytic_scan_in.scanned_type,			analytic_scan_in.associated_to,			analytic_scan_in.user_name,			analytic_scan_in.inv_name,			analytic_scan_in.num_inst,			analytic_scan_in.tray_or_pack,			analytic_scan_in.item_name,			analytic_scan_in.scan_time_utc_dts,			analytic_scan_in.scan_time_local_dts,			analytic_scan_in.location_description$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.analytic_scan_to_v1 (analytic_scan_in analytic_scan) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert analytic_scan rows into the analytic_scan_v1 compound type format using the following syntax:-- select analytic_scan::analytic_scan_v1 from analytic_scanDROP CAST IF EXISTS (analytic_scan as analytic_scan_v1);CREATE CAST (analytic_scan as analytic_scan_v1) WITH FUNCTION types_plus.analytic_scan_to_v1(analytic_scan);-- Create a function to accept an array of rows formatted as analytic_scan_v1 for UPSERT into analytic_scan.DROP FUNCTION IF EXISTS types_plus.insert_analytic_scan_v1 (types_plus.analytic_scan_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_analytic_scan_v1 (data_in types_plus.analytic_scan_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO analytic_scan (			id,			data_file_id,			marked_for_deletion,			hsys_id,			facility_id,			facility_location_id,			specialty_id,			scanned_type,			associated_to,			user_name,			inv_name,			num_inst,			tray_or_pack,			item_name,			scan_time_utc_dts,			scan_time_local_dts,			location_description)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.hsys_id,			rows_in.facility_id,			rows_in.facility_location_id,			rows_in.specialty_id,			rows_in.scanned_type,			rows_in.associated_to,			rows_in.user_name,			rows_in.inv_name,			rows_in.num_inst,			rows_in.tray_or_pack,			rows_in.item_name,			rows_in.scan_time_utc_dts,			rows_in.scan_time_local_dts,			rows_in.location_description        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			hsys_id = EXCLUDED.hsys_id,			facility_id = EXCLUDED.facility_id,			facility_location_id = EXCLUDED.facility_location_id,			specialty_id = EXCLUDED.specialty_id,			scanned_type = EXCLUDED.scanned_type,			associated_to = EXCLUDED.associated_to,			user_name = EXCLUDED.user_name,			inv_name = EXCLUDED.inv_name,			num_inst = EXCLUDED.num_inst,			tray_or_pack = EXCLUDED.tray_or_pack,			item_name = EXCLUDED.item_name,			scan_time_utc_dts = EXCLUDED.scan_time_utc_dts,			scan_time_local_dts = EXCLUDED.scan_time_local_dts,			location_description = EXCLUDED.location_description        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_analytic_scan_v1(types_plus.analytic_scan_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:analytic_sterilizer_load_v1:analytic_sterilizer_load_v1_combined.sql-- Create a view onto analytic_sterilizer_load formatted as analytic_sterilizer_load_v1.-- If analytic_sterilizer_load changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_analytic_sterilizer_load_v1.DROP VIEW IF EXISTS types_plus.analytic_sterilizer_load_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.analytic_sterilizer_load_v1 AS select id,        marked_for_deletion,        data_file_id,        sterilize_method_id,        sterilize_params_id,        sterilizer_id,        facility_id,        web_user_id,        status_building_dts,        status_building_local_dts,        status_done_dts,        status_done_local_dts,        status,        is_iuss,        instruments_count,        packs_count,        trays_count   from analytic_sterilizer_load;ALTER TABLE types_plus.analytic_sterilizer_load_v1    OWNER TO user_change_structure;-- Create a casting function to convert analytic_sterilizer_load rows into the compound type format analytic_sterilizer_load_v1.-- If analytic_sterilizer_load changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.analytic_sterilizer_load_to_v1 (analytic_sterilizer_load_in analytic_sterilizer_load)  RETURNS analytic_sterilizer_load_v1AS $BODY$        SELECT			analytic_sterilizer_load_in.id,			analytic_sterilizer_load_in.marked_for_deletion,			analytic_sterilizer_load_in.data_file_id,			analytic_sterilizer_load_in.sterilize_method_id,			analytic_sterilizer_load_in.sterilize_params_id,			analytic_sterilizer_load_in.sterilizer_id,			analytic_sterilizer_load_in.facility_id,			analytic_sterilizer_load_in.web_user_id,			analytic_sterilizer_load_in.status_building_dts,			analytic_sterilizer_load_in.status_building_local_dts,			analytic_sterilizer_load_in.status_done_dts,			analytic_sterilizer_load_in.status_done_local_dts,			analytic_sterilizer_load_in.status,			analytic_sterilizer_load_in.is_iuss,			analytic_sterilizer_load_in.instruments_count,			analytic_sterilizer_load_in.packs_count,			analytic_sterilizer_load_in.trays_count$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.analytic_sterilizer_load_to_v1 (analytic_sterilizer_load_in analytic_sterilizer_load) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert analytic_sterilizer_load rows into the analytic_sterilizer_load_v1 compound type format using the following syntax:-- select analytic_sterilizer_load::analytic_sterilizer_load_v1 from analytic_sterilizer_loadDROP CAST IF EXISTS (analytic_sterilizer_load as analytic_sterilizer_load_v1);CREATE CAST (analytic_sterilizer_load as analytic_sterilizer_load_v1) WITH FUNCTION types_plus.analytic_sterilizer_load_to_v1(analytic_sterilizer_load);-- Create a function to accept an array of rows formatted as analytic_sterilizer_load_v1 for UPSERT into analytic_sterilizer_load.DROP FUNCTION IF EXISTS types_plus.insert_analytic_sterilizer_load_v1 (types_plus.analytic_sterilizer_load_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_analytic_sterilizer_load_v1 (data_in types_plus.analytic_sterilizer_load_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO analytic_sterilizer_load (			id,			marked_for_deletion,			data_file_id,			sterilize_method_id,			sterilize_params_id,			sterilizer_id,			facility_id,			web_user_id,			status_building_dts,			status_building_local_dts,			status_done_dts,			status_done_local_dts,			status,			is_iuss,			instruments_count,			packs_count,			trays_count)        SELECT			rows_in.id,			rows_in.marked_for_deletion,			rows_in.data_file_id,			rows_in.sterilize_method_id,			rows_in.sterilize_params_id,			rows_in.sterilizer_id,			rows_in.facility_id,			rows_in.web_user_id,			rows_in.status_building_dts,			rows_in.status_building_local_dts,			rows_in.status_done_dts,			rows_in.status_done_local_dts,			rows_in.status,			rows_in.is_iuss,			rows_in.instruments_count,			rows_in.packs_count,			rows_in.trays_count        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			marked_for_deletion = EXCLUDED.marked_for_deletion,			data_file_id = EXCLUDED.data_file_id,			sterilize_method_id = EXCLUDED.sterilize_method_id,			sterilize_params_id = EXCLUDED.sterilize_params_id,			sterilizer_id = EXCLUDED.sterilizer_id,			facility_id = EXCLUDED.facility_id,			web_user_id = EXCLUDED.web_user_id,			status_building_dts = EXCLUDED.status_building_dts,			status_building_local_dts = EXCLUDED.status_building_local_dts,			status_done_dts = EXCLUDED.status_done_dts,			status_done_local_dts = EXCLUDED.status_done_local_dts,			status = EXCLUDED.status,			is_iuss = EXCLUDED.is_iuss,			instruments_count = EXCLUDED.instruments_count,			packs_count = EXCLUDED.packs_count,			trays_count = EXCLUDED.trays_count        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_analytic_sterilizer_load_v1(types_plus.analytic_sterilizer_load_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:analytic_sterilizer_loadinv_v1:analytic_sterilizer_loadinv_v1_combined.sql-- Create a view onto analytic_sterilizer_loadinv formatted as analytic_sterilizer_loadinv_v1.-- If analytic_sterilizer_loadinv changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_analytic_sterilizer_loadinv_v1.DROP VIEW IF EXISTS types_plus.analytic_sterilizer_loadinv_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.analytic_sterilizer_loadinv_v1 AS select id,        data_file_id,        marked_for_deletion,        facility_id,        hsys_id,        inv_id,        item_id,        item_type_id,        speciality_id,        sterilize_method_id,        sterilize_params_id,        sterilizer_id,        sterilizerload_id,        web_user_id,        inv_name_provided,        is_iuss,        num_inst,        qty,        category,        clinic_dept_name,        processing_seconds,        done_dts,        done_local_dts   from analytic_sterilizer_loadinv;ALTER TABLE types_plus.analytic_sterilizer_loadinv_v1    OWNER TO user_change_structure;-- Create a casting function to convert analytic_sterilizer_loadinv rows into the compound type format analytic_sterilizer_loadinv_v1.-- If analytic_sterilizer_loadinv changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.analytic_sterilizer_loadinv_to_v1 (analytic_sterilizer_loadinv_in analytic_sterilizer_loadinv)  RETURNS analytic_sterilizer_loadinv_v1AS $BODY$        SELECT			analytic_sterilizer_loadinv_in.id,			analytic_sterilizer_loadinv_in.data_file_id,			analytic_sterilizer_loadinv_in.marked_for_deletion,			analytic_sterilizer_loadinv_in.facility_id,			analytic_sterilizer_loadinv_in.hsys_id,			analytic_sterilizer_loadinv_in.inv_id,			analytic_sterilizer_loadinv_in.item_id,			analytic_sterilizer_loadinv_in.item_type_id,			analytic_sterilizer_loadinv_in.speciality_id,			analytic_sterilizer_loadinv_in.sterilize_method_id,			analytic_sterilizer_loadinv_in.sterilize_params_id,			analytic_sterilizer_loadinv_in.sterilizer_id,			analytic_sterilizer_loadinv_in.sterilizerload_id,			analytic_sterilizer_loadinv_in.web_user_id,			analytic_sterilizer_loadinv_in.inv_name_provided,			analytic_sterilizer_loadinv_in.is_iuss,			analytic_sterilizer_loadinv_in.num_inst,			analytic_sterilizer_loadinv_in.qty,			analytic_sterilizer_loadinv_in.category,			analytic_sterilizer_loadinv_in.clinic_dept_name,			analytic_sterilizer_loadinv_in.processing_seconds,			analytic_sterilizer_loadinv_in.done_dts,			analytic_sterilizer_loadinv_in.done_local_dts$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.analytic_sterilizer_loadinv_to_v1 (analytic_sterilizer_loadinv_in analytic_sterilizer_loadinv) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert analytic_sterilizer_loadinv rows into the analytic_sterilizer_loadinv_v1 compound type format using the following syntax:-- select analytic_sterilizer_loadinv::analytic_sterilizer_loadinv_v1 from analytic_sterilizer_loadinvDROP CAST IF EXISTS (analytic_sterilizer_loadinv as analytic_sterilizer_loadinv_v1);CREATE CAST (analytic_sterilizer_loadinv as analytic_sterilizer_loadinv_v1) WITH FUNCTION types_plus.analytic_sterilizer_loadinv_to_v1(analytic_sterilizer_loadinv);-- Create a function to accept an array of rows formatted as analytic_sterilizer_loadinv_v1 for UPSERT into analytic_sterilizer_loadinv.DROP FUNCTION IF EXISTS types_plus.insert_analytic_sterilizer_loadinv_v1 (types_plus.analytic_sterilizer_loadinv_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_analytic_sterilizer_loadinv_v1 (data_in types_plus.analytic_sterilizer_loadinv_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO analytic_sterilizer_loadinv (			id,			data_file_id,			marked_for_deletion,			facility_id,			hsys_id,			inv_id,			item_id,			item_type_id,			speciality_id,			sterilize_method_id,			sterilize_params_id,			sterilizer_id,			sterilizerload_id,			web_user_id,			inv_name_provided,			is_iuss,			num_inst,			qty,			category,			clinic_dept_name,			processing_seconds,			done_dts,			done_local_dts)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.facility_id,			rows_in.hsys_id,			rows_in.inv_id,			rows_in.item_id,			rows_in.item_type_id,			rows_in.speciality_id,			rows_in.sterilize_method_id,			rows_in.sterilize_params_id,			rows_in.sterilizer_id,			rows_in.sterilizerload_id,			rows_in.web_user_id,			rows_in.inv_name_provided,			rows_in.is_iuss,			rows_in.num_inst,			rows_in.qty,			rows_in.category,			rows_in.clinic_dept_name,			rows_in.processing_seconds,			rows_in.done_dts,			rows_in.done_local_dts        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			facility_id = EXCLUDED.facility_id,			hsys_id = EXCLUDED.hsys_id,			inv_id = EXCLUDED.inv_id,			item_id = EXCLUDED.item_id,			item_type_id = EXCLUDED.item_type_id,			speciality_id = EXCLUDED.speciality_id,			sterilize_method_id = EXCLUDED.sterilize_method_id,			sterilize_params_id = EXCLUDED.sterilize_params_id,			sterilizer_id = EXCLUDED.sterilizer_id,			sterilizerload_id = EXCLUDED.sterilizerload_id,			web_user_id = EXCLUDED.web_user_id,			inv_name_provided = EXCLUDED.inv_name_provided,			is_iuss = EXCLUDED.is_iuss,			num_inst = EXCLUDED.num_inst,			qty = EXCLUDED.qty,			category = EXCLUDED.category,			clinic_dept_name = EXCLUDED.clinic_dept_name,			processing_seconds = EXCLUDED.processing_seconds,			done_dts = EXCLUDED.done_dts,			done_local_dts = EXCLUDED.done_local_dts        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_analytic_sterilizer_loadinv_v1(types_plus.analytic_sterilizer_loadinv_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:analytic_sterilizer_loadinv_v2:analytic_sterilizer_loadinv_v2_combined.sql-- Create a view onto analytic_sterilizer_loadinv formatted as analytic_sterilizer_loadinv_v2.-- If analytic_sterilizer_loadinv changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_analytic_sterilizer_loadinv_v2.DROP VIEW IF EXISTS types_plus.analytic_sterilizer_loadinv_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.analytic_sterilizer_loadinv_v2 AS select id,        data_file_id,        marked_for_deletion,        facility_id,        hsys_id,        inv_id,        item_id,        item_type_id,        speciality_id,        sterilize_method_id,        sterilize_params_id,        sterilizer_id,        sterilizerload_id,        web_user_id,        inv_name_provided,        is_iuss,        num_inst,        qty,        category,        clinic_dept_name,        processing_seconds,        done_dts,        done_local_dts,        status   from analytic_sterilizer_loadinv;ALTER TABLE types_plus.analytic_sterilizer_loadinv_v2    OWNER TO user_change_structure;-- Create a casting function to convert analytic_sterilizer_loadinv rows into the compound type format analytic_sterilizer_loadinv_v2.-- If analytic_sterilizer_loadinv changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.analytic_sterilizer_loadinv_to_v2 (analytic_sterilizer_loadinv_in analytic_sterilizer_loadinv)  RETURNS analytic_sterilizer_loadinv_v2AS $BODY$        SELECT			analytic_sterilizer_loadinv_in.id,			analytic_sterilizer_loadinv_in.data_file_id,			analytic_sterilizer_loadinv_in.marked_for_deletion,			analytic_sterilizer_loadinv_in.facility_id,			analytic_sterilizer_loadinv_in.hsys_id,			analytic_sterilizer_loadinv_in.inv_id,			analytic_sterilizer_loadinv_in.item_id,			analytic_sterilizer_loadinv_in.item_type_id,			analytic_sterilizer_loadinv_in.speciality_id,			analytic_sterilizer_loadinv_in.sterilize_method_id,			analytic_sterilizer_loadinv_in.sterilize_params_id,			analytic_sterilizer_loadinv_in.sterilizer_id,			analytic_sterilizer_loadinv_in.sterilizerload_id,			analytic_sterilizer_loadinv_in.web_user_id,			analytic_sterilizer_loadinv_in.inv_name_provided,			analytic_sterilizer_loadinv_in.is_iuss,			analytic_sterilizer_loadinv_in.num_inst,			analytic_sterilizer_loadinv_in.qty,			analytic_sterilizer_loadinv_in.category,			analytic_sterilizer_loadinv_in.clinic_dept_name,			analytic_sterilizer_loadinv_in.processing_seconds,			analytic_sterilizer_loadinv_in.done_dts,			analytic_sterilizer_loadinv_in.done_local_dts,			analytic_sterilizer_loadinv_in.status$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.analytic_sterilizer_loadinv_to_v2 (analytic_sterilizer_loadinv_in analytic_sterilizer_loadinv) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert analytic_sterilizer_loadinv rows into the analytic_sterilizer_loadinv_v2 compound type format using the following syntax:-- select analytic_sterilizer_loadinv::analytic_sterilizer_loadinv_v2 from analytic_sterilizer_loadinvDROP CAST IF EXISTS (analytic_sterilizer_loadinv as analytic_sterilizer_loadinv_v2);CREATE CAST (analytic_sterilizer_loadinv as analytic_sterilizer_loadinv_v2) WITH FUNCTION types_plus.analytic_sterilizer_loadinv_to_v2(analytic_sterilizer_loadinv);-- Create a function to accept an array of rows formatted as analytic_sterilizer_loadinv_v2 for UPSERT into analytic_sterilizer_loadinv.DROP FUNCTION IF EXISTS types_plus.insert_analytic_sterilizer_loadinv_v2 (types_plus.analytic_sterilizer_loadinv_v2[]);CREATE OR REPLACE FUNCTION types_plus.insert_analytic_sterilizer_loadinv_v2 (data_in types_plus.analytic_sterilizer_loadinv_v2[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO analytic_sterilizer_loadinv (			id,			data_file_id,			marked_for_deletion,			facility_id,			hsys_id,			inv_id,			item_id,			item_type_id,			speciality_id,			sterilize_method_id,			sterilize_params_id,			sterilizer_id,			sterilizerload_id,			web_user_id,			inv_name_provided,			is_iuss,			num_inst,			qty,			category,			clinic_dept_name,			processing_seconds,			done_dts,			done_local_dts,			status)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.facility_id,			rows_in.hsys_id,			rows_in.inv_id,			rows_in.item_id,			rows_in.item_type_id,			rows_in.speciality_id,			rows_in.sterilize_method_id,			rows_in.sterilize_params_id,			rows_in.sterilizer_id,			rows_in.sterilizerload_id,			rows_in.web_user_id,			rows_in.inv_name_provided,			rows_in.is_iuss,			rows_in.num_inst,			rows_in.qty,			rows_in.category,			rows_in.clinic_dept_name,			rows_in.processing_seconds,			rows_in.done_dts,			rows_in.done_local_dts,			rows_in.status        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			facility_id = EXCLUDED.facility_id,			hsys_id = EXCLUDED.hsys_id,			inv_id = EXCLUDED.inv_id,			item_id = EXCLUDED.item_id,			item_type_id = EXCLUDED.item_type_id,			speciality_id = EXCLUDED.speciality_id,			sterilize_method_id = EXCLUDED.sterilize_method_id,			sterilize_params_id = EXCLUDED.sterilize_params_id,			sterilizer_id = EXCLUDED.sterilizer_id,			sterilizerload_id = EXCLUDED.sterilizerload_id,			web_user_id = EXCLUDED.web_user_id,			inv_name_provided = EXCLUDED.inv_name_provided,			is_iuss = EXCLUDED.is_iuss,			num_inst = EXCLUDED.num_inst,			qty = EXCLUDED.qty,			category = EXCLUDED.category,			clinic_dept_name = EXCLUDED.clinic_dept_name,			processing_seconds = EXCLUDED.processing_seconds,			done_dts = EXCLUDED.done_dts,			done_local_dts = EXCLUDED.done_local_dts,			status = EXCLUDED.status        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_analytic_sterilizer_loadinv_v2(types_plus.analytic_sterilizer_loadinv_v2[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:analytic_work_v2:analytic_work_v2_combined.sql-- Create a view onto analytic_work formatted as analytic_work_v2.-- If analytic_work changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_analytic_work_v2.DROP VIEW IF EXISTS types_plus.analytic_work_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.analytic_work_v2 AS select id,        key_supplement,        hsys_id,        facility_id,        inv_id,        user_id,        activity_id,        assembly_id,        q_event_id,        scan_id,        scase_id,        scase_inv_id,        sterilizer_load_id,        sterilizer_loadinv_id,        start_dts,        end_dts,        start_local_dts,        end_local_dts,        date_time,        duration,        missing_inst,        num_inst,        num_items,        points,        num_packs,        num_trays,        activity,        description,        marked_for_deletion   from analytic_work;ALTER TABLE types_plus.analytic_work_v2    OWNER TO user_change_structure;-- Create a casting function to convert analytic_work rows into the compound type format analytic_work_v2.-- If analytic_work changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.analytic_work_to_v2 (analytic_work_in analytic_work)  RETURNS analytic_work_v2AS $BODY$        SELECT			analytic_work_in.id,			analytic_work_in.key_supplement,			analytic_work_in.hsys_id,			analytic_work_in.facility_id,			analytic_work_in.inv_id,			analytic_work_in.user_id,			analytic_work_in.activity_id,			analytic_work_in.assembly_id,			analytic_work_in.q_event_id,			analytic_work_in.scan_id,			analytic_work_in.scase_id,			analytic_work_in.scase_inv_id,			analytic_work_in.sterilizer_load_id,			analytic_work_in.sterilizer_loadinv_id,			analytic_work_in.start_dts,			analytic_work_in.end_dts,			analytic_work_in.start_local_dts,			analytic_work_in.end_local_dts,			analytic_work_in.date_time,			analytic_work_in.duration,			analytic_work_in.missing_inst,			analytic_work_in.num_inst,			analytic_work_in.num_items,			analytic_work_in.points,			analytic_work_in.num_packs,			analytic_work_in.num_trays,			analytic_work_in.activity,			analytic_work_in.description,			analytic_work_in.marked_for_deletion$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.analytic_work_to_v2 (analytic_work_in analytic_work)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert analytic_work rows into the analytic_work_v2 compound type format using the following syntax:-- select analytic_work::analytic_work_v2 from analytic_workDROP CAST IF EXISTS (analytic_work as analytic_work_v2);CREATE CAST (analytic_work as analytic_work_v2) WITH FUNCTION types_plus.analytic_work_to_v2(analytic_work);-- Create a function to accept an array of rows formatted as analytic_work_v2 for UPSERT into analytic_work.DROP FUNCTION IF EXISTS types_plus.insert_analytic_work_v2 (types_plus.analytic_work_v2[]);CREATE OR REPLACE FUNCTION types_plus.insert_analytic_work_v2 (data_in types_plus.analytic_work_v2[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO analytic_work (			id,			key_supplement,			hsys_id,			facility_id,			inv_id,			user_id,			activity_id,			assembly_id,			q_event_id,			scan_id,			scase_id,			scase_inv_id,			sterilizer_load_id,			sterilizer_loadinv_id,			start_dts,			end_dts,			start_local_dts,			end_local_dts,			date_time,			duration,			missing_inst,			num_inst,			num_items,			points,			num_packs,			num_trays,			activity,			description,			marked_for_deletion)        SELECT			rows_in.id,			rows_in.key_supplement,			rows_in.hsys_id,			rows_in.facility_id,			rows_in.inv_id,			rows_in.user_id,			rows_in.activity_id,			rows_in.assembly_id,			rows_in.q_event_id,			rows_in.scan_id,			rows_in.scase_id,			rows_in.scase_inv_id,			rows_in.sterilizer_load_id,			rows_in.sterilizer_loadinv_id,			rows_in.start_dts,			rows_in.end_dts,			rows_in.start_local_dts,			rows_in.end_local_dts,			rows_in.date_time,			rows_in.duration,			rows_in.missing_inst,			rows_in.num_inst,			rows_in.num_items,			rows_in.points,			rows_in.num_packs,			rows_in.num_trays,			rows_in.activity,			rows_in.description,			rows_in.marked_for_deletion        FROM unnest(data_in) as rows_in        ON CONFLICT(id, key_supplement) DO UPDATE SET			key_supplement = EXCLUDED.key_supplement,			hsys_id = EXCLUDED.hsys_id,			facility_id = EXCLUDED.facility_id,			inv_id = EXCLUDED.inv_id,			user_id = EXCLUDED.user_id,			activity_id = EXCLUDED.activity_id,			assembly_id = EXCLUDED.assembly_id,			q_event_id = EXCLUDED.q_event_id,			scan_id = EXCLUDED.scan_id,			scase_id = EXCLUDED.scase_id,			scase_inv_id = EXCLUDED.scase_inv_id,			sterilizer_load_id = EXCLUDED.sterilizer_load_id,			sterilizer_loadinv_id = EXCLUDED.sterilizer_loadinv_id,			start_dts = EXCLUDED.start_dts,			end_dts = EXCLUDED.end_dts,			start_local_dts = EXCLUDED.start_local_dts,			end_local_dts = EXCLUDED.end_local_dts,			date_time = EXCLUDED.date_time,			duration = EXCLUDED.duration,			missing_inst = EXCLUDED.missing_inst,			num_inst = EXCLUDED.num_inst,			num_items = EXCLUDED.num_items,			points = EXCLUDED.points,			num_packs = EXCLUDED.num_packs,			num_trays = EXCLUDED.num_trays,			activity = EXCLUDED.activity,			description = EXCLUDED.description,			marked_for_deletion = EXCLUDED.marked_for_deletion        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_analytic_work_v2(types_plus.analytic_work_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:assembly_prods_v1:assembly_prods_v1_combined.sql-- Create a view onto assembly_prods formatted as assembly_prods_v1.-- If assembly_prods changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_assembly_prods_v1.DROP VIEW IF EXISTS types_plus.assembly_prods_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.assembly_prods_v1 AS select id,        data_file_id,        assembly_id,        item_prod_id,        created_dts,        updated_dts,        target,        found_,        repair,        backup,        actual,        assembly_pos,        marked_for_deletion,        created_by,        updated_by,        prod_alert_text_ack,        audit_events   from assembly_prods;ALTER TABLE types_plus.assembly_prods_v1    OWNER TO user_change_structure;-- Create a casting function to convert assembly_prods rows into the compound type format assembly_prods_v1.-- If assembly_prods changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.assembly_prods_to_v1 (assembly_prods_in assembly_prods)  RETURNS assembly_prods_v1AS $BODY$        SELECT			assembly_prods_in.id,			assembly_prods_in.data_file_id,			assembly_prods_in.assembly_id,			assembly_prods_in.item_prod_id,			assembly_prods_in.created_dts,			assembly_prods_in.updated_dts,			assembly_prods_in.target,			assembly_prods_in.found_,			assembly_prods_in.repair,			assembly_prods_in.backup,			assembly_prods_in.actual,			assembly_prods_in.assembly_pos,			assembly_prods_in.marked_for_deletion,			assembly_prods_in.created_by,			assembly_prods_in.updated_by,			assembly_prods_in.prod_alert_text_ack,			assembly_prods_in.audit_events$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.assembly_prods_to_v1 (assembly_prods_in assembly_prods)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert assembly_prods rows into the assembly_prods_v1 compound type format using the following syntax:-- select assembly_prods::assembly_prods_v1 from assembly_prodsDROP CAST IF EXISTS (assembly_prods as assembly_prods_v1);CREATE CAST (assembly_prods as assembly_prods_v1) WITH FUNCTION types_plus.assembly_prods_to_v1(assembly_prods);-- Create a function to accept an array of rows formatted as assembly_prods_v1 for UPSERT into assembly_prods.DROP FUNCTION IF EXISTS types_plus.insert_assembly_prods_v1 (types_plus.assembly_prods_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_assembly_prods_v1 (data_in types_plus.assembly_prods_v1[])  RETURNS intAS $BODY$-- Note: This method is hand-tweaked to populate updated_date with a whole date (4 bytes), like-- !2021-04-15'. This is how the partitions are divided on the table level.-- Why not a generated column instead? Can't use it for partition keys.-- Why not an expression condition on the partition key? Not allowed, if you also have a PK.-- Why not a trigger? Ugh, bit of hassle & wildly inefficient.-- We already wear the overhead of this insert handler method, so let's put it to work!-- Kind of a drag, if there's an INSERT mechanism other than this method. Such as, COPY, import, etc.-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO assembly_prods (			id,			data_file_id,			assembly_id,			item_prod_id,			created_dts,			updated_dts,			target,			found_,			repair,			backup,			actual,			assembly_pos,			marked_for_deletion,			created_by,			updated_by,			prod_alert_text_ack,			audit_events,			updated_date)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.assembly_id,			rows_in.item_prod_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.target,			rows_in.found_,			rows_in.repair,			rows_in.backup,			rows_in.actual,			rows_in.assembly_pos,			rows_in.marked_for_deletion,			rows_in.created_by,			rows_in.updated_by,			rows_in.prod_alert_text_ack,			rows_in.audit_events,			updated_dts::date-- <-- Extract this value in advance for the partition key.        FROM unnest(data_in) as rows_in        ON CONFLICT ON CONSTRAINT assembly_prods_pkey DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			assembly_id = EXCLUDED.assembly_id,			item_prod_id = EXCLUDED.item_prod_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			target = EXCLUDED.target,			found_ = EXCLUDED.found_,			repair = EXCLUDED.repair,			backup = EXCLUDED.backup,			actual = EXCLUDED.actual,			assembly_pos = EXCLUDED.assembly_pos,			marked_for_deletion = EXCLUDED.marked_for_deletion,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			prod_alert_text_ack = EXCLUDED.prod_alert_text_ack,			audit_events = EXCLUDED.audit_events,			updated_date = EXCLUDED.updated_date        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_assembly_prods_v1(types_plus.assembly_prods_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:assembly_v1:assembly_v1_combined.sql-- Create a view onto assembly formatted as assembly_v1.-- If assembly changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_assembly_v1.DROP VIEW IF EXISTS types_plus.assembly_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.assembly_v1 AS select id,        data_file_id,        marked_for_deletion,        created_by_user_id,        done_by_user_id,        facility_location_id,        inv_id,        last_updated_by_data_file_id,        updated_by_user_id,        is_complete,        is_quick_turn,        con_id,        created_by,        difficulty,        quantity,        sequence_no,        num_inst,        points,        done_dts,        created_dts,        updated_dts,        missing_list,        priority,        status,        updated_by   from assembly;ALTER TABLE types_plus.assembly_v1    OWNER TO user_change_structure;-- Create a casting function to convert assembly rows into the compound type format assembly_v1.-- If assembly changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.assembly_to_v1 (assembly_in assembly)  RETURNS assembly_v1AS $BODY$        SELECT			assembly_in.id,			assembly_in.data_file_id,			assembly_in.marked_for_deletion,			assembly_in.created_by_user_id,			assembly_in.done_by_user_id,			assembly_in.facility_location_id,			assembly_in.inv_id,			assembly_in.last_updated_by_data_file_id,			assembly_in.updated_by_user_id,			assembly_in.is_complete,			assembly_in.is_quick_turn,			assembly_in.con_id,			assembly_in.created_by,			assembly_in.difficulty,			assembly_in.quantity,			assembly_in.sequence_no,			assembly_in.num_inst,			assembly_in.points,			assembly_in.done_dts,			assembly_in.created_dts,			assembly_in.updated_dts,			assembly_in.missing_list,			assembly_in.priority,			assembly_in.status,			assembly_in.updated_by$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.assembly_to_v1 (assembly_in assembly) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert assembly rows into the assembly_v1 compound type format using the following syntax:-- select assembly::assembly_v1 from assemblyDROP CAST IF EXISTS (assembly as assembly_v1);CREATE CAST (assembly as assembly_v1) WITH FUNCTION types_plus.assembly_to_v1(assembly);-- Create a function to accept an array of rows formatted as assembly_v1 for UPSERT into assembly.DROP FUNCTION IF EXISTS types_plus.insert_assembly_v1 (types_plus.assembly_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_assembly_v1 (data_in types_plus.assembly_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO assembly (			id,			data_file_id,			marked_for_deletion,			created_by_user_id,			done_by_user_id,			facility_location_id,			inv_id,			last_updated_by_data_file_id,			updated_by_user_id,			is_complete,			is_quick_turn,			con_id,			created_by,			difficulty,			quantity,			sequence_no,			num_inst,			points,			done_dts,			created_dts,			updated_dts,			missing_list,			priority,			status,			updated_by)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.created_by_user_id,			rows_in.done_by_user_id,			rows_in.facility_location_id,			rows_in.inv_id,			rows_in.last_updated_by_data_file_id,			rows_in.updated_by_user_id,			rows_in.is_complete,			rows_in.is_quick_turn,			rows_in.con_id,			rows_in.created_by,			rows_in.difficulty,			rows_in.quantity,			rows_in.sequence_no,			rows_in.num_inst,			rows_in.points,			rows_in.done_dts,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.missing_list,			rows_in.priority,			rows_in.status,			rows_in.updated_by        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			created_by_user_id = EXCLUDED.created_by_user_id,			done_by_user_id = EXCLUDED.done_by_user_id,			facility_location_id = EXCLUDED.facility_location_id,			inv_id = EXCLUDED.inv_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			updated_by_user_id = EXCLUDED.updated_by_user_id,			is_complete = EXCLUDED.is_complete,			is_quick_turn = EXCLUDED.is_quick_turn,			con_id = EXCLUDED.con_id,			created_by = EXCLUDED.created_by,			difficulty = EXCLUDED.difficulty,			quantity = EXCLUDED.quantity,			sequence_no = EXCLUDED.sequence_no,			num_inst = EXCLUDED.num_inst,			points = EXCLUDED.points,			done_dts = EXCLUDED.done_dts,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			missing_list = EXCLUDED.missing_list,			priority = EXCLUDED.priority,			status = EXCLUDED.status,			updated_by = EXCLUDED.updated_by        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_assembly_v1(types_plus.assembly_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:clinic_v1:clinic_v1_combined.sql-- Create a view onto clinic formatted as clinic_v1.-- If clinic changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_clinic_v1.DROP VIEW IF EXISTS types_plus.clinic_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.clinic_v1 AS select id,        hsys_id,        created_dts,        updated_dts,        marked_for_deletion,        receive_at_clinic,        name_,        created_by,        updated_by   from clinic;ALTER TABLE types_plus.clinic_v1    OWNER TO user_change_structure;-- Create a casting function to convert clinic rows into the compound type format clinic_v1.-- If clinic changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.clinic_to_v1 (clinic_in clinic)  RETURNS clinic_v1AS $BODY$                   SELECT			clinic_in.id,			clinic_in.hsys_id,			clinic_in.created_dts,			clinic_in.updated_dts,			clinic_in.marked_for_deletion,			clinic_in.receive_at_clinic,			clinic_in.name_,			clinic_in.created_by,			clinic_in.updated_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.clinic_to_v1 (clinic_in clinic)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert clinic rows into the clinic_v1 compound type format using the following syntax:-- select clinic::clinic_v1 from clinicDROP CAST IF EXISTS (clinic as clinic_v1);CREATE CAST (clinic as clinic_v1) WITH FUNCTION types_plus.clinic_to_v1(clinic);-- Create a function to accept an array of rows formatted as clinic_v1 for UPSERT into clinic.DROP FUNCTION IF EXISTS types_plus.insert_clinic_v1 (types_plus.clinic_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_clinic_v1 (data_in types_plus.clinic_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO clinic (			id,			hsys_id,			created_dts,			updated_dts,			marked_for_deletion,			receive_at_clinic,			name_,			created_by,			updated_by)                  SELECT			rows_in.id,			rows_in.hsys_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.receive_at_clinic,			rows_in.name_,			rows_in.created_by,			rows_in.updated_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			hsys_id = EXCLUDED.hsys_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			receive_at_clinic = EXCLUDED.receive_at_clinic,			name_ = EXCLUDED.name_,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_clinic_v1(types_plus.clinic_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:domo_dataset_v1:domo_dataset_v1_combined.sql-- Create a view onto domo_dataset formatted as domo_dataset_v1.-- If domo_dataset changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_domo_dataset_v1.DROP VIEW IF EXISTS types_plus.domo_dataset_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.domo_dataset_v1 AS select id,        dataset_name,        rows_count,        columns_count,        created_at_dts,        updated_at_dts   from domo_dataset;ALTER TABLE types_plus.domo_dataset_v1    OWNER TO user_change_structure;-- Create a casting function to convert domo_dataset rows into the compound type format domo_dataset_v1.-- If domo_dataset changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.domo_dataset_to_v1 (domo_dataset_in domo_dataset)  RETURNS domo_dataset_v1AS $BODY$                   SELECT			domo_dataset_in.id,			domo_dataset_in.dataset_name,			domo_dataset_in.rows_count,			domo_dataset_in.columns_count,			domo_dataset_in.created_at_dts,			domo_dataset_in.updated_at_dts               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.domo_dataset_to_v1 (domo_dataset_in domo_dataset)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert domo_dataset rows into the domo_dataset_v1 compound type format using the following syntax:-- select domo_dataset::domo_dataset_v1 from domo_datasetDROP CAST IF EXISTS (domo_dataset as domo_dataset_v1);CREATE CAST (domo_dataset as domo_dataset_v1) WITH FUNCTION types_plus.domo_dataset_to_v1(domo_dataset);-- Create a function to accept an array of rows formatted as domo_dataset_v1 for UPSERT into domo_dataset.DROP FUNCTION IF EXISTS types_plus.insert_domo_dataset_v1 (types_plus.domo_dataset_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_domo_dataset_v1 (data_in types_plus.domo_dataset_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO domo_dataset (			id,			dataset_name,			rows_count,			columns_count,			created_at_dts,			updated_at_dts)                  SELECT			rows_in.id,			rows_in.dataset_name,			rows_in.rows_count,			rows_in.columns_count,			rows_in.created_at_dts,			rows_in.updated_at_dts                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			dataset_name = EXCLUDED.dataset_name,			rows_count = EXCLUDED.rows_count,			columns_count = EXCLUDED.columns_count,			created_at_dts = EXCLUDED.created_at_dts,			updated_at_dts = EXCLUDED.updated_at_dts          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_domo_dataset_v1(types_plus.domo_dataset_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:domo_passthrough_v1:domo_passthrough_v1_combined.sql-- Create a view onto domo_passthrough formatted as domo_passthrough_v1.-- If domo_passthrough changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_domo_passthrough_v1.DROP VIEW IF EXISTS types_plus.domo_passthrough_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.domo_passthrough_v1 AS select source_id,        hsys_id,        facility_id,        view_version,        dataset_name,        data   from domo_passthrough;ALTER TABLE types_plus.domo_passthrough_v1    OWNER TO user_change_structure;-- Create a casting function to convert domo_passthrough rows into the compound type format domo_passthrough_v1.-- If domo_passthrough changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.domo_passthrough_to_v1 (domo_passthrough_in domo_passthrough)  RETURNS domo_passthrough_v1AS $BODY$        SELECT			domo_passthrough_in.source_id,			domo_passthrough_in.hsys_id,			domo_passthrough_in.facility_id,			domo_passthrough_in.view_version,			domo_passthrough_in.dataset_name,			domo_passthrough_in.data$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.domo_passthrough_to_v1 (domo_passthrough_in domo_passthrough) OWNER TO user_bender;-- Create a view onto domo_passthrough formatted as domo_passthrough_v1.-- If domo_passthrough changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_domo_passthrough_v1.DROP VIEW IF EXISTS types_plus.domo_passthrough_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.domo_passthrough_v1 AS select source_id,        hsys_id,        facility_id,        view_version,        dataset_name,        data   from domo_passthrough;ALTER TABLE types_plus.domo_passthrough_v1    OWNER TO user_change_structure;-- Create a casting function to convert domo_passthrough rows into the compound type format domo_passthrough_v1.-- If domo_passthrough changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.domo_passthrough_to_v1 (domo_passthrough_in domo_passthrough)  RETURNS domo_passthrough_v1AS $BODY$        SELECT			domo_passthrough_in.source_id,			domo_passthrough_in.hsys_id,			domo_passthrough_in.facility_id,			domo_passthrough_in.view_version,			domo_passthrough_in.dataset_name,			domo_passthrough_in.data$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.domo_passthrough_to_v1 (domo_passthrough_in domo_passthrough) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert domo_passthrough rows into the domo_passthrough_v1 compound type format using the following syntax:-- select domo_passthrough::domo_passthrough_v1 from domo_passthroughDROP CAST IF EXISTS (domo_passthrough as domo_passthrough_v1);CREATE CAST (domo_passthrough as domo_passthrough_v1) WITH FUNCTION types_plus.domo_passthrough_to_v1(domo_passthrough);-- Create a function to accept an array of rows formatted as domo_passthrough_v1 for UPSERT into domo_passthrough.DROP FUNCTION IF EXISTS types_plus.insert_domo_passthrough_v1 (types_plus.domo_passthrough_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_domo_passthrough_v1 (data_in types_plus.domo_passthrough_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.-- 2020-04-05: Updated constraint clause to to match unqiue index name in v2 of table.with inserted_rows as (        INSERT INTO domo_passthrough (			source_id,			hsys_id,			facility_id,			view_version,			dataset_name,			data)        SELECT			rows_in.source_id,			rows_in.hsys_id,			rows_in.facility_id,			rows_in.view_version,			rows_in.dataset_name,			rows_in.data        FROM unnest(data_in) as rows_in        ON CONFLICT ON CONSTRAINT domo_passthrough_key_unique DO UPDATE SET			hsys_id         = EXCLUDED.hsys_id,			facility_id     = EXCLUDED.facility_id,			view_version    = EXCLUDED.view_version,			data            = EXCLUDED.data        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_domo_passthrough_v1(types_plus.domo_passthrough_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:domo_passthrough_v2:domo_passthrough_v2_combined.sql-- Create a view onto domo_passthrough formatted as domo_passthrough_v2.-- If domo_passthrough changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_domo_passthrough_v2.DROP VIEW IF EXISTS types_plus.domo_passthrough_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.domo_passthrough_v2 AS select key_supplement,        source_id,        hsys_id,        facility_id,        view_version,        dataset_name,        data,        from_dts,        to_dts   from domo_passthrough;ALTER TABLE types_plus.domo_passthrough_v2    OWNER TO user_change_structure;-- Create a casting function to convert domo_passthrough rows into the compound type format domo_passthrough_v2.-- If domo_passthrough changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.domo_passthrough_to_v2 (domo_passthrough_in domo_passthrough)  RETURNS domo_passthrough_v2AS $BODY$        SELECT			domo_passthrough_in.key_supplement,			domo_passthrough_in.source_id,			domo_passthrough_in.hsys_id,			domo_passthrough_in.facility_id,			domo_passthrough_in.view_version,			domo_passthrough_in.dataset_name,			domo_passthrough_in.data,			domo_passthrough_in.from_dts,			domo_passthrough_in.to_dts$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.domo_passthrough_to_v2 (domo_passthrough_in domo_passthrough)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert domo_passthrough rows into the domo_passthrough_v2 compound type format using the following syntax:-- select domo_passthrough::domo_passthrough_v2 from domo_passthroughDROP CAST IF EXISTS (domo_passthrough as domo_passthrough_v2);CREATE CAST (domo_passthrough as domo_passthrough_v2) WITH FUNCTION types_plus.domo_passthrough_to_v2(domo_passthrough);-- Create a function to accept an array of rows formatted as domo_passthrough_v2 for UPSERT into domo_passthrough.DROP FUNCTION IF EXISTS types_plus.insert_domo_passthrough_v2 (types_plus.domo_passthrough_v2[]);CREATE OR REPLACE FUNCTION types_plus.insert_domo_passthrough_v2 (data_in types_plus.domo_passthrough_v2[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO domo_passthrough (			key_supplement,			source_id,			hsys_id,			facility_id,			view_version,			dataset_name,			data,			from_dts,			to_dts)        SELECT			rows_in.key_supplement,			rows_in.source_id,			rows_in.hsys_id,			rows_in.facility_id,			rows_in.view_version,			rows_in.dataset_name,			rows_in.data,			rows_in.from_dts,			rows_in.to_dts        FROM unnest(data_in) as rows_in        ON CONFLICT ON CONSTRAINT domo_passthrough_key_unique DO UPDATE SET			hsys_id         = EXCLUDED.hsys_id,			facility_id     = EXCLUDED.facility_id,			view_version    = EXCLUDED.view_version,			data            = EXCLUDED.data,			from_dts        = EXCLUDED.from_dts,			to_dts          = EXCLUDED.to_dts        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_domo_passthrough_v2(types_plus.domo_passthrough_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:facility_activities_v1:facility_activities_v1_combined.sql-- Create a view onto facility_activities formatted as facility_activities_v1.-- If facility_activities changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_facility_activities_v1.DROP VIEW IF EXISTS types_plus.facility_activities_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.facility_activities_v1 AS select id,        facility_id,        last_updated_by_data_file_id,        created_dts,        updated_dts,        marked_for_deletion,        name_,        created_by,        updated_by   from facility_activities;ALTER TABLE types_plus.facility_activities_v1    OWNER TO user_change_structure;-- Create a casting function to convert facility_activities rows into the compound type format facility_activities_v1.-- If facility_activities changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.facility_activities_to_v1 (facility_activities_in facility_activities)  RETURNS facility_activities_v1AS $BODY$                   SELECT			facility_activities_in.id,			facility_activities_in.facility_id,			facility_activities_in.last_updated_by_data_file_id,			facility_activities_in.created_dts,			facility_activities_in.updated_dts,			facility_activities_in.marked_for_deletion,			facility_activities_in.name_,			facility_activities_in.created_by,			facility_activities_in.updated_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.facility_activities_to_v1 (facility_activities_in facility_activities)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert facility_activities rows into the facility_activities_v1 compound type format using the following syntax:-- select facility_activities::facility_activities_v1 from facility_activitiesDROP CAST IF EXISTS (facility_activities as facility_activities_v1);CREATE CAST (facility_activities as facility_activities_v1) WITH FUNCTION types_plus.facility_activities_to_v1(facility_activities);-- Create a function to accept an array of rows formatted as facility_activities_v1 for UPSERT into facility_activities.DROP FUNCTION IF EXISTS types_plus.insert_facility_activities_v1 (types_plus.facility_activities_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_facility_activities_v1 (data_in types_plus.facility_activities_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO facility_activities (			id,			facility_id,			last_updated_by_data_file_id,			created_dts,			updated_dts,			marked_for_deletion,			name_,			created_by,			updated_by)                  SELECT			rows_in.id,			rows_in.facility_id,			rows_in.last_updated_by_data_file_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.name_,			rows_in.created_by,			rows_in.updated_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			facility_id = EXCLUDED.facility_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_facility_activities_v1(types_plus.facility_activities_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:facility_department_v1:facility_department_v1_combined.sql-- Create a view onto facility_department formatted as facility_department_v1.-- If facility_department changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_facility_department_v1.DROP VIEW IF EXISTS types_plus.facility_department_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.facility_department_v1 AS select id,        facility_id,        their_id,        created_dts,        updated_dts,        marked_for_deletion,        is_available_in_sonar,        receive_at_dept,        is_from_emr,        name_,        created_by,        updated_by,        label_name,        inv_audit   from facility_department;ALTER TABLE types_plus.facility_department_v1    OWNER TO user_change_structure;-- Create a casting function to convert facility_department rows into the compound type format facility_department_v1.-- If facility_department changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.facility_department_to_v1 (facility_department_in facility_department)  RETURNS facility_department_v1AS $BODY$                   SELECT			facility_department_in.id,			facility_department_in.facility_id,			facility_department_in.their_id,			facility_department_in.created_dts,			facility_department_in.updated_dts,			facility_department_in.marked_for_deletion,			facility_department_in.is_available_in_sonar,			facility_department_in.receive_at_dept,			facility_department_in.is_from_emr,			facility_department_in.name_,			facility_department_in.created_by,			facility_department_in.updated_by,			facility_department_in.label_name,			facility_department_in.inv_audit               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.facility_department_to_v1 (facility_department_in facility_department)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert facility_department rows into the facility_department_v1 compound type format using the following syntax:-- select facility_department::facility_department_v1 from facility_departmentDROP CAST IF EXISTS (facility_department as facility_department_v1);CREATE CAST (facility_department as facility_department_v1) WITH FUNCTION types_plus.facility_department_to_v1(facility_department);-- Create a function to accept an array of rows formatted as facility_department_v1 for UPSERT into facility_department.DROP FUNCTION IF EXISTS types_plus.insert_facility_department_v1 (types_plus.facility_department_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_facility_department_v1 (data_in types_plus.facility_department_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO facility_department (			id,			facility_id,			their_id,			created_dts,			updated_dts,			marked_for_deletion,			is_available_in_sonar,			receive_at_dept,			is_from_emr,			name_,			created_by,			updated_by,			label_name,			inv_audit)                  SELECT			rows_in.id,			rows_in.facility_id,			rows_in.their_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.is_available_in_sonar,			rows_in.receive_at_dept,			rows_in.is_from_emr,			rows_in.name_,			rows_in.created_by,			rows_in.updated_by,			rows_in.label_name,			rows_in.inv_audit                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			facility_id = EXCLUDED.facility_id,			their_id = EXCLUDED.their_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_available_in_sonar = EXCLUDED.is_available_in_sonar,			receive_at_dept = EXCLUDED.receive_at_dept,			is_from_emr = EXCLUDED.is_from_emr,			name_ = EXCLUDED.name_,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			label_name = EXCLUDED.label_name,			inv_audit = EXCLUDED.inv_audit          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_facility_department_v1(types_plus.facility_department_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:facility_location_v1:facility_location_v1_combined.sql-- Create a view onto facility_location formatted as facility_location_v1.-- If facility_location changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_facility_location_v1.DROP VIEW IF EXISTS types_plus.facility_location_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.facility_location_v1 AS select id,        marked_for_deletion,        facility_id,        type_,        name_   from facility_location;ALTER TABLE types_plus.facility_location_v1    OWNER TO user_change_structure;-- Create a casting function to convert facility_location rows into the compound type format facility_location_v1.-- If facility_location changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.facility_location_to_v1 (facility_location_in facility_location)  RETURNS facility_location_v1AS $BODY$        SELECT			facility_location_in.id,			facility_location_in.marked_for_deletion,			facility_location_in.facility_id,			facility_location_in.type_,			facility_location_in.name_$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.facility_location_to_v1 (facility_location_in facility_location) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert facility_location rows into the facility_location_v1 compound type format using the following syntax:-- select facility_location::facility_location_v1 from facility_locationDROP CAST IF EXISTS (facility_location as facility_location_v1);CREATE CAST (facility_location as facility_location_v1) WITH FUNCTION types_plus.facility_location_to_v1(facility_location);-- Create a function to accept an array of rows formatted as facility_location_v1 for UPSERT into facility_location.DROP FUNCTION IF EXISTS types_plus.insert_facility_location_v1 (types_plus.facility_location_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_facility_location_v1 (data_in types_plus.facility_location_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO facility_location (			id,			marked_for_deletion,			facility_id,			type_,			name_)        SELECT			rows_in.id,			rows_in.marked_for_deletion,			rows_in.facility_id,			rows_in.type_,			rows_in.name_        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			marked_for_deletion = EXCLUDED.marked_for_deletion,			facility_id = EXCLUDED.facility_id,			type_ = EXCLUDED.type_,			name_ = EXCLUDED.name_        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_facility_location_v1(types_plus.facility_location_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:facility_v1:facility_v1_combined.sql-- Create a view onto facility formatted as facility_v1.-- If facility changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_facility_v1.DROP VIEW IF EXISTS types_plus.facility_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.facility_v1 AS select id,        marked_for_deletion,        hsys_id,        name_,        tz_name   from facility;ALTER TABLE types_plus.facility_v1    OWNER TO user_change_structure;-- Create a casting function to convert facility rows into the compound type format facility_v1.-- If facility changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.facility_to_v1 (facility_in facility)  RETURNS facility_v1AS $BODY$        SELECT			facility_in.id,			facility_in.marked_for_deletion,			facility_in.hsys_id,			facility_in.name_,			facility_in.tz_name$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.facility_to_v1 (facility_in facility) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert facility rows into the facility_v1 compound type format using the following syntax:-- select facility::facility_v1 from facilityDROP CAST IF EXISTS (facility as facility_v1);CREATE CAST (facility as facility_v1) WITH FUNCTION types_plus.facility_to_v1(facility);-- Create a function to accept an array of rows formatted as facility_v1 for UPSERT into facility.DROP FUNCTION IF EXISTS types_plus.insert_facility_v1 (types_plus.facility_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_facility_v1 (data_in types_plus.facility_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO facility (			id,			marked_for_deletion,			hsys_id,			name_,			tz_name)        SELECT			rows_in.id,			rows_in.marked_for_deletion,			rows_in.hsys_id,			rows_in.name_,			rows_in.tz_name        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			marked_for_deletion = EXCLUDED.marked_for_deletion,			hsys_id = EXCLUDED.hsys_id,			name_ = EXCLUDED.name_,			tz_name = EXCLUDED.tz_name        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_facility_v1(types_plus.facility_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:facility_v2:facility_v2_combined.sql-- Create a view onto facility formatted as facility_v2.-- If facility changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_facility_v2.DROP VIEW IF EXISTS types_plus.facility_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.facility_v2 AS select id,        hsys_id,        production_label_form_id,        permanent_label_form_id,        missing_inst_label_form_id,        facility_location_label_form_id,        sterilizer_label_form_id,        user_badge_label_form_id,        workstation_label_form_id,        default_spd_facility_id,        created_dts,        updated_dts,        sonar_auto_logout_minutes,        sonar_auto_logout_dialog_minutes,        num_ors,        sonar_go_live_date,        marked_for_deletion,        is_count_sheet_source_truth,        hide_doc_names_for_stats,        is_item_master_live,        is_sonar_live,        sterilizer_print_at_sterilizing,        sterilizer_print_at_cooling,        sterilizer_print_at_released,        can_set_all_found_in_assembly,        name_,        their_id,        created_by,        updated_by,        reporting_name,        label_name,        tz_name,        sonar_name_full,        sonar_count_sheet_form_name,        sterilize_alert_level,        sonar_scanner_stop_char,        emr_location_name,        sonar_features,        interfaces,        needs_scheduling,        analytics_prefs   from facility;ALTER TABLE types_plus.facility_v2    OWNER TO user_change_structure;-- Create a casting function to convert facility rows into the compound type format facility_v2.-- If facility changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.facility_to_v2 (facility_in facility)  RETURNS facility_v2AS $BODY$                   SELECT			facility_in.id,			facility_in.hsys_id,			facility_in.production_label_form_id,			facility_in.permanent_label_form_id,			facility_in.missing_inst_label_form_id,			facility_in.facility_location_label_form_id,			facility_in.sterilizer_label_form_id,			facility_in.user_badge_label_form_id,			facility_in.workstation_label_form_id,			facility_in.default_spd_facility_id,			facility_in.created_dts,			facility_in.updated_dts,			facility_in.sonar_auto_logout_minutes,			facility_in.sonar_auto_logout_dialog_minutes,			facility_in.num_ors,			facility_in.sonar_go_live_date,			facility_in.marked_for_deletion,			facility_in.is_count_sheet_source_truth,			facility_in.hide_doc_names_for_stats,			facility_in.is_item_master_live,			facility_in.is_sonar_live,			facility_in.sterilizer_print_at_sterilizing,			facility_in.sterilizer_print_at_cooling,			facility_in.sterilizer_print_at_released,			facility_in.can_set_all_found_in_assembly,			facility_in.name_,			facility_in.their_id,			facility_in.created_by,			facility_in.updated_by,			facility_in.reporting_name,			facility_in.label_name,			facility_in.tz_name,			facility_in.sonar_name_full,			facility_in.sonar_count_sheet_form_name,			facility_in.sterilize_alert_level,			facility_in.sonar_scanner_stop_char,			facility_in.emr_location_name,			facility_in.sonar_features,			facility_in.interfaces,			facility_in.needs_scheduling,			facility_in.analytics_prefs               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.facility_to_v2 (facility_in facility)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert facility rows into the facility_v2 compound type format using the following syntax:-- select facility::facility_v2 from facilityDROP CAST IF EXISTS (facility as facility_v2);CREATE CAST (facility as facility_v2) WITH FUNCTION types_plus.facility_to_v2(facility);-- Create a function to accept an array of rows formatted as facility_v2 for UPSERT into facility.DROP FUNCTION IF EXISTS types_plus.insert_facility_v2 (types_plus.facility_v2[]);  CREATE OR REPLACE FUNCTION types_plus.insert_facility_v2 (data_in types_plus.facility_v2[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO facility (			id,			hsys_id,			production_label_form_id,			permanent_label_form_id,			missing_inst_label_form_id,			facility_location_label_form_id,			sterilizer_label_form_id,			user_badge_label_form_id,			workstation_label_form_id,			default_spd_facility_id,			created_dts,			updated_dts,			sonar_auto_logout_minutes,			sonar_auto_logout_dialog_minutes,			num_ors,			sonar_go_live_date,			marked_for_deletion,			is_count_sheet_source_truth,			hide_doc_names_for_stats,			is_item_master_live,			is_sonar_live,			sterilizer_print_at_sterilizing,			sterilizer_print_at_cooling,			sterilizer_print_at_released,			can_set_all_found_in_assembly,			name_,			their_id,			created_by,			updated_by,			reporting_name,			label_name,			tz_name,			sonar_name_full,			sonar_count_sheet_form_name,			sterilize_alert_level,			sonar_scanner_stop_char,			emr_location_name,			sonar_features,			interfaces,			needs_scheduling,			analytics_prefs)                  SELECT			rows_in.id,			rows_in.hsys_id,			rows_in.production_label_form_id,			rows_in.permanent_label_form_id,			rows_in.missing_inst_label_form_id,			rows_in.facility_location_label_form_id,			rows_in.sterilizer_label_form_id,			rows_in.user_badge_label_form_id,			rows_in.workstation_label_form_id,			rows_in.default_spd_facility_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.sonar_auto_logout_minutes,			rows_in.sonar_auto_logout_dialog_minutes,			rows_in.num_ors,			rows_in.sonar_go_live_date,			rows_in.marked_for_deletion,			rows_in.is_count_sheet_source_truth,			rows_in.hide_doc_names_for_stats,			rows_in.is_item_master_live,			rows_in.is_sonar_live,			rows_in.sterilizer_print_at_sterilizing,			rows_in.sterilizer_print_at_cooling,			rows_in.sterilizer_print_at_released,			rows_in.can_set_all_found_in_assembly,			rows_in.name_,			rows_in.their_id,			rows_in.created_by,			rows_in.updated_by,			rows_in.reporting_name,			rows_in.label_name,			rows_in.tz_name,			rows_in.sonar_name_full,			rows_in.sonar_count_sheet_form_name,			rows_in.sterilize_alert_level,			rows_in.sonar_scanner_stop_char,			rows_in.emr_location_name,			rows_in.sonar_features,			rows_in.interfaces,			rows_in.needs_scheduling,			rows_in.analytics_prefs                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			hsys_id = EXCLUDED.hsys_id,			production_label_form_id = EXCLUDED.production_label_form_id,			permanent_label_form_id = EXCLUDED.permanent_label_form_id,			missing_inst_label_form_id = EXCLUDED.missing_inst_label_form_id,			facility_location_label_form_id = EXCLUDED.facility_location_label_form_id,			sterilizer_label_form_id = EXCLUDED.sterilizer_label_form_id,			user_badge_label_form_id = EXCLUDED.user_badge_label_form_id,			workstation_label_form_id = EXCLUDED.workstation_label_form_id,			default_spd_facility_id = EXCLUDED.default_spd_facility_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			sonar_auto_logout_minutes = EXCLUDED.sonar_auto_logout_minutes,			sonar_auto_logout_dialog_minutes = EXCLUDED.sonar_auto_logout_dialog_minutes,			num_ors = EXCLUDED.num_ors,			sonar_go_live_date = EXCLUDED.sonar_go_live_date,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_count_sheet_source_truth = EXCLUDED.is_count_sheet_source_truth,			hide_doc_names_for_stats = EXCLUDED.hide_doc_names_for_stats,			is_item_master_live = EXCLUDED.is_item_master_live,			is_sonar_live = EXCLUDED.is_sonar_live,			sterilizer_print_at_sterilizing = EXCLUDED.sterilizer_print_at_sterilizing,			sterilizer_print_at_cooling = EXCLUDED.sterilizer_print_at_cooling,			sterilizer_print_at_released = EXCLUDED.sterilizer_print_at_released,			can_set_all_found_in_assembly = EXCLUDED.can_set_all_found_in_assembly,			name_ = EXCLUDED.name_,			their_id = EXCLUDED.their_id,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			reporting_name = EXCLUDED.reporting_name,			label_name = EXCLUDED.label_name,			tz_name = EXCLUDED.tz_name,			sonar_name_full = EXCLUDED.sonar_name_full,			sonar_count_sheet_form_name = EXCLUDED.sonar_count_sheet_form_name,			sterilize_alert_level = EXCLUDED.sterilize_alert_level,			sonar_scanner_stop_char = EXCLUDED.sonar_scanner_stop_char,			emr_location_name = EXCLUDED.emr_location_name,			sonar_features = EXCLUDED.sonar_features,			interfaces = EXCLUDED.interfaces,			needs_scheduling = EXCLUDED.needs_scheduling,			analytics_prefs = EXCLUDED.analytics_prefs          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_facility_v2(types_plus.facility_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:focus_v2:focus_v2_combined.sql-- Create a view onto focus formatted as focus_v2.-- If focus changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_focus_v2.DROP VIEW IF EXISTS types_plus.focus_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.focus_v2 AS select scase_id,        hsys_id,        facility_id,        sched_dts,        facility_name,        or_name,        case_seq,        desc_,        status,        transport_from,        surgeon_name,        proc_name,        when_   from focus;ALTER TABLE types_plus.focus_v2    OWNER TO user_change_structure;-- Create a casting function to convert focus rows into the compound type format focus_v2.-- If focus changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.focus_to_v2 (focus_in focus)  RETURNS focus_v2AS $BODY$                   SELECT			focus_in.scase_id,			focus_in.hsys_id,			focus_in.facility_id,			focus_in.sched_dts,			focus_in.facility_name,			focus_in.or_name,			focus_in.case_seq,			focus_in.desc_,			focus_in.status,			focus_in.transport_from,			focus_in.surgeon_name,			focus_in.proc_name,			focus_in.when_               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.focus_to_v2 (focus_in focus)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert focus rows into the focus_v2 compound type format using the following syntax:-- select focus::focus_v2 from focusDROP CAST IF EXISTS (focus as focus_v2);CREATE CAST (focus as focus_v2) WITH FUNCTION types_plus.focus_to_v2(focus);-- Create a function to accept an array of rows formatted as focus_v2 for UPSERT into focus.DROP FUNCTION IF EXISTS types_plus.insert_focus_v2 (types_plus.focus_v2[]);  CREATE OR REPLACE FUNCTION types_plus.insert_focus_v2 (data_in types_plus.focus_v2[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO focus (			scase_id,			hsys_id,			facility_id,			sched_dts,			facility_name,			or_name,			case_seq,			desc_,			status,			transport_from,			surgeon_name,			proc_name,			when_)                  SELECT			rows_in.scase_id,			rows_in.hsys_id,			rows_in.facility_id,			rows_in.sched_dts,			rows_in.facility_name,			rows_in.or_name,			rows_in.case_seq,			rows_in.desc_,			rows_in.status,			rows_in.transport_from,			rows_in.surgeon_name,			rows_in.proc_name,			rows_in.when_                      FROM unnest(data_in) as rows_in                  returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_focus_v2(types_plus.focus_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:form_template_v1:form_template_v1_combined.sql-- Create a view onto form_template formatted as form_template_v1.-- If form_template changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_form_template_v1.DROP VIEW IF EXISTS types_plus.form_template_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.form_template_v1 AS select id,        created_dts,        updated_dts,        marked_for_deletion,        name_,        comments_,        updated_by,        created_by,        form_definition   from form_template;ALTER TABLE types_plus.form_template_v1    OWNER TO user_change_structure;-- Create a casting function to convert form_template rows into the compound type format form_template_v1.-- If form_template changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.form_template_to_v1 (form_template_in form_template)  RETURNS form_template_v1AS $BODY$                   SELECT			form_template_in.id,			form_template_in.created_dts,			form_template_in.updated_dts,			form_template_in.marked_for_deletion,			form_template_in.name_,			form_template_in.comments_,			form_template_in.updated_by,			form_template_in.created_by,			form_template_in.form_definition               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.form_template_to_v1 (form_template_in form_template)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert form_template rows into the form_template_v1 compound type format using the following syntax:-- select form_template::form_template_v1 from form_templateDROP CAST IF EXISTS (form_template as form_template_v1);CREATE CAST (form_template as form_template_v1) WITH FUNCTION types_plus.form_template_to_v1(form_template);-- Create a function to accept an array of rows formatted as form_template_v1 for UPSERT into form_template.DROP FUNCTION IF EXISTS types_plus.insert_form_template_v1 (types_plus.form_template_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_form_template_v1 (data_in types_plus.form_template_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO form_template (			id,			created_dts,			updated_dts,			marked_for_deletion,			name_,			comments_,			updated_by,			created_by,			form_definition)                  SELECT			rows_in.id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.name_,			rows_in.comments_,			rows_in.updated_by,			rows_in.created_by,			rows_in.form_definition                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_,			comments_ = EXCLUDED.comments_,			updated_by = EXCLUDED.updated_by,			created_by = EXCLUDED.created_by,			form_definition = EXCLUDED.form_definition          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_form_template_v1(types_plus.form_template_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:hsys_v1:hsys_v1_combined.sql-- Create a view onto hsys formatted as hsys_v1.-- If hsys changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_hsys_v1.DROP VIEW IF EXISTS types_plus.hsys_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.hsys_v1 AS select id,        marked_for_deletion,        name_   from hsys;ALTER TABLE types_plus.hsys_v1    OWNER TO user_change_structure;-- Create a casting function to convert hsys rows into the compound type format hsys_v1.-- If hsys changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.hsys_to_v1 (hsys_in hsys)  RETURNS hsys_v1AS $BODY$        SELECT			hsys_in.id,			hsys_in.marked_for_deletion,			hsys_in.name_$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.hsys_to_v1 (hsys_in hsys) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert hsys rows into the hsys_v1 compound type format using the following syntax:-- select hsys::hsys_v1 from hsysDROP CAST IF EXISTS (hsys as hsys_v1);CREATE CAST (hsys as hsys_v1) WITH FUNCTION types_plus.hsys_to_v1(hsys);-- Create a function to accept an array of rows formatted as hsys_v1 for UPSERT into hsys.DROP FUNCTION IF EXISTS types_plus.insert_hsys_v1 (types_plus.hsys_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_hsys_v1 (data_in types_plus.hsys_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO hsys (			id,			marked_for_deletion,			name_)        SELECT			rows_in.id,			rows_in.marked_for_deletion,			rows_in.name_        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_hsys_v1(types_plus.hsys_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:hsys_v2:hsys_v2_combined.sql-- Create a view onto hsys formatted as hsys_v2.-- If hsys changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_hsys_v2.DROP VIEW IF EXISTS types_plus.hsys_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.hsys_v2 AS select id,        marked_for_deletion,        name_,        sonar_client_version,        sonar_server_version,        sonar_browser_version   from hsys;ALTER TABLE types_plus.hsys_v2    OWNER TO user_change_structure;-- Create a casting function to convert hsys rows into the compound type format hsys_v2.-- If hsys changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.hsys_to_v2 (hsys_in hsys)  RETURNS hsys_v2AS $BODY$        SELECT			hsys_in.id,			hsys_in.marked_for_deletion,			hsys_in.name_,			hsys_in.sonar_client_version,			hsys_in.sonar_server_version,			hsys_in.sonar_browser_version$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.hsys_to_v2 (hsys_in hsys) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert hsys rows into the hsys_v2 compound type format using the following syntax:-- select hsys::hsys_v2 from hsysDROP CAST IF EXISTS (hsys as hsys_v2);CREATE CAST (hsys as hsys_v2) WITH FUNCTION types_plus.hsys_to_v2(hsys);-- Create a function to accept an array of rows formatted as hsys_v2 for UPSERT into hsys.DROP FUNCTION IF EXISTS types_plus.insert_hsys_v2 (types_plus.hsys_v2[]);CREATE OR REPLACE FUNCTION types_plus.insert_hsys_v2 (data_in types_plus.hsys_v2[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO hsys (			id,			marked_for_deletion,			name_,			sonar_client_version,			sonar_server_version,			sonar_browser_version)        SELECT			rows_in.id,			rows_in.marked_for_deletion,			rows_in.name_,			rows_in.sonar_client_version,			rows_in.sonar_server_version,			rows_in.sonar_browser_version        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_,			sonar_client_version = EXCLUDED.sonar_client_version,			sonar_server_version = EXCLUDED.sonar_server_version,			sonar_browser_version = EXCLUDED.sonar_browser_version        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_hsys_v2(types_plus.hsys_v2[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:inv_v2:inv_v2_combined.sql-- Create a view onto inv formatted as inv_v2.-- If inv changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_inv_v2.DROP VIEW IF EXISTS types_plus.inv_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.inv_v2 AS select id,        item_id,        item_arch_id,        facility_location_id,        standard_faclity_id,        store_at_facility_id,        created_dts,        updated_dts,        serial_no_as_of_dts,        qty,        flow,        flow_long,        par,        last_seen_date,        their_next_repair_date,        last_sterilized_date,        repair_last_repair_date,        is_searched_but_not_found,        marked_for_deletion,        is_found,        is_go_live_perm_printed,        is_sleeping,        is_handwritten_label,        is_wrong_loc,        is_facility_loc_inherited,        needs_repair,        is_deactivated,        is_contents_incomplete,        their_location,        category,        their_name,        their_id,        created_by,        updated_by,        their_id_scrubbed,        crossing_status,        inv_no,        their_raw_name,        comments_,        their_bar_code,        loc_rack,        loc_row,        loc_bin,        loc_note,        serial_no,        data_cleanse_classification,        repair_next_due,        repair_last_repaired_by,        msgs   from inv;ALTER TABLE types_plus.inv_v2    OWNER TO user_change_structure;-- Create a casting function to convert inv rows into the compound type format inv_v2.-- If inv changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.inv_to_v2 (inv_in inv)  RETURNS inv_v2AS $BODY$                   SELECT			inv_in.id,			inv_in.item_id,			inv_in.item_arch_id,			inv_in.facility_location_id,			inv_in.standard_faclity_id,			inv_in.store_at_facility_id,			inv_in.created_dts,			inv_in.updated_dts,			inv_in.serial_no_as_of_dts,			inv_in.qty,			inv_in.flow,			inv_in.flow_long,			inv_in.par,			inv_in.last_seen_date,			inv_in.their_next_repair_date,			inv_in.last_sterilized_date,			inv_in.repair_last_repair_date,			inv_in.is_searched_but_not_found,			inv_in.marked_for_deletion,			inv_in.is_found,			inv_in.is_go_live_perm_printed,			inv_in.is_sleeping,			inv_in.is_handwritten_label,			inv_in.is_wrong_loc,			inv_in.is_facility_loc_inherited,			inv_in.needs_repair,			inv_in.is_deactivated,			inv_in.is_contents_incomplete,			inv_in.their_location,			inv_in.category,			inv_in.their_name,			inv_in.their_id,			inv_in.created_by,			inv_in.updated_by,			inv_in.their_id_scrubbed,			inv_in.crossing_status,			inv_in.inv_no,			inv_in.their_raw_name,			inv_in.comments_,			inv_in.their_bar_code,			inv_in.loc_rack,			inv_in.loc_row,			inv_in.loc_bin,			inv_in.loc_note,			inv_in.serial_no,			inv_in.data_cleanse_classification,			inv_in.repair_next_due,			inv_in.repair_last_repaired_by,			inv_in.msgs               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.inv_to_v2 (inv_in inv)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert inv rows into the inv_v2 compound type format using the following syntax:-- select inv::inv_v2 from invDROP CAST IF EXISTS (inv as inv_v2);CREATE CAST (inv as inv_v2) WITH FUNCTION types_plus.inv_to_v2(inv);-- Create a function to accept an array of rows formatted as inv_v2 for UPSERT into inv.DROP FUNCTION IF EXISTS types_plus.insert_inv_v2 (types_plus.inv_v2[]);  CREATE OR REPLACE FUNCTION types_plus.insert_inv_v2 (data_in types_plus.inv_v2[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO inv (			id,			item_id,			item_arch_id,			facility_location_id,			standard_faclity_id,			store_at_facility_id,			created_dts,			updated_dts,			serial_no_as_of_dts,			qty,			flow,			flow_long,			par,			last_seen_date,			their_next_repair_date,			last_sterilized_date,			repair_last_repair_date,			is_searched_but_not_found,			marked_for_deletion,			is_found,			is_go_live_perm_printed,			is_sleeping,			is_handwritten_label,			is_wrong_loc,			is_facility_loc_inherited,			needs_repair,			is_deactivated,			is_contents_incomplete,			their_location,			category,			their_name,			their_id,			created_by,			updated_by,			their_id_scrubbed,			crossing_status,			inv_no,			their_raw_name,			comments_,			their_bar_code,			loc_rack,			loc_row,			loc_bin,			loc_note,			serial_no,			data_cleanse_classification,			repair_next_due,			repair_last_repaired_by,			msgs)                  SELECT			rows_in.id,			rows_in.item_id,			rows_in.item_arch_id,			rows_in.facility_location_id,			rows_in.standard_faclity_id,			rows_in.store_at_facility_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.serial_no_as_of_dts,			rows_in.qty,			rows_in.flow,			rows_in.flow_long,			rows_in.par,			rows_in.last_seen_date,			rows_in.their_next_repair_date,			rows_in.last_sterilized_date,			rows_in.repair_last_repair_date,			rows_in.is_searched_but_not_found,			rows_in.marked_for_deletion,			rows_in.is_found,			rows_in.is_go_live_perm_printed,			rows_in.is_sleeping,			rows_in.is_handwritten_label,			rows_in.is_wrong_loc,			rows_in.is_facility_loc_inherited,			rows_in.needs_repair,			rows_in.is_deactivated,			rows_in.is_contents_incomplete,			rows_in.their_location,			rows_in.category,			rows_in.their_name,			rows_in.their_id,			rows_in.created_by,			rows_in.updated_by,			rows_in.their_id_scrubbed,			rows_in.crossing_status,			rows_in.inv_no,			rows_in.their_raw_name,			rows_in.comments_,			rows_in.their_bar_code,			rows_in.loc_rack,			rows_in.loc_row,			rows_in.loc_bin,			rows_in.loc_note,			rows_in.serial_no,			rows_in.data_cleanse_classification,			rows_in.repair_next_due,			rows_in.repair_last_repaired_by,			rows_in.msgs                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			item_id = EXCLUDED.item_id,			item_arch_id = EXCLUDED.item_arch_id,			facility_location_id = EXCLUDED.facility_location_id,			standard_faclity_id = EXCLUDED.standard_faclity_id,			store_at_facility_id = EXCLUDED.store_at_facility_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			serial_no_as_of_dts = EXCLUDED.serial_no_as_of_dts,			qty = EXCLUDED.qty,			flow = EXCLUDED.flow,			flow_long = EXCLUDED.flow_long,			par = EXCLUDED.par,			last_seen_date = EXCLUDED.last_seen_date,			their_next_repair_date = EXCLUDED.their_next_repair_date,			last_sterilized_date = EXCLUDED.last_sterilized_date,			repair_last_repair_date = EXCLUDED.repair_last_repair_date,			is_searched_but_not_found = EXCLUDED.is_searched_but_not_found,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_found = EXCLUDED.is_found,			is_go_live_perm_printed = EXCLUDED.is_go_live_perm_printed,			is_sleeping = EXCLUDED.is_sleeping,			is_handwritten_label = EXCLUDED.is_handwritten_label,			is_wrong_loc = EXCLUDED.is_wrong_loc,			is_facility_loc_inherited = EXCLUDED.is_facility_loc_inherited,			needs_repair = EXCLUDED.needs_repair,			is_deactivated = EXCLUDED.is_deactivated,			is_contents_incomplete = EXCLUDED.is_contents_incomplete,			their_location = EXCLUDED.their_location,			category = EXCLUDED.category,			their_name = EXCLUDED.their_name,			their_id = EXCLUDED.their_id,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			their_id_scrubbed = EXCLUDED.their_id_scrubbed,			crossing_status = EXCLUDED.crossing_status,			inv_no = EXCLUDED.inv_no,			their_raw_name = EXCLUDED.their_raw_name,			comments_ = EXCLUDED.comments_,			their_bar_code = EXCLUDED.their_bar_code,			loc_rack = EXCLUDED.loc_rack,			loc_row = EXCLUDED.loc_row,			loc_bin = EXCLUDED.loc_bin,			loc_note = EXCLUDED.loc_note,			serial_no = EXCLUDED.serial_no,			data_cleanse_classification = EXCLUDED.data_cleanse_classification,			repair_next_due = EXCLUDED.repair_next_due,			repair_last_repaired_by = EXCLUDED.repair_last_repaired_by,			msgs = EXCLUDED.msgs          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_inv_v2(types_plus.inv_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:item_arch_v1:item_arch_v1_combined.sql-- Create a view onto item_arch formatted as item_arch_v1.-- If item_arch changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_item_arch_v1.DROP VIEW IF EXISTS types_plus.item_arch_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.item_arch_v1 AS select id,        facility_id,        clinic_id,        created_dts,        updated_dts,        previous_as_of,        marked_for_deletion,        is_current,        name_,        type_,        created_by,        updated_by   from item_arch;ALTER TABLE types_plus.item_arch_v1    OWNER TO user_change_structure;-- Create a casting function to convert item_arch rows into the compound type format item_arch_v1.-- If item_arch changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.item_arch_to_v1 (item_arch_in item_arch)  RETURNS item_arch_v1AS $BODY$                   SELECT			item_arch_in.id,			item_arch_in.facility_id,			item_arch_in.clinic_id,			item_arch_in.created_dts,			item_arch_in.updated_dts,			item_arch_in.previous_as_of,			item_arch_in.marked_for_deletion,			item_arch_in.is_current,			item_arch_in.name_,			item_arch_in.type_,			item_arch_in.created_by,			item_arch_in.updated_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.item_arch_to_v1 (item_arch_in item_arch)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert item_arch rows into the item_arch_v1 compound type format using the following syntax:-- select item_arch::item_arch_v1 from item_archDROP CAST IF EXISTS (item_arch as item_arch_v1);CREATE CAST (item_arch as item_arch_v1) WITH FUNCTION types_plus.item_arch_to_v1(item_arch);-- Create a function to accept an array of rows formatted as item_arch_v1 for UPSERT into item_arch.DROP FUNCTION IF EXISTS types_plus.insert_item_arch_v1 (types_plus.item_arch_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_item_arch_v1 (data_in types_plus.item_arch_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO item_arch (			id,			facility_id,			clinic_id,			created_dts,			updated_dts,			previous_as_of,			marked_for_deletion,			is_current,			name_,			type_,			created_by,			updated_by)                  SELECT			rows_in.id,			rows_in.facility_id,			rows_in.clinic_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.previous_as_of,			rows_in.marked_for_deletion,			rows_in.is_current,			rows_in.name_,			rows_in.type_,			rows_in.created_by,			rows_in.updated_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			facility_id = EXCLUDED.facility_id,			clinic_id = EXCLUDED.clinic_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			previous_as_of = EXCLUDED.previous_as_of,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_current = EXCLUDED.is_current,			name_ = EXCLUDED.name_,			type_ = EXCLUDED.type_,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_item_arch_v1(types_plus.item_arch_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:item_type_v1:item_type_v1_combined.sql-- Create a view onto item_type formatted as item_type_v1.-- If item_type changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_item_type_v1.DROP VIEW IF EXISTS types_plus.item_type_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.item_type_v1 AS select id,        marked_for_deletion,        name_   from item_type;ALTER TABLE types_plus.item_type_v1    OWNER TO user_change_structure;-- Create a casting function to convert item_type rows into the compound type format item_type_v1.-- If item_type changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.item_type_to_v1 (item_type_in item_type)  RETURNS item_type_v1AS $BODY$        SELECT			item_type_in.id,			item_type_in.marked_for_deletion,			item_type_in.name_$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.item_type_to_v1 (item_type_in item_type) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert item_type rows into the item_type_v1 compound type format using the following syntax:-- select item_type::item_type_v1 from item_typeDROP CAST IF EXISTS (item_type as item_type_v1);CREATE CAST (item_type as item_type_v1) WITH FUNCTION types_plus.item_type_to_v1(item_type);-- Create a function to accept an array of rows formatted as item_type_v1 for UPSERT into item_type.DROP FUNCTION IF EXISTS types_plus.insert_item_type_v1 (types_plus.item_type_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_item_type_v1 (data_in types_plus.item_type_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO item_type (			id,			marked_for_deletion,			name_)        SELECT			rows_in.id,			rows_in.marked_for_deletion,			rows_in.name_        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_item_type_v1(types_plus.item_type_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:item_v2:item_v2_combined.sql-- Create a view onto item formatted as item_v2.-- If item changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_item_v2.DROP VIEW IF EXISTS types_plus.item_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.item_v2 AS select id,        item_arch_id,        facility_specialty_id,        item_uu_id_across_item_archs,        inv_responsible_user_id,        facility_department_id,        specialty_id,        sup_id,        dr_people_id,        item_type_id,        item_master_link_id,        facility_location_id,        clinic_id,        hsys_tag_id,        name_copied_from_prod_id,        created_dts,        updated_dts,        named_dts,        needs_sched_sync_as_of_dts,        weight_lb,        qty,        flow,        flow_long,        max_processed_one_day,        par,        assembly_difficulty,        num_inst,        repair_every_x,        their_qty,        replace_every_x_cycles,        hide_specialty_in_name,        marked_for_deletion,        is_assembly_critical,        requires_leak_test,        is_not_tracked_by_inv_no,        is_imlink_locked,        is_robotic,        is_flexible_scope,        is_generic_pack,        dont_print_count_sheet,        is_conflict_check,        is_small_set,        hide_hsys_tag_in_name,        is_name_finalized,        is_in_data_cleanse_scope,        is_label_abbr,        has_implants,        sync_to_other_software_systems,        inv_has_implants,        is_custom_sort,        is_name_copied_from_prod,        is_deactivated,        is_vendor_data,        name_needs_review,        ignore_for_optimization,        inv_status,        their_name,        opt_status,        created_by,        updated_by,        old_names,        their_serial_no,        name_desc,        name_,        their_id,        decon_special_instructions,        named_by,        needs_review_notes,        vendor_tray_type,        sterilization_method,        priority,        category,        packaging_type,        packaging_notes,        their_packaging_type,        assembly_special_instructions,        sterilize_special_instructions,        label_name_abbr,        their_location,        count_sheet_status,        requested_by,        rack_row_bin_note,        standardization_status,        repair_every_x_type,        their_base_barcode,        their_key,        stuff   from item;ALTER TABLE types_plus.item_v2    OWNER TO user_change_structure;-- Create a casting function to convert item rows into the compound type format item_v2.-- If item changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.item_to_v2 (item_in item)  RETURNS item_v2AS $BODY$                   SELECT			item_in.id,			item_in.item_arch_id,			item_in.facility_specialty_id,			item_in.item_uu_id_across_item_archs,			item_in.inv_responsible_user_id,			item_in.facility_department_id,			item_in.specialty_id,			item_in.sup_id,			item_in.dr_people_id,			item_in.item_type_id,			item_in.item_master_link_id,			item_in.facility_location_id,			item_in.clinic_id,			item_in.hsys_tag_id,			item_in.name_copied_from_prod_id,			item_in.created_dts,			item_in.updated_dts,			item_in.named_dts,			item_in.needs_sched_sync_as_of_dts,			item_in.weight_lb,			item_in.qty,			item_in.flow,			item_in.flow_long,			item_in.max_processed_one_day,			item_in.par,			item_in.assembly_difficulty,			item_in.num_inst,			item_in.repair_every_x,			item_in.their_qty,			item_in.replace_every_x_cycles,			item_in.hide_specialty_in_name,			item_in.marked_for_deletion,			item_in.is_assembly_critical,			item_in.requires_leak_test,			item_in.is_not_tracked_by_inv_no,			item_in.is_imlink_locked,			item_in.is_robotic,			item_in.is_flexible_scope,			item_in.is_generic_pack,			item_in.dont_print_count_sheet,			item_in.is_conflict_check,			item_in.is_small_set,			item_in.hide_hsys_tag_in_name,			item_in.is_name_finalized,			item_in.is_in_data_cleanse_scope,			item_in.is_label_abbr,			item_in.has_implants,			item_in.sync_to_other_software_systems,			item_in.inv_has_implants,			item_in.is_custom_sort,			item_in.is_name_copied_from_prod,			item_in.is_deactivated,			item_in.is_vendor_data,			item_in.name_needs_review,			item_in.ignore_for_optimization,			item_in.inv_status,			item_in.their_name,			item_in.opt_status,			item_in.created_by,			item_in.updated_by,			item_in.old_names,			item_in.their_serial_no,			item_in.name_desc,			item_in.name_,			item_in.their_id,			item_in.decon_special_instructions,			item_in.named_by,			item_in.needs_review_notes,			item_in.vendor_tray_type,			item_in.sterilization_method,			item_in.priority,			item_in.category,			item_in.packaging_type,			item_in.packaging_notes,			item_in.their_packaging_type,			item_in.assembly_special_instructions,			item_in.sterilize_special_instructions,			item_in.label_name_abbr,			item_in.their_location,			item_in.count_sheet_status,			item_in.requested_by,			item_in.rack_row_bin_note,			item_in.standardization_status,			item_in.repair_every_x_type,			item_in.their_base_barcode,			item_in.their_key,			item_in.stuff               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.item_to_v2 (item_in item)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert item rows into the item_v2 compound type format using the following syntax:-- select item::item_v2 from itemDROP CAST IF EXISTS (item as item_v2);CREATE CAST (item as item_v2) WITH FUNCTION types_plus.item_to_v2(item);-- Create a function to accept an array of rows formatted as item_v2 for UPSERT into item.DROP FUNCTION IF EXISTS types_plus.insert_item_v2 (types_plus.item_v2[]);  CREATE OR REPLACE FUNCTION types_plus.insert_item_v2 (data_in types_plus.item_v2[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO item (			id,			item_arch_id,			facility_specialty_id,			item_uu_id_across_item_archs,			inv_responsible_user_id,			facility_department_id,			specialty_id,			sup_id,			dr_people_id,			item_type_id,			item_master_link_id,			facility_location_id,			clinic_id,			hsys_tag_id,			name_copied_from_prod_id,			created_dts,			updated_dts,			named_dts,			needs_sched_sync_as_of_dts,			weight_lb,			qty,			flow,			flow_long,			max_processed_one_day,			par,			assembly_difficulty,			num_inst,			repair_every_x,			their_qty,			replace_every_x_cycles,			hide_specialty_in_name,			marked_for_deletion,			is_assembly_critical,			requires_leak_test,			is_not_tracked_by_inv_no,			is_imlink_locked,			is_robotic,			is_flexible_scope,			is_generic_pack,			dont_print_count_sheet,			is_conflict_check,			is_small_set,			hide_hsys_tag_in_name,			is_name_finalized,			is_in_data_cleanse_scope,			is_label_abbr,			has_implants,			sync_to_other_software_systems,			inv_has_implants,			is_custom_sort,			is_name_copied_from_prod,			is_deactivated,			is_vendor_data,			name_needs_review,			ignore_for_optimization,			inv_status,			their_name,			opt_status,			created_by,			updated_by,			old_names,			their_serial_no,			name_desc,			name_,			their_id,			decon_special_instructions,			named_by,			needs_review_notes,			vendor_tray_type,			sterilization_method,			priority,			category,			packaging_type,			packaging_notes,			their_packaging_type,			assembly_special_instructions,			sterilize_special_instructions,			label_name_abbr,			their_location,			count_sheet_status,			requested_by,			rack_row_bin_note,			standardization_status,			repair_every_x_type,			their_base_barcode,			their_key,			stuff)                  SELECT			rows_in.id,			rows_in.item_arch_id,			rows_in.facility_specialty_id,			rows_in.item_uu_id_across_item_archs,			rows_in.inv_responsible_user_id,			rows_in.facility_department_id,			rows_in.specialty_id,			rows_in.sup_id,			rows_in.dr_people_id,			rows_in.item_type_id,			rows_in.item_master_link_id,			rows_in.facility_location_id,			rows_in.clinic_id,			rows_in.hsys_tag_id,			rows_in.name_copied_from_prod_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.named_dts,			rows_in.needs_sched_sync_as_of_dts,			rows_in.weight_lb,			rows_in.qty,			rows_in.flow,			rows_in.flow_long,			rows_in.max_processed_one_day,			rows_in.par,			rows_in.assembly_difficulty,			rows_in.num_inst,			rows_in.repair_every_x,			rows_in.their_qty,			rows_in.replace_every_x_cycles,			rows_in.hide_specialty_in_name,			rows_in.marked_for_deletion,			rows_in.is_assembly_critical,			rows_in.requires_leak_test,			rows_in.is_not_tracked_by_inv_no,			rows_in.is_imlink_locked,			rows_in.is_robotic,			rows_in.is_flexible_scope,			rows_in.is_generic_pack,			rows_in.dont_print_count_sheet,			rows_in.is_conflict_check,			rows_in.is_small_set,			rows_in.hide_hsys_tag_in_name,			rows_in.is_name_finalized,			rows_in.is_in_data_cleanse_scope,			rows_in.is_label_abbr,			rows_in.has_implants,			rows_in.sync_to_other_software_systems,			rows_in.inv_has_implants,			rows_in.is_custom_sort,			rows_in.is_name_copied_from_prod,			rows_in.is_deactivated,			rows_in.is_vendor_data,			rows_in.name_needs_review,			rows_in.ignore_for_optimization,			rows_in.inv_status,			rows_in.their_name,			rows_in.opt_status,			rows_in.created_by,			rows_in.updated_by,			rows_in.old_names,			rows_in.their_serial_no,			rows_in.name_desc,			rows_in.name_,			rows_in.their_id,			rows_in.decon_special_instructions,			rows_in.named_by,			rows_in.needs_review_notes,			rows_in.vendor_tray_type,			rows_in.sterilization_method,			rows_in.priority,			rows_in.category,			rows_in.packaging_type,			rows_in.packaging_notes,			rows_in.their_packaging_type,			rows_in.assembly_special_instructions,			rows_in.sterilize_special_instructions,			rows_in.label_name_abbr,			rows_in.their_location,			rows_in.count_sheet_status,			rows_in.requested_by,			rows_in.rack_row_bin_note,			rows_in.standardization_status,			rows_in.repair_every_x_type,			rows_in.their_base_barcode,			rows_in.their_key,			rows_in.stuff                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			item_arch_id = EXCLUDED.item_arch_id,			facility_specialty_id = EXCLUDED.facility_specialty_id,			item_uu_id_across_item_archs = EXCLUDED.item_uu_id_across_item_archs,			inv_responsible_user_id = EXCLUDED.inv_responsible_user_id,			facility_department_id = EXCLUDED.facility_department_id,			specialty_id = EXCLUDED.specialty_id,			sup_id = EXCLUDED.sup_id,			dr_people_id = EXCLUDED.dr_people_id,			item_type_id = EXCLUDED.item_type_id,			item_master_link_id = EXCLUDED.item_master_link_id,			facility_location_id = EXCLUDED.facility_location_id,			clinic_id = EXCLUDED.clinic_id,			hsys_tag_id = EXCLUDED.hsys_tag_id,			name_copied_from_prod_id = EXCLUDED.name_copied_from_prod_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			named_dts = EXCLUDED.named_dts,			needs_sched_sync_as_of_dts = EXCLUDED.needs_sched_sync_as_of_dts,			weight_lb = EXCLUDED.weight_lb,			qty = EXCLUDED.qty,			flow = EXCLUDED.flow,			flow_long = EXCLUDED.flow_long,			max_processed_one_day = EXCLUDED.max_processed_one_day,			par = EXCLUDED.par,			assembly_difficulty = EXCLUDED.assembly_difficulty,			num_inst = EXCLUDED.num_inst,			repair_every_x = EXCLUDED.repair_every_x,			their_qty = EXCLUDED.their_qty,			replace_every_x_cycles = EXCLUDED.replace_every_x_cycles,			hide_specialty_in_name = EXCLUDED.hide_specialty_in_name,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_assembly_critical = EXCLUDED.is_assembly_critical,			requires_leak_test = EXCLUDED.requires_leak_test,			is_not_tracked_by_inv_no = EXCLUDED.is_not_tracked_by_inv_no,			is_imlink_locked = EXCLUDED.is_imlink_locked,			is_robotic = EXCLUDED.is_robotic,			is_flexible_scope = EXCLUDED.is_flexible_scope,			is_generic_pack = EXCLUDED.is_generic_pack,			dont_print_count_sheet = EXCLUDED.dont_print_count_sheet,			is_conflict_check = EXCLUDED.is_conflict_check,			is_small_set = EXCLUDED.is_small_set,			hide_hsys_tag_in_name = EXCLUDED.hide_hsys_tag_in_name,			is_name_finalized = EXCLUDED.is_name_finalized,			is_in_data_cleanse_scope = EXCLUDED.is_in_data_cleanse_scope,			is_label_abbr = EXCLUDED.is_label_abbr,			has_implants = EXCLUDED.has_implants,			sync_to_other_software_systems = EXCLUDED.sync_to_other_software_systems,			inv_has_implants = EXCLUDED.inv_has_implants,			is_custom_sort = EXCLUDED.is_custom_sort,			is_name_copied_from_prod = EXCLUDED.is_name_copied_from_prod,			is_deactivated = EXCLUDED.is_deactivated,			is_vendor_data = EXCLUDED.is_vendor_data,			name_needs_review = EXCLUDED.name_needs_review,			ignore_for_optimization = EXCLUDED.ignore_for_optimization,			inv_status = EXCLUDED.inv_status,			their_name = EXCLUDED.their_name,			opt_status = EXCLUDED.opt_status,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			old_names = EXCLUDED.old_names,			their_serial_no = EXCLUDED.their_serial_no,			name_desc = EXCLUDED.name_desc,			name_ = EXCLUDED.name_,			their_id = EXCLUDED.their_id,			decon_special_instructions = EXCLUDED.decon_special_instructions,			named_by = EXCLUDED.named_by,			needs_review_notes = EXCLUDED.needs_review_notes,			vendor_tray_type = EXCLUDED.vendor_tray_type,			sterilization_method = EXCLUDED.sterilization_method,			priority = EXCLUDED.priority,			category = EXCLUDED.category,			packaging_type = EXCLUDED.packaging_type,			packaging_notes = EXCLUDED.packaging_notes,			their_packaging_type = EXCLUDED.their_packaging_type,			assembly_special_instructions = EXCLUDED.assembly_special_instructions,			sterilize_special_instructions = EXCLUDED.sterilize_special_instructions,			label_name_abbr = EXCLUDED.label_name_abbr,			their_location = EXCLUDED.their_location,			count_sheet_status = EXCLUDED.count_sheet_status,			requested_by = EXCLUDED.requested_by,			rack_row_bin_note = EXCLUDED.rack_row_bin_note,			standardization_status = EXCLUDED.standardization_status,			repair_every_x_type = EXCLUDED.repair_every_x_type,			their_base_barcode = EXCLUDED.their_base_barcode,			their_key = EXCLUDED.their_key,			stuff = EXCLUDED.stuff          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_item_v2(types_plus.item_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:loaner_case_v1:loaner_case_v1_combined.sql-- Create a view onto loaner_case formatted as loaner_case_v1.-- If loaner_case changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_loaner_case_v1.DROP VIEW IF EXISTS types_plus.loaner_case_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.loaner_case_v1 AS select id,        loaner_id,        last_updated_by_data_file_id,        updated_dts,        created_dts,        case_dts,        marked_for_deletion,        desc_,        surgeon,        updated_by,        created_by   from loaner_case;ALTER TABLE types_plus.loaner_case_v1    OWNER TO user_change_structure;-- Create a casting function to convert loaner_case rows into the compound type format loaner_case_v1.-- If loaner_case changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.loaner_case_to_v1 (loaner_case_in loaner_case)  RETURNS loaner_case_v1AS $BODY$                   SELECT			loaner_case_in.id,			loaner_case_in.loaner_id,			loaner_case_in.last_updated_by_data_file_id,			loaner_case_in.updated_dts,			loaner_case_in.created_dts,			loaner_case_in.case_dts,			loaner_case_in.marked_for_deletion,			loaner_case_in.desc_,			loaner_case_in.surgeon,			loaner_case_in.updated_by,			loaner_case_in.created_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.loaner_case_to_v1 (loaner_case_in loaner_case)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert loaner_case rows into the loaner_case_v1 compound type format using the following syntax:-- select loaner_case::loaner_case_v1 from loaner_caseDROP CAST IF EXISTS (loaner_case as loaner_case_v1);CREATE CAST (loaner_case as loaner_case_v1) WITH FUNCTION types_plus.loaner_case_to_v1(loaner_case);-- Create a function to accept an array of rows formatted as loaner_case_v1 for UPSERT into loaner_case.DROP FUNCTION IF EXISTS types_plus.insert_loaner_case_v1 (types_plus.loaner_case_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_loaner_case_v1 (data_in types_plus.loaner_case_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO loaner_case (			id,			loaner_id,			last_updated_by_data_file_id,			updated_dts,			created_dts,			case_dts,			marked_for_deletion,			desc_,			surgeon,			updated_by,			created_by)                  SELECT			rows_in.id,			rows_in.loaner_id,			rows_in.last_updated_by_data_file_id,			rows_in.updated_dts,			rows_in.created_dts,			rows_in.case_dts,			rows_in.marked_for_deletion,			rows_in.desc_,			rows_in.surgeon,			rows_in.updated_by,			rows_in.created_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			loaner_id = EXCLUDED.loaner_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			updated_dts = EXCLUDED.updated_dts,			created_dts = EXCLUDED.created_dts,			case_dts = EXCLUDED.case_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			desc_ = EXCLUDED.desc_,			surgeon = EXCLUDED.surgeon,			updated_by = EXCLUDED.updated_by,			created_by = EXCLUDED.created_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_loaner_case_v1(types_plus.loaner_case_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:loaner_item_v1:loaner_item_v1_combined.sql-- Create a view onto loaner_item formatted as loaner_item_v1.-- If loaner_item changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_loaner_item_v1.DROP VIEW IF EXISTS types_plus.loaner_item_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.loaner_item_v1 AS select id,        loaner_id,        item_id,        last_updated_by_data_file_id,        updated_dts,        created_dts,        left_behind_qty,        qty,        pickup_qty,        marked_for_deletion,        updated_by,        created_by   from loaner_item;ALTER TABLE types_plus.loaner_item_v1    OWNER TO user_change_structure;-- Create a casting function to convert loaner_item rows into the compound type format loaner_item_v1.-- If loaner_item changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.loaner_item_to_v1 (loaner_item_in loaner_item)  RETURNS loaner_item_v1AS $BODY$                   SELECT			loaner_item_in.id,			loaner_item_in.loaner_id,			loaner_item_in.item_id,			loaner_item_in.last_updated_by_data_file_id,			loaner_item_in.updated_dts,			loaner_item_in.created_dts,			loaner_item_in.left_behind_qty,			loaner_item_in.qty,			loaner_item_in.pickup_qty,			loaner_item_in.marked_for_deletion,			loaner_item_in.updated_by,			loaner_item_in.created_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.loaner_item_to_v1 (loaner_item_in loaner_item)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert loaner_item rows into the loaner_item_v1 compound type format using the following syntax:-- select loaner_item::loaner_item_v1 from loaner_itemDROP CAST IF EXISTS (loaner_item as loaner_item_v1);CREATE CAST (loaner_item as loaner_item_v1) WITH FUNCTION types_plus.loaner_item_to_v1(loaner_item);-- Create a function to accept an array of rows formatted as loaner_item_v1 for UPSERT into loaner_item.DROP FUNCTION IF EXISTS types_plus.insert_loaner_item_v1 (types_plus.loaner_item_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_loaner_item_v1 (data_in types_plus.loaner_item_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO loaner_item (			id,			loaner_id,			item_id,			last_updated_by_data_file_id,			updated_dts,			created_dts,			left_behind_qty,			qty,			pickup_qty,			marked_for_deletion,			updated_by,			created_by)                  SELECT			rows_in.id,			rows_in.loaner_id,			rows_in.item_id,			rows_in.last_updated_by_data_file_id,			rows_in.updated_dts,			rows_in.created_dts,			rows_in.left_behind_qty,			rows_in.qty,			rows_in.pickup_qty,			rows_in.marked_for_deletion,			rows_in.updated_by,			rows_in.created_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			loaner_id = EXCLUDED.loaner_id,			item_id = EXCLUDED.item_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			updated_dts = EXCLUDED.updated_dts,			created_dts = EXCLUDED.created_dts,			left_behind_qty = EXCLUDED.left_behind_qty,			qty = EXCLUDED.qty,			pickup_qty = EXCLUDED.pickup_qty,			marked_for_deletion = EXCLUDED.marked_for_deletion,			updated_by = EXCLUDED.updated_by,			created_by = EXCLUDED.created_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_loaner_item_v1(types_plus.loaner_item_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:loaner_iteminv_v1:loaner_iteminv_v1_combined.sql-- Create a view onto loaner_iteminv formatted as loaner_iteminv_v1.-- If loaner_iteminv changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_loaner_iteminv_v1.DROP VIEW IF EXISTS types_plus.loaner_iteminv_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.loaner_iteminv_v1 AS select id,        loaner_item_id,        inv_id,        last_updated_by_data_file_id,        created_dts,        updated_dts,        marked_for_deletion,        created_by,        updated_by   from loaner_iteminv;ALTER TABLE types_plus.loaner_iteminv_v1    OWNER TO user_change_structure;-- Create a casting function to convert loaner_iteminv rows into the compound type format loaner_iteminv_v1.-- If loaner_iteminv changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.loaner_iteminv_to_v1 (loaner_iteminv_in loaner_iteminv)  RETURNS loaner_iteminv_v1AS $BODY$                   SELECT			loaner_iteminv_in.id,			loaner_iteminv_in.loaner_item_id,			loaner_iteminv_in.inv_id,			loaner_iteminv_in.last_updated_by_data_file_id,			loaner_iteminv_in.created_dts,			loaner_iteminv_in.updated_dts,			loaner_iteminv_in.marked_for_deletion,			loaner_iteminv_in.created_by,			loaner_iteminv_in.updated_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.loaner_iteminv_to_v1 (loaner_iteminv_in loaner_iteminv)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert loaner_iteminv rows into the loaner_iteminv_v1 compound type format using the following syntax:-- select loaner_iteminv::loaner_iteminv_v1 from loaner_iteminvDROP CAST IF EXISTS (loaner_iteminv as loaner_iteminv_v1);CREATE CAST (loaner_iteminv as loaner_iteminv_v1) WITH FUNCTION types_plus.loaner_iteminv_to_v1(loaner_iteminv);-- Create a function to accept an array of rows formatted as loaner_iteminv_v1 for UPSERT into loaner_iteminv.DROP FUNCTION IF EXISTS types_plus.insert_loaner_iteminv_v1 (types_plus.loaner_iteminv_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_loaner_iteminv_v1 (data_in types_plus.loaner_iteminv_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO loaner_iteminv (			id,			loaner_item_id,			inv_id,			last_updated_by_data_file_id,			created_dts,			updated_dts,			marked_for_deletion,			created_by,			updated_by)                  SELECT			rows_in.id,			rows_in.loaner_item_id,			rows_in.inv_id,			rows_in.last_updated_by_data_file_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.created_by,			rows_in.updated_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			loaner_item_id = EXCLUDED.loaner_item_id,			inv_id = EXCLUDED.inv_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_loaner_iteminv_v1(types_plus.loaner_iteminv_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:loaner_v1:loaner_v1_combined.sql-- Create a view onto loaner formatted as loaner_v1.-- If loaner changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_loaner_v1.DROP VIEW IF EXISTS types_plus.loaner_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.loaner_v1 AS select s_case_id,        id,        sup_id,        rep_id,        facility_id,        last_updated_by_data_file_id,        pickup_dts,        created_dts,        updated_dts,        datetime_local,        drop_off_dts,        num_items,        marked_for_deletion,        is_printed,        created_by,        updated_by,        status,        notes   from loaner;ALTER TABLE types_plus.loaner_v1    OWNER TO user_change_structure;-- Create a casting function to convert loaner rows into the compound type format loaner_v1.-- If loaner changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.loaner_to_v1 (loaner_in loaner)  RETURNS loaner_v1AS $BODY$                   SELECT			loaner_in.s_case_id,			loaner_in.id,			loaner_in.sup_id,			loaner_in.rep_id,			loaner_in.facility_id,			loaner_in.last_updated_by_data_file_id,			loaner_in.pickup_dts,			loaner_in.created_dts,			loaner_in.updated_dts,			loaner_in.datetime_local,			loaner_in.drop_off_dts,			loaner_in.num_items,			loaner_in.marked_for_deletion,			loaner_in.is_printed,			loaner_in.created_by,			loaner_in.updated_by,			loaner_in.status,			loaner_in.notes               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.loaner_to_v1 (loaner_in loaner)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert loaner rows into the loaner_v1 compound type format using the following syntax:-- select loaner::loaner_v1 from loanerDROP CAST IF EXISTS (loaner as loaner_v1);CREATE CAST (loaner as loaner_v1) WITH FUNCTION types_plus.loaner_to_v1(loaner);-- Create a function to accept an array of rows formatted as loaner_v1 for UPSERT into loaner.DROP FUNCTION IF EXISTS types_plus.insert_loaner_v1 (types_plus.loaner_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_loaner_v1 (data_in types_plus.loaner_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO loaner (			s_case_id,			id,			sup_id,			rep_id,			facility_id,			last_updated_by_data_file_id,			pickup_dts,			created_dts,			updated_dts,			datetime_local,			drop_off_dts,			num_items,			marked_for_deletion,			is_printed,			created_by,			updated_by,			status,			notes)                  SELECT			rows_in.s_case_id,			rows_in.id,			rows_in.sup_id,			rows_in.rep_id,			rows_in.facility_id,			rows_in.last_updated_by_data_file_id,			rows_in.pickup_dts,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.datetime_local,			rows_in.drop_off_dts,			rows_in.num_items,			rows_in.marked_for_deletion,			rows_in.is_printed,			rows_in.created_by,			rows_in.updated_by,			rows_in.status,			rows_in.notes                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			s_case_id = EXCLUDED.s_case_id,			sup_id = EXCLUDED.sup_id,			rep_id = EXCLUDED.rep_id,			facility_id = EXCLUDED.facility_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			pickup_dts = EXCLUDED.pickup_dts,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			datetime_local = EXCLUDED.datetime_local,			drop_off_dts = EXCLUDED.drop_off_dts,			num_items = EXCLUDED.num_items,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_printed = EXCLUDED.is_printed,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			status = EXCLUDED.status,			notes = EXCLUDED.notes          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_loaner_v1(types_plus.loaner_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:need_v5:need_v5_combined.sql-- Create a view onto need formatted as need_v5.-- If need changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_need_v5.DROP VIEW IF EXISTS types_plus.need_v5 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.need_v5 AS select id,        hsys_id,        facility_id,        item_id,        percent_down,        next_case_dts,        flow,        qty_circulation,        qty_ready_everywhere,        qty_ready_here,        qty_sched_everywhere,        qty_sched_here,        qty_sterile_everywhere,        qty_sterile_here,        qty_suggest_sterilize,        qty_total,        ready_vs_need_defecit,        sched_sort,        sort_rank,        suggest_transport,        next_needed,        or_name,        status,        status_sort,        when_,        qty_here   from need;ALTER TABLE types_plus.need_v5    OWNER TO user_change_structure;-- Create a casting function to convert need rows into the compound type format need_v5.-- If need changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.need_to_v5 (need_in need)  RETURNS need_v5AS $BODY$                   SELECT			need_in.id,			need_in.hsys_id,			need_in.facility_id,			need_in.item_id,			need_in.percent_down,			need_in.next_case_dts,			need_in.flow,			need_in.qty_circulation,			need_in.qty_ready_everywhere,			need_in.qty_ready_here,			need_in.qty_sched_everywhere,			need_in.qty_sched_here,			need_in.qty_sterile_everywhere,			need_in.qty_sterile_here,			need_in.qty_suggest_sterilize,			need_in.qty_total,			need_in.ready_vs_need_defecit,			need_in.sched_sort,			need_in.sort_rank,			need_in.suggest_transport,			need_in.next_needed,			need_in.or_name,			need_in.status,			need_in.status_sort,			need_in.when_,			need_in.qty_here               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.need_to_v5 (need_in need)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert need rows into the need_v5 compound type format using the following syntax:-- select need::need_v5 from needDROP CAST IF EXISTS (need as need_v5);CREATE CAST (need as need_v5) WITH FUNCTION types_plus.need_to_v5(need);-- Create a function to accept an array of rows formatted as need_v5 for UPSERT into need.DROP FUNCTION IF EXISTS types_plus.insert_need_v5 (types_plus.need_v5[]);  CREATE OR REPLACE FUNCTION types_plus.insert_need_v5 (data_in types_plus.need_v5[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO need (			id,			hsys_id,			facility_id,			item_id,			percent_down,			next_case_dts,			flow,			qty_circulation,			qty_ready_everywhere,			qty_ready_here,			qty_sched_everywhere,			qty_sched_here,			qty_sterile_everywhere,			qty_sterile_here,			qty_suggest_sterilize,			qty_total,			ready_vs_need_defecit,			sched_sort,			sort_rank,			suggest_transport,			next_needed,			or_name,			status,			status_sort,			when_,			qty_here)                  SELECT			rows_in.id,			rows_in.hsys_id,			rows_in.facility_id,			rows_in.item_id,			rows_in.percent_down,			rows_in.next_case_dts,			rows_in.flow,			rows_in.qty_circulation,			rows_in.qty_ready_everywhere,			rows_in.qty_ready_here,			rows_in.qty_sched_everywhere,			rows_in.qty_sched_here,			rows_in.qty_sterile_everywhere,			rows_in.qty_sterile_here,			rows_in.qty_suggest_sterilize,			rows_in.qty_total,			rows_in.ready_vs_need_defecit,			rows_in.sched_sort,			rows_in.sort_rank,			rows_in.suggest_transport,			rows_in.next_needed,			rows_in.or_name,			rows_in.status,			rows_in.status_sort,			rows_in.when_,			rows_in.qty_here                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			hsys_id = EXCLUDED.hsys_id,			facility_id = EXCLUDED.facility_id,			item_id = EXCLUDED.item_id,			percent_down = EXCLUDED.percent_down,			next_case_dts = EXCLUDED.next_case_dts,			flow = EXCLUDED.flow,			qty_circulation = EXCLUDED.qty_circulation,			qty_ready_everywhere = EXCLUDED.qty_ready_everywhere,			qty_ready_here = EXCLUDED.qty_ready_here,			qty_sched_everywhere = EXCLUDED.qty_sched_everywhere,			qty_sched_here = EXCLUDED.qty_sched_here,			qty_sterile_everywhere = EXCLUDED.qty_sterile_everywhere,			qty_sterile_here = EXCLUDED.qty_sterile_here,			qty_suggest_sterilize = EXCLUDED.qty_suggest_sterilize,			qty_total = EXCLUDED.qty_total,			ready_vs_need_defecit = EXCLUDED.ready_vs_need_defecit,			sched_sort = EXCLUDED.sched_sort,			sort_rank = EXCLUDED.sort_rank,			suggest_transport = EXCLUDED.suggest_transport,			next_needed = EXCLUDED.next_needed,			or_name = EXCLUDED.or_name,			status = EXCLUDED.status,			status_sort = EXCLUDED.status_sort,			when_ = EXCLUDED.when_,			qty_here = EXCLUDED.qty_here          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_need_v5(types_plus.need_v5[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:productivity_detail_v1:productivity_detail_v1_combined.sql-- Create a view onto productivity_detail formatted as productivity_detail_v1.-- If productivity_detail changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_productivity_detail_v1.DROP VIEW IF EXISTS types_plus.productivity_detail_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.productivity_detail_v1 AS select id,        source_record_row_counter,        start_time_dts,        source_table_number,        data_file_id,        user_id,        facility_id,        assembly_inst,        assembly_pack,        assembly_tray,        assembly_points,        assembly_seconds_trays,        assembly_seconds_overall,        pause_seconds,        duration_seconds,        placeholder_row,        description,        year_and_month,        start_date,        time_label,        duration,        pause_time,        activity,        user_label   from productivity_detail;ALTER TABLE types_plus.productivity_detail_v1    OWNER TO user_change_structure;-- Create a casting function to convert productivity_detail rows into the compound type format productivity_detail_v1.-- If productivity_detail changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.productivity_detail_to_v1 (productivity_detail_in productivity_detail)  RETURNS productivity_detail_v1AS $BODY$        SELECT			productivity_detail_in.id,			productivity_detail_in.source_record_row_counter,			productivity_detail_in.start_time_dts,			productivity_detail_in.source_table_number,			productivity_detail_in.data_file_id,			productivity_detail_in.user_id,			productivity_detail_in.facility_id,			productivity_detail_in.assembly_inst,			productivity_detail_in.assembly_pack,			productivity_detail_in.assembly_tray,			productivity_detail_in.assembly_points,			productivity_detail_in.assembly_seconds_trays,			productivity_detail_in.assembly_seconds_overall,			productivity_detail_in.pause_seconds,			productivity_detail_in.duration_seconds,			productivity_detail_in.placeholder_row,			productivity_detail_in.description,			productivity_detail_in.year_and_month,			productivity_detail_in.start_date,			productivity_detail_in.time_label,			productivity_detail_in.duration,			productivity_detail_in.pause_time,			productivity_detail_in.activity,			productivity_detail_in.user_label$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.productivity_detail_to_v1 (productivity_detail_in productivity_detail)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert productivity_detail rows into the productivity_detail_v1 compound type format using the following syntax:-- select productivity_detail::productivity_detail_v1 from productivity_detailDROP CAST IF EXISTS (productivity_detail as productivity_detail_v1);CREATE CAST (productivity_detail as productivity_detail_v1) WITH FUNCTION types_plus.productivity_detail_to_v1(productivity_detail);-- Create a function to accept an array of rows formatted as productivity_detail_v1 for UPSERT into productivity_detail.DROP FUNCTION IF EXISTS types_plus.insert_productivity_detail_v1 (types_plus.productivity_detail_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_productivity_detail_v1 (data_in types_plus.productivity_detail_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO productivity_detail (			id,			source_record_row_counter,			start_time_dts,			source_table_number,			data_file_id,			user_id,			facility_id,			assembly_inst,			assembly_pack,			assembly_tray,			assembly_points,			assembly_seconds_trays,			assembly_seconds_overall,			pause_seconds,			duration_seconds,			placeholder_row,			description,			year_and_month,			start_date,			time_label,			duration,			pause_time,			activity,			user_label)        SELECT			rows_in.id,			rows_in.source_record_row_counter,			rows_in.start_time_dts,			rows_in.source_table_number,			rows_in.data_file_id,			rows_in.user_id,			rows_in.facility_id,			rows_in.assembly_inst,			rows_in.assembly_pack,			rows_in.assembly_tray,			rows_in.assembly_points,			rows_in.assembly_seconds_trays,			rows_in.assembly_seconds_overall,			rows_in.pause_seconds,			rows_in.duration_seconds,			rows_in.placeholder_row,			rows_in.description,			rows_in.year_and_month,			rows_in.start_date,			rows_in.time_label,			rows_in.duration,			rows_in.pause_time,			rows_in.activity,			rows_in.user_label        FROM unnest(data_in) as rows_in        ON CONFLICT ON CONSTRAINT productivity_detail_id_pkey DO UPDATE SET			source_record_row_counter = EXCLUDED.source_record_row_counter,			start_time_dts = EXCLUDED.start_time_dts,			source_table_number = EXCLUDED.source_table_number,			data_file_id = EXCLUDED.data_file_id,			user_id = EXCLUDED.user_id,			facility_id = EXCLUDED.facility_id,			assembly_inst = EXCLUDED.assembly_inst,			assembly_pack = EXCLUDED.assembly_pack,			assembly_tray = EXCLUDED.assembly_tray,			assembly_points = EXCLUDED.assembly_points,			assembly_seconds_trays = EXCLUDED.assembly_seconds_trays,			assembly_seconds_overall = EXCLUDED.assembly_seconds_overall,			pause_seconds = EXCLUDED.pause_seconds,			duration_seconds = EXCLUDED.duration_seconds,			placeholder_row = EXCLUDED.placeholder_row,			description = EXCLUDED.description,			year_and_month = EXCLUDED.year_and_month,			start_date = EXCLUDED.start_date,			time_label = EXCLUDED.time_label,			duration = EXCLUDED.duration,			pause_time = EXCLUDED.pause_time,			activity = EXCLUDED.activity,			user_label = EXCLUDED.user_label        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_productivity_detail_v1(types_plus.productivity_detail_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:push_audit_v1:push_audit_v1_combined.sql-- Create a view onto push_audit formatted as push_audit_v1.-- If push_audit changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_push_audit_v1.DROP VIEW IF EXISTS types_plus.push_audit_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.push_audit_v1 AS select target.schema_name,        target.target_name,        target.unique_path,        target.target_type,        audit.data_file_id,        audit.duration_seconds,        audit.records_count,        audit.version_number,        audit.start_local_dts,        audit.end_local_dts,        audit.end_utc_dts,        audit.error_occurred,        audit.client_user_name,        audit.push_method_name,        audit.error_text     from push_audit     auditleft join dba.push_target    target on target.id = audit.target_id;-- Create a function to accept an array of rows formatted as push_audit_v1 for UPSERT into push_audit.DROP FUNCTION IF EXISTS types_plus.insert_push_audit_v1 (types_plus.push_audit_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_push_audit_v1 (    data_in  types_plus.push_audit_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.WITHinserted_rows AS (        INSERT INTO dba.push_audit (            data_file_id,			duration_seconds,			records_count,			target_id, -- int4 link to dba.push_target, PG-side.			version_number,			start_local_dts,			end_local_dts,			end_utc_dts,			error_occurred,			client_user_name,			push_method_name,			error_text)        SELECT			rows_in.data_file_id,			rows_in.duration_seconds,			rows_in.records_count,			push_target_add_if_missing (			     rows_in.schema_name,			     rows_in.target_name,			     rows_in.unique_path,			     rows_in.target_type),			rows_in.version_number,			rows_in.start_local_dts,			rows_in.end_local_dts,			rows_in.end_utc_dts,			rows_in.error_occurred,			rows_in.client_user_name,			rows_in.push_method_name,			rows_in.error_text        FROM unnest(data_in) as rows_in        RETURNING 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_push_audit_v1(types_plus.push_audit_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:q_audit_step_v1:q_audit_step_v1_combined.sql-- Create a view onto q_audit_step formatted as q_audit_step_v1.-- If q_audit_step changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_q_audit_step_v1.DROP VIEW IF EXISTS types_plus.q_audit_step_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.q_audit_step_v1 AS select id,        hsys_id,        qsub_type_id_audit,        step,        marked_for_deletion,        last_updated_by_data_file_id,        created_dts,        updated_dts,        created_by,        updated_by,        sort,        qsub_type_id_event   from q_audit_step;ALTER TABLE types_plus.q_audit_step_v1    OWNER TO user_change_structure;-- Create a casting function to convert q_audit_step rows into the compound type format q_audit_step_v1.-- If q_audit_step changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.q_audit_step_to_v1 (q_audit_step_in q_audit_step)  RETURNS q_audit_step_v1AS $BODY$                   SELECT			q_audit_step_in.id,			q_audit_step_in.hsys_id,			q_audit_step_in.qsub_type_id_audit,			q_audit_step_in.step,			q_audit_step_in.marked_for_deletion,			q_audit_step_in.last_updated_by_data_file_id,			q_audit_step_in.created_dts,			q_audit_step_in.updated_dts,			q_audit_step_in.created_by,			q_audit_step_in.updated_by,			q_audit_step_in.sort,			q_audit_step_in.qsub_type_id_event               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.q_audit_step_to_v1 (q_audit_step_in q_audit_step)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert q_audit_step rows into the q_audit_step_v1 compound type format using the following syntax:-- select q_audit_step::q_audit_step_v1 from q_audit_stepDROP CAST IF EXISTS (q_audit_step as q_audit_step_v1);CREATE CAST (q_audit_step as q_audit_step_v1) WITH FUNCTION types_plus.q_audit_step_to_v1(q_audit_step);-- Create a function to accept an array of rows formatted as q_audit_step_v1 for UPSERT into q_audit_step.DROP FUNCTION IF EXISTS types_plus.insert_q_audit_step_v1 (types_plus.q_audit_step_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_q_audit_step_v1 (data_in types_plus.q_audit_step_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO q_audit_step (			id,			hsys_id,			qsub_type_id_audit,			step,			marked_for_deletion,			last_updated_by_data_file_id,			created_dts,			updated_dts,			created_by,			updated_by,			sort,			qsub_type_id_event)                  SELECT			rows_in.id,			rows_in.hsys_id,			rows_in.qsub_type_id_audit,			rows_in.step,			rows_in.marked_for_deletion,			rows_in.last_updated_by_data_file_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.created_by,			rows_in.updated_by,			rows_in.sort,			rows_in.qsub_type_id_event                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			hsys_id = EXCLUDED.hsys_id,			qsub_type_id_audit = EXCLUDED.qsub_type_id_audit,			step = EXCLUDED.step,			marked_for_deletion = EXCLUDED.marked_for_deletion,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			sort = EXCLUDED.sort,			qsub_type_id_event = EXCLUDED.qsub_type_id_event          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_q_audit_step_v1(types_plus.q_audit_step_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:q_event_audit_step_v1:q_event_audit_step_v1_combined.sql-- Create a view onto q_event_audit_step formatted as q_event_audit_step_v1.-- If q_event_audit_step changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_q_event_audit_step_v1.DROP VIEW IF EXISTS types_plus.q_event_audit_step_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.q_event_audit_step_v1 AS select id,        qevent_id,        qaudit_step_id,        last_updated_by_data_file_id,        updated_dts,        created_dts,        sort,        marked_for_deletion,        is_coached,        notes,        created_by,        updated_by,        step,        qsub_type_id_event,        status   from q_event_audit_step;ALTER TABLE types_plus.q_event_audit_step_v1    OWNER TO user_change_structure;-- Create a casting function to convert q_event_audit_step rows into the compound type format q_event_audit_step_v1.-- If q_event_audit_step changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.q_event_audit_step_to_v1 (q_event_audit_step_in q_event_audit_step)  RETURNS q_event_audit_step_v1AS $BODY$                   SELECT			q_event_audit_step_in.id,			q_event_audit_step_in.qevent_id,			q_event_audit_step_in.qaudit_step_id,			q_event_audit_step_in.last_updated_by_data_file_id,			q_event_audit_step_in.updated_dts,			q_event_audit_step_in.created_dts,			q_event_audit_step_in.sort,			q_event_audit_step_in.marked_for_deletion,			q_event_audit_step_in.is_coached,			q_event_audit_step_in.notes,			q_event_audit_step_in.created_by,			q_event_audit_step_in.updated_by,			q_event_audit_step_in.step,			q_event_audit_step_in.qsub_type_id_event,			q_event_audit_step_in.status               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.q_event_audit_step_to_v1 (q_event_audit_step_in q_event_audit_step)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert q_event_audit_step rows into the q_event_audit_step_v1 compound type format using the following syntax:-- select q_event_audit_step::q_event_audit_step_v1 from q_event_audit_stepDROP CAST IF EXISTS (q_event_audit_step as q_event_audit_step_v1);CREATE CAST (q_event_audit_step as q_event_audit_step_v1) WITH FUNCTION types_plus.q_event_audit_step_to_v1(q_event_audit_step);-- Create a function to accept an array of rows formatted as q_event_audit_step_v1 for UPSERT into q_event_audit_step.DROP FUNCTION IF EXISTS types_plus.insert_q_event_audit_step_v1 (types_plus.q_event_audit_step_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_q_event_audit_step_v1 (data_in types_plus.q_event_audit_step_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO q_event_audit_step (			id,			qevent_id,			qaudit_step_id,			last_updated_by_data_file_id,			updated_dts,			created_dts,			sort,			marked_for_deletion,			is_coached,			notes,			created_by,			updated_by,			step,			qsub_type_id_event,			status)                  SELECT			rows_in.id,			rows_in.qevent_id,			rows_in.qaudit_step_id,			rows_in.last_updated_by_data_file_id,			rows_in.updated_dts,			rows_in.created_dts,			rows_in.sort,			rows_in.marked_for_deletion,			rows_in.is_coached,			rows_in.notes,			rows_in.created_by,			rows_in.updated_by,			rows_in.step,			rows_in.qsub_type_id_event,			rows_in.status                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			qevent_id = EXCLUDED.qevent_id,			qaudit_step_id = EXCLUDED.qaudit_step_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			updated_dts = EXCLUDED.updated_dts,			created_dts = EXCLUDED.created_dts,			sort = EXCLUDED.sort,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_coached = EXCLUDED.is_coached,			notes = EXCLUDED.notes,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			step = EXCLUDED.step,			qsub_type_id_event = EXCLUDED.qsub_type_id_event,			status = EXCLUDED.status          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_q_event_audit_step_v1(types_plus.q_event_audit_step_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:q_event_person_v1:q_event_person_v1_combined.sql-- Create a view onto q_event_person formatted as q_event_person_v1.-- If q_event_person changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_q_event_person_v1.DROP VIEW IF EXISTS types_plus.q_event_person_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.q_event_person_v1 AS select id,        web_user_id,        last_updated_by_data_file_id,        qevent_id,        created_dts,        updated_dts,        marked_for_deletion,        is_accountable,        send_email,        updated_by,        role_,        created_by   from q_event_person;ALTER TABLE types_plus.q_event_person_v1    OWNER TO user_change_structure;-- Create a casting function to convert q_event_person rows into the compound type format q_event_person_v1.-- If q_event_person changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.q_event_person_to_v1 (q_event_person_in q_event_person)  RETURNS q_event_person_v1AS $BODY$                   SELECT			q_event_person_in.id,			q_event_person_in.web_user_id,			q_event_person_in.last_updated_by_data_file_id,			q_event_person_in.qevent_id,			q_event_person_in.created_dts,			q_event_person_in.updated_dts,			q_event_person_in.marked_for_deletion,			q_event_person_in.is_accountable,			q_event_person_in.send_email,			q_event_person_in.updated_by,			q_event_person_in.role_,			q_event_person_in.created_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.q_event_person_to_v1 (q_event_person_in q_event_person)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert q_event_person rows into the q_event_person_v1 compound type format using the following syntax:-- select q_event_person::q_event_person_v1 from q_event_personDROP CAST IF EXISTS (q_event_person as q_event_person_v1);CREATE CAST (q_event_person as q_event_person_v1) WITH FUNCTION types_plus.q_event_person_to_v1(q_event_person);-- Create a function to accept an array of rows formatted as q_event_person_v1 for UPSERT into q_event_person.DROP FUNCTION IF EXISTS types_plus.insert_q_event_person_v1 (types_plus.q_event_person_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_q_event_person_v1 (data_in types_plus.q_event_person_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO q_event_person (			id,			web_user_id,			last_updated_by_data_file_id,			qevent_id,			created_dts,			updated_dts,			marked_for_deletion,			is_accountable,			send_email,			updated_by,			role_,			created_by)                  SELECT			rows_in.id,			rows_in.web_user_id,			rows_in.last_updated_by_data_file_id,			rows_in.qevent_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.is_accountable,			rows_in.send_email,			rows_in.updated_by,			rows_in.role_,			rows_in.created_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			web_user_id = EXCLUDED.web_user_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			qevent_id = EXCLUDED.qevent_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_accountable = EXCLUDED.is_accountable,			send_email = EXCLUDED.send_email,			updated_by = EXCLUDED.updated_by,			role_ = EXCLUDED.role_,			created_by = EXCLUDED.created_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_q_event_person_v1(types_plus.q_event_person_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:q_event_v1:q_event_v1_combined.sql-- Create a view onto q_event formatted as q_event_v1.-- If q_event changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_q_event_v1.DROP VIEW IF EXISTS types_plus.q_event_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.q_event_v1 AS select or_surgeon_people_id,        id,        qtype_id,        qsub_type_id,        inv_id,        scan_id,        assembly_id,        status_when_user_id,        facility_id,        last_updated_by_data_file_id,        status_reported_by_user_id,        status_done_user_id,        status_investigating_user_id,        datetime_local,        status_done_dts,        status_when_dts,        status_investigating_dts,        status_reported_dts,        updated_dts,        created_dts,        or_delay_minutes,        marked_for_deletion,        is_data_problem,        is_process_problem,        assembly_audit_prods,        is_coached,        updated_by,        or_room,        status_done_name,        status,        status_when_name,        desc_,        status_investigating_name,        or_delay_type,        status_reported_by_name,        notes,        created_by   from q_event;ALTER TABLE types_plus.q_event_v1    OWNER TO user_change_structure;-- Create a casting function to convert q_event rows into the compound type format q_event_v1.-- If q_event changes, you can update the casting to handle the modification smoothly.DROP FUNCTION IF EXISTS types_plus.q_event_to_v1 (q_event_in q_event);CREATE OR REPLACE FUNCTION types_plus.q_event_to_v1 (q_event_in q_event)  RETURNS q_event_v1AS $BODY$        SELECT			q_event_in.or_surgeon_people_id,			q_event_in.id,			q_event_in.qtype_id,			q_event_in.qsub_type_id,			q_event_in.inv_id,			q_event_in.scan_id,			q_event_in.assembly_id,			q_event_in.status_when_user_id,			q_event_in.facility_id,			q_event_in.last_updated_by_data_file_id,			q_event_in.status_reported_by_user_id,			q_event_in.status_done_user_id,			q_event_in.status_investigating_user_id,			q_event_in.datetime_local,			q_event_in.status_done_dts,			q_event_in.status_when_dts,			q_event_in.status_investigating_dts,			q_event_in.status_reported_dts,			q_event_in.updated_dts,			q_event_in.created_dts,			q_event_in.or_delay_minutes,			q_event_in.marked_for_deletion,			q_event_in.is_data_problem,			q_event_in.is_process_problem,			q_event_in.assembly_audit_prods,			q_event_in.is_coached,			q_event_in.updated_by,			q_event_in.or_room,			q_event_in.status_done_name,			q_event_in.status,			q_event_in.status_when_name,			q_event_in.desc_,			q_event_in.status_investigating_name,			q_event_in.or_delay_type,			q_event_in.status_reported_by_name,			q_event_in.notes,			q_event_in.created_by$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.q_event_to_v1 (q_event_in q_event)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert q_event rows into the q_event_v1 compound type format using the following syntax:-- select q_event::q_event_v1 from q_eventDROP CAST IF EXISTS (q_event as q_event_v1);CREATE CAST (q_event as q_event_v1) WITH FUNCTION types_plus.q_event_to_v1(q_event);-- Create a function to accept an array of rows formatted as q_event_v1 for UPSERT into q_event.DROP FUNCTION IF EXISTS types_plus.insert_q_event_v1 (types_plus.q_event_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_q_event_v1 (data_in types_plus.q_event_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO q_event (			or_surgeon_people_id,			id,			qtype_id,			qsub_type_id,			inv_id,			scan_id,			assembly_id,			status_when_user_id,			facility_id,			last_updated_by_data_file_id,			status_reported_by_user_id,			status_done_user_id,			status_investigating_user_id,			datetime_local,			status_done_dts,			status_when_dts,			status_investigating_dts,			status_reported_dts,			updated_dts,			created_dts,			or_delay_minutes,			marked_for_deletion,			is_data_problem,			is_process_problem,			assembly_audit_prods,			is_coached,			updated_by,			or_room,			status_done_name,			status,			status_when_name,			desc_,			status_investigating_name,			or_delay_type,			status_reported_by_name,			notes,			created_by)        SELECT			rows_in.or_surgeon_people_id,			rows_in.id,			rows_in.qtype_id,			rows_in.qsub_type_id,			rows_in.inv_id,			rows_in.scan_id,			rows_in.assembly_id,			rows_in.status_when_user_id,			rows_in.facility_id,			rows_in.last_updated_by_data_file_id,			rows_in.status_reported_by_user_id,			rows_in.status_done_user_id,			rows_in.status_investigating_user_id,			rows_in.datetime_local,			rows_in.status_done_dts,			rows_in.status_when_dts,			rows_in.status_investigating_dts,			rows_in.status_reported_dts,			rows_in.updated_dts,			rows_in.created_dts,			rows_in.or_delay_minutes,			rows_in.marked_for_deletion,			rows_in.is_data_problem,			rows_in.is_process_problem,			rows_in.assembly_audit_prods,			rows_in.is_coached,			rows_in.updated_by,			rows_in.or_room,			rows_in.status_done_name,			rows_in.status,			rows_in.status_when_name,			rows_in.desc_,			rows_in.status_investigating_name,			rows_in.or_delay_type,			rows_in.status_reported_by_name,			rows_in.notes,			rows_in.created_by        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			or_surgeon_people_id = EXCLUDED.or_surgeon_people_id,			qtype_id = EXCLUDED.qtype_id,			qsub_type_id = EXCLUDED.qsub_type_id,			inv_id = EXCLUDED.inv_id,			scan_id = EXCLUDED.scan_id,			assembly_id = EXCLUDED.assembly_id,			status_when_user_id = EXCLUDED.status_when_user_id,			facility_id = EXCLUDED.facility_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			status_reported_by_user_id = EXCLUDED.status_reported_by_user_id,			status_done_user_id = EXCLUDED.status_done_user_id,			status_investigating_user_id = EXCLUDED.status_investigating_user_id,			datetime_local = EXCLUDED.datetime_local,			status_done_dts = EXCLUDED.status_done_dts,			status_when_dts = EXCLUDED.status_when_dts,			status_investigating_dts = EXCLUDED.status_investigating_dts,			status_reported_dts = EXCLUDED.status_reported_dts,			updated_dts = EXCLUDED.updated_dts,			created_dts = EXCLUDED.created_dts,			or_delay_minutes = EXCLUDED.or_delay_minutes,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_data_problem = EXCLUDED.is_data_problem,			is_process_problem = EXCLUDED.is_process_problem,			assembly_audit_prods = EXCLUDED.assembly_audit_prods,			is_coached = EXCLUDED.is_coached,			updated_by = EXCLUDED.updated_by,			or_room = EXCLUDED.or_room,			status_done_name = EXCLUDED.status_done_name,			status = EXCLUDED.status,			status_when_name = EXCLUDED.status_when_name,			desc_ = EXCLUDED.desc_,			status_investigating_name = EXCLUDED.status_investigating_name,			or_delay_type = EXCLUDED.or_delay_type,			status_reported_by_name = EXCLUDED.status_reported_by_name,			notes = EXCLUDED.notes,			created_by = EXCLUDED.created_by        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_q_event_v1(types_plus.q_event_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:q_level_v1:q_level_v1_combined.sql-- Create a view onto q_level formatted as q_level_v1.-- If q_level changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_q_level_v1.DROP VIEW IF EXISTS types_plus.q_level_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.q_level_v1 AS select id,        hsys_id,        last_updated_by_data_file_id,        created_dts,        updated_dts,        level_,        marked_for_deletion,        created_by,        updated_by,        name_,        ascendco_name   from q_level;ALTER TABLE types_plus.q_level_v1    OWNER TO user_change_structure;-- Create a casting function to convert q_level rows into the compound type format q_level_v1.-- If q_level changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.q_level_to_v1 (q_level_in q_level)  RETURNS q_level_v1AS $BODY$                   SELECT			q_level_in.id,			q_level_in.hsys_id,			q_level_in.last_updated_by_data_file_id,			q_level_in.created_dts,			q_level_in.updated_dts,			q_level_in.level_,			q_level_in.marked_for_deletion,			q_level_in.created_by,			q_level_in.updated_by,			q_level_in.name_,			q_level_in.ascendco_name               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.q_level_to_v1 (q_level_in q_level)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert q_level rows into the q_level_v1 compound type format using the following syntax:-- select q_level::q_level_v1 from q_levelDROP CAST IF EXISTS (q_level as q_level_v1);CREATE CAST (q_level as q_level_v1) WITH FUNCTION types_plus.q_level_to_v1(q_level);-- Create a function to accept an array of rows formatted as q_level_v1 for UPSERT into q_level.DROP FUNCTION IF EXISTS types_plus.insert_q_level_v1 (types_plus.q_level_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_q_level_v1 (data_in types_plus.q_level_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO q_level (			id,			hsys_id,			last_updated_by_data_file_id,			created_dts,			updated_dts,			level_,			marked_for_deletion,			created_by,			updated_by,			name_,			ascendco_name)                  SELECT			rows_in.id,			rows_in.hsys_id,			rows_in.last_updated_by_data_file_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.level_,			rows_in.marked_for_deletion,			rows_in.created_by,			rows_in.updated_by,			rows_in.name_,			rows_in.ascendco_name                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			hsys_id = EXCLUDED.hsys_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			level_ = EXCLUDED.level_,			marked_for_deletion = EXCLUDED.marked_for_deletion,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			name_ = EXCLUDED.name_,			ascendco_name = EXCLUDED.ascendco_name          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_q_level_v1(types_plus.q_level_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:q_subtype_v1:q_subtype_v1_combined.sql-- Create a view onto q_subtype formatted as q_subtype_v1.-- If q_subtype changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_q_subtype_v1.DROP VIEW IF EXISTS types_plus.q_subtype_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.q_subtype_v1 AS select id,        qtype_id,        qlevel_id,        facility_group_id,        facility_id,        hsys_id,        last_updated_by_data_file_id,        created_dts,        updated_dts,        is_available_in_assembly,        is_available_in_decon,        marked_for_deletion,        is_for_inv,        is_active,        ascendco_name,        updated_by,        type_,        available_for,        created_by,        name_,        item_type_ids   from q_subtype;ALTER TABLE types_plus.q_subtype_v1    OWNER TO user_change_structure;-- Create a casting function to convert q_subtype rows into the compound type format q_subtype_v1.-- If q_subtype changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.q_subtype_to_v1 (q_subtype_in q_subtype)  RETURNS q_subtype_v1AS $BODY$        SELECT			q_subtype_in.id,			q_subtype_in.qtype_id,			q_subtype_in.qlevel_id,			q_subtype_in.facility_group_id,			q_subtype_in.facility_id,			q_subtype_in.hsys_id,			q_subtype_in.last_updated_by_data_file_id,			q_subtype_in.created_dts,			q_subtype_in.updated_dts,			q_subtype_in.is_available_in_assembly,			q_subtype_in.is_available_in_decon,			q_subtype_in.marked_for_deletion,			q_subtype_in.is_for_inv,			q_subtype_in.is_active,			q_subtype_in.ascendco_name,			q_subtype_in.updated_by,			q_subtype_in.type_,			q_subtype_in.available_for,			q_subtype_in.created_by,			q_subtype_in.name_,			q_subtype_in.item_type_ids$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.q_subtype_to_v1 (q_subtype_in q_subtype)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert q_subtype rows into the q_subtype_v1 compound type format using the following syntax:-- select q_subtype::q_subtype_v1 from q_subtypeDROP CAST IF EXISTS (q_subtype as q_subtype_v1);CREATE CAST (q_subtype as q_subtype_v1) WITH FUNCTION types_plus.q_subtype_to_v1(q_subtype);-- Create a function to accept an array of rows formatted as q_subtype_v1 for UPSERT into q_subtype.DROP FUNCTION IF EXISTS types_plus.insert_q_subtype_v1 (types_plus.q_subtype_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_q_subtype_v1 (data_in types_plus.q_subtype_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO q_subtype (			id,			qtype_id,			qlevel_id,			facility_group_id,			facility_id,			hsys_id,			last_updated_by_data_file_id,			created_dts,			updated_dts,			is_available_in_assembly,			is_available_in_decon,			marked_for_deletion,			is_for_inv,			is_active,			ascendco_name,			updated_by,			type_,			available_for,			created_by,			name_,			item_type_ids)        SELECT			rows_in.id,			rows_in.qtype_id,			rows_in.qlevel_id,			rows_in.facility_group_id,			rows_in.facility_id,			rows_in.hsys_id,			rows_in.last_updated_by_data_file_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.is_available_in_assembly,			rows_in.is_available_in_decon,			rows_in.marked_for_deletion,			rows_in.is_for_inv,			rows_in.is_active,			rows_in.ascendco_name,			rows_in.updated_by,			rows_in.type_,			rows_in.available_for,			rows_in.created_by,			rows_in.name_,			rows_in.item_type_ids        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			qtype_id = EXCLUDED.qtype_id,			qlevel_id = EXCLUDED.qlevel_id,			facility_group_id = EXCLUDED.facility_group_id,			facility_id = EXCLUDED.facility_id,			hsys_id = EXCLUDED.hsys_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			is_available_in_assembly = EXCLUDED.is_available_in_assembly,			is_available_in_decon = EXCLUDED.is_available_in_decon,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_for_inv = EXCLUDED.is_for_inv,			is_active = EXCLUDED.is_active,			ascendco_name = EXCLUDED.ascendco_name,			updated_by = EXCLUDED.updated_by,			type_ = EXCLUDED.type_,			available_for = EXCLUDED.available_for,			created_by = EXCLUDED.created_by,			name_ = EXCLUDED.name_,			item_type_ids = EXCLUDED.item_type_ids        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_q_subtype_v1(types_plus.q_subtype_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:q_type_v1:q_type_v1_combined.sql-- Create a view onto q_type formatted as q_type_v1.-- If q_type changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_q_type_v1.DROP VIEW IF EXISTS types_plus.q_type_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.q_type_v1 AS select id,        hsys_id,        last_updated_by_data_file_id,        created_dts,        updated_dts,        marked_for_deletion,        is_active,        updated_by,        created_by,        ascendco_name,        name_,        type_   from q_type;ALTER TABLE types_plus.q_type_v1    OWNER TO user_change_structure;-- Create a casting function to convert q_type rows into the compound type format q_type_v1.-- If q_type changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.q_type_to_v1 (q_type_in q_type)  RETURNS q_type_v1AS $BODY$                   SELECT			q_type_in.id,			q_type_in.hsys_id,			q_type_in.last_updated_by_data_file_id,			q_type_in.created_dts,			q_type_in.updated_dts,			q_type_in.marked_for_deletion,			q_type_in.is_active,			q_type_in.updated_by,			q_type_in.created_by,			q_type_in.ascendco_name,			q_type_in.name_,			q_type_in.type_               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.q_type_to_v1 (q_type_in q_type)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert q_type rows into the q_type_v1 compound type format using the following syntax:-- select q_type::q_type_v1 from q_typeDROP CAST IF EXISTS (q_type as q_type_v1);CREATE CAST (q_type as q_type_v1) WITH FUNCTION types_plus.q_type_to_v1(q_type);-- Create a function to accept an array of rows formatted as q_type_v1 for UPSERT into q_type.DROP FUNCTION IF EXISTS types_plus.insert_q_type_v1 (types_plus.q_type_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_q_type_v1 (data_in types_plus.q_type_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO q_type (			id,			hsys_id,			last_updated_by_data_file_id,			created_dts,			updated_dts,			marked_for_deletion,			is_active,			updated_by,			created_by,			ascendco_name,			name_,			type_)                  SELECT			rows_in.id,			rows_in.hsys_id,			rows_in.last_updated_by_data_file_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.is_active,			rows_in.updated_by,			rows_in.created_by,			rows_in.ascendco_name,			rows_in.name_,			rows_in.type_                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			hsys_id = EXCLUDED.hsys_id,			last_updated_by_data_file_id = EXCLUDED.last_updated_by_data_file_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_active = EXCLUDED.is_active,			updated_by = EXCLUDED.updated_by,			created_by = EXCLUDED.created_by,			ascendco_name = EXCLUDED.ascendco_name,			name_ = EXCLUDED.name_,			type_ = EXCLUDED.type_          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_q_type_v1(types_plus.q_type_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:rep_v1:rep_v1_combined.sql-- Create a view onto rep formatted as rep_v1.-- If rep changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_rep_v1.DROP VIEW IF EXISTS types_plus.rep_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.rep_v1 AS select id,        user_id,        hsys_id,        sup_id,        created_dts,        updated_dts,        marked_for_deletion,        name_,        phone,        email,        created_by,        updated_by   from rep;ALTER TABLE types_plus.rep_v1    OWNER TO user_change_structure;-- Create a casting function to convert rep rows into the compound type format rep_v1.-- If rep changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.rep_to_v1 (rep_in rep)  RETURNS rep_v1AS $BODY$                   SELECT			rep_in.id,			rep_in.user_id,			rep_in.hsys_id,			rep_in.sup_id,			rep_in.created_dts,			rep_in.updated_dts,			rep_in.marked_for_deletion,			rep_in.name_,			rep_in.phone,			rep_in.email,			rep_in.created_by,			rep_in.updated_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.rep_to_v1 (rep_in rep)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert rep rows into the rep_v1 compound type format using the following syntax:-- select rep::rep_v1 from repDROP CAST IF EXISTS (rep as rep_v1);CREATE CAST (rep as rep_v1) WITH FUNCTION types_plus.rep_to_v1(rep);-- Create a function to accept an array of rows formatted as rep_v1 for UPSERT into rep.DROP FUNCTION IF EXISTS types_plus.insert_rep_v1 (types_plus.rep_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_rep_v1 (data_in types_plus.rep_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO rep (			id,			user_id,			hsys_id,			sup_id,			created_dts,			updated_dts,			marked_for_deletion,			name_,			phone,			email,			created_by,			updated_by)                  SELECT			rows_in.id,			rows_in.user_id,			rows_in.hsys_id,			rows_in.sup_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.name_,			rows_in.phone,			rows_in.email,			rows_in.created_by,			rows_in.updated_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			user_id = EXCLUDED.user_id,			hsys_id = EXCLUDED.hsys_id,			sup_id = EXCLUDED.sup_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_,			phone = EXCLUDED.phone,			email = EXCLUDED.email,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_rep_v1(types_plus.rep_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:specialty_v1:specialty_v1_combined.sql-- Create a view onto specialty formatted as specialty_v1.-- If specialty changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_specialty_v1.DROP VIEW IF EXISTS types_plus.specialty_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.specialty_v1 AS select id,        data_file_id,        marked_for_deletion,        name_,        name_short   from specialty;ALTER TABLE types_plus.specialty_v1    OWNER TO user_change_structure;-- Create a casting function to convert specialty rows into the compound type format specialty_v1.-- If specialty changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.specialty_to_v1 (specialty_in specialty)  RETURNS specialty_v1AS $BODY$        SELECT			specialty_in.id,			specialty_in.data_file_id,			specialty_in.marked_for_deletion,			specialty_in.name_,			specialty_in.name_short$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.specialty_to_v1 (specialty_in specialty) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert specialty rows into the specialty_v1 compound type format using the following syntax:-- select specialty::specialty_v1 from specialtyDROP CAST IF EXISTS (specialty as specialty_v1);CREATE CAST (specialty as specialty_v1) WITH FUNCTION types_plus.specialty_to_v1(specialty);-- Create a function to accept an array of rows formatted as specialty_v1 for UPSERT into specialty.DROP FUNCTION IF EXISTS types_plus.insert_specialty_v1 (types_plus.specialty_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_specialty_v1 (data_in types_plus.specialty_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO specialty (			id,			data_file_id,			marked_for_deletion,			name_,			name_short)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.name_,			rows_in.name_short        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_,			name_short = EXCLUDED.name_short        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_specialty_v1(types_plus.specialty_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:stat_facility_v1:stat_facility_v1_combined.sql-- Create a view onto stat_facility formatted as stat_facility_v1.-- If stat_facility changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_stat_facility_v1.DROP VIEW IF EXISTS types_plus.stat_facility_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.stat_facility_v1 AS select id,        facility_id,        hsys_id,        date_,        category,        item_type,        stat_type,        is_most_recent,        in_data_cleanse_scope,        items_inactive,        items_count,        items_qty,        items_inventoried,        items_to_inventory,        items_named,        items_to_name,        inst_qty,        items_has_loc,        items_missing_locs,        item_prods_count,        item_prods_missing_part_nos_thier,        item_prods_missing_vendors_thier,        item_prods_dr_pref,        item_prods_critical,        item_prods_not_linked,        item_prods_missing_part_nos,        item_prods_missing_vendors,        item_prods_cant_determine,        item_prods_linked,        sup_prods_count,        sups_count,        prods_count,        prods_with_pic,        prods_without_pic,        item_prods_verified,        item_prods_expert_linked,        item_prods_dup_names_their,        item_prods_dup_names,        prods_named,        part_nos_fixed,        invs_inactive,        invs_count,        invs_found,        emr_items_count,        emr_items_linked,        emr_items_matches_their_name,        emr_items_matches_our_name,        emr_items_no_match_their_name,        emr_items_no_match_our_name,        emr_items_dups   from stat_facility;ALTER TABLE types_plus.stat_facility_v1    OWNER TO user_change_structure;-- Create a casting function to convert stat_facility rows into the compound type format stat_facility_v1.-- If stat_facility changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.stat_facility_to_v1 (stat_facility_in stat_facility)  RETURNS stat_facility_v1AS $BODY$        SELECT			stat_facility_in.id,			stat_facility_in.facility_id,			stat_facility_in.hsys_id,			stat_facility_in.date_,			stat_facility_in.category,			stat_facility_in.item_type,			stat_facility_in.stat_type,			stat_facility_in.is_most_recent,			stat_facility_in.in_data_cleanse_scope,			stat_facility_in.items_inactive,			stat_facility_in.items_count,			stat_facility_in.items_qty,			stat_facility_in.items_inventoried,			stat_facility_in.items_to_inventory,			stat_facility_in.items_named,			stat_facility_in.items_to_name,			stat_facility_in.inst_qty,			stat_facility_in.items_has_loc,			stat_facility_in.items_missing_locs,			stat_facility_in.item_prods_count,			stat_facility_in.item_prods_missing_part_nos_thier,			stat_facility_in.item_prods_missing_vendors_thier,			stat_facility_in.item_prods_dr_pref,			stat_facility_in.item_prods_critical,			stat_facility_in.item_prods_not_linked,			stat_facility_in.item_prods_missing_part_nos,			stat_facility_in.item_prods_missing_vendors,			stat_facility_in.item_prods_cant_determine,			stat_facility_in.item_prods_linked,			stat_facility_in.sup_prods_count,			stat_facility_in.sups_count,			stat_facility_in.prods_count,			stat_facility_in.prods_with_pic,			stat_facility_in.prods_without_pic,			stat_facility_in.item_prods_verified,			stat_facility_in.item_prods_expert_linked,			stat_facility_in.item_prods_dup_names_their,			stat_facility_in.item_prods_dup_names,			stat_facility_in.prods_named,			stat_facility_in.part_nos_fixed,			stat_facility_in.invs_inactive,			stat_facility_in.invs_count,			stat_facility_in.invs_found,			stat_facility_in.emr_items_count,			stat_facility_in.emr_items_linked,			stat_facility_in.emr_items_matches_their_name,			stat_facility_in.emr_items_matches_our_name,			stat_facility_in.emr_items_no_match_their_name,			stat_facility_in.emr_items_no_match_our_name,			stat_facility_in.emr_items_dups$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.stat_facility_to_v1 (stat_facility_in stat_facility) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert stat_facility rows into the stat_facility_v1 compound type format using the following syntax:-- select stat_facility::stat_facility_v1 from stat_facilityDROP CAST IF EXISTS (stat_facility as stat_facility_v1);CREATE CAST (stat_facility as stat_facility_v1) WITH FUNCTION types_plus.stat_facility_to_v1(stat_facility);-- Create a function to accept an array of rows formatted as stat_facility_v1 for UPSERT into stat_facility.DROP FUNCTION IF EXISTS types_plus.insert_stat_facility_v1 (types_plus.stat_facility_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_stat_facility_v1 (data_in types_plus.stat_facility_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO stat_facility (			id,			facility_id,			hsys_id,			date_,			category,			item_type,			stat_type,			is_most_recent,			in_data_cleanse_scope,			items_inactive,			items_count,			items_qty,			items_inventoried,			items_to_inventory,			items_named,			items_to_name,			inst_qty,			items_has_loc,			items_missing_locs,			item_prods_count,			item_prods_missing_part_nos_thier,			item_prods_missing_vendors_thier,			item_prods_dr_pref,			item_prods_critical,			item_prods_not_linked,			item_prods_missing_part_nos,			item_prods_missing_vendors,			item_prods_cant_determine,			item_prods_linked,			sup_prods_count,			sups_count,			prods_count,			prods_with_pic,			prods_without_pic,			item_prods_verified,			item_prods_expert_linked,			item_prods_dup_names_their,			item_prods_dup_names,			prods_named,			part_nos_fixed,			invs_inactive,			invs_count,			invs_found,			emr_items_count,			emr_items_linked,			emr_items_matches_their_name,			emr_items_matches_our_name,			emr_items_no_match_their_name,			emr_items_no_match_our_name,			emr_items_dups)        SELECT			rows_in.id,			rows_in.facility_id,			rows_in.hsys_id,			rows_in.date_,			rows_in.category,			rows_in.item_type,			rows_in.stat_type,			rows_in.is_most_recent,			rows_in.in_data_cleanse_scope,			rows_in.items_inactive,			rows_in.items_count,			rows_in.items_qty,			rows_in.items_inventoried,			rows_in.items_to_inventory,			rows_in.items_named,			rows_in.items_to_name,			rows_in.inst_qty,			rows_in.items_has_loc,			rows_in.items_missing_locs,			rows_in.item_prods_count,			rows_in.item_prods_missing_part_nos_thier,			rows_in.item_prods_missing_vendors_thier,			rows_in.item_prods_dr_pref,			rows_in.item_prods_critical,			rows_in.item_prods_not_linked,			rows_in.item_prods_missing_part_nos,			rows_in.item_prods_missing_vendors,			rows_in.item_prods_cant_determine,			rows_in.item_prods_linked,			rows_in.sup_prods_count,			rows_in.sups_count,			rows_in.prods_count,			rows_in.prods_with_pic,			rows_in.prods_without_pic,			rows_in.item_prods_verified,			rows_in.item_prods_expert_linked,			rows_in.item_prods_dup_names_their,			rows_in.item_prods_dup_names,			rows_in.prods_named,			rows_in.part_nos_fixed,			rows_in.invs_inactive,			rows_in.invs_count,			rows_in.invs_found,			rows_in.emr_items_count,			rows_in.emr_items_linked,			rows_in.emr_items_matches_their_name,			rows_in.emr_items_matches_our_name,			rows_in.emr_items_no_match_their_name,			rows_in.emr_items_no_match_our_name,			rows_in.emr_items_dups        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			facility_id = EXCLUDED.facility_id,			hsys_id = EXCLUDED.hsys_id,			date_ = EXCLUDED.date_,			category = EXCLUDED.category,			item_type = EXCLUDED.item_type,			stat_type = EXCLUDED.stat_type,			is_most_recent = EXCLUDED.is_most_recent,			in_data_cleanse_scope = EXCLUDED.in_data_cleanse_scope,			items_inactive = EXCLUDED.items_inactive,			items_count = EXCLUDED.items_count,			items_qty = EXCLUDED.items_qty,			items_inventoried = EXCLUDED.items_inventoried,			items_to_inventory = EXCLUDED.items_to_inventory,			items_named = EXCLUDED.items_named,			items_to_name = EXCLUDED.items_to_name,			inst_qty = EXCLUDED.inst_qty,			items_has_loc = EXCLUDED.items_has_loc,			items_missing_locs = EXCLUDED.items_missing_locs,			item_prods_count = EXCLUDED.item_prods_count,			item_prods_missing_part_nos_thier = EXCLUDED.item_prods_missing_part_nos_thier,			item_prods_missing_vendors_thier = EXCLUDED.item_prods_missing_vendors_thier,			item_prods_dr_pref = EXCLUDED.item_prods_dr_pref,			item_prods_critical = EXCLUDED.item_prods_critical,			item_prods_not_linked = EXCLUDED.item_prods_not_linked,			item_prods_missing_part_nos = EXCLUDED.item_prods_missing_part_nos,			item_prods_missing_vendors = EXCLUDED.item_prods_missing_vendors,			item_prods_cant_determine = EXCLUDED.item_prods_cant_determine,			item_prods_linked = EXCLUDED.item_prods_linked,			sup_prods_count = EXCLUDED.sup_prods_count,			sups_count = EXCLUDED.sups_count,			prods_count = EXCLUDED.prods_count,			prods_with_pic = EXCLUDED.prods_with_pic,			prods_without_pic = EXCLUDED.prods_without_pic,			item_prods_verified = EXCLUDED.item_prods_verified,			item_prods_expert_linked = EXCLUDED.item_prods_expert_linked,			item_prods_dup_names_their = EXCLUDED.item_prods_dup_names_their,			item_prods_dup_names = EXCLUDED.item_prods_dup_names,			prods_named = EXCLUDED.prods_named,			part_nos_fixed = EXCLUDED.part_nos_fixed,			invs_inactive = EXCLUDED.invs_inactive,			invs_count = EXCLUDED.invs_count,			invs_found = EXCLUDED.invs_found,			emr_items_count = EXCLUDED.emr_items_count,			emr_items_linked = EXCLUDED.emr_items_linked,			emr_items_matches_their_name = EXCLUDED.emr_items_matches_their_name,			emr_items_matches_our_name = EXCLUDED.emr_items_matches_our_name,			emr_items_no_match_their_name = EXCLUDED.emr_items_no_match_their_name,			emr_items_no_match_our_name = EXCLUDED.emr_items_no_match_our_name,			emr_items_dups = EXCLUDED.emr_items_dups        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_stat_facility_v1(types_plus.stat_facility_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sterilize_method_v1:sterilize_method_v1_combined.sql-- Create a view onto sterilize_method formatted as sterilize_method_v1.-- If sterilize_method changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sterilize_method_v1.DROP VIEW IF EXISTS types_plus.sterilize_method_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sterilize_method_v1 AS select id,        data_file_id,        marked_for_deletion,        name_   from sterilize_method;ALTER TABLE types_plus.sterilize_method_v1    OWNER TO user_change_structure;-- Create a casting function to convert sterilize_method rows into the compound type format sterilize_method_v1.-- If sterilize_method changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sterilize_method_to_v1 (sterilize_method_in sterilize_method)  RETURNS sterilize_method_v1AS $BODY$        SELECT			sterilize_method_in.id,			sterilize_method_in.data_file_id,			sterilize_method_in.marked_for_deletion,			sterilize_method_in.name_$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.sterilize_method_to_v1 (sterilize_method_in sterilize_method) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sterilize_method rows into the sterilize_method_v1 compound type format using the following syntax:-- select sterilize_method::sterilize_method_v1 from sterilize_methodDROP CAST IF EXISTS (sterilize_method as sterilize_method_v1);CREATE CAST (sterilize_method as sterilize_method_v1) WITH FUNCTION types_plus.sterilize_method_to_v1(sterilize_method);-- Create a function to accept an array of rows formatted as sterilize_method_v1 for UPSERT into sterilize_method.DROP FUNCTION IF EXISTS types_plus.insert_sterilize_method_v1 (types_plus.sterilize_method_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_sterilize_method_v1 (data_in types_plus.sterilize_method_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sterilize_method (			id,			data_file_id,			marked_for_deletion,			name_)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.name_        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_sterilize_method_v1(types_plus.sterilize_method_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sterilize_params_v1:sterilize_params_v1_combined.sql-- Create a view onto sterilize_params formatted as sterilize_params_v1.-- If sterilize_params changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sterilize_params_v1.DROP VIEW IF EXISTS types_plus.sterilize_params_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sterilize_params_v1 AS select id,        data_file_id,        marked_for_deletion,        hsys_id,        sterilize_method_id,        name_   from sterilize_params;ALTER TABLE types_plus.sterilize_params_v1    OWNER TO user_change_structure;-- Create a casting function to convert sterilize_params rows into the compound type format sterilize_params_v1.-- If sterilize_params changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sterilize_params_to_v1 (sterilize_params_in sterilize_params)  RETURNS sterilize_params_v1AS $BODY$        SELECT			sterilize_params_in.id,			sterilize_params_in.data_file_id,			sterilize_params_in.marked_for_deletion,			sterilize_params_in.hsys_id,			sterilize_params_in.sterilize_method_id,			sterilize_params_in.name_$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.sterilize_params_to_v1 (sterilize_params_in sterilize_params) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sterilize_params rows into the sterilize_params_v1 compound type format using the following syntax:-- select sterilize_params::sterilize_params_v1 from sterilize_paramsDROP CAST IF EXISTS (sterilize_params as sterilize_params_v1);CREATE CAST (sterilize_params as sterilize_params_v1) WITH FUNCTION types_plus.sterilize_params_to_v1(sterilize_params);-- Create a function to accept an array of rows formatted as sterilize_params_v1 for UPSERT into sterilize_params.DROP FUNCTION IF EXISTS types_plus.insert_sterilize_params_v1 (types_plus.sterilize_params_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_sterilize_params_v1 (data_in types_plus.sterilize_params_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sterilize_params (			id,			data_file_id,			marked_for_deletion,			hsys_id,			sterilize_method_id,			name_)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.hsys_id,			rows_in.sterilize_method_id,			rows_in.name_        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			hsys_id = EXCLUDED.hsys_id,			sterilize_method_id = EXCLUDED.sterilize_method_id,			name_ = EXCLUDED.name_        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_sterilize_params_v1(types_plus.sterilize_params_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sterilizer_load_v1:sterilizer_load_v1_combined.sql-- Create a view onto sterilizer_load formatted as sterilizer_load_v1.-- If sterilizer_load changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sterilizer_load_v1.DROP VIEW IF EXISTS types_plus.sterilizer_load_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sterilizer_load_v1 AS select id,        data_file_id,        marked_for_deletion,        sterilize_method_id,        sterilizer_id,        sterilize_params_id,        created_dts,        load_no,        status_building_dts,        status_sterilizing_dts,        status_cooling_dts,        status_done_dts,        notes,        failed_notes,        utcoffset_seconds   from sterilizer_load;ALTER TABLE types_plus.sterilizer_load_v1    OWNER TO user_change_structure;-- Create a casting function to convert sterilizer_load rows into the compound type format sterilizer_load_v1.-- If sterilizer_load changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sterilizer_load_to_v1 (sterilizer_load_in sterilizer_load)  RETURNS sterilizer_load_v1AS $BODY$        SELECT			sterilizer_load_in.id,			sterilizer_load_in.data_file_id,			sterilizer_load_in.marked_for_deletion,			sterilizer_load_in.sterilize_method_id,			sterilizer_load_in.sterilizer_id,			sterilizer_load_in.sterilize_params_id,			sterilizer_load_in.created_dts,			sterilizer_load_in.load_no,			sterilizer_load_in.status_building_dts,			sterilizer_load_in.status_sterilizing_dts,			sterilizer_load_in.status_cooling_dts,			sterilizer_load_in.status_done_dts,			sterilizer_load_in.notes,			sterilizer_load_in.failed_notes,			sterilizer_load_in.utcoffset_seconds$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.sterilizer_load_to_v1 (sterilizer_load_in sterilizer_load) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sterilizer_load rows into the sterilizer_load_v1 compound type format using the following syntax:-- select sterilizer_load::sterilizer_load_v1 from sterilizer_loadDROP CAST IF EXISTS (sterilizer_load as sterilizer_load_v1);CREATE CAST (sterilizer_load as sterilizer_load_v1) WITH FUNCTION types_plus.sterilizer_load_to_v1(sterilizer_load);-- Create a function to accept an array of rows formatted as sterilizer_load_v1 for UPSERT into sterilizer_load.DROP FUNCTION IF EXISTS types_plus.insert_sterilizer_load_v1 (types_plus.sterilizer_load_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_sterilizer_load_v1 (data_in types_plus.sterilizer_load_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sterilizer_load (			id,			data_file_id,			marked_for_deletion,			sterilize_method_id,			sterilizer_id,			sterilize_params_id,			created_dts,			load_no,			status_building_dts,			status_sterilizing_dts,			status_cooling_dts,			status_done_dts,			notes,			failed_notes,			utcoffset_seconds)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.sterilize_method_id,			rows_in.sterilizer_id,			rows_in.sterilize_params_id,			rows_in.created_dts,			rows_in.load_no,			rows_in.status_building_dts,			rows_in.status_sterilizing_dts,			rows_in.status_cooling_dts,			rows_in.status_done_dts,			rows_in.notes,			rows_in.failed_notes,			rows_in.utcoffset_seconds        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			sterilize_method_id = EXCLUDED.sterilize_method_id,			sterilizer_id = EXCLUDED.sterilizer_id,			sterilize_params_id = EXCLUDED.sterilize_params_id,			created_dts = EXCLUDED.created_dts,			load_no = EXCLUDED.load_no,			status_building_dts = EXCLUDED.status_building_dts,			status_sterilizing_dts = EXCLUDED.status_sterilizing_dts,			status_cooling_dts = EXCLUDED.status_cooling_dts,			status_done_dts = EXCLUDED.status_done_dts,			notes = EXCLUDED.notes,			failed_notes = EXCLUDED.failed_notes,			utcoffset_seconds = EXCLUDED.utcoffset_seconds        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_sterilizer_load_v1(types_plus.sterilizer_load_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sterilizer_load_v2:sterilizer_load_v2_combined.sql-- Create a view onto sterilizer_load formatted as sterilizer_load_v2.-- If sterilizer_load changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sterilizer_load_v2.DROP VIEW IF EXISTS types_plus.sterilizer_load_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sterilizer_load_v2 AS select id,        data_file_id,        marked_for_deletion,        sterilize_method_id,        sterilizer_id,        sterilize_params_id,        created_dts,        load_no,        status_building_dts,        status_sterilizing_dts,        status_cooling_dts,        status_done_dts,        notes,        failed_notes,        utcoffset_seconds   from sterilizer_load;ALTER TABLE types_plus.sterilizer_load_v2    OWNER TO user_change_structure;-- Create a casting function to convert sterilizer_load rows into the compound type format sterilizer_load_v2.-- If sterilizer_load changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sterilizer_load_to_v2 (sterilizer_load_in sterilizer_load)  RETURNS sterilizer_load_v2AS $BODY$        SELECT			sterilizer_load_in.id,			sterilizer_load_in.data_file_id,			sterilizer_load_in.marked_for_deletion,			sterilizer_load_in.sterilize_method_id,			sterilizer_load_in.sterilizer_id,			sterilizer_load_in.sterilize_params_id,			sterilizer_load_in.created_dts,			sterilizer_load_in.load_no,			sterilizer_load_in.status_building_dts,			sterilizer_load_in.status_sterilizing_dts,			sterilizer_load_in.status_cooling_dts,			sterilizer_load_in.status_done_dts,			sterilizer_load_in.notes,			sterilizer_load_in.failed_notes,			sterilizer_load_in.utcoffset_seconds$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.sterilizer_load_to_v2 (sterilizer_load_in sterilizer_load) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sterilizer_load rows into the sterilizer_load_v2 compound type format using the following syntax:-- select sterilizer_load::sterilizer_load_v2 from sterilizer_loadDROP CAST IF EXISTS (sterilizer_load as sterilizer_load_v2);CREATE CAST (sterilizer_load as sterilizer_load_v2) WITH FUNCTION types_plus.sterilizer_load_to_v2(sterilizer_load);-- Create a function to accept an array of rows formatted as sterilizer_load_v2 for UPSERT into sterilizer_load.DROP FUNCTION IF EXISTS types_plus.insert_sterilizer_load_v2 (types_plus.sterilizer_load_v2[]);CREATE OR REPLACE FUNCTION types_plus.insert_sterilizer_load_v2 (data_in types_plus.sterilizer_load_v2[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sterilizer_load (			id,			data_file_id,			marked_for_deletion,			sterilize_method_id,			sterilizer_id,			sterilize_params_id,			created_dts,			load_no,			status_building_dts,			status_sterilizing_dts,			status_cooling_dts,			status_done_dts,			notes,			failed_notes,			utcoffset_seconds)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.sterilize_method_id,			rows_in.sterilizer_id,			rows_in.sterilize_params_id,			rows_in.created_dts,			rows_in.load_no,			rows_in.status_building_dts,			rows_in.status_sterilizing_dts,			rows_in.status_cooling_dts,			rows_in.status_done_dts,			rows_in.notes,			rows_in.failed_notes,			rows_in.utcoffset_seconds        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			sterilize_method_id = EXCLUDED.sterilize_method_id,			sterilizer_id = EXCLUDED.sterilizer_id,			sterilize_params_id = EXCLUDED.sterilize_params_id,			created_dts = EXCLUDED.created_dts,			load_no = EXCLUDED.load_no,			status_building_dts = EXCLUDED.status_building_dts,			status_sterilizing_dts = EXCLUDED.status_sterilizing_dts,			status_cooling_dts = EXCLUDED.status_cooling_dts,			status_done_dts = EXCLUDED.status_done_dts,			notes = EXCLUDED.notes,			failed_notes = EXCLUDED.failed_notes,			utcoffset_seconds = EXCLUDED.utcoffset_seconds        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_sterilizer_load_v2(types_plus.sterilizer_load_v2[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sterilizer_log_v1:sterilizer_log_v1_combined.sql-- Create a view onto sterilizer_log formatted as sterilizer_log_v1.-- If sterilizer_log changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sterilizer_log_v1.DROP VIEW IF EXISTS types_plus.sterilizer_log_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sterilizer_log_v1 AS select id,        data_file_id,        log_type,        summary_json,        log_xml   from sterilizer_log;ALTER TABLE types_plus.sterilizer_log_v1    OWNER TO user_change_structure;-- Create a casting function to convert sterilizer_log rows into the compound type format sterilizer_log_v1.-- If sterilizer_log changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sterilizer_log_to_v1 (sterilizer_log_in sterilizer_log)  RETURNS sterilizer_log_v1AS $BODY$        SELECT			sterilizer_log_in.id,			sterilizer_log_in.data_file_id,			sterilizer_log_in.log_type,			sterilizer_log_in.summary_json,			sterilizer_log_in.log_xml$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.sterilizer_log_to_v1 (sterilizer_log_in sterilizer_log) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sterilizer_log rows into the sterilizer_log_v1 compound type format using the following syntax:-- select sterilizer_log::sterilizer_log_v1 from sterilizer_logDROP CAST IF EXISTS (sterilizer_log as sterilizer_log_v1);CREATE CAST (sterilizer_log as sterilizer_log_v1) WITH FUNCTION types_plus.sterilizer_log_to_v1(sterilizer_log);-- Create a function to accept an array of rows formatted as sterilizer_log_v1 for UPSERT into sterilizer_log.DROP FUNCTION IF EXISTS types_plus.insert_sterilizer_log_v1 (types_plus.sterilizer_log_v1[]);CREATE OR REPLACE FUNCTION types_plus.insert_sterilizer_log_v1 (data_in types_plus.sterilizer_log_v1[])  RETURNS intAS $BODY$-- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sterilizer_log (			id,			data_file_id,			log_type,			summary_json,			log_xml)        SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.log_type,			rows_in.summary_json,			rows_in.log_xml        FROM unnest(data_in) as rows_in        ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			log_type = EXCLUDED.log_type,			summary_json = EXCLUDED.summary_json,			log_xml = EXCLUDED.log_xml        returning 1 as row_counter)    select sum(row_counter)::integer from inserted_rows;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_sterilizer_log_v1(types_plus.sterilizer_log_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sterilizer_v1:sterilizer_v1_combined.sql-- Create a view onto sterilizer formatted as sterilizer_v1.-- If sterilizer changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sterilizer_v1.DROP VIEW IF EXISTS types_plus.sterilizer_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sterilizer_v1 AS select id,        data_file_id,        marked_for_deletion,        facility_id,        sterilize_method_id,        name_   from sterilizer;ALTER TABLE types_plus.sterilizer_v1    OWNER TO user_change_structure;-- Create a casting function to convert sterilizer rows into the compound type format sterilizer_v1.-- If sterilizer changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sterilizer_to_v1 (sterilizer_in sterilizer)  RETURNS sterilizer_v1AS $BODY$                   SELECT			sterilizer_in.id,			sterilizer_in.data_file_id,			sterilizer_in.marked_for_deletion,			sterilizer_in.facility_id,			sterilizer_in.sterilize_method_id,			sterilizer_in.name_               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.sterilizer_to_v1 (sterilizer_in sterilizer) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sterilizer rows into the sterilizer_v1 compound type format using the following syntax:-- select sterilizer::sterilizer_v1 from sterilizerDROP CAST IF EXISTS (sterilizer as sterilizer_v1);CREATE CAST (sterilizer as sterilizer_v1) WITH FUNCTION types_plus.sterilizer_to_v1(sterilizer);-- Create a function to accept an array of rows formatted as sterilizer_v1 for UPSERT into sterilizer.DROP FUNCTION IF EXISTS types_plus.insert_sterilizer_v1 (types_plus.sterilizer_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_sterilizer_v1 (data_in types_plus.sterilizer_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sterilizer (			id,			data_file_id,			marked_for_deletion,			facility_id,			sterilize_method_id,			name_)                  SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.facility_id,			rows_in.sterilize_method_id,			rows_in.name_                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			facility_id = EXCLUDED.facility_id,			sterilize_method_id = EXCLUDED.sterilize_method_id,			name_ = EXCLUDED.name_          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_sterilizer_v1(types_plus.sterilizer_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sup_parent_v1:sup_parent_v1_combined.sql-- Create a view onto sup_parent formatted as sup_parent_v1.-- If sup_parent changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sup_parent_v1.DROP VIEW IF EXISTS types_plus.sup_parent_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sup_parent_v1 AS select id,        created_dts,        updated_dts,        marked_for_deletion,        name_,        created_by,        updated_by   from sup_parent;ALTER TABLE types_plus.sup_parent_v1    OWNER TO user_change_structure;-- Create a casting function to convert sup_parent rows into the compound type format sup_parent_v1.-- If sup_parent changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sup_parent_to_v1 (sup_parent_in sup_parent)  RETURNS sup_parent_v1AS $BODY$                   SELECT			sup_parent_in.id,			sup_parent_in.created_dts,			sup_parent_in.updated_dts,			sup_parent_in.marked_for_deletion,			sup_parent_in.name_,			sup_parent_in.created_by,			sup_parent_in.updated_by               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.sup_parent_to_v1 (sup_parent_in sup_parent)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sup_parent rows into the sup_parent_v1 compound type format using the following syntax:-- select sup_parent::sup_parent_v1 from sup_parentDROP CAST IF EXISTS (sup_parent as sup_parent_v1);CREATE CAST (sup_parent as sup_parent_v1) WITH FUNCTION types_plus.sup_parent_to_v1(sup_parent);-- Create a function to accept an array of rows formatted as sup_parent_v1 for UPSERT into sup_parent.DROP FUNCTION IF EXISTS types_plus.insert_sup_parent_v1 (types_plus.sup_parent_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_sup_parent_v1 (data_in types_plus.sup_parent_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sup_parent (			id,			created_dts,			updated_dts,			marked_for_deletion,			name_,			created_by,			updated_by)                  SELECT			rows_in.id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.marked_for_deletion,			rows_in.name_,			rows_in.created_by,			rows_in.updated_by                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_ = EXCLUDED.name_,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_sup_parent_v1(types_plus.sup_parent_v1[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:sup_v2:sup_v2_combined.sql-- Create a view onto sup formatted as sup_v2.-- If sup changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_sup_v2.DROP VIEW IF EXISTS types_plus.sup_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.sup_v2 AS select id,        custom_facility_id,        sup_parent_id,        created_dts,        updated_dts,        is_custom_by_facility,        marked_for_deletion,        is_available_for_loaners,        name_,        created_by,        updated_by,        short_name   from sup;ALTER TABLE types_plus.sup_v2    OWNER TO user_change_structure;-- Create a casting function to convert sup rows into the compound type format sup_v2.-- If sup changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.sup_to_v2 (sup_in sup)  RETURNS sup_v2AS $BODY$                   SELECT			sup_in.id,			sup_in.custom_facility_id,			sup_in.sup_parent_id,			sup_in.created_dts,			sup_in.updated_dts,			sup_in.is_custom_by_facility,			sup_in.marked_for_deletion,			sup_in.is_available_for_loaners,			sup_in.name_,			sup_in.created_by,			sup_in.updated_by,			sup_in.short_name               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.sup_to_v2 (sup_in sup)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert sup rows into the sup_v2 compound type format using the following syntax:-- select sup::sup_v2 from supDROP CAST IF EXISTS (sup as sup_v2);CREATE CAST (sup as sup_v2) WITH FUNCTION types_plus.sup_to_v2(sup);-- Create a function to accept an array of rows formatted as sup_v2 for UPSERT into sup.DROP FUNCTION IF EXISTS types_plus.insert_sup_v2 (types_plus.sup_v2[]);  CREATE OR REPLACE FUNCTION types_plus.insert_sup_v2 (data_in types_plus.sup_v2[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO sup (			id,			custom_facility_id,			sup_parent_id,			created_dts,			updated_dts,			is_custom_by_facility,			marked_for_deletion,			is_available_for_loaners,			name_,			created_by,			updated_by,			short_name)                  SELECT			rows_in.id,			rows_in.custom_facility_id,			rows_in.sup_parent_id,			rows_in.created_dts,			rows_in.updated_dts,			rows_in.is_custom_by_facility,			rows_in.marked_for_deletion,			rows_in.is_available_for_loaners,			rows_in.name_,			rows_in.created_by,			rows_in.updated_by,			rows_in.short_name                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			custom_facility_id = EXCLUDED.custom_facility_id,			sup_parent_id = EXCLUDED.sup_parent_id,			created_dts = EXCLUDED.created_dts,			updated_dts = EXCLUDED.updated_dts,			is_custom_by_facility = EXCLUDED.is_custom_by_facility,			marked_for_deletion = EXCLUDED.marked_for_deletion,			is_available_for_loaners = EXCLUDED.is_available_for_loaners,			name_ = EXCLUDED.name_,			created_by = EXCLUDED.created_by,			updated_by = EXCLUDED.updated_by,			short_name = EXCLUDED.short_name          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_sup_v2(types_plus.sup_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:text_collection_v1:text_collection_v1_combined.sql-- Create a function to accept an array of rows formatted as text_collection_v1 for UPSERT into text_collection.DROP FUNCTION IF EXISTS types_plus.insert_text_collection_v1 (text[], boolean, uuid, citext);DROP FUNCTION IF EXISTS types_plus.insert_text_collection_v1 (text_id[], boolean, uuid, citext);CREATE OR REPLACE FUNCTION types_plus.insert_text_collection_v1 (    data_in                text_text[],    mark_for_retention_in  boolean  DEFAULT false,    facility_id_in         uuid     DEFAULT '00000000-0000-0000-0000-000000000000'::uuid,    collection_name_in     citext   DEFAULT '')RETURNS uuidAS $BODY$-- First, add the new collection and get back its ID for use in the rest of the script.WITH new_collection AS (  INSERT INTO text_collection (              retain,              facility_id,              collection_name)    VALUES (mark_for_retention_in,            facility_id_in,            collection_name_in)-- Note: ON CONFLICT on a partial index requires the WHERE clause to be repeated here in ON CONFLICT.ON CONFLICT (collection_name) WHERE collection_name <> '' DO UPDATE SET            retain      = EXCLUDED.retain,            facility_id = EXCLUDED.facility_idRETURNING id)-- Now, unpack the incoming array of strings, and insert each one into-- text_collectoin_item, along with the ID of the text_collection just created.INSERT INTO text_collection_item (   	   collection_id,       text,       source_id)SELECT DISTINCT ON (rows_in.text)      new_collection.id,      rows_in.text,      rows_in.id FROM new_collection,      unnest(data_in) as rows_in -- Silently remove duplicate strings from the list. ON CONFLICT (collection_id, text) DO UPDATE SET      source_id = EXCLUDED.source_id-- Everything is done, return the new collection's ID to the client. -- RETURNING is a *very* cool Postgres extension to standard SQL. -- Earlier, we used it to get the new ID out of the CTE for reuse -- by the main query. Now, we're returning that ID to the client -- for whatever purpose they have.RETURNING collection_id;$BODY$LANGUAGE sql;ALTER FUNCTION types_plus.insert_text_collection_v1(text_text[], boolean, uuid, citext)	OWNER TO user_bender;-- Create a view onto text_collection formatted as text_collection_v1.-- If text_collection changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_text_collection_v1.DROP VIEW IF EXISTS types_plus.text_collection_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.text_collection_v1 AS select id,        collection_name,        added_dts,        retain,        facility_id   from text_collection;ALTER TABLE types_plus.text_collection_v1    OWNER TO user_change_structure;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:web_user_v1:web_user_v1_combined.sql-- Create a view onto web_user formatted as web_user_v1.-- If web_user changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_web_user_v1.DROP VIEW IF EXISTS types_plus.web_user_v1 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.web_user_v1 AS select id,        data_file_id,        marked_for_deletion,        hsys_id,        username,        role_,        name_first,        name_last,        name_full   from web_user;ALTER TABLE types_plus.web_user_v1    OWNER TO user_change_structure;-- Create a casting function to convert web_user rows into the compound type format web_user_v1.-- If web_user changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.web_user_to_v1 (web_user_in web_user)  RETURNS web_user_v1AS $BODY$                   SELECT			web_user_in.id,			web_user_in.data_file_id,			web_user_in.marked_for_deletion,			web_user_in.hsys_id,			web_user_in.username,			web_user_in.role_,			web_user_in.name_first,			web_user_in.name_last,			web_user_in.name_full               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.web_user_to_v1 (web_user_in web_user) OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert web_user rows into the web_user_v1 compound type format using the following syntax:-- select web_user::web_user_v1 from web_userDROP CAST IF EXISTS (web_user as web_user_v1);CREATE CAST (web_user as web_user_v1) WITH FUNCTION types_plus.web_user_to_v1(web_user);-- Create a function to accept an array of rows formatted as web_user_v1 for UPSERT into web_user.DROP FUNCTION IF EXISTS types_plus.insert_web_user_v1 (types_plus.web_user_v1[]);  CREATE OR REPLACE FUNCTION types_plus.insert_web_user_v1 (data_in types_plus.web_user_v1[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO web_user (			id,			data_file_id,			marked_for_deletion,			hsys_id,			username,			role_,			name_first,			name_last,			name_full)                  SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.marked_for_deletion,			rows_in.hsys_id,			rows_in.username,			rows_in.role_,			rows_in.name_first,			rows_in.name_last,			rows_in.name_full                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			marked_for_deletion = EXCLUDED.marked_for_deletion,			hsys_id = EXCLUDED.hsys_id,			username = EXCLUDED.username,			role_ = EXCLUDED.role_,			name_first = EXCLUDED.name_first,			name_last = EXCLUDED.name_last,			name_full = EXCLUDED.name_full          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_web_user_v1(types_plus.web_user_v1[]) OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:types_plus:web_user_v2:web_user_v2_combined.sql-- Create a view onto web_user formatted as web_user_v2.-- If web_user changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_web_user_v2.DROP VIEW IF EXISTS types_plus.web_user_v2 CASCADE;-- Careful!CREATE OR REPLACE VIEW types_plus.web_user_v2 AS select id,        data_file_id,        hsys_id,        is_sonar_ascendco_support,        marked_for_deletion,        name_first,        role_,        username,        name_full,        name_last   from web_user;ALTER TABLE types_plus.web_user_v2    OWNER TO user_change_structure;-- Create a casting function to convert web_user rows into the compound type format web_user_v2.-- If web_user changes, you can update the casting to handle the modification smoothly.CREATE OR REPLACE FUNCTION types_plus.web_user_to_v2 (web_user_in web_user)  RETURNS web_user_v2AS $BODY$                   SELECT			web_user_in.id,			web_user_in.data_file_id,			web_user_in.hsys_id,			web_user_in.is_sonar_ascendco_support,			web_user_in.marked_for_deletion,			web_user_in.name_first,			web_user_in.role_,			web_user_in.username,			web_user_in.name_full,			web_user_in.name_last               $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.web_user_to_v2 (web_user_in web_user)	OWNER TO user_bender;-- Create/recreate the CAST. Use this to convert web_user rows into the web_user_v2 compound type format using the following syntax:-- select web_user::web_user_v2 from web_userDROP CAST IF EXISTS (web_user as web_user_v2);CREATE CAST (web_user as web_user_v2) WITH FUNCTION types_plus.web_user_to_v2(web_user);-- Create a function to accept an array of rows formatted as web_user_v2 for UPSERT into web_user.DROP FUNCTION IF EXISTS types_plus.insert_web_user_v2 (types_plus.web_user_v2[]);  CREATE OR REPLACE FUNCTION types_plus.insert_web_user_v2 (data_in types_plus.web_user_v2[])  RETURNS intAS $BODY$ -- The CTE below is a roundabout way of returning an insertion count from a pure SQL function in Postgres.with inserted_rows as (        INSERT INTO web_user (			id,			data_file_id,			hsys_id,			is_sonar_ascendco_support,			marked_for_deletion,			name_first,			role_,			username,			name_full,			name_last)                  SELECT			rows_in.id,			rows_in.data_file_id,			rows_in.hsys_id,			rows_in.is_sonar_ascendco_support,			rows_in.marked_for_deletion,			rows_in.name_first,			rows_in.role_,			rows_in.username,			rows_in.name_full,			rows_in.name_last                      FROM unnest(data_in) as rows_in                  ON CONFLICT(id) DO UPDATE SET			data_file_id = EXCLUDED.data_file_id,			hsys_id = EXCLUDED.hsys_id,			is_sonar_ascendco_support = EXCLUDED.is_sonar_ascendco_support,			marked_for_deletion = EXCLUDED.marked_for_deletion,			name_first = EXCLUDED.name_first,			role_ = EXCLUDED.role_,			username = EXCLUDED.username,			name_full = EXCLUDED.name_full,			name_last = EXCLUDED.name_last          returning 1 as row_counter)         select sum(row_counter)::integer from inserted_rows; $BODY$LANGUAGE sql;  ALTER FUNCTION types_plus.insert_web_user_v2(types_plus.web_user_v2[])	OWNER TO user_bender;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:musc_orscansinout_v1:musc_orscansinout_v1_view.sql-- This view is selected in the 'musc_orscansinout' master UNION view, and is not pulled by Domo directly.-- View: passthrough.musc_orscansinout_v1DROP VIEW IF EXISTS passthrough.musc_orscansinout_v1;CREATE OR REPLACE VIEW passthrough.musc_orscansinout_v1 AS     SELECT            coalesce(hsys.name_,'') AS "HsysName",            coalesce(facility.name_,'') AS "FacilityName",            expanded_data."Category" AS "Category",            expanded_data."ClinicDeptName" AS "ClinicDeptName",            expanded_data."Event" AS "Event",            expanded_data."InvName" AS "InvName",            expanded_data."ItemName" AS "ItemName",            expanded_data."ItemType" AS "ItemType",            expanded_data."locationDesc" AS "locationDesc",            expanded_data."NumInst" AS "NumInst",            expanded_data."Scan_Date" AS "Scan_Date",            expanded_data."Scan_DayName" AS "Scan_DayName",            expanded_data."Scan_DayOfWeek" AS "Scan_DayOfWeek",            expanded_data."Scan_HourBin" AS "Scan_HourBin",            expanded_data."Scan_HourOfDay" AS "Scan_HourOfDay",            expanded_data."Scan_Local" AS "Scan_Local",            expanded_data."ScanDTS" AS "ScanDTS",            expanded_data."scanID" AS "scanID",            expanded_data."scannedAt" AS "scannedAt",            expanded_data."scannedBy" AS "scannedBy",            expanded_data."scannedDesc" AS "scannedDesc",            expanded_data."scannedDTS" AS "scannedDTS",            expanded_data."scannedType" AS "scannedType",            expanded_data."Specialty" AS "Specialty",            expanded_data."state" AS "state",            expanded_data."substate" AS "substate",            expanded_data."timezone" AS "timezone"                FROM domo_passthrough  LEFT JOIN facility on (domo_passthrough.facility_id = facility.id)  LEFT JOIN hsys     on (domo_passthrough.hsys_id = hsys.id)CROSS JOIN jsonb_to_recordset(domo_passthrough.data) AS expanded_data (            "Category" citext,            "ClinicDeptName" citext,            "Event" citext,            "InvName" citext,            "ItemName" citext,            "ItemType" citext,            "locationDesc" citext,            "NumInst" int4,            "Scan_Date" date,            "Scan_DayName" citext,            "Scan_DayOfWeek" int4,            "Scan_HourBin" int4,            "Scan_HourOfDay" int4,            "Scan_Local" timestamp,            "ScanDTS" timestamp,            "scanID" uuid,            "scannedAt" timestamp,            "scannedBy" citext,            "scannedDesc" citext,            "scannedDTS" timestamp,            "scannedType" citext,            "Specialty" citext,            "state" citext,            "substate" citext,            "timezone" citext)           WHERE dataset_name = 'MUSC_OrScansInOut_PG' AND          view_version = 1; -- Important! The view knows how to parse out JSONB data packed in this way.ALTER TABLE passthrough.musc_orscansinout_v1    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('passthrough','musc_orscansinout_v1','Pulled into ''musc_orscansinout'' master (UNION) view, not pulled directly. ','MUSC_OrScansInOut_PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:musc_orscansinoutraw_v1:musc_orscansinoutraw_v1_view.sql-- This view is selected in the 'musc_orscansinoutraw' master UNION view, and is not pulled by Domo directly.-- View: passthrough.musc_orscansinoutraw_v1DROP VIEW IF EXISTS passthrough.musc_orscansinoutraw_v1;CREATE OR REPLACE VIEW passthrough.musc_orscansinoutraw_v1 AS     SELECT            coalesce(hsys.name_,'') AS "HsysName",            coalesce(facility.name_,'') AS "FacilityName",            expanded_data."Category" AS "Category",            expanded_data."ClinicDeptName" AS "ClinicDeptName",            expanded_data."Event" AS "Event",            expanded_data."Event2" AS "Event2",            expanded_data."InvName" AS "InvName",            expanded_data."ItemName" AS "ItemName",            expanded_data."ItemType" AS "ItemType",            expanded_data."locationDesc" AS "locationDesc",            expanded_data."NumInst" AS "NumInst",            expanded_data."Scan_Date" AS "Scan_Date",            expanded_data."Scan_DayName" AS "Scan_DayName",            expanded_data."Scan_DayOfWeek" AS "Scan_DayOfWeek",            expanded_data."Scan_HourBin" AS "Scan_HourBin",            expanded_data."Scan_HourOfDay" AS "Scan_HourOfDay",            expanded_data."Scan_Local" AS "Scan_Local",            expanded_data."ScanDTS" AS "ScanDTS",            expanded_data."scanID" AS "scanID",            expanded_data."scannedAt" AS "scannedAt",            expanded_data."scannedBy" AS "scannedBy",            expanded_data."scannedDesc" AS "scannedDesc",            expanded_data."scannedDTS" AS "scannedDTS",            expanded_data."scannedRecordID" AS "scannedRecordID",            expanded_data."scannedType" AS "scannedType",            expanded_data."SpecialityID" AS "SpecialityID",            expanded_data."Specialty" AS "Specialty",            expanded_data."state" AS "state",            expanded_data."substate" AS "substate",            expanded_data."timezone" AS "timezone"                FROM domo_passthrough  LEFT JOIN facility on (domo_passthrough.facility_id = facility.id)  LEFT JOIN hsys     on (domo_passthrough.hsys_id = hsys.id)CROSS JOIN jsonb_to_recordset(domo_passthrough.data) AS expanded_data (            "Category" citext,            "ClinicDeptName" citext,            "Event" citext,            "Event2" citext,            "InvName" citext,            "ItemName" citext,            "ItemType" citext,            "locationDesc" citext,            "NumInst" int4,            "Scan_Date" date,            "Scan_DayName" citext,            "Scan_DayOfWeek" int4,            "Scan_HourBin" int4,            "Scan_HourOfDay" int4,            "Scan_Local" citext,            "ScanDTS" timestamp,            "scanID" uuid,            "scannedAt" citext,            "scannedBy" citext,            "scannedDesc" citext,            "scannedDTS" timestamp,            "scannedRecordID" uuid,            "scannedType" citext,            "SpecialityID" uuid,            "Specialty" citext,            "state" citext,            "substate" citext,            "timezone" citext)           WHERE dataset_name = 'MUSC_OrScansInOutRaw_PG' AND          view_version = 1; -- Important! The view knows how to parse out JSONB data packed in this way.ALTER TABLE passthrough.musc_orscansinoutraw_v1    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('passthrough','musc_orscansinoutraw_v1','Pulled into ''musc_orscansinoutraw'' master (UNION) view, not pulled directly. ','MUSC_OrScansInOutRaw_PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:sonar_backlog_v3:sonar_backlog_v3_view.sql-- This view is selected in the 'sonar_backlog' master UNION view, and is not pulled by Domo directly.-- View: passthrough.sonar_backlog_v3DROP VIEW IF EXISTS passthrough.sonar_backlog_v3;CREATE OR REPLACE VIEW passthrough.sonar_backlog_v3 AS     SELECT            coalesce(hsys.name_,'') AS "HsysName",            coalesce(facility.name_,'') AS "FacilityName",            expanded_data."BacklogDTS" AS "BacklogDTS",            expanded_data."OverallBacklog" AS "OverallBacklog",            expanded_data."CleanBacklog" AS "CleanBacklog",            expanded_data."DirtyInstBacklog" AS "DirtyInstBacklog",            expanded_data."Backlog_FiscalWeekNo" AS "Backlog_FiscalWeekNo",            expanded_data."Backlog_HourBin" AS "Backlog_HourBin",            expanded_data."Backlog_DayOfWeek" AS "Backlog_DayOfWeek",            expanded_data."Backlog_MonthNo" AS "Backlog_MonthNo",            expanded_data."OverallInstBacklog" AS "OverallInstBacklog",            expanded_data."Backlog_HourOfDay" AS "Backlog_HourOfDay",            expanded_data."DirtyBacklog" AS "DirtyBacklog",            expanded_data."Backlog_YearNo" AS "Backlog_YearNo",            expanded_data."CleanInstBacklog" AS "CleanInstBacklog",            expanded_data."Backlog_Date" AS "Backlog_Date",            expanded_data."Backlog_Year" AS "Backlog_Year",            expanded_data."DateTime" AS "DateTime",            expanded_data."Backlog_Local" AS "Backlog_Local",            expanded_data."Backlog_FiscalWeek" AS "Backlog_FiscalWeek",            expanded_data."DateHour" AS "DateHour",            expanded_data."Backlog_DayName" AS "Backlog_DayName",            expanded_data."Backlog_Month" AS "Backlog_Month"       FROM domo_passthrough  LEFT JOIN facility on (domo_passthrough.facility_id = facility.id)  LEFT JOIN hsys     on (domo_passthrough.hsys_id = hsys.id)CROSS JOIN jsonb_to_recordset(domo_passthrough.data) AS expanded_data (            "BacklogDTS" timestamp,            "OverallBacklog" int4,            "CleanBacklog" int4,            "DirtyInstBacklog" int4,            "Backlog_FiscalWeekNo" int4,            "Backlog_HourBin" int4,            "Backlog_DayOfWeek" int4,            "Backlog_MonthNo" int4,            "OverallInstBacklog" int4,            "Backlog_HourOfDay" int4,            "DirtyBacklog" int4,            "Backlog_YearNo" int4,            "CleanInstBacklog" int4,            "Backlog_Date" date,            "Backlog_Year" citext,            "DateTime" citext,            "Backlog_Local" citext,            "Backlog_FiscalWeek" citext,            "DateHour" citext,            "Backlog_DayName" citext,            "Backlog_Month" citext)    WHERE dataset_name IN ('Sonar_Backlog', 'Sonar_BackLog_PG') -- Case-sensitive!      AND view_version = 3; -- Important! The view knows how to parse out JSONB data packed in this way.ALTER TABLE passthrough.sonar_backlog_v3    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('passthrough','sonar_backlog_v3','Pulled into ''sonar_backlog'' master (UNION) view, not pulled directly. ','Sonar_BackLog_PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:trays_per_hour_pg_v1:trays_per_hour_pg_v1_view.sql-- This view is selected in the 'trays_per_hour_pg' master UNION view, and is not pulled by Domo directly.-- View: passthrough.trays_per_hour_pg_v1DROP VIEW IF EXISTS passthrough.trays_per_hour_pg_v1 CASCADE;CREATE OR REPLACE VIEW passthrough.trays_per_hour_pg_v1 AS     SELECT            coalesce(hsys.name_,'') AS "HsysName",            coalesce(facility.name_,'') AS "FacilityName",            expanded_data."Assemble_DayName" AS "Assemble_DayName",            expanded_data."UserName" AS "UserName",            expanded_data."Assemble_Date" AS "Assemble_Date",            expanded_data."HoursAssembly" AS "HoursAssembly",            expanded_data."InstPerHour" AS "InstPerHour",            expanded_data."TraysPerHour" AS "TraysPerHour",            expanded_data."TraysAssembled" AS "TraysAssembled",            expanded_data."Assemble_DayOfWeek" AS "Assemble_DayOfWeek",            expanded_data."InstAssembled" AS "InstAssembled"       FROM domo_passthrough  LEFT JOIN facility on (domo_passthrough.facility_id = facility.id)  LEFT JOIN hsys     on (domo_passthrough.hsys_id = hsys.id)CROSS JOIN jsonb_to_recordset(domo_passthrough.data) AS expanded_data (            "Assemble_DayName" citext,            "UserName" citext,            "Assemble_Date" date,            "HoursAssembly" float8,            "InstPerHour" float8,            "TraysPerHour" float8,            "TraysAssembled" int4,            "Assemble_DayOfWeek" int4,            "InstAssembled" int4)    WHERE dataset_name IN ('TraysPerHour_PG', 'TraysPerHour')      AND view_version = 1; -- Important! The view knows how to parse out JSONB data packed in this way.ALTER TABLE passthrough.trays_per_hour_pg_v1    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('passthrough','trays_per_hour_pg_v1','Pulled into ''trays_per_hour_pg'' master (UNION) view, not pulled directly. ','TraysPerHour_PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:master_views:musc_orscansinoutraw.sql/*This view UNIONs all versions of the passthrough format for this DataSet.Comment out or remove any obsolete versions.Update earlier versions, as needed, to produce the same column names as the latest version.*/-- View: passthrough.musc_orscansinoutrawDROP VIEW IF EXISTS passthrough.musc_orscansinoutraw;CREATE OR REPLACE VIEW passthrough.musc_orscansinoutraw ASSELECT *,"Scan_Local" as "DateTime_Local" FROM musc_orscansinoutraw_v1;ALTER TABLE passthrough.musc_orscansinoutraw    OWNER TO user_change_structure;-----------------------------------------------Register view---------------------------------------------CALL view_register ('passthrough','musc_orscansinoutraw','Master (UNION) view for this DataSet.','MUSC_OrScansInOutRaw_PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:master_views:trays_per_hour.sql/*This view UNIONs all versions of the passthrough format for this DataSet.Comment out or remove any obsolete versions.Update earlier versions, as needed, to produce the same column names as the latest version.*/-- View: passthrough.trays_per_hour_pgCREATE OR REPLACE VIEW passthrough.trays_per_hour ASSELECT * FROM trays_per_hour_pg_v1;ALTER TABLE passthrough.trays_per_hour    OWNER TO user_change_structure;-----------------------------------------------Register view---------------------------------------------CALL view_register ('passthrough','trays_per_hour','Master (UNION) view for this DataSet.','TraysPerHour_PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:master_views:musc_orscansinout.sql/*This view UNIONs all versions of the passthrough format for this DataSet.Comment out or remove any obsolete versions.Update earlier versions, as needed, to produce the same column names as the latest version.*/-- View: passthrough.musc_orscansinoutDROP VIEW IF EXISTS passthrough.musc_orscansinout;CREATE OR REPLACE VIEW passthrough.musc_orscansinout ASSELECT *,"Scan_Local" as "DateTime_Local" FROM musc_orscansinout_v1;ALTER TABLE passthrough.musc_orscansinout    OWNER TO user_change_structure;-----------------------------------------------Register view---------------------------------------------CALL view_register ('passthrough','musc_orscansinout','Master (UNION) view for this DataSet.','MUSC_OrScansInOut_PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:passthrough:master_views:sonar_backlog.sql/*This view UNIONs all versions of the passthrough format for this DataSet.Comment out or remove any obsolete versions.Update earlier versions, as needed, to produce the same column names as the latest version.*/-- View: passthrough.sonar_backlogDROP VIEW IF EXISTS passthrough.sonar_backlog;CREATE OR REPLACE VIEW passthrough.sonar_backlog ASSELECT *,"Backlog_Local" as "DateTime_Local" FROM sonar_backlog_v3;ALTER TABLE passthrough.sonar_backlog    OWNER TO user_change_structure;-----------------------------------------------Register view---------------------------------------------CALL view_register ('passthrough','sonar_backlog','Master (UNION) view for this DataSet.','Sonar_BackLog_PG');------------------------------------------- Views-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:calendar_day_plus.sqlCREATE OR REPLACE VIEW api.calendar_day_plus AS   select calendar.calendar_name,          calendar.week_starts_on,          calendar_year.fiscal_year_name,          calendar_year.fiscal_year_abbr,		  to_number(calendar_year.fiscal_year_abbr, 'fm0000') as fiscal_year_number, -- Will give weird results for things like 2019-2020, or 19/20          calendar_year.days_in_year,          calendar_year.weeks_in_year,          calendar_year.first_day_of_week_usa,          calendar_year.first_day_of_week_iso,          calendar_year.first_day_of_week_name,          calendar_year.week_start_offset,          calendar_day.*     from calendar_dayleft join calendar      ON calendar.id      = calendar_day.calendar_idleft join calendar_year ON calendar_year.id = calendar_day.calendar_year_id;ALTER VIEW api.calendar_day_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','calendar_day_plus','Calender date data, with the parent calendar name displayed.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_scan_domo.sqlDROP VIEW IF EXISTS api.analytic_scan_domo;CREATE VIEW api.analytic_scan_domo ASWITH expanded_data AS (         SELECT            analytic_scan.scanned_type                  AS "ScannedType",            analytic_scan.associated_to                 AS "AssociatedTo",            analytic_scan.user_name                     AS "UserName",            analytic_scan.inv_name                      AS "InvName",            analytic_scan.location_description          AS "LocationDesc",            GREATEST(1, analytic_scan.num_inst)         AS "NumInst",            analytic_scan.tray_or_pack                  AS "TrayOrPack",            analytic_scan.scan_time_utc_dts             AS "ScanTime_UTC",            analytic_scan.item_name                     AS "ItemName",            analytic_scan.scan_time_local_dts           AS "ScanTime_Local",			analytic_scan.scan_time_local_dts           AS "DateTime_Local", -- 13-10-20: Consistent name for filters.            COALESCE(hsys.name_, ''::citext)            AS "HsysName",            COALESCE(facility.name_, ''::citext)        AS "FacilityName",            COALESCE(specialty.name_, ''::citext)       AS "Specialty",            scan_date.date_actual                       AS "ScanTime_Date",            scan_date.day_of_week_usa                   AS "ScanTime_DayOfWeek",            scan_date.day_name_abbreviated              AS "ScanTime_DayName",            scan_date.week_of_year_fiscal_name          AS "ScanTime_FiscalWeek",   --  Week 24 2020            scan_date.week_of_year_fiscal               AS "ScanTime_FiscalWeekNo", --  2020-24            scan_date.month_actual                      AS "ScanTime_MonthNo",            scan_date.month_actual_name_abbreviated     AS "ScanTime_MonthName",            scan_date.month_fiscal                      AS "ScanTime_FiscalMonthNo",            scan_date.month_fiscal_name_abbreviated     AS "ScanTime_FiscalMonthName",            to_char(scan_date.year_actual, 'fm0000')    AS "ScanTime_Year",            scan_date.year_actual                       AS "ScanTime_YearNo",            scan_date.fiscal_year_abbr                  AS "ScanTime_FiscalYear",            scan_date.fiscal_year_abbr::int             AS "ScanTime_FiscalYearNo",            (date_part('hour'::text, analytic_scan.scan_time_local_dts))::integer                         AS "ScanTime_HourOfDay",            hour_bin_get_bin((date_part('hour'::text, analytic_scan.scan_time_local_dts))::integer)       AS "ScanTime_HourBin",            hour_bin_get_bin_label((date_part('hour'::text, analytic_scan.scan_time_local_dts))::integer) AS "ScanTime_HourBinName"           FROM analytic_scan           LEFT JOIN facility       ON analytic_scan.facility_id  = facility.id           LEFT JOIN hsys           ON facility.hsys_id           = hsys.id           LEFT JOIN specialty      ON analytic_scan.specialty_id = specialty.id           LEFT JOIN data_file_info ON analytic_scan.data_file_id = data_file_info.id       -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.          JOIN calendar_day_plus scan_date                   ON (scan_date.calendar_id = facility.calendar_id                 AND scan_date.date_actual = date(analytic_scan.scan_time_local_dts))         WHERE analytic_scan.marked_for_deletion = false) SELECT expanded_data."ScannedType",        expanded_data."AssociatedTo",        expanded_data."UserName",        expanded_data."InvName",        expanded_data."LocationDesc",        expanded_data."NumInst",        expanded_data."TrayOrPack",        expanded_data."ItemName",        expanded_data."ScanTime_UTC",        expanded_data."ScanTime_Local",        expanded_data."DateTime_Local", -- 13-10-20: Consistent name for filters.        expanded_data."HsysName",        expanded_data."FacilityName",        expanded_data."Specialty",        expanded_data."ScanTime_Date",        expanded_data."ScanTime_DayOfWeek",        expanded_data."ScanTime_DayName",        expanded_data."ScanTime_FiscalWeek",        expanded_data."ScanTime_FiscalWeekNo",        expanded_data."ScanTime_HourOfDay",        expanded_data."ScanTime_HourBin",        expanded_data."ScanTime_HourBinName",        ntile(100) OVER (ORDER BY expanded_data."NumInst") AS "NumInstPercentile"   FROM expanded_data;ALTER VIEW api.analytic_scan_domo	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_scan_domo','Analytic data, dervied largely from [Scan].','PROD Analytic Scan PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:push_log_plus.sqlCREATE OR REPLACE VIEW api.push_log_plus AS SELECT 	push_log.id,	push_log.data_file_id,	data_file_info.server_name_,	push_log.ib_table_name,	push_log.ib_table_number,	push_log.records_count,	push_log.push_dts,	age(now(), push_log.push_dts) AS age,	minutes_old(push_log.push_dts) AS minutes_old,	/* Lookup fields */	data_file_info.app_name,	data_file_info.app_version,	data_file_info.shell_version,	data_file_info.sync_version,	data_file_info.iam_type,	data_file_info.compiled,	data_file_info.merged,	data_file_info.type_of_4d,	data_file_info.version_of_4d,	data_file_info.machine_name,	data_file_info.platform_description,	data_file_info.os_tz_name	FROM (ascendco.push_log	LEFT JOIN data_file_info ON ((data_file_info.id = push_log.data_file_id)))   ;ALTER VIEW api.push_log_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','push_log_plus','Push_log data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:activity_domo.sqlDROP VIEW IF EXISTS api.activity_domo;-- Query addapted from Will on Feb 11, 2021.CREATE VIEW api.activity_domo ASSELECT     activity.id                                                                     AS "id",     COALESCE (facility.name_, ''::citext)                                           AS "FacilityName",     COALESCE (hsys.name_, ''::citext)                                               AS "HsysName",     COALESCE (web_user.username, ''::citext)                                        AS "UserName",     COALESCE (facility_activities.name_, ''::citext)                                AS "ActivityName",     activity.facility_activities_id                                                 AS "ActivitiesID",     activity.other_desc                                                             AS "OtherActivityName",     activity.start_dts                                                              AS "StartTime_DTS",     activity.start_dts AT TIME ZONE facility.tz_name_pg                             AS "StartTime_Local_DTS",     activity.done_dts                                                               AS "DoneTime_DTS",     activity.duration_seconds                                                       AS "Duration_Seconds",     ROUND(activity.duration_seconds/60.,2)                                          AS "Duration_Mins",     ROUND(activity.duration_seconds/3600.,2)                                        AS "Duration_Hours",     scan_date.date_actual                                                           AS "ActivityTime_Date",     scan_date.day_of_week_usa                                                       AS "ActivityTime_DayOfWeek",     scan_date.day_name_abbreviated                                                  AS "ActivityTime_DayName",     scan_date.week_of_year_fiscal_name                                              AS "ActivityTime_FiscalWeek",   --  Week 24 2020     scan_date.week_of_year_fiscal                                                   AS "ActivityTime_FiscalWeekNo", --  2020-24     scan_date.month_actual                                                          AS "ActivityTime_MonthNo",     scan_date.month_actual_name_abbreviated                                         AS "ActivityTime_MonthName",     scan_date.month_fiscal                                                          AS "ActivityTime_FiscalMonthNo",     scan_date.month_fiscal_name_abbreviated                                         AS "ActivityTime_FiscalMonthName",     to_char(scan_date.year_actual, 'fm0000')                                        AS "ActivityTime_Year",     scan_date.year_actual                                                           AS "ActivityTime_YearNo",     scan_date.fiscal_year_abbr::int                                                 AS "ActivityTime_FiscalYearNo",     (date_part('hour'::text, activity.start_dts))::integer                          AS "ActivityTime_HourOfDay",     hour_bin_get_bin((date_part('hour'::text, activity.start_dts))::integer)        AS "ActivityTime_HourBin",     hour_bin_get_bin_label((date_part('hour'::text, activity.start_dts))::integer)  AS "ActivityTime_HourBinName"FROM activityLEFT JOIN facility              ON facility.id             =  activity.facility_idLEFT JOIN hsys                  ON hsys.id                 =  facility.hsys_idLEFT JOIN facility_activities   ON facility_activities.id  =  activity.facility_activities_idLEFT JOIN web_user              ON web_user.id             =  activity.web_user_idJOIN calendar_day_plus scan_date  ON (scan_date.calendar_id = facility.calendar_id AND scan_date.date_actual = date(activity.created_dts))WHERE      activity.marked_for_deletion = 'false';ALTER VIEW api.activity_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','activity_domo','activity data for Domo.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_productivity_domo.sql-- Note: FacilityName and LocationName come FROM the same value and are identical. We're cloning an existing bug--       AS we don't want to break anything in Domo. The analytic_productivity table does have the facility_location ID,--       if we ever want to change how this view works.-- Note: For some reason, StartDate and Start_Date both exist with the same data. Becasue history.DROP VIEW IF EXISTS api.analytic_productivity_domo;CREATE VIEW api.analytic_productivity_domo ASWITH expanded_data AS(SELECT    hsys.name_                                     AS "HsysName",    facility.name_                                 AS "FacilityName",    facility.name_                                 AS "LocationName",    analytic_productivity.user_name                AS "UserName",    analytic_productivity.inv_name                 AS "InvName",    analytic_productivity.num_inst                 AS "NumInst",    analytic_productivity.assembly_minutes         AS "AssemblyMinute",    analytic_productivity.pause_minutes            AS "PauseMinute",    analytic_productivity.assembly_hour::real      AS "AssemblyHour",    analytic_productivity.pause_hour::real         AS "PauseHour",    specialty.name_                                AS "Specialty",    analytic_productivity.tray_or_pack             AS "TrayOrPack",    item_type.name_                                AS "ItemType",    analytic_productivity.item_name                AS "ItemName",    analytic_productivity.points::bigint           AS "Points",    analytic_productivity.points_per_hour::bigint  AS "PointsPerHour",    analytic_productivity.start_utc AS "Start_UTC",    analytic_productivity.start_local AS "Start_Local",    start_local.date_actual                       AS "Start_Date",    start_local.date_actual                       AS "StartDate",    start_local.day_of_week_usa                   AS "Start_DayOfWeek",    start_local.day_name_abbreviated              AS "Start_DayName",    start_local.week_of_year_fiscal_name          AS "Start_FiscalWeek",   --  Week 24 2020    start_local.week_of_year_fiscal               AS "Start_FiscalWeekNo", --  2020-24    start_local.month_actual                      AS "Start_MonthNo",    start_local.month_actual_name_abbreviated     AS "Start_MonthName",    start_local.month_fiscal                      AS "Start_FiscalMonthNo",    start_local.month_fiscal_name_abbreviated     AS "Start_FiscalMonthName",    to_char(start_local.year_actual, 'fm0000')    AS "Start_Year",    start_local.year_actual                       AS "Start_YearNo",    start_local.fiscal_year_abbr                  AS "Start_FiscalYear",    start_local.fiscal_year_abbr::int             AS "Start_FiscalYearNo",    date_part('hour', analytic_productivity.start_local)::bigint                          AS "Start_HourOfDay",    hour_bin_get_bin(date_part('hour', analytic_productivity.start_local)::integer)       AS "Start_HourBin",    hour_bin_get_bin_label(date_part('hour', analytic_productivity.start_local)::integer) AS "Start_HourBinName",    analytic_productivity.end_utc                AS "End_UTC",    analytic_productivity.end_local              AS "End_Local",    analytic_productivity.end_local              AS "DateTime_Local", -- 13-10-20: Consistent name for filters.    end_local.date_actual                        AS "End_Date",    end_local.day_of_week_usa                    AS "End_DayOfWeek",    end_local.day_name_abbreviated               AS "End_DayName",    end_local.week_of_year_fiscal_name           AS "End_FiscalWeek",   --  Week 24 2020    end_local.week_of_year_fiscal                AS "End_FiscalWeekNo", --  2020-24    end_local.month_actual                       AS "End_MonthNo",    end_local.month_actual_name_abbreviated      AS "End_MonthName",    end_local.month_fiscal                       AS "End_FiscalMonthNo",    end_local.month_fiscal_name_abbreviated      AS "End_FiscalMonthName",    to_char(end_local.year_actual, 'fm0000')     AS "End_Year",    end_local.year_actual                        AS "End_YearNo",    end_local.fiscal_year_abbr                   AS "End_FiscalYear",    end_local.fiscal_year_abbr::int              AS "End_FiscalYearNo",    date_part('hour', analytic_productivity.end_local)::bigint                          AS "End_HourOfDay",    hour_bin_get_bin(date_part('hour', analytic_productivity.end_local)::integer)       AS "End_HourBin",    hour_bin_get_bin_label(date_part('hour', analytic_productivity.end_local)::integer) AS "End_HourBinName"    FROM analytic_productivity    LEFT JOIN hsys                ON (analytic_productivity.hsys_id               = hsys.id)    LEFT JOIN facility            ON (analytic_productivity.facility_id           = facility.id)    LEFT JOIN facility_location   ON (analytic_productivity.facility_location_id  = facility_location.id)    LEFT JOIN specialty           ON (analytic_productivity.specialty_id          = specialty.id)    LEFT JOIN item_type           ON (analytic_productivity.item_type_id          = item_type.id)    LEFT JOIN data_file_info      ON (analytic_productivity.data_file_id          = data_file_info.id)    -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.       JOIN calendar_day_plus start_local         ON (start_local.calendar_id = facility.calendar_id        AND start_local.date_actual = date(analytic_productivity.start_local))    -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.       JOIN calendar_day_plus end_local         ON (end_local.calendar_id = facility.calendar_id        AND end_local.date_actual = date(analytic_productivity.end_local))     WHERE analytic_productivity.marked_for_deletion = false  ) SELECT *,       ntile(100) over (order by "NumInst") AS "NumInstValuePercentile",       ntile(100) over (order by "AssemblyMinute") AS "AssemblyMinuteValuePercentile",       ntile(100) over (order by "PauseMinute") AS "PauseMinuteValuePercentile",       ntile(100) over (order by "Points") AS "PointsValuePercentile",       ntile(100) over (order by "PointsPerHour") AS "PointsPerHourValuePercentile"   FROM expanded_data  ;ALTER VIEW api.analytic_productivity_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_productivity_domo','Analytic data, derived largely from [Assembly].','PROD Analytic Productivity PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_productivity_plus.sqlCREATE OR REPLACE VIEW api.analytic_productivity_plus ASSELECT	analytic_productivity.id,    analytic_productivity.pg_con_id,    analytic_productivity.data_file_id,    analytic_productivity.marked_for_deletion,    analytic_productivity.hsys_id,    analytic_productivity.facility_id,    analytic_productivity.facility_location_id,    analytic_productivity.specialty_id,    analytic_productivity.item_type_id,    analytic_productivity.user_name,    analytic_productivity.inv_name,    analytic_productivity.item_name,    analytic_productivity.tray_or_pack,    analytic_productivity.num_inst,    analytic_productivity.assembly_minutes,    analytic_productivity.pause_minutes,    analytic_productivity.points,    analytic_productivity.points_per_hour,    analytic_productivity.assembly_hour,    analytic_productivity.pause_hour,    analytic_productivity.start_utc,    analytic_productivity.start_local,    analytic_productivity.end_utc,    analytic_productivity.end_local,    /* Lookup fields */    hsys.name_ AS hsys_name,    facility.name_ AS facility_name,    facility.tz_name,	facility_location.name_ AS Location_name,    specialty.name_ AS specialty_name,    item_type.name_ AS item_type_name,    data_file_info.server_name_	FROM analytic_productivity	LEFT JOIN hsys               ON (analytic_productivity.hsys_id                = hsys.id)	LEFT JOIN facility           ON (analytic_productivity.facility_id            = facility.id)	LEFT JOIN facility_location  ON (analytic_productivity.facility_location_id   = facility_location.id)	LEFT JOIN specialty          ON (analytic_productivity.specialty_id           = specialty.id)	LEFT JOIN item_type          ON (analytic_productivity.item_type_id           = item_type.id)	LEFT JOIN data_file_info   	 ON (analytic_productivity.data_file_id           = data_file_info.id)    ;ALTER VIEW api.analytic_productivity_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_productivity_plus','Analytic data, derived largely from [Assembly].');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_scan_plus.sqlCREATE OR REPLACE VIEW api.analytic_scan_plus ASSELECT 	analytic_scan.id,    analytic_scan.pg_con_id,    analytic_scan.marked_for_deletion,    analytic_scan.hsys_id,    analytic_scan.facility_id,    analytic_scan.facility_location_id,    analytic_scan.location_description,    analytic_scan.specialty_id,    analytic_scan.scanned_type,    analytic_scan.associated_to,    analytic_scan.user_name,    analytic_scan.inv_name,    greatest (1,analytic_scan.num_inst) AS num_inst, -- Assumes no negative numbers, turns 0 values into 1.    analytic_scan.tray_or_pack,    analytic_scan.item_name,    analytic_scan.scan_time_utc_dts,    analytic_scan.scan_time_local_dts,    /* Lookup fields */    hsys.name_ AS hsys_name,    facility.name_ AS facility_name,    facility.tz_name,	facility_location.name_ AS Location_name,    specialty.name_ AS specialty_name,    data_file_info.server_name_	FROM analytic_scan	LEFT JOIN hsys 				ON (analytic_scan.hsys_id 				= hsys.id)	LEFT JOIN facility		 	ON (analytic_scan.facility_id 			= facility.id)	LEFT JOIN facility_location 	ON (analytic_scan.facility_location_id = facility_location.id)	LEFT JOIN specialty	 		ON (analytic_scan.specialty_id		  	= specialty.id)	LEFT JOIN data_file_info   	ON (analytic_scan.data_file_id	 	 	= data_file_info.id)    ;ALTER VIEW api.analytic_scan_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_scan_plus','Analytic data, dervied largely from [Scan]');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_sterilizer_load_domo.sqlDROP VIEW IF EXISTS api.analytic_sterilizer_load_domo;CREATE VIEW api.analytic_sterilizer_load_domo AS WITH expanded_data AS (         SELECT hsys.name_                                                                                                 AS "HsysName",            facility.name_                                                                                                 AS "FacilityName",            COALESCE(web_user.name_full, ''::citext)                                                                       AS "UserName",            COALESCE(sterilizer.name_, ''::citext)                                                                         AS "Sterilizer",            analytic_sterilizer_load.status                                                                                AS "Status",            COALESCE(sterilize_method.name_, ''::citext)                                                                   AS "Method",            COALESCE(sterilize_params.name_, ''::citext)                                                                   AS "Params",            (analytic_sterilizer_load.is_iuss)::text                                                                       AS "isIUSS",            analytic_sterilizer_load.trays_count                                                                           AS "NumTrays",            analytic_sterilizer_load.packs_count                                                                           AS "NumPacks",            analytic_sterilizer_load.instruments_count                                                                     AS "NumInst",            analytic_sterilizer_load.status_building_dts                                                                   AS "Built_UTC",            analytic_sterilizer_load.status_building_dts                                                                   AS "BuiltDTS",            analytic_sterilizer_load.status_building_local_dts                                                             AS "Built_Local",            built_date.date_actual                                                                                         AS "Built_Date",            built_date.day_of_week_usa                                                                                     AS "Built_DayOfWeek",            built_date.day_name_abbreviated                                                                                AS "Built_DayName",            built_date.week_of_year_fiscal_name                                                                            AS "Built_FiscalWeek",   --  Week 24 2020            built_date.week_of_year_fiscal                                                                                 AS "Built_FiscalWeekNo", --  2020-24            built_date.month_actual                                                                                        AS "Built_MonthNo",            built_date.month_actual_name_abbreviated                                                                       AS "Built_MonthName",            built_date.month_fiscal                                                                                        AS "Built_FiscalMonthNo",            built_date.month_fiscal_name_abbreviated                                                                       AS "Built_FiscalMonthName",            to_char(built_date.year_actual, 'fm0000')                                                                      AS "Built_Year",            built_date.year_actual                                                                                         AS "Built_YearNo",            built_date.fiscal_year_abbr                                                                                    AS "Built_FiscalYear",            built_date.fiscal_year_abbr::int                                                                               AS "Built_FiscalYearNo",            (date_part('hour'::text, analytic_sterilizer_load.status_building_local_dts))::integer                         AS "Built_HourOfDay",            hour_bin_get_bin((date_part('hour'::text, analytic_sterilizer_load.status_building_local_dts))::integer)       AS "Built_HourBin",            hour_bin_get_bin_label((date_part('hour'::text, analytic_sterilizer_load.status_building_local_dts))::integer) AS "Built_HourBinName",            analytic_sterilizer_load.status_done_dts                                                                       AS "Done_UTC",            analytic_sterilizer_load.status_done_dts                                                                       AS "DoneDTS",            analytic_sterilizer_load.status_done_local_dts                                                                 AS "Done_Local",            analytic_sterilizer_load.status_done_local_dts                                                                 AS "DateTime_Local", -- 13-10-20: Consistent name for filters.            done_date.date_actual                                                                                          AS "Done_Date",            done_date.day_of_week_usa                                                                                      AS "Done_DayOfWeek",            done_date.day_name_abbreviated                                                                                 AS "Done_DayName",            done_date.week_of_year_fiscal_name                                                                             AS "Done_FiscalWeek",   --  Week 24 2020            done_date.week_of_year_fiscal                                                                                  AS "Done_FiscalWeekNo", --  2020-24            done_date.month_actual                                                                                         AS "Done_MonthNo",            done_date.month_actual_name_abbreviated                                                                        AS "Done_MonthName",            done_date.month_fiscal                                                                                         AS "Done_FiscalMonthNo",            done_date.month_fiscal_name_abbreviated                                                                        AS "Done_FiscalMonthName",            to_char(done_date.year_actual, 'fm0000')                                                                       AS "Done_Year",            done_date.year_actual                                                                                          AS "Done_YearNo",            done_date.fiscal_year_abbr                                                                                     AS "Done_FiscalYear",            done_date.fiscal_year_abbr::int                                                                                AS "Done_FiscalYearNo",            (date_part('hour'::text, analytic_sterilizer_load.status_done_local_dts))::integer                             AS "Done_HourOfDay",            hour_bin_get_bin((date_part('hour'::text, analytic_sterilizer_load.status_done_local_dts))::integer)           AS "Done_HourBin",            hour_bin_get_bin_label((date_part('hour'::text, analytic_sterilizer_load.status_done_local_dts))::integer)     AS "Done_HourBinName",            analytic_sterilizer_load.id                                                                                   AS sterilizer_load_id           FROM analytic_sterilizer_load           LEFT JOIN sterilize_method ON analytic_sterilizer_load.sterilize_method_id = sterilize_method.id           LEFT JOIN sterilize_params ON analytic_sterilizer_load.sterilize_params_id = sterilize_params.id           LEFT JOIN sterilizer ON analytic_sterilizer_load.sterilizer_id = sterilizer.id           LEFT JOIN facility ON analytic_sterilizer_load.facility_id = facility.id           LEFT JOIN web_user ON analytic_sterilizer_load.web_user_id = web_user.id           LEFT JOIN hour_bin ON date_part('hour'::text, analytic_sterilizer_load.status_building_local_dts) = (hour_bin.bin_hour)::double precision           LEFT JOIN hsys ON facility.hsys_id = hsys.id       -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.           JOIN calendar_day_plus built_date             ON (built_date.calendar_id = facility.calendar_id             AND built_date.date_actual = date(analytic_sterilizer_load.status_building_local_dts))       -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.          JOIN calendar_day_plus done_date            ON (done_date.calendar_id = facility.calendar_id           AND done_date.date_actual = date(analytic_sterilizer_load.status_done_local_dts))         WHERE analytic_sterilizer_load.marked_for_deletion = false        ) SELECT expanded_data."HsysName",        expanded_data."FacilityName",        expanded_data."UserName",        expanded_data."Status",        expanded_data."Sterilizer",        expanded_data."Method",        expanded_data."Params",        expanded_data."isIUSS",        expanded_data."NumTrays",        expanded_data."NumPacks",        expanded_data."NumInst",        expanded_data."Built_UTC",        expanded_data."BuiltDTS",        expanded_data."Built_Local",        expanded_data."Built_Date",        expanded_data."Built_DayOfWeek",        expanded_data."Built_DayName",        expanded_data."Built_FiscalWeek",        expanded_data."Built_FiscalWeekNo",        expanded_data."Built_HourOfDay",        expanded_data."Built_HourBin",        expanded_data."Built_HourBinName",        expanded_data."Done_UTC",        expanded_data."DoneDTS",        expanded_data."Done_Local",        expanded_data."DateTime_Local", -- 13-10-20: Consistent name for filters.        expanded_data."Done_Date",        expanded_data."Done_DayOfWeek",        expanded_data."Done_DayName",        expanded_data."Done_FiscalWeek",        expanded_data."Done_FiscalWeekNo",        expanded_data."Done_HourOfDay",        expanded_data."Done_HourBin",        expanded_data."Done_HourBinName",    ntile(100) OVER (ORDER BY expanded_data."NumInst")  AS "NumInstValuePercentile",    ntile(100) OVER (ORDER BY expanded_data."NumPacks") AS "NumPacksValuePercentile",    ntile(100) OVER (ORDER BY expanded_data."NumTrays") AS "NumTraysValuePercentile",   sterilizer_load_id   FROM expanded_data;ALTER VIEW api.analytic_sterilizer_load_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_sterilizer_load_domo','[SterilizerLoad] details','PROD Analytic Sterilizer Load PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_sterilizer_load_percentiles_domo.sqlCREATE OR REPLACE VIEW api.analytic_sterilizer_load_percentiles_domo AS/*First, set up a CTE for each numeric column we want percentiles from.For each, you get a distinct list of values with-- the value-- the frequency (count) of that value in the whole table-- the percentile of that value in the whole table-- the percentile of that frequency in the whole table.Each CTE should contain a small number of rows since it's based on SELECT DISTINCT.These temporary views then become something we can lookup (join) on in the mainbody of the query. That point of all of this is to generate the stats once,and then be able to efficiently bolt the results onto each source row.Percentiles aren't easy/efficient to calculate this way in Domo, andpercentiles make for *much* more illuminating charts, on some of our data.*/WITHinstruments_count_stats AS (  SELECT DISTINCT instruments_count AS value,  		  ntile(100) over (order by instruments_count) AS value_percentile,		  count(*) AS frequency_count,		  ntile(100) over (order by count(instruments_count)) AS frequency_percentile    FROM analytic_sterilizer_loadGROUP BY instruments_count),-- Get the details for the points column.trays_count_stats AS (  SELECT DISTINCT trays_count AS value,  		  ntile(100) over (order by trays_count) AS value_percentile,		  count(*) AS frequency_count,		  ntile(100) over (order by count(trays_count)) AS frequency_percentile    FROM analytic_sterilizer_loadGROUP BY trays_count),-- Get the details for the points column.packs_count_stats AS (  SELECT DISTINCT packs_count AS value,  		  ntile(100) over (order by packs_count) AS value_percentile,		  count(*) AS frequency_count,		  ntile(100) over (order by count(packs_count)) AS frequency_percentile    FROM analytic_sterilizer_loadGROUP BY packs_count)-- Get every row in the base table and use the CTEs above for lookups (joins) with the extra data.SELECT    hsys.name_ AS "HsysName",    facility.name_ AS "FacilityName",    analytic_sterilizer_load.trays_count AS "NumTrays",    analytic_sterilizer_load.packs_count AS "NumPacks",    analytic_sterilizer_load.instruments_count AS "NumInst",    -- Bolt on the calculated stats FROM the CTEs at the top.    trays_count_stats.frequency_count AS "NumTraysFrequency",    trays_count_stats.value_percentile AS "NumTraysValuePercentile",    trays_count_stats.frequency_percentile AS "NumTraysFrequencyPercentile",    packs_count_stats.frequency_count AS "NumPacksFrequency",    packs_count_stats.value_percentile AS "NumPacksValuePercentile",    packs_count_stats.frequency_percentile AS "NumPacksFrequencyPercentile",	instruments_count_stats.frequency_count AS "NumInstFrequency",    instruments_count_stats.value_percentile AS "NumInstValuePercentile",    instruments_count_stats.frequency_percentile AS "NumInstFrequencyPercentile"	FROM analytic_sterilizer_load	JOIN facility ON (analytic_sterilizer_load.facility_id = facility.id)	JOIN hsys ON (facility.hsys_id = hsys.id)	JOIN trays_count_stats ON (analytic_sterilizer_load.trays_count = trays_count_stats.value)	JOIN packs_count_stats ON (analytic_sterilizer_load.packs_count = packs_count_stats.value)	JOIN instruments_count_stats ON (analytic_sterilizer_load.instruments_count = instruments_count_stats.value)    WHERE analytic_sterilizer_load.marked_for_deletion = false  ;ALTER VIEW api.analytic_sterilizer_load_percentiles_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_sterilizer_load_percentiles_domo','[SterilizerLoad] details, with percentiles calculated for instruments, trays, and packs.','PROD Analytic Sterilizer Load Percentiles PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_sterilizer_load_plus.sqlCREATE OR REPLACE VIEW api.analytic_sterilizer_load_plus ASSELECT 	analytic_sterilizer_load.id,    analytic_sterilizer_load.sterilize_method_id,    analytic_sterilizer_load.sterilize_params_id,    analytic_sterilizer_load.sterilizer_id,    analytic_sterilizer_load.facility_id,    analytic_sterilizer_load.web_user_id,    analytic_sterilizer_load.status_building_dts,    analytic_sterilizer_load.status_building_local_dts,    analytic_sterilizer_load.status_done_dts,    analytic_sterilizer_load.status_done_local_dts,    analytic_sterilizer_load.status,    analytic_sterilizer_load.is_iuss,    analytic_sterilizer_load.instruments_count,    analytic_sterilizer_load.packs_count,    analytic_sterilizer_load.trays_count,    /* Lookup fields */    sterilize_method.name_ AS method_name,    sterilize_params.name_ AS params_name,    sterilizer.name_ AS sterilizer_name,    facility.name_ AS facility_name,    facility.tz_name,    data_file_info.server_name_,    web_user.name_full,    hour_bin_get_bin_label(date_part('hour', analytic_sterilizer_load.status_building_dts)::INTEGER) AS building_hour_gin,    hsys.name_ AS hsys_name	FROM analytic_sterilizer_load	LEFT JOIN sterilize_method ON (analytic_sterilizer_load.sterilize_method_id = sterilize_method.id)	LEFT JOIN sterilize_params ON (analytic_sterilizer_load.sterilize_params_id = sterilize_params.id)	LEFT JOIN sterilizer 	   ON (analytic_sterilizer_load.sterilizer_id  	    = sterilizer.id)	LEFT JOIN facility 		   ON (analytic_sterilizer_load.facility_id		    = facility.id)	LEFT JOIN data_file_info   ON (analytic_sterilizer_load.data_file_id	    = data_file_info.id)	LEFT JOIN web_user 	   	   ON (analytic_sterilizer_load.web_user_id		    = web_user.id)	LEFT JOIN hsys			   ON (facility.hsys_id 					        = hsys.id)    ;ALTER VIEW api.analytic_sterilizer_load_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_sterilizer_load_plus','[SterilizerLoad] details, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_sterilizer_loadinv_domo.sqlDROP VIEW IF EXISTS api.analytic_sterilizer_loadinv_domo;CREATE VIEW api.analytic_sterilizer_loadinv_domo ASWITH expanded_data AS(SELECT --   analytic_sterilizer_load.status AS "Status",    analytic_sterilizer_loadinv.id                                                                  AS "AnalyticSterilizerLoadinvID",    COALESCE (hsys.name_ ,'')                                                                       AS "HsysName",    COALESCE (facility.name_ , '')                                                                  AS "FacilityName",    COALESCE (web_user.name_full, '')                                                               AS "UserName",    COALESCE (specialty.name_ , '')                                                                 AS "Specialty",    COALESCE(item_type.name_,'')                                                                    AS "ItemType",    item.name_                                                                                      AS "ItemName",    analytic_sterilizer_loadinv.inv_name_provided                                                   AS "InvName",    inv.their_name                                                                                  AS "InvName_TheirName",    analytic_sterilizer_loadinv.num_inst                                                            AS "NumInst",    sterilizer.name_                                                                                AS "Sterilizer",    sterilize_method.name_                                                                          AS "Method",    sterilize_params.name_                                                                          AS "Params",    analytic_sterilizer_loadinv.is_iuss                                                             AS "isIUSS",    analytic_sterilizer_loadinv.qty                                                                 AS "Qty",    analytic_sterilizer_loadinv.category                                                            AS "Category",    analytic_sterilizer_loadinv.clinic_dept_name                                                    AS "ClinicDeptName",    analytic_sterilizer_loadinv.status                                                              AS "Status", -- Dec 24, 2020    analytic_sterilizer_loadinv.done_dts                                                            AS "DoneDTS",    analytic_sterilizer_loadinv.done_local_dts                                                      AS "Done_Local",    analytic_sterilizer_loadinv.done_local_dts                                                      AS "DateTime_Local", -- 13-10-20: Consistent name for filters.    done_date.date_actual                                                                           AS "Done_Date",    done_date.day_of_week_usa                                                                       AS "Done_DayOfWeek",    done_date.day_name_abbreviated                                                                  AS "Done_DayName",    done_date.week_of_year_fiscal_name                                                              AS "Done_FiscalWeek",   --  Week 24 2020    done_date.week_of_year_fiscal                                                                   AS "Done_FiscalWeekNo", --  2020-24    done_date.month_actual                                                                          AS "Done_MonthNo",    done_date.month_actual_name_abbreviated                                                         AS "Done_MonthName",    done_date.month_fiscal                                                                          AS "Done_FiscalMonthNo",    done_date.month_fiscal_name_abbreviated                                                         AS "Done_FiscalMonthName",    to_char(done_date.year_actual, 'fm0000')                                                        AS "Done_Year",    done_date.year_actual                                                                           AS "Done_YearNo",    done_date.fiscal_year_abbr                                                                      AS "Done_FiscalYear",    done_date.fiscal_year_abbr::int                                                                 AS "Done_FiscalYearNo",    date_part('hour', analytic_sterilizer_loadinv.done_local_dts)::integer                          AS "Done_HourOfDay",    hour_bin_get_bin(date_part('hour', analytic_sterilizer_loadinv.done_local_dts)::INTEGER)        AS "Done_HourBin",    hour_bin_get_bin_label(date_part('hour', analytic_sterilizer_loadinv.done_local_dts)::INTEGER)  AS "Done_HourBinName",    analytic_sterilizer_loadinv.processing_seconds                                                  AS "Processing_Seconds",    analytic_sterilizer_load.id                                                                     AS sterilizer_load_id    FROM analytic_sterilizer_loadinv         JOIN analytic_sterilizer_load ON (analytic_sterilizer_loadinv.sterilizerload_id    = analytic_sterilizer_load.id)    LEFT JOIN sterilize_method         ON (analytic_sterilizer_loadinv.sterilize_method_id  = sterilize_method.id)    LEFT JOIN sterilize_params         ON (analytic_sterilizer_loadinv.sterilize_params_id  = sterilize_params.id)    LEFT JOIN sterilizer               ON (analytic_sterilizer_loadinv.sterilizer_id        = sterilizer.id)    LEFT JOIN facility                 ON (analytic_sterilizer_loadinv.facility_id          = facility.id)    LEFT JOIN data_file_info           ON (analytic_sterilizer_loadinv.data_file_id         = data_file_info.id)    LEFT JOIN web_user                 ON (analytic_sterilizer_loadinv.web_user_id          = web_user.id)    LEFT JOIN hsys                     ON (analytic_sterilizer_loadinv.hsys_id              = hsys.id)    LEFT JOIN inv                      ON (analytic_sterilizer_loadinv.inv_id               = inv.id)    LEFT JOIN item                     ON (analytic_sterilizer_loadinv.item_id              = item.id)    LEFT JOIN specialty                ON (analytic_sterilizer_loadinv.speciality_id        = specialty.id)    LEFT JOIN item_type                ON (analytic_sterilizer_loadinv.item_type_id         = item_type.id) /* We dont' always have a related item_type.*/    -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.   JOIN calendar_day_plus done_date           ON (done_date.calendar_id = facility.calendar_id          AND done_date.date_actual  = date(analytic_sterilizer_loadinv.done_local_dts))	WHERE analytic_sterilizer_loadinv.marked_for_deletion = false	  AND analytic_sterilizer_loadinv.status <> 'Deleted') SELECT *,       ntile(100) over (order by "NumInst") AS "NumInstPercentile",       ntile(100) over (order by "Qty") AS "QtyPercentile"   FROM expanded_data;ALTER VIEW api.analytic_sterilizer_loadinv_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_sterilizer_loadinv_domo','Analytic data derived largely from [SterilizerLoad_Inv].','PROD Analytic Load Inventory PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_sterilizer_loadinv_plus.sqlDROP VIEW IF EXISTS api.analytic_sterilizer_loadinv_plus;CREATE OR REPLACE VIEW api.analytic_sterilizer_loadinv_plus ASSELECT 	analytic_sterilizer_loadinv.id, 	analytic_sterilizer_loadinv.item_id,    analytic_sterilizer_loadinv.data_file_id,    analytic_sterilizer_loadinv.marked_for_deletion,    analytic_sterilizer_loadinv.facility_id,    analytic_sterilizer_loadinv.hsys_id,    analytic_sterilizer_loadinv.item_type_id,    analytic_sterilizer_loadinv.speciality_id,    analytic_sterilizer_loadinv.sterilize_method_id,    analytic_sterilizer_loadinv.sterilize_params_id,    analytic_sterilizer_loadinv.sterilizer_id,    analytic_sterilizer_loadinv.web_user_id,    analytic_sterilizer_loadinv.inv_name_provided,    analytic_sterilizer_loadinv.is_iuss,    greatest(1,analytic_sterilizer_loadinv.num_inst) AS num_inst, -- Get rid of 0, just like in Domo view.    (greatest(1,analytic_sterilizer_loadinv.num_inst) * analytic_sterilizer_loadinv.qty) AS num_inst_extended, -- Calculate extended count.    analytic_sterilizer_loadinv.qty,    analytic_sterilizer_loadinv.category,    analytic_sterilizer_loadinv.clinic_dept_name,    analytic_sterilizer_loadinv.status, -- Dec 24, 2020    analytic_sterilizer_loadinv.done_dts,    analytic_sterilizer_loadinv.done_local_dts,    analytic_sterilizer_loadinv.processing_seconds,    /* Lookup fields */    sterilize_method.name_ AS method_name,    sterilize_params.name_ AS params_name,    sterilizer.name_ AS sterilizer_name,    facility.name_ AS facility_name,    facility.tz_name,    data_file_info.server_name_,    web_user.name_full,    hsys.name_ AS hsys_name,    inv.their_name AS "inv_their_name",    item.name_ AS "item_name",    specialty.name_ AS specialty_name,    COALESCE(item_type.name_,'') AS item_type_name /* We dont' always have a related item_type.*/   	FROM analytic_sterilizer_loadinv	LEFT JOIN sterilize_method ON (analytic_sterilizer_loadinv.sterilize_method_id = sterilize_method.id)	LEFT JOIN sterilize_params ON (analytic_sterilizer_loadinv.sterilize_params_id = sterilize_params.id)	LEFT JOIN sterilizer 	   ON (analytic_sterilizer_loadinv.sterilizer_id  	  = sterilizer.id)	LEFT JOIN facility 		   ON (analytic_sterilizer_loadinv.facility_id		  = facility.id)	LEFT JOIN data_file_info   ON (analytic_sterilizer_loadinv.data_file_id	 	  = data_file_info.id)	LEFT JOIN web_user 	   	   ON (analytic_sterilizer_loadinv.web_user_id		  = web_user.id)	LEFT JOIN hsys			   ON (analytic_sterilizer_loadinv.hsys_id 			  = hsys.id)	LEFT JOIN inv	 	   	   ON (analytic_sterilizer_loadinv.inv_id			  = inv.id)	LEFT JOIN item	 	   	   ON (analytic_sterilizer_loadinv.item_id			  = item.id)	LEFT JOIN specialty 	   ON (analytic_sterilizer_loadinv.speciality_id	  = specialty.id)	LEFT JOIN item_type 	   ON (analytic_sterilizer_loadinv.item_type_id		  = item_type.id) /* We dont' always have a related item_type.*/	;ALTER VIEW api.analytic_sterilizer_loadinv_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_sterilizer_loadinv_plus','Analytic data derived largely from [SterilizerLoad_Inv].');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:analytic_work_domo.sqlDROP VIEW IF EXISTS api.analytic_work_domo;CREATE VIEW api.analytic_work_domo ASSELECT-- Key values and lookups    hsys.name_                                                                AS "HsysName",    facility.name_                                                            AS "FacilityName",    web_user.name_full                                                        AS "UserName",    inv.their_name                                                            AS "InvName",    work.num_items                                                            AS "NumItems",    work.num_inst                                                             AS "NumInst",    work.missing_inst                                                         AS "MissingInst",    work.points                                                               AS "Points",    coalesce (specialty.name_, 'Multi')                                       AS "Specialty",    CASE         WHEN item.item_type_id = 'e2278be4-0b60-294b-8764-2afda7cb7c6a'         THEN 'Pack' ELSE 'Tray'    END                                                                       AS "TrayOrPack",    work.num_packs                                                            AS "NumPacks",    work.num_trays                                                            AS "NumTrays",    item_type.name_                                                           AS "ItemType",    item.name_                                                                AS "ItemName",    work.activity                                                             AS "Activity",    inv_getdesc(work.inv_id)                                                  AS "Description",    work.duration                                                             AS "Duration",    work.date_time                                                            AS "DateTime",--  Start time and extracts    work.start_dts                                                            AS "Start_UTC",    work.start_local_dts                                                      AS "Start_Local",    start_local.date_actual                                                   AS "Start_Date",    start_local.date_actual                                                   AS "StartDate",    start_local.day_of_week_usa                                               AS "Start_DayOfWeek",    start_local.day_name_abbreviated                                          AS "Start_DayName",    start_local.week_of_year_fiscal_name                                      AS "Start_FiscalWeek",   --  Week 24 2020    start_local.week_of_year_fiscal                                           AS "Start_FiscalWeekNo", --  2020-24    start_local.month_actual                                                  AS "Start_MonthNo",    start_local.month_actual_name_abbreviated                                 AS "Start_MonthName",    start_local.month_fiscal                                                  AS "Start_FiscalMonthNo",    start_local.month_fiscal_name_abbreviated                                 AS "Start_FiscalMonthName",    to_char(start_local.year_actual, 'fm0000')                                AS "Start_Year",    start_local.year_actual                                                   AS "Start_YearNo",    start_local.fiscal_year_abbr                                              AS "Start_FiscalYear",    start_local.fiscal_year_abbr::int                                         AS "Start_FiscalYearNo",    date_part('hour', work.start_local_dts)::integer                          AS "Start_HourOfDay",    hour_bin_get_bin(date_part('hour', work.start_local_dts)::integer)        AS "Start_HourBin",    hour_bin_get_bin_label(date_part('hour', work.start_local_dts)::integer)  AS "Start_HourBinName",--  End time and extracts    work.end_dts                                                              AS "End_UTC",    work.end_local_dts                                                        AS "End_Local",    end_local.date_actual                                                     AS "End_Date",    end_local.date_actual                                                     AS "EndDate",          -- I added this in to match StartDate ‚Äî DPA.    end_local.day_of_week_usa                                                 AS "End_DayOfWeek",    end_local.day_name_abbreviated                                            AS "End_DayName",    end_local.week_of_year_fiscal_name                                        AS "End_FiscalWeek",   --  Week 24 2020    end_local.week_of_year_fiscal                                             AS "End_FiscalWeekNo", --  2020-24    end_local.month_actual                                                    AS "End_MonthNo",    end_local.month_actual_name_abbreviated                                   AS "End_MonthName",    end_local.month_fiscal                                                    AS "End_FiscalMonthNo",    end_local.month_fiscal_name_abbreviated                                   AS "End_FiscalMonthName",    to_char(end_local.year_actual, 'fm0000')                                  AS "End_Year",    end_local.year_actual                                                     AS "End_YearNo",    end_local.fiscal_year_abbr                                                AS "End_FiscalYear",    end_local.fiscal_year_abbr::int                                           AS "End_FiscalYearNo",    date_part('hour', work.end_local_dts)::integer                            AS "End_HourOfDay",    hour_bin_get_bin(date_part('hour', work.end_local_dts)::integer)          AS "End_HourBin",    hour_bin_get_bin_label(date_part('hour', work.end_local_dts)::integer)    AS "End_HourBinName",--  Spare IDs for back-tracking questions about invididual rows.    work.activity_id,    work.assembly_id,    work.inv_id,    work.scan_id,    work.sterilizer_load_id,    work.sterilizer_loadInv_id,    work.key_supplement--  Get the data for the SELECT above    FROM analytic_work AS work    LEFT JOIN inv             ON inv.id          =  work.inv_id    LEFT JOIN item            ON inv.item_id     =  inv.item_id    LEFT JOIN item_type       ON item_type.id    =  item.item_type_id    LEFT JOIN specialty       ON specialty.id    =  item.specialty_id    LEFT JOIN hsys            ON hsys.id         =  work.hsys_id    LEFT JOIN facility        ON facility.id     =  work.facility_id    LEFT JOIN web_user        ON work.user_id    =  web_user.id    -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.       JOIN calendar_day_plus start_local         ON (start_local.calendar_id = facility.calendar_id        AND start_local.date_actual = date(work.start_local_dts))    -- JOIN instead of LEFT JOIN to drop rows with invalid facility_id, invalid facility.calendar_id, or an epoch DTS.       JOIN calendar_day_plus end_local         ON (end_local.calendar_id = facility.calendar_id        AND end_local.date_actual = date(work.end_local_dts))   WHERE work.marked_for_deletion <> true  ;ALTER VIEW api.analytic_work_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','analytic_work_domo','Analytic data from multiple Sonar data streams.','PROD Analytic Work PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:assembly_plus.sqlCREATE OR REPLACE VIEW api.assembly_plus ASSELECT	assembly.id,	assembly.data_file_id,	data_file_info.server_name_,	assembly.created_by_user_id,	COALESCE(web_user_created.username,'') AS created_by_lookup,	assembly.created_by,	assembly.done_by_user_id,	COALESCE(web_user_done.username,'') AS done_by,	assembly.facility_location_id,	facility_location.name_ AS faciility_location,	assembly.inv_id,	assembly.last_updated_by_data_file_id,	assembly.updated_by_user_id,	assembly.marked_for_deletion,	assembly.is_complete,	assembly.is_quick_turn,	assembly.con_id,	assembly.difficulty,	assembly.quantity,	assembly.sequence_no,	assembly.num_inst,	assembly.points,	assembly.done_dts,	assembly.created_dts,	assembly.updated_dts,	assembly.missing_list,	assembly.priority,	assembly.status,	assembly.updated_byFROM assemblyLEFT JOIN web_user AS web_user_created on web_user_created.id = assembly.created_by_user_idLEFT JOIN web_user AS web_user_done    on web_user_done.id = assembly.done_by_user_idLEFT JOIN data_file_info on (data_file_info.id = assembly.data_file_id)LEFT JOIN facility_location on (facility_location.id = assembly.facility_location_id);ALTER VIEW api.assembly_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','assembly_plus','Assembly data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:decon_demand_flow.sqlDROP VIEW IF EXISTS api.decon_demand_flow CASCADE;CREATE VIEW api.decon_demand_flow AS----------------------------------------------------------- Build matrix of hours + facilities + associated_to---------------------------------------------------------WITH-- Keep the date range here compatible with the WHERE clause in the analytic data query.date_range AS (select (current_date - interval '8 weeks') as first_dts,        current_date + interval '1 day' - interval '1 sec' as last_dts -- 1 second before midnight   ),-- https://stackoverflow.com/questions/29023336/generate-series-in-postgres-from-start-and-end-date-in-a-table.-- LATERAL JOIN with generate_series.hours AS (select date_hour  from date_range,       generate_series(date_range.first_dts, date_range.last_dts, interval '1 hour') g(date_hour)),associated_to AS (         select associated_to AS "AssociatedTo",                count(*) as row_count            from analytic_scan       where associated_to <> ''    group by associated_to    having count(*) >= 10 -- Screen out some rare, weird values.),hours_associated_to AS (-- CROSS JOIN (full Cartesian product)select --hours.date_hour,       hours.date_hour::date                              AS "ScanTime_Date",      (date_part('dow'::text, hours.date_hour))::integer  AS "ScanTime_DayOfWeek",       to_char(hours.date_hour, 'Day'::text)              AS "ScanTime_DayName",      (date_part('hour'::text, hours.date_hour))::integer AS "ScanTime_HourOfDay",       associated_to."AssociatedTo" from hours,      associated_to ), facilities AS ( select distinct ON ("FacilityName")        "FacilityName",        "HsysName"   from analytic_scan_domo  group by 1,2), join_matrix AS ( -- Another big CROSS JOIN. The end result is facilities * hours * associated_to rows. This is a full range, with empty slots. -- The analytic data is then joined in to fill in whatever slots apply.  select facilities."FacilityName",         facilities."HsysName",         hours_associated_to."ScanTime_Date",         hours_associated_to."ScanTime_DayOfWeek",         hours_associated_to."ScanTime_DayName",         hours_associated_to."ScanTime_HourOfDay",         hours_associated_to."AssociatedTo"    from facilities,         hours_associated_to),----------------------------------------------------------- Build analytic results----------------------------------------------------------- Get only the data needed from analytic_scan.-- Notice that the date WHERE is in here, that helps with the speed.analytic_scan_data AS (    select GREATEST(1, analytic_scan.num_inst)                                   AS "NumInst",           analytic_scan.tray_or_pack                                            AS "TrayOrPack",           COALESCE(hsys.name_, ''::citext)                                      AS "HsysName",           COALESCE(facility.name_, ''::citext)                                  AS "FacilityName",           analytic_scan.associated_to                                           AS "AssociatedTo",           date(analytic_scan.scan_time_local_dts)                               AS "ScanTime_Date",           (date_part('dow'::text, analytic_scan.scan_time_local_dts))::integer  AS "ScanTime_DayOfWeek",           to_char(analytic_scan.scan_time_local_dts, 'Day'::text)               AS "ScanTime_DayName",           (date_part('hour'::text, analytic_scan.scan_time_local_dts))::integer AS "ScanTime_HourOfDay"    from  analytic_scan     join facility ON (analytic_scan.facility_id = facility.id)     join hsys     ON (facility.hsys_id          = hsys.id)   where analytic_scan.scan_time_local_dts >= (current_date - interval '8 weeks')-- Keep the WHERE condition here in line with date_range up at the top.),-- Get the basic details and counts. These values then have names that can be used-- in the following CTE ("WITH" search)total as (SELECT  "HsysName",  "FacilityName",  "ScanTime_Date",  "ScanTime_DayOfWeek",  "ScanTime_DayName",  "ScanTime_HourOfDay",  "AssociatedTo",  SUM("NumInst") as totalflow,  COUNT("TrayOrPack") as trayflowFROM  analytic_scan_dataGROUP BY  "HsysName",  "FacilityName",  "ScanTime_Date",  "ScanTime_DayOfWeek",  "ScanTime_DayName",  "ScanTime_HourOfDay",  "AssociatedTo"),analytic_scan_data_final AS (-- Final results, pull everything together.SELECT  "HsysName",  "FacilityName",  "ScanTime_Date",  "ScanTime_DayOfWeek",  "ScanTime_DayName",  "ScanTime_HourOfDay",  "AssociatedTo",  AVG (totalflow) AS "AvgInstFlow",  AVG (trayflow)  As "AvgTrayFlow"FROM totalWHERE "FacilityName"  IS NOT NULL  AND "ScanTime_Date" IS NOT NULLGROUP BY  "HsysName",  "FacilityName",  "ScanTime_Date",  "ScanTime_DayOfWeek",  "ScanTime_DayName",  "ScanTime_HourOfDay",  "AssociatedTo")----------------------------------------------------------- LEFT JOIN matrix and analytic results---------------------------------------------------------select    join_matrix."HsysName"                              AS "HsysName",    join_matrix."FacilityName"                          AS "FacilityName",    join_matrix."ScanTime_Date"                         AS "ScanTime_Date",    join_matrix."ScanTime_DayOfWeek"                    AS "ScanTime_DayOfWeek",    join_matrix."ScanTime_DayName"                      AS "ScanTime_DayName",    join_matrix."ScanTime_HourOfDay"                    AS "ScanTime_HourOfDay",    join_matrix."AssociatedTo"                          AS "AssociatedTo",    coalesce(analytic_scan_data_final."AvgInstFlow",0)  AS "AvgInstFlow",    coalesce(analytic_scan_data_final."AvgTrayFlow",0)  AS "AvgTrayFlow"     from join_matrixleft join analytic_scan_data_final        on (analytic_scan_data_final."FacilityName"       =  join_matrix."FacilityName"       and  analytic_scan_data_final."ScanTime_Date"      =  join_matrix."ScanTime_Date"       and  analytic_scan_data_final."ScanTime_HourOfDay" =  join_matrix."ScanTime_HourOfDay"       and  analytic_scan_data_final."AssociatedTo"       =  join_matrix."AssociatedTo");ALTER VIEW api.decon_demand_flow    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','decon_demand_flow','Average demand by hour for the past eight weeks.','PROD Decon Demand Flow PG');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:domo_dataset_plus.sqlCREATE OR REPLACE VIEW api.domo_dataset_plus AS /* Create a CTE so that we can used the calculation easily in a case structure in the main select. */ WITH datasets AS 	(select	domo_dataset.id,		    domo_dataset.dataset_name,		    domo_dataset.columns_count,			domo_dataset.rows_count,		    domo_dataset.created_at_dts,		    domo_dataset.updated_at_dts,		    domo_dataset.late_threshold_minutes,		    domo_dataset.late_threshold_minutes > 0 AS monitor_this,		    round(extract(epoch from(age(now(),domo_dataset.updated_at_dts)))::numeric,0) AS minutes_since_update		FROM domo_dataset) SELECT id,		dataset_name,		columns_count,		rows_count,		created_at_dts,		updated_at_dts,		monitor_this,		late_threshold_minutes,		minutes_since_update,		minutes_since_update - late_threshold_minutes AS minutes_late,    	CASE			WHEN late_threshold_minutes < 1 THEN 'unmonitored'			WHEN late_threshold_minutes < minutes_since_update THEN 'late'			ELSE 'okay'		END AS dataset_status,		CASE			WHEN late_threshold_minutes < 1 THEN false			WHEN minutes_since_update - late_threshold_minutes > 0 THEN true			ELSE false		END AS is_late,		CASE			WHEN late_threshold_minutes < 1 THEN 0			WHEN minutes_since_update - late_threshold_minutes > 0 THEN 1			ELSE 0		END AS is_late_number  FROM datasets;ALTER VIEW api.domo_dataset_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','domo_dataset_plus','Proof-of-concept for a Domo DataSet size and last update monitor.','RDS Domo DataSet Age');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:inv_plus.sqlCREATE OR REPLACE VIEW api.inv_plus ASSELECT    inv.id,    inv.marked_for_deletion,    inv.item_id,    inv.inv_no,    inv.their_name,--  Lookup fields    coalesce (item.name_, '')                  AS item_name,    coalesce (inv_getdesc(inv.id), '')         AS description,    coalesce (facility_location.name_,'')      AS facility_location,    facility_get_name (standard_faclity_id)    AS standard_facility,    facility_get_name (store_at_facility_id)   AS store_at_facility,--  More raw fields    inv.created_dts,    inv.updated_dts,    inv.serial_no_as_of_dts,    inv.qty,    inv.flow,    inv.flow_long,    inv.par,    inv.last_seen_date,    inv.their_next_repair_date,    inv.last_sterilized_date,    inv.repair_last_repair_date,    inv.is_found,    inv.is_go_live_perm_printed,    inv.is_facility_loc_inherited,    inv.is_contents_incomplete,    inv.is_deactivated,    inv.needs_repair,    inv.is_searched_but_not_found,    inv.is_wrong_loc,    inv.is_handwritten_label,    inv.is_sleeping,    inv.category,    inv.their_id,    inv.their_location,    inv.created_by,    inv.updated_by,    inv.their_id_scrubbed,    inv.crossing_status,    inv.their_raw_name,    inv.comments_,    inv.their_bar_code,    inv.loc_rack,    inv.loc_row,    inv.loc_bin,    inv.loc_note,    inv.serial_no,    inv.data_cleanse_classification,    inv.repair_next_due,    inv.repair_last_repaired_by,    inv.msgs    FROM inv LEFT JOIN item              ON inv.item_id           = item.id LEFT JOIN facility_location ON facility_location.id  = inv.facility_location_id ;ALTER VIEW api.inv_plus    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','inv_plus','Inv data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:push_audit_latest.sqlDROP VIEW IF EXISTS api.push_audit_latest;CREATE OR REPLACE VIEW api.push_audit_latest ASWITH latest_push AS (SELECT DISTINCT ON (unique_path,data_file_id)        server.server_name_ AS server_name,        target.unique_path,        minutes_old (audit.inserted_utc_dts) as minutes_old,        audit.records_count,        audit.duration_seconds,		target.schema_name,        target.target_name,        target.target_type,        audit.start_local_dts,        audit.end_local_dts,        audit.end_utc_dts,        audit.inserted_utc_dts,        now() - audit.inserted_utc_dts AS age,        audit.client_user_name,        audit.inserted_by,        audit.version_number,        audit.error_occurred,        audit.push_method_name,        audit.error_text     FROM push_audit       auditLEFT JOIN dba.push_target  target on target.id = audit.target_idLEFT JOIN data_file_info   server on server.id = audit.data_file_idORDER BY unique_path,		 data_file_id,		 end_utc_dts desc)-- Wrapped the search in a CTE above as DISTINCT ON has special requirements for the ORDER BY.-- Now, we can grab the final results and sort them the way we prefer.select *  from latest_pushorder by server_name, unique_path;COMMENT ON VIEW api.push_audit_latest IS'DISTINCT ON with a sort is a Postgres extension and, dang, it is awesome. In standard SQL, a GROUP BY works fine, until you want a value FROM one of the ungrouped columns. Which row out of the group is used for the column? It is random. There are lots of solutions to this but, for straightforward cases, nothing is AS simple AS the Postgres DISTINCT ON. The secret sauce here is the order by! Without that, you get a random row value. Random within the group, but is that random enough.';ALTER VIEW api.push_audit_latest    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','push_audit_latest','Displays the age of the last push by each server to each target. Good for spotting stragglers.','RDS push_audit_latest');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:push_audit_plus.sql-- Create a view onto push_audit formatted as push_audit_plus.-- If push_audit changes, you can update the view to handle the modification smoothly.-- Note: This view is automatically a custom type, with an array type to match. See types_plus.insert_push_audit_plus.DROP VIEW IF EXISTS api.push_audit_plus CASCADE;-- Careful!CREATE OR REPLACE VIEW api.push_audit_plus AS select target.schema_name,        target.target_name,        target.unique_path,        target.target_type,        server.server_name_,        audit.start_local_dts,        audit.end_local_dts,        audit.end_utc_dts,        audit.inserted_utc_dts,        now() - audit.inserted_utc_dts AS age,        minutes_old (audit.inserted_utc_dts) as minutes_old,        audit.client_user_name,        audit.inserted_by,        audit.duration_seconds,        audit.records_count,        audit.version_number,        audit.error_occurred,        audit.push_method_name,        audit.error_text     from push_audit       auditleft join dba.push_target  target on target.id = audit.target_idleft join data_file_info   server on server.id = audit.data_file_id;ALTER TABLE api.push_audit_plus    OWNER TO user_change_structure;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:push_log_domo.sqlCREATE OR REPLACE VIEW api.push_log_domo AS SELECT 	push_log.id,	push_log.data_file_id,	data_file_info.server_name_,	push_log.ib_table_name,	push_log.ib_table_number,	push_log.records_count,	push_log.push_dts,	age(now(), push_log.push_dts) AS age,	minutes_old(push_log.push_dts) AS minutes_old,	data_file_info.app_name,	data_file_info.app_version,	data_file_info.shell_version,	data_file_info.sync_version,	data_file_info.iam_type,	data_file_info.compiled,	data_file_info.merged,	data_file_info.type_of_4d,	data_file_info.version_of_4d,	data_file_info.machine_name,	data_file_info.platform_description,	data_file_info.os_tz_name	FROM (ascendco.push_log	JOIN data_file_info ON ((data_file_info.id = push_log.data_file_id)))   ;ALTER VIEW api.push_log_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','push_log_domo','The server, table name, record counts, and additional server details for every push into Postgres.','RDS push_log_domo');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:push_log_latest.sqlCREATE OR REPLACE VIEW api.push_log_latest ASSELECT DISTINCT ON (ib_table_name,data_file_id)	    *,        NOW() AS dts,        minutes_old(push_dts) AS push_log_minutes_old    FROM push_log_plusORDER BY ib_table_name,		 data_file_id,		 push_dts desc;COMMENT ON VIEW api.push_log_latest IS'DISTINCT ON with a sort is a Postgres extension and, dang, it is awesome. In standard SQL, a GROUP BY works fine, until you want a value FROM one of the ungrouped columns. Which row out of the group is used for the column? It is random. There are lots of solutions to this but, for straightforward cases, nothing is AS simple AS the Postgres DISTINCT ON. The secret sauce here is the order by! Without that, you get a random row value. Random within the group, but is that random enough.';ALTER VIEW api.push_log_latest    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','push_log_latest','Displays the age of the last push by each server to each table. Good for spotting stragglers.','RDS push_log_latest');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:quality_domo.sqlDROP VIEW IF EXISTS api.quality_domo;-- Query addapted from Will on Feb 11, 2021.CREATE VIEW api.quality_domo ASSELECT    q_event.id                                          AS "id",	q_event.created_dts        						    AS "CreatedDTS",	q_event.datetime_local        						AS "DateTime_Local",    COALESCE (q_type.name_,''::citext)                  AS "EventType",    COALESCE (q_level.name_,''::citext)                 AS "Level",    COALESCE (q_subtype.name_,''::citext)               AS "TheirSubType",    COALESCE (q_subtype.name_,''::citext)               AS "AscendcoSubType",    q_event.status                                      AS "status",    q_event.status_when_name                            AS "UserName",    inv.inv_no                                          AS "InvNo",    item.name_                                          AS "ItemName",    COALESCE (item_type.name_,''::citext)               AS "ItemType",    COALESCE (specialty.name_,''::citext)               AS "Specialty",    COALESCE (facility_department.name_,''::citext)     AS "Department",    COALESCE (facility.name_, ''::citext)               AS "FacilityName",    COALESCE (hsys.name_, ''::citext)                   AS "HsysName",	q_event.datetime_local,    scan_date.date_actual                               AS "Quality_Date",    scan_date.day_of_week_usa                           AS "Quality_DayOfWeek",    scan_date.day_name_abbreviated                      AS "Quality_DayName",    scan_date.week_of_year_fiscal_name                  AS "Quality_FiscalWeek",   --  Week 24 2020    scan_date.week_of_year_fiscal                       AS "Quality_FiscalWeekNo", --  2020-24    scan_date.month_actual                              AS "Quality_MonthNo",    scan_date.month_actual_name_abbreviated             AS "Quality_MonthName",    scan_date.month_fiscal                              AS "Quality_FiscalMonthNo",    scan_date.month_fiscal_name_abbreviated             AS "Quality_FiscalMonthName",    to_char(scan_date.year_actual, 'fm0000')            AS "Quality_Year",    scan_date.year_actual                               AS "Quality_YearNo",    scan_date.fiscal_year_abbr::int                     AS "Quality_FiscalYearNo",    (date_part('hour'::text, q_event.datetime_local))::integer                           AS "Quality_HourOfDay",    hour_bin_get_bin((date_part('hour'::text,q_event.datetime_local))::integer)          AS "Quality_HourBin",    hour_bin_get_bin_label((date_part('hour'::text, q_event.datetime_local))::integer)   AS "Quality_HourBinName"FROM ascendco.q_eventLEFT JOIN ascendco.q_subtype            ON ascendco.q_event.qsub_type_id         = ascendco.q_subtype.idLEFT JOIN ascendco.q_level              ON ascendco.q_subtype.qlevel_id          = ascendco.q_level.idLEFT JOIN ascendco.q_type               ON ascendco.q_subtype.qtype_id           = ascendco.q_type.idLEFT JOIN ascendco.facility             ON ascendco.q_event.facility_id          = ascendco.facility.idLEFT JOIN ascendco.hsys                 ON ascendco.facility.hsys_id             = ascendco.hsys.idLEFT JOIN ascendco.inv                  ON ascendco.q_event.inv_id               = ascendco.inv.idLEFT JOIN ascendco.item                 ON ascendco.inv.item_id                  = ascendco.item.idLEFT JOIN ascendco.facility_department  ON ascendco.item.facility_department_id  = ascendco.facility_department.idLEFT JOIN ascendco.specialty            ON ascendco.item.specialty_id            = ascendco.specialty.idLEFT JOIN ascendco.item_type            ON ascendco.item.item_type_id            = ascendco.item_type.idJOIN calendar_day_plus scan_date           ON (scan_date.calendar_id = facility.calendar_id         AND scan_date.date_actual = date(ascendco.q_event.datetime_local))WHERE ascendco.q_event.marked_for_deletion = 'false';ALTER VIEW api.quality_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','quality_domo','quality data for Domo.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:rcl_combined.sqlCREATE OR REPLACE VIEW api.rcl_combined ASSELECT	record_changes_log.id,	record_changes_log.record_id,    record_changes_log.table_number,    record_changes_log.updated_dts,    record_changes_log.updated_by,    record_changes_log.app_type,    record_changes_log.machine_name,    record_changes_log_detail.id AS details_id,    record_changes_log_detail.field_name,    record_changes_log_detail.old_value,    record_changes_log_detail.new_valueFROM (record_changes_logJOIN record_changes_log_detail ON ((record_changes_log.id = record_changes_log_detail.record_changes_log_id)));ALTER VIEW api.rcl_combined    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','rcl_combined','Consolidated old:new details of a record_change_log and its items. Comparable to the originl [RecordChangesLog] in IceBerg/Sonar.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:rcl_detail.sqlCREATE OR REPLACE VIEW api.rcl_detail ASSELECT	 record_changes_log_detail.id,	 record_changes_log_detail.record_changes_log_id,  	 record_changes_log_detail.field_name, 	 record_changes_log_detail.old_value,	 record_changes_log_detail.new_value,	 record_changes_log_detail.record_idFROM record_changes_log_detail;ALTER VIEW api.rcl_detail    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','rcl_detail','The item (child) part of an rcl, showing a single field old:new.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:rcl.sqlCREATE OR REPLACE VIEW api.rcl ASSELECT	record_changes_log.id,	record_changes_log.table_number,	record_changes_log.record_id,	record_changes_log.updated_dts,	record_changes_log.updated_by,	record_changes_log.app_type,	record_changes_log.machine_nameFROM record_changes_log;ALTER VIEW api.rcl    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','rcl','The record_change_log (parent) event, which  may have any number of related details.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:stat_facility_domo.sqlCREATE OR REPLACE VIEW api.stat_facility_domo AS SELECT stat_facility.id AS "ID",    stat_facility.date_ AS "Date",    stat_facility.category AS "Category",    stat_facility.item_type AS "ItemType",    stat_facility.stat_type AS "StatType",    stat_facility.is_most_recent AS "isMostRecent",    stat_facility.in_data_cleanse_scope AS "inDataCleanseScope",    COALESCE(hsys.name_, ''::citext) AS "HsysName",    COALESCE(facility.name_, ''::citext) AS "FacilityName",    stat_facility.items_inactive AS "Items_Inactive",    stat_facility.items_count AS "Items_Count",    stat_facility.items_qty AS "Items_Qty",    stat_facility.items_inventoried AS "Items_Inventoried",    stat_facility.items_to_inventory AS "Items_ToInventory",    stat_facility.items_named AS "Items_Named",    stat_facility.items_to_name AS "Items_ToName",    stat_facility.inst_qty AS "Inst_Qty",    stat_facility.items_has_loc AS "Items_HasLoc",    stat_facility.items_missing_locs AS "Items_MissingLocs",    stat_facility.item_prods_count AS "ItemProds_Count",    stat_facility.item_prods_missing_part_nos_thier AS "ItemProds_MissingPartNosThier",    stat_facility.item_prods_missing_vendors_thier AS "ItemProds_MissingVendorsThier",    stat_facility.item_prods_dr_pref AS "ItemProds_DrPref",    stat_facility.item_prods_critical AS "ItemProds_Critical",    stat_facility.item_prods_not_linked AS "ItemProds_NotLinked",    stat_facility.item_prods_missing_part_nos AS "ItemProds_MissingPartNos",    stat_facility.item_prods_missing_vendors AS "ItemProds_MissingVendors",    stat_facility.item_prods_cant_determine AS "ItemProds_CantDetermine",    stat_facility.item_prods_linked AS "ItemProds_Linked",    stat_facility.sup_prods_count AS "SupProds_Count",    stat_facility.sups_count AS "Sups_Count",    stat_facility.prods_count AS "Prods_Count",    stat_facility.prods_with_pic AS "Prods_WithPic",    stat_facility.prods_without_pic AS "Prods_WithoutPic",    stat_facility.item_prods_verified AS "ItemProds_Verified",    stat_facility.item_prods_expert_linked AS "ItemProds_ExpertLinked",    stat_facility.item_prods_dup_names_their AS "ItemProds_DupNamesTheir",    stat_facility.item_prods_dup_names AS "ItemProds_DupNames",    stat_facility.prods_named AS "Prods_Named",    stat_facility.part_nos_fixed AS "PartNos_Fixed",    stat_facility.invs_inactive AS "Invs_Inactive",    stat_facility.invs_count AS "Invs_Count",    stat_facility.invs_found AS "Invs_Found",    stat_facility.emr_items_count AS "EmrItems_Count",    stat_facility.emr_items_linked AS "EmrItems_Linked",    stat_facility.emr_items_matches_their_name AS "EmrItems_MatchesTheirName",    stat_facility.emr_items_matches_our_name AS "EmrItems_MatchesOurName",    stat_facility.emr_items_no_match_their_name AS "EmrItems_NoMatchTheirName",    stat_facility.emr_items_no_match_our_name AS "EmrItems_NoMatchOurName",    stat_facility.emr_items_dups AS "EmrItems_Dups"    FROM stat_facility	LEFT JOIN hsys 		ON (stat_facility.hsys_id     = hsys.id)	LEFT JOIN facility	ON (stat_facility.facility_id = facility.id) ;ALTER VIEW api.stat_facility_domo    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','stat_facility_domo','[Stat_Facility] data.','PROD Stat Facility');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:target_count_comparison.sqlDROP VIEW IF EXISTS api.target_count_comparison;CREATE VIEW api.target_count_comparison AS-- Ummm...this all feels a bit too involved. There's likely a simpler way.-- Still it's fast, and it works. I verified the output by manually checking-- what should be generated in advance.---------------------------------------------------- First get two days of counts---------------------------------------------------- The dba.target_count table holds a daily count snapshot for tables of interest.WITHsource_data AS (select hsys_id,       qualified_name,       count_date,       current_date     as today,       current_date - 1 as yesterday,       records_count  from target_count where count_date = current_date    or count_date = current_date - 1),---------------------------------------------------- Now generate comparisons based on the two days---------------------------------------------------- Use the lag() function to look back to the previous day.-- The coalesce calls are to get a 0 insead of NULL when there is no reading.comparison_data AS (select hsys_id,       qualified_name,       today,       count_date,       yesterday,       coalesce(lag(records_count,1) OVER          (partition by hsys_id, qualified_name  -- GROUP by hsys and target.               order by count_date ASC)          -- Sort the grouping by date.        ,0) as yesterdays_count,       coalesce (records_count) as todays_count  from source_data),-------------------------------------------------- Add change count and comment label------------------------------------------------comparisons_plus AS (select hsys.name_ AS hsys_name,       qualified_name,       yesterday,       count_date,       today,       yesterdays_count,       todays_count,       todays_count - yesterdays_count as daily_change,       case          when todays_count - yesterdays_count < 0 then '? Records were removed'          when todays_count - yesterdays_count = 0 then '* No data was added'          when todays_count - yesterdays_count > 0 then '+ Records were added '      end as comments from comparison_data join hsys on hsys.id = comparison_data.hsys_id) -------------------------------------------------- -- Reduce to just the rows we want -------------------------------------------------- select *   from comparisons_plus  where count_date = current_date;COMMENT ON VIEW api.target_count_comparison IS 'Compare target row counts of interest between today and yesterday. Not really meant to be called live, this view is more of a place to stash a query.';ALTER VIEW api.target_count_comparison    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','target_count_comparison','Compare target row counts of interest between today and yesterday. Not really meant to be called live, this view is more of a place to stash a query and to call from a scheduled task.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:api:views.sqlCREATE OR REPLACE VIEW api.views ASSELECT schema_name,       view_name,       domo_dataset,       description  FROM dba.view_catalog;ALTER VIEW api.views    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('api','views','You''re looking at it! This is the public face of dba.view_catalog. Not all views are listed, only ones of interest.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:activity_plus.sqlDROP VIEW IF EXISTS ascendco.activity_plus;CREATE OR REPLACE VIEW ascendco.activity_plus ASSELECT activity.id,       coalesce(hsys.name_, 'Unknown')                         AS hsys_name,       facility.id                                             AS facility_id,       coalesce(facility.name_, 'Unknown')                     AS facility_name,       coalesce(facility_activities.name_, 'Unknown')          AS activity_name,       coalesce(data_file_info.server_name_, 'Unknown')        AS server_name,       activity.start_dts,       activity.done_dts,       activity.duration_seconds,       activity.updated_dts,       activity.marked_for_deletion,       activity.other_desc,       coalesce(web_user.name_full, 'Unknown')                 AS user_name,       activity.created_dts,       activity.created_by,       activity.updated_by--   Note: activity doesn't have hsys_id, you neeed to load facility, and get the hsys_id from there.     FROM activityLEFT JOIN facility_activities  ON facility_activities.id   = activity.facility_activities_idLEFT JOIN web_user             ON web_user.id              =  activity.web_user_idLEFT JOIN data_file_info       ON data_file_info.id        =  activity.last_updated_by_data_file_idLEFT JOIN facility             ON facility.id              =  activity.facility_idLEFT JOIN hsys                 ON hsys.id                  =  facility.hsys_id;ALTER VIEW ascendco.activity_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','activity_plus','activity data, with lookup values');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:clinic_plus.sqlCREATE OR REPLACE VIEW ascendco.clinic_plus AS   SELECT clinic.id,          clinic.name_,          clinic.receive_at_clinic,          coalesce (hsys.name_, '')  AS hsys_name,          clinic.marked_for_deletion,          clinic.created_dts,          clinic.updated_dts,          clinic.created_by,          clinic.updated_by     FROM clinicLEFT JOIN hsys     ON hsys.id     = clinic.hsys_id;ALTER VIEW ascendco.clinic_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','clinic_plus','clinc data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:data_file_info_pg_details.sqlCREATE OR REPLACE VIEW ascendco.data_file_info_pg_details AS     SELECT data_file_info.last_updated_dts,            age(now(), data_file_info.last_updated_dts) AS age,            minutes_old(last_updated_dts) AS minutes_old,            jsonb_path_query (data_file_info.iam,'$.organization') as organization,            jsonb_path_query (data_file_info.iam,'$.pgsql.host_name') as host_name,            jsonb_path_query (data_file_info.iam,'$.pgsql.database_name') as database_name,            jsonb_path_query (data_file_info.iam,'$.pgsql.use_ssh') as use_ssh,            jsonb_path_query (data_file_info.iam,'$.pgsql.app_type') as app_type,            jsonb_path_query (data_file_info.iam,'$.pgsql.use_new_config_system') as use_new_config_system,            jsonb_path_query (data_file_info.iam,'$.pgsql.go_full_diagnostic') as go_full_diagnostic,            jsonb_path_query (data_file_info.iam,'$.pgsql.log_errors_locally') as log_errors_locally,            jsonb_path_query (data_file_info.iam,'$.pgsql.maximum_push_size_kb') as maximum_push_size_kb,            jsonb_path_query (data_file_info.iam,'$.pgsql.display_timing_results') as display_timing_results,            data_file_info.os_tz_name,            data_file_info.server_name_,            data_file_info.app_name,            data_file_info.app_version,            data_file_info.shell_version,            data_file_info.sync_version,            data_file_info.compiled,            data_file_info.merged,            data_file_info.iam_type,            data_file_info.type_of_4d,            data_file_info.version_of_4d,            data_file_info.machine_name,            data_file_info.platform_description,            data_file_info.id,            data_file_info.iam,            data_file_info.table_stats       FROM data_file_info;ALTER VIEW ascendco.data_file_info_pg_details    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','data_file_info_pg_details','This view combines basic machine description details and extracted Postgres IAM settings into a searchable view.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:data_file_info_table_stats.sqlCREATE OR REPLACE VIEW ascendco.data_file_info_table_stats AS	 SELECT data_file_info.last_updated_dts,			age(now(), data_file_info.last_updated_dts) AS age,			minutes_old(last_updated_dts) AS minutes_old,			data_file_info.os_tz_name,			data_file_info.server_name_,			data_file_info.app_name,			data_file_info.app_version,			data_file_info.shell_version,			data_file_info.sync_version,			data_file_info.compiled,			data_file_info.merged,			data_file_info.iam_type,			data_file_info.type_of_4d,			data_file_info.version_of_4d,			data_file_info.machine_name,			data_file_info.platform_description,			data_file_info.id,			data_file_info.iam,			data_file_info.table_stats,			expanded_data.table_name,			expanded_data.record_count,			expanded_data.table_number       FROM data_file_infoCROSS JOIN jsonb_to_recordset(data_file_info.table_stats) AS expanded_data (			table_name citext,			record_count integer,			table_number integer		);ALTER VIEW ascendco.data_file_info_table_stats	OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','data_file_info_table_stats','The data_file_info snapshot for each server includes table counts for each IceBerg/Sonar table. This view expands the packed counts into a searchable table.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:domo_passthrough_counts.sqlCREATE OR REPLACE VIEW ascendco.domo_passthrough_counts AS   SELECT hsys.name_     AS hsys_name,          facility.name_ AS facility_name,          dataset_name,          count(*)     FROM domo_passthroughLEFT JOIN hsys      ON (hsys.id     = domo_passthrough.hsys_id)LEFT JOIN facility  ON (facility.id = domo_passthrough.facility_id)GROUP BY hsys_name,         facility_name,         dataset_name;ALTER VIEW ascendco.domo_passthrough_counts    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','domo_passthrough_counts','Counts the records in domo_passthrough, broken out by hsys, facility and DataSet. This is a quick way to see what''s going into domo_passthrough.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:domo_passthrough_plus.sqlDROP VIEW IF EXISTS ascendco.domo_passthrough_plus;CREATE OR REPLACE VIEW ascendco.domo_passthrough_plus AS    SELECT domo_passthrough.id,	       domo_passthrough.source_id,	       domo_passthrough.key_supplement,	       hsys.name_ AS hsys_name,	       facility.name_ AS facility_name,	       domo_passthrough.dataset_name,	       domo_passthrough.view_version,	       domo_passthrough.created_dts,		   age(now(), domo_passthrough.created_dts) AS age,	       minutes_old(domo_passthrough.created_dts) AS minutes_old,		   domo_passthrough.from_dts,	       domo_passthrough.to_dts,	       domo_passthrough.data     FROM domo_passthroughLEFT JOIN hsys      ON (hsys.id     = domo_passthrough.hsys_id)LEFT JOIN facility  ON (facility.id = domo_passthrough.facility_id);ALTER VIEW ascendco.domo_passthrough_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','domo_passthrough_plus','domo_passthrough data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:facility_activities_plus.sqlCREATE OR REPLACE VIEW ascendco.facility_activities_plus ASSELECT	facility_activities.id,         facility_activities.name_,         hsys.name_                      AS hsys_name,         facility.name_                  AS facility_name,         data_file_info.server_name_     AS server_name,         facility_activities.created_dts,         facility_activities.updated_dts,         facility_activities.marked_for_deletion,         facility_activities.created_by,         facility_activities.updated_by	 FROM facility_activitiesLEFT JOIN facility       ON facility_activities.facility_id = facility.idLEFT JOIN hsys           ON facility.hsys_id = hsys.idLEFT JOIN data_file_info ON data_file_info.id = facility_activities.last_updated_by_data_file_id ;ALTER VIEW ascendco.facility_activities_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','facility_activities_plus','facility_activities data, with lookup values');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:facility_department_plus.sqlCREATE OR REPLACE VIEW ascendco.facility_department_plus AS   SELECT facility_department.id,          coalesce(facility.name_, '') as facility_name,          facility_department.name_,          facility_department.label_name,          facility_department.inv_audit,          facility_department.their_id,          facility_department.is_available_in_sonar,          facility_department.receive_at_dept,          facility_department.is_from_emr,          facility_department.created_dts,          facility_department.updated_dts,          facility_department.created_by,          facility_department.updated_by,          facility_department.marked_for_deletion     FROM facility_departmentLEFT JOIN facility ON facility.id = facility_department.facility_id;ALTER VIEW ascendco.facility_department_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','facility_department_plus','facility_department data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:facility_plus.sqlDROP VIEW IF EXISTS ascendco.facility_plus;CREATE OR REPLACE VIEW ascendco.facility_plus ASSELECT	f.id,	    coalesce (hsys.name_, '')                                   AS hsys_name,		f.name_,		coalesce (spd_facility.name_,'')                            AS default_spd_facility,        f.tz_name                                                   AS tz_name_ib,        convert_ib_timezone_name(f.tz_name)                         AS tz_name_postgres,        coalesce (calendar.calendar_name, '')                       AS calendar_name,		f.marked_for_deletion, 		form_template_get_name (f.production_label_form_id)        AS production_label, 		form_template_get_name (f.permanent_label_form_id)         AS permanent_label, 		form_template_get_name (f.missing_inst_label_form_id)      AS missing_inst_label, 		form_template_get_name (f.facility_location_label_form_id) AS facility_location_label, 		form_template_get_name (f.sterilizer_label_form_id)        AS sterilizer_label, 		form_template_get_name (f.user_badge_label_form_id)        AS user_badge_label, 		form_template_get_name (f.workstation_label_form_id)       AS workstation_label,		f.created_dts,		f.updated_dts,		f.sonar_auto_logout_minutes,		f.sonar_auto_logout_dialog_minutes,		f.num_ors,		f.sonar_go_live_date,		f.is_count_sheet_source_truth,		f.hide_doc_names_for_stats,		f.is_item_master_live,		f.is_sonar_live,		f.sterilizer_print_at_sterilizing,		f.sterilizer_print_at_cooling,		f.sterilizer_print_at_released,		f.can_set_all_found_in_assembly,		f.their_id,		f.created_by,		f.updated_by,		f.reporting_name,		f.label_name,		f.sonar_name_full,		f.sonar_count_sheet_form_name,		f.sterilize_alert_level,		f.sonar_scanner_stop_char,		f.emr_location_name	     FROM facility f	LEFT JOIN hsys 		ON (f.hsys_id      =  hsys.id)	LEFT JOIN calendar	ON (f.calendar_id  =  calendar.id) -- SELF JOIN to get the name of the related default SPD facility, if there is one.    LEFT JOIN facility spd_facility ON (spd_facility.id =  f.default_spd_facility_id);ALTER VIEW ascendco.facility_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','facility_plus','facility data, with lookup values');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:focus_plus.sqlCREATE OR REPLACE VIEW ascendco.focus_plus AS   SELECT		scase_id,		hsys_id,		hsys.name_ as hsys_name,		facility_id,		facility_name,		sched_dts,		or_name,		case_seq,		desc_,		status,		transport_from,		surgeon_name,		proc_name,		when_     FROM focusLEFT JOIN hsys     ON (hsys.id     = focus.hsys_id);ALTER VIEW ascendco.focus_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','focus_plus','focus data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:item_arch_plus.sqlCREATE OR REPLACE VIEW ascendco.item_arch_plus AS   SELECT item_arch.id,          item_arch.name_,          item_arch.type_,          coalesce(facility.name_,'') as facility_name,       -- clinic.name_ as clinic_name, -- nope, don't have ascendco.clinic yet          item_arch.created_dts,          item_arch.updated_dts     FROM item_archLEFT JOIN facility ON facility.id = item_arch.facility_id;ALTER VIEW ascendco.item_arch_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','item_arch_plus','item_arch data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:need_plus.sqlCREATE OR REPLACE VIEW ascendco.need_plus AS   SELECT need.id,          need.hsys_id,          need.facility_id,          need.item_id,          item.name_ AS item_name,          facility.name_ AS facility_name,          hsys.name_ AS hsys_name,          need.percent_down,          need.created_dts,          need.next_case_dts,          need.flow,          need.qty_circulation,          need.qty_ready_everywhere,          need.qty_ready_here,          need.qty_sched_everywhere,          need.qty_sched_here,          need.qty_sterile_everywhere,          need.qty_sterile_here,          need.qty_suggest_sterilize,          need.qty_total,          need.qty_here,          need.ready_vs_need_defecit,          need.sched_sort,          need.sort_rank,          need.suggest_transport,          need.next_needed,          need.or_name,          need.status,          need.status_sort,          need.when_     FROM needLEFT JOIN item     ON (item.id     = need.item_id)LEFT JOIN facility ON (facility.id = need.facility_id)LEFT JOIN hsys     ON (hsys.id     = need.hsys_id);ALTER VIEW ascendco.need_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','need_plus','need data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:outlier_change_plus.sqlCREATE OR REPLACE VIEW ascendco.outlier_change_plus AS   SELECT outlier_rule.id AS outlier_rule_id,          outlier_rule.schema_name,          outlier_rule.table_name,          outlier_rule.column_name,          outlier_change.id,          outlier_change.value_was,          outlier_change.set_to,          outlier_change.change_count,          outlier_change.last_changed_dts     FROM outlier_changeLEFT JOIN outlier_rule ON (outlier_change.outlier_rule_id = outlier_rule.id)    ;ALTER VIEW ascendco.outlier_change_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','outlier_change_plus','outlier_change data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:outlier_rule_plus.sqlCREATE OR REPLACE VIEW ascendco.outlier_rule_plus AS   SELECT id,          schema_name,          table_name,          column_name,          threshold,          set_to,          (SELECT count(*) FROM outlier_change WHERE outlier_rule_id = outlier_rule.id) AS change_rows    FROM  outlier_rule;ALTER VIEW ascendco.outlier_rule_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','outlier_rule_plus','outlier_rule data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:productivity_detail_plus.sqlDROP VIEW IF EXISTS ascendco.productivity_detail_plus;CREATE OR REPLACE VIEW ascendco.productivity_detail_plus AS   SELECT		    data_file_info.server_name_ AS "server_name",		    hsys.name_ AS hsys_name,		    facility.name_ AS facility_name,		    iceberg_table.table_name as source_table_name,			productivity_detail.user_label, -- We have user_id and can join over to web_user, if that's better.			productivity_detail.start_time_dts,			productivity_detail.start_date,			productivity_detail.time_label,			productivity_detail.duration,			productivity_detail.year_and_month, -- This is the partition key			productivity_detail.assembly_inst,			productivity_detail.assembly_pack,			productivity_detail.assembly_tray,			productivity_detail.assembly_points,			productivity_detail.assembly_seconds_trays,			productivity_detail.assembly_seconds_overall,			productivity_detail.pause_seconds,			productivity_detail.pause_time,			productivity_detail.duration_seconds,			productivity_detail.description,			productivity_detail.activity,			-- Source IDs			productivity_detail.facility_id,			productivity_detail.user_id,			productivity_detail.data_file_id,			productivity_detail.source_table_number,			productivity_detail.id AS source_record_id,			productivity_detail.source_record_row_counter    FROM  productivity_detailLEFT JOIN ascendco.iceberg_table  ON (productivity_detail.source_table_number = iceberg_table.table_number)LEFT JOIN ascendco.facility       ON (productivity_detail.facility_id         = facility.id)LEFT JOIN ascendco.hsys           ON (hsys.id                                 = facility.hsys_id)LEFT JOIN ascendco.data_file_info ON (productivity_detail.data_file_id        = data_file_info.id);ALTER VIEW ascendco.productivity_detail_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','productivity_detail_plus','productivity_detail data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:rcl_detail_hash_this.sql/* Find duplicates like this:select distinct rcl_detail_hash_this.record_changes_log_id,        rcl_detail_hash_this.updated_dts,        count(*) as duplicates   from rcl_detail_hash_thisgroup by rcl_detail_hash_this.record_changes_log_id,         rcl_detail_hash_this.updated_dts,         hashtext(rcl_detail_hash_this::text)  having count(*) > 1 order by  rcl_detail_hash_this.updated_dts desc,   -- I'd like to know if the bug is still active 		    rcl_detail_hash_this.record_changes_log_id          */DROP VIEW IF EXISTS ascendco.rcl_detail_hash_this;CREATE OR REPLACE VIEW ascendco.rcl_detail_hash_this ASSELECT record_changes_log.updated_dts,		record_changes_log.updated_by,		record_changes_log_detail.id,		record_changes_log_detail.record_changes_log_id,		record_changes_log_detail.field_name,		record_changes_log_detail.old_value,		record_changes_log_detail.new_value,		record_changes_log_detail.record_idFROM record_changes_log_detailLEFT JOIN record_changes_log ON (record_changes_log.id = record_changes_log_detail.record_changes_log_id);ALTER VIEW ascendco.rcl_detail_hash_this    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('ascendco','rcl_detail_hash_this','Historical tool: Helped finding duplicate RCL IDs.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:rep_plus.sqlCREATE OR REPLACE VIEW ascendco.rep_plus AS   SELECT rep.id,          rep.name_,          rep.phone,          rep.email,          coalesce (hsys.name_, '')  AS hsys_name,          coalesce (sup.name_,  '')  AS sup_name,          coalesce (web_user.name_full, '')  AS user_name,          rep.marked_for_deletion,          rep.created_dts,          rep.updated_dts     FROM repLEFT JOIN hsys     ON hsys.id     = rep.hsys_idLEFT JOIN sup      ON sup.id      = rep.sup_idLEFT JOIN web_user ON web_user.id = rep.user_id;ALTER VIEW ascendco.rep_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','rep_plus','rep data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:stat_facility_plus.sqlCREATE OR REPLACE VIEW ascendco.stat_facility_plus ASSELECT	stat_facility.id,	date_,	category,	item_type,	stat_type,	is_most_recent,	in_data_cleanse_scope,	stat_facility.facility_id,	stat_facility.hsys_id,    COALESCE(hsys.name_,'') AS hsys_name,    COALESCE(facility.name_,'') AS facility_name,	items_inactive,	items_count,	items_qty,	items_inventoried,	items_to_inventory,	items_named,	items_to_name,	inst_qty,	items_has_loc,	items_missing_locs,	item_prods_count,	item_prods_missing_part_nos_thier,	item_prods_missing_vendors_thier,	item_prods_dr_pref,	item_prods_critical,	item_prods_not_linked,	item_prods_missing_part_nos,	item_prods_missing_vendors,	item_prods_cant_determine,	item_prods_linked,	sup_prods_count,	sups_count,	prods_count,	prods_with_pic,	prods_without_pic,	item_prods_verified,	item_prods_expert_linked,	item_prods_dup_names_their,	item_prods_dup_names,	prods_named,	part_nos_fixed,	invs_inactive,	invs_count,	invs_found,	emr_items_count,	emr_items_linked,	emr_items_matches_their_name,	emr_items_matches_our_name,	emr_items_no_match_their_name,	emr_items_no_match_our_name,	emr_items_dups	FROM  stat_facility	LEFT JOIN hsys 		ON (stat_facility.hsys_id     = hsys.id)	LEFT JOIN facility	ON (stat_facility.facility_id = facility.id) ;ALTER VIEW ascendco.stat_facility_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','stat_facility_plus','facility data, with lookup values');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:sup_plus.sqlDROP VIEW IF EXISTS ascendco.sup_plus;CREATE OR REPLACE VIEW ascendco.sup_plus AS   SELECT sup.id,          sup.name_,          coalesce(sup_parent.name_,'') AS parent_name,          sup.is_custom_by_facility,          coalesce(facility.name_,'')   AS facility_name,          sup.is_available_for_loaners,          sup.marked_for_deletion,          sup.created_by,          sup.updated_by,          sup.created_dts,          sup.updated_dts     FROM supLEFT JOIN facility   ON facility.id   = sup.custom_facility_idLEFT JOIN sup_parent ON sup_parent.id = sup.sup_parent_id;ALTER VIEW ascendco.sup_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','sup_plus','sup data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:text_collection_item_plus.sqlDROP VIEW IF EXISTS ascendco.text_collection_item_plus;CREATE OR REPLACE VIEW ascendco.text_collection_item_plus AS   SELECT text_collection_item.collection_id,          text_collection.collection_name,          text_collection_item.text,          text_collection_item.source_id,          coalesce(facility.name_,'') AS facility_name,          text_collection.added_dts,          text_collection.retain     FROM text_collection_itemLEFT JOIN text_collection ON (text_collection.id = text_collection_item.collection_id)LEFT JOIN facility ON (facility.id = text_collection.facility_id);ALTER VIEW ascendco.text_collection_item_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','text_collection_item_plus','text_collection_item data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:ascendco:text_collection_plus.sqlDROP VIEW IF EXISTS ascendco.text_collection_plus;CREATE OR REPLACE VIEW ascendco.text_collection_plus AS   SELECT text_collection.id,          text_collection.collection_name,          coalesce(facility.name_,'') AS facility_name,          (select count(*) from text_collection_item where collection_id = text_collection.id) as items_count,          text_collection.added_dts,          text_collection.retain     FROM text_collectionLEFT JOIN facility ON (facility.id = text_collection.facility_id);ALTER VIEW ascendco.text_collection_plus    OWNER TO user_change_structure;----------------------------------------------- Register view---------------------------------------------CALL view_register ('ascendco','text_collection_plus','text_collection data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:test_result_plus.sqlDROP VIEW IF EXISTS dba.test_result_plus;CREATE OR REPLACE VIEW dba.test_result_plus ASSELECT-- test_result tr source table-- test_case  tc  required parent table-- patch_log  tl  optional parent table	tr.test_passed,	tc.object_class,	tc.object_schema,	tc.object_name,	tc.function_signature,	tc.test_name,	tr.id,	tr.result_dts,	tr.server_address,	tr.database_name,	tr.pg_version,	tr.user_name,	tr.diagnostics,	tr.summary,	tc.test_code,    tc.object_schema = 'IB_not_Postgres' as is_an_ib_test,	tc.rds_only,	tc.modifies_data,	tc.expected_response,	tr.actual_response,	tc.expected_error,	tr.actual_error,	tc.expected_outcome,	tr.actual_outcome,    tc.id as test_case_id,	tc.response_type,	tc.comparison_options,	tc.setup_code,	tc.teardown_codeFROM test_result    AS trLEFT JOIN test_case AS tc ON (tc.id = tr.test_case_id)LEFT JOIN patch_log AS pl ON (pl.id = tr.patch_log_id);ALTER VIEW dba.test_result_plus	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','test_result_plus','test_result data, with lookup values.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:count_rows.sqlDROP VIEW IF EXISTS ascendco.count_rows; -- Previous schema location.DROP VIEW IF EXISTS dba.count_rows;CREATE OR REPLACE VIEW dba.count_rows AS  SELECT table_schema,         table_name,         count_rows(table_schema, table_name)   FROM information_schema.tables  WHERE  table_schema not in ('pg_catalog', 'information_schema') and         table_type='BASE TABLE';ALTER VIEW dba.count_rows    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','count_rows','Counts the rows in each of our tables, including individual partitions. This is likely to be quite slow on RDS.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:ddl_event_log_plus.sqlCREATE OR REPLACE VIEW dba.ddl_event_log_plus AS SELECT event_timestamp,		age(now(), event_timestamp) AS age,		schema_name,		classid::regclass::text as object_class,		object_type,		object_identity,		object_name,		command_tag,		address_args,		address_names,		in_extension,		trigger_event,		id     FROM dba.ddl_event_logLEFT JOIN pg_proc on (pg_proc.oid =  ddl_event_log.objid);ALTER VIEW dba.ddl_event_log_plus	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','ddl_event_log_plus','Displays information about each structure modification made to the server. Including add/modify/delete operations on tables, functions, and more.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:extension_list.sqlCREATE OR REPLACE VIEW dba.extension_list AS  SELECT name,         installed_version,         default_version,         case when installed_version = default_version then '' else 'Out of date' end as update_hint,         comment    FROM pg_available_extensions   WHERE installed_version is not nullORDER BY name;ALTER VIEW dba.extension_list	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','extension_list','Lists installed extensions, with hints where updates are needed.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:function_list.sqlDROP VIEW IF EXISTS dba.function_list;CREATE OR REPLACE VIEW dba.function_list ASSELECT	n.nspname AS SCHEMA,	P.proname AS function_name,	P.proargtypes,	p.oid AS function_oid,	l.lanname AS lang,	typ.typname AS return_type,	CASE WHEN (P.prosecdef = TRUE) THEN 'INVOKER' ELSE 'OWNER' END AS run_as,	pg_get_userbyid (P.proowner) AS owner_name,	P.proisstrict AS STRICT,	P.proretset AS returnset,	P.provolatile AS VOLATILE,	P.proargnames AS paramnames,	pg_get_expr (P.proargdefaults, 'pg_proc' :: regclass) AS defaultvalues,	P.proconfig AS configparams,	P.proallargtypes AS paramalltypes,	obj_description (P.oid) AS COMMENT,	(P.oid <= d.datlastsysoid) AS systable,	typns.nspname AS rettypeschema,	P.proargmodes AS parammodes,	P.procost AS estimcost,	P.prorows AS estimrows,	P.prosrc AS definition,	P.proacl AS aclFROM	pg_proc P	LEFT JOIN pg_type typ ON typ.oid = P.prorettype	LEFT JOIN pg_namespace typns ON typns.oid = typ.typnamespace	LEFT JOIN pg_namespace n ON n.oid = P.pronamespace	LEFT JOIN pg_language l ON l.oid = P.prolang	LEFT JOIN pg_user u ON P.proowner = u.usesysid	LEFT JOIN pg_database d ON d.datname = current_database ()WHERE	has_function_privilege(P.oid,'execute') AND	n.nspname NOT IN ('information_schema','pg_catalog')ORDER BY	n.nspname,	P.proname;ALTER VIEW dba.function_list	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','function_list','Lists all of our functions, with a lot of under-the-hood details.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:role_settings_list.sqlDROP VIEW IF EXISTS dba.role_settings_list;CREATE OR REPLACE VIEW dba.role_settings_list AS   select pg_database.datname,          pg_roles.rolname,          pg_db_role_setting.setconfig     from pg_db_role_settingleft join pg_database ON (pg_database.oid = pg_db_role_setting.setdatabase)left join pg_roles    ON (pg_roles.oid    = pg_db_role_setting.setrole);ALTER VIEW dba.role_settings_list	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','role_settings_list','Displays default connection settings for each role, including search_path.)');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:table_grants.sqlDROP VIEW IF EXISTS ascendco.table_grants; -- Previous schema location.CREATE OR REPLACE VIEW dba.table_grants ASWITHtable_list AS(   SELECT schemaname AS schema_name,		    tablename AS table_name,			quote_ident(schemaname) || '.' || quote_ident(tablename) AS qualified_name,			tableowner AS owner_name      FROM pg_tables     WHERE schemaname not in ('information_schema','pg_catalog')  ORDER BY 3),user_list AS(   SELECT usename AS user_name      FROM pg_user  ORDER BY 1)SELECT  table_list.*,  user_list.user_name,  privilege,  has_table_privilege(user_name, qualified_name, privilege) AS setting  FROM table_list  CROSS JOIN user_list  CROSS JOIN (values    ('delete'), ('insert'), ('references'), ('select'), ('trigger'), ('truncate'), ('update')  ) AS p(privilege); -- unnest('{delete, insert, references, select, trigger, truncate, update}'::text[]) -- That's the other option instead of values() above.ALTER VIEW dba.table_grants    OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','table_grants','Lists each table GRANT for each user. Massive.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:test_failed_focus.sqlDROP VIEW IF EXISTS dba.test_failed_focus;CREATE OR REPLACE VIEW dba.test_failed_focus ASSELECT-- test_result tr source table-- test_case  tc  required parent table	tr.test_passed,	tc.object_class,	tc.object_schema,	tc.object_name,	tc.function_signature,	tc.test_name,	tc.comparison_options,	tr.diagnostics,	tr.summary,	tc.test_code,    tc.object_schema = 'IB_not_Postgres' as is_an_ib_test,	tc.expected_response,	tr.actual_response,	tc.expected_error,	tr.actual_error,	tc.expected_outcome,	tr.actual_outcomeFROM test_result    AS trLEFT JOIN test_case AS tc ON (tc.id = tr.test_case_id)WHERE test_passed = false;ALTER VIEW dba.test_failed_focus	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','test_failed_focus','Finds failed test results, and strips down the output to the most releavant fields.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:test_failed.sqlDROP VIEW IF EXISTS dba.test_failed;CREATE OR REPLACE VIEW dba.test_failed ASSELECT *  FROM test_result_plus WHERE test_passed = false;ALTER VIEW dba.test_failed	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','test_failed','Eesults from test_result_plus where the outcome was failure.');--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:views:dba:view_list.sqlDROP VIEW IF EXISTS dba.view_list;CREATE OR REPLACE VIEW dba.view_list AS    SELECT schemaname::citext AS schema_name,   		   viewname::citext   AS view_name,   		   viewowner::citext  AS view_owner      FROM pg_views     WHERE schemaname NOT IN ('pg_catalog','information_schema','extensions')  ORDER BY viewname;ALTER VIEW dba.view_list	OWNER TO user_change_structure;-------------------------------------------------- Register view------------------------------------------------CALL view_register ('dba','view_list','Lists all of our views, even ''plumbing'' views in types_plus used for INSERTs.');------------------------------------------- Grants-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:grants:rebuild.local.database.grants.sql-------------------------------------------------------------------------------- REGRANT CONNECT.-------------------------------------------------------------------------------- REVOKE ALL.REVOKE ALL PRIVILEGES ON DATABASE squid FROM PUBLIC; -- Clear out the magic PUBLIC pseudo-user.REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_admins;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_api_users;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_cleanup;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_developers;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_iceberg;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_leviathan;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_reporting_super;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_saws;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_server_bots;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_sonar;REVOKE ALL PRIVILEGES ON DATABASE squid FROM rdsadmin;REVOKE ALL PRIVILEGES ON DATABASE squid FROM rds_super;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_admin;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_backup;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_bender;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_change_structure;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_cleanup;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_domo_pull;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_iceberg;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_iceberg_remote;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_saws;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_reporting;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_sonar;-- GRANT CONNECT and CREATE, as appropriate.GRANT CONNECT, CREATE ON DATABASE squid TO rdsadmin;GRANT CONNECT, CREATE ON DATABASE squid TO rds_super;GRANT CONNECT, CREATE ON DATABASE squid TO user_admin;GRANT CONNECT ON DATABASE squid TO user_backup;GRANT CONNECT, CREATE ON DATABASE squid TO user_bender;GRANT CONNECT, CREATE ON DATABASE squid TO user_change_structure;GRANT CONNECT ON DATABASE squid TO user_cleanup;GRANT CONNECT ON DATABASE squid TO user_domo_pull;GRANT CONNECT ON DATABASE squid TO user_iceberg_remote;GRANT CONNECT ON DATABASE squid TO user_iceberg;GRANT CONNECT ON DATABASE squid TO user_leviathan;GRANT CONNECT ON DATABASE squid TO user_reporting;GRANT CONNECT ON DATABASE squid TO user_saws;GRANT CONNECT ON DATABASE squid TO user_sonar;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:grants:rebuild.local.grants.sql-- Log in as postgres to run this script.-------------------------------------------------------------------------------- REGRANT CONNECT.-------------------------------------------------------------------------------- REVOKE ALL.REVOKE ALL PRIVILEGES ON DATABASE squid FROM PUBLIC; -- Clear out the magic PUBLIC pseudo-user.REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_admins;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_api_users;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_cleanup;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_developers;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_iceberg;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_leviathan;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_reporting_super;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_saws;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_server_bots;REVOKE ALL PRIVILEGES ON DATABASE squid FROM group_sonar;REVOKE ALL PRIVILEGES ON DATABASE squid FROM rdsadmin;REVOKE ALL PRIVILEGES ON DATABASE squid FROM rds_super;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_admin;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_backup;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_bender;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_change_structure;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_cleanup;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_domo_pull;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_iceberg;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_iceberg_remote;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_saws;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_reporting;REVOKE ALL PRIVILEGES ON DATABASE squid FROM user_sonar;-- GRANT CONNECT and CREATE, as appropriate.GRANT CONNECT, CREATE ON DATABASE squid TO rdsadmin;GRANT CONNECT, CREATE ON DATABASE squid TO rds_super;GRANT CONNECT, CREATE ON DATABASE squid TO user_admin;GRANT CONNECT ON DATABASE squid TO user_backup;GRANT CONNECT, CREATE ON DATABASE squid TO user_bender;GRANT CONNECT, CREATE ON DATABASE squid TO user_change_structure;GRANT CONNECT ON DATABASE squid TO user_cleanup;GRANT CONNECT ON DATABASE squid TO user_domo_pull;GRANT CONNECT ON DATABASE squid TO user_iceberg;GRANT CONNECT ON DATABASE squid TO user_iceberg_remote;GRANT CONNECT ON DATABASE squid TO user_saws;GRANT CONNECT ON DATABASE squid TO user_reporting;GRANT CONNECT ON DATABASE squid TO user_sonar;-------------------------------------------------------------------------------- REVOKE ALL on each schema.------------------------------------------------------------------------------REVOKE ALL PRIVILEGES ON SCHEMA api FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA api FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA api_queries FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA analytics FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA ascendco FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA dba FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA domains FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA extensions FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA event_triggers FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA passthrough FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA tools FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA types FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA types FROM group_sonar;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM PUBLIC;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_admins;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_api_users;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_cleanup;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_developers;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_iceberg;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_leviathan;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_reporting_super;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_saws;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_server_bots;REVOKE ALL PRIVILEGES ON SCHEMA types_plus FROM group_sonar;-------------------------------------------------------------------------------- GRANT USAGE on each schema and CREATE selectively.-- Note: The api group only gets access to some schemas.------------------------------------------------------------------------------GRANT USAGE, CREATE ON SCHEMA api TO group_admins;GRANT USAGE ON SCHEMA api TO group_api_users;GRANT USAGE ON SCHEMA api TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA api TO group_developers;GRANT USAGE ON SCHEMA api TO group_iceberg;GRANT USAGE ON SCHEMA api TO group_leviathan;GRANT USAGE ON SCHEMA api TO group_reporting_super;GRANT USAGE ON SCHEMA api TO group_saws;GRANT USAGE ON SCHEMA api TO group_server_bots;GRANT USAGE ON SCHEMA api TO group_sonar;GRANT USAGE, CREATE ON SCHEMA api_queries TO group_admins;GRANT USAGE ON SCHEMA api_queries TO group_api_users;GRANT USAGE ON SCHEMA api_queries TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA api_queries TO group_developers;GRANT USAGE ON SCHEMA api_queries TO group_iceberg;GRANT USAGE ON SCHEMA api_queries TO group_leviathan;GRANT USAGE ON SCHEMA api_queries TO group_reporting_super;GRANT USAGE ON SCHEMA api_queries TO group_saws;GRANT USAGE ON SCHEMA api_queries TO group_server_bots;GRANT USAGE ON SCHEMA api_queries TO group_sonar;GRANT USAGE, CREATE ON SCHEMA analytics TO group_admins;GRANT USAGE ON SCHEMA analytics TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA analytics TO group_developers;GRANT USAGE ON SCHEMA analytics TO group_iceberg;GRANT USAGE ON SCHEMA analytics TO group_leviathan;GRANT USAGE ON SCHEMA analytics TO group_reporting_super;GRANT USAGE ON SCHEMA analytics TO group_saws;GRANT USAGE ON SCHEMA analytics TO group_server_bots;GRANT USAGE ON SCHEMA analytics TO group_sonar;GRANT USAGE, CREATE ON SCHEMA ascendco TO group_admins;GRANT USAGE ON SCHEMA ascendco TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA ascendco TO group_developers;GRANT USAGE ON SCHEMA ascendco TO group_iceberg;GRANT USAGE ON SCHEMA ascendco TO group_leviathan;GRANT USAGE ON SCHEMA ascendco TO group_reporting_super;GRANT USAGE ON SCHEMA ascendco TO group_saws;GRANT USAGE ON SCHEMA ascendco TO group_server_bots;GRANT USAGE ON SCHEMA ascendco TO group_sonar;GRANT USAGE, CREATE ON SCHEMA dba TO group_admins;GRANT USAGE ON SCHEMA dba TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA dba TO group_developers;GRANT USAGE ON SCHEMA dba TO group_iceberg;GRANT USAGE ON SCHEMA dba TO group_leviathan;GRANT USAGE ON SCHEMA dba TO group_reporting_super;GRANT USAGE ON SCHEMA dba TO group_saws;GRANT USAGE ON SCHEMA dba TO group_server_bots;GRANT USAGE ON SCHEMA dba TO group_sonar;GRANT USAGE, CREATE ON SCHEMA domains TO group_admins;GRANT USAGE ON SCHEMA domains TO group_api_users;GRANT USAGE ON SCHEMA domains TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA domains TO group_developers;GRANT USAGE ON SCHEMA domains TO group_iceberg;GRANT USAGE ON SCHEMA domains TO group_leviathan;GRANT USAGE ON SCHEMA domains TO group_reporting_super;GRANT USAGE ON SCHEMA domains TO group_saws;GRANT USAGE ON SCHEMA domains TO group_server_bots;GRANT USAGE ON SCHEMA domains TO group_sonar;GRANT USAGE, CREATE ON SCHEMA extensions TO group_admins;GRANT USAGE ON SCHEMA extensions TO group_api_users;GRANT USAGE ON SCHEMA extensions TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA extensions TO group_developers;GRANT USAGE ON SCHEMA extensions TO group_iceberg;GRANT USAGE ON SCHEMA extensions TO group_leviathan;GRANT USAGE ON SCHEMA extensions TO group_reporting_super;GRANT USAGE ON SCHEMA extensions TO group_saws;GRANT USAGE ON SCHEMA extensions TO group_server_bots;GRANT USAGE ON SCHEMA extensions TO group_sonar;GRANT USAGE, CREATE ON SCHEMA event_triggers TO group_admins;GRANT USAGE ON SCHEMA event_triggers TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA event_triggers TO group_developers;GRANT USAGE ON SCHEMA event_triggers TO group_iceberg;GRANT USAGE ON SCHEMA event_triggers TO group_leviathan;GRANT USAGE ON SCHEMA event_triggers TO group_reporting_super;GRANT USAGE ON SCHEMA event_triggers TO group_saws;GRANT USAGE ON SCHEMA event_triggers TO group_server_bots;GRANT USAGE ON SCHEMA event_triggers TO group_sonar;GRANT USAGE, CREATE ON SCHEMA passthrough TO group_admins;GRANT USAGE ON SCHEMA passthrough TO group_api_users;GRANT USAGE ON SCHEMA passthrough TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA passthrough TO group_developers;GRANT USAGE ON SCHEMA passthrough TO group_iceberg;GRANT USAGE ON SCHEMA passthrough TO group_leviathan;GRANT USAGE ON SCHEMA passthrough TO group_reporting_super;GRANT USAGE ON SCHEMA passthrough TO group_saws;GRANT USAGE ON SCHEMA passthrough TO group_server_bots;GRANT USAGE ON SCHEMA passthrough TO group_sonar;GRANT USAGE, CREATE ON SCHEMA tools TO group_admins;GRANT USAGE ON SCHEMA tools TO group_api_users;GRANT USAGE ON SCHEMA tools TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA tools TO group_developers;GRANT USAGE ON SCHEMA tools TO group_iceberg;GRANT USAGE ON SCHEMA tools TO group_leviathan;GRANT USAGE ON SCHEMA tools TO group_reporting_super;GRANT USAGE ON SCHEMA tools TO group_saws;GRANT USAGE ON SCHEMA tools TO group_server_bots;GRANT USAGE ON SCHEMA tools TO group_sonar;GRANT USAGE, CREATE ON SCHEMA types TO group_admins;GRANT USAGE ON SCHEMA types TO group_api_users;GRANT USAGE ON SCHEMA types TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA types TO group_developers;GRANT USAGE ON SCHEMA types TO group_iceberg;GRANT USAGE ON SCHEMA types TO group_leviathan;GRANT USAGE ON SCHEMA types TO group_reporting_super;GRANT USAGE ON SCHEMA types TO group_saws;GRANT USAGE ON SCHEMA types TO group_server_bots;GRANT USAGE ON SCHEMA types TO group_sonar;GRANT USAGE, CREATE ON SCHEMA types_plus TO group_admins;GRANT USAGE ON SCHEMA types_plus TO group_api_users;GRANT USAGE ON SCHEMA types_plus TO group_cleanup;GRANT USAGE, CREATE ON SCHEMA types_plus TO group_developers;GRANT USAGE ON SCHEMA types_plus TO group_iceberg;GRANT USAGE ON SCHEMA types_plus TO group_leviathan;GRANT USAGE ON SCHEMA types_plus TO group_reporting_super;GRANT USAGE ON SCHEMA types_plus TO group_saws;GRANT USAGE ON SCHEMA types_plus TO group_server_bots;GRANT USAGE ON SCHEMA types_plus TO group_sonar;-------------------------------------------------------------------------------- REGRANT functions.-------------------------------------------------------------------------------- REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN each schema.REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA api_queries FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA analytics FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA ascendco FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA dba FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA domains FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA extensions FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA event_triggers FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA passthrough FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA tools FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_admins;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_developers;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_saws;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA types_plus FROM group_sonar;-- GRANT EXECUTE ON ALL FUNCTIONS IN each schema.GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA analytics TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_admins;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_api_users;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_developers;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_leviathan;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_reporting_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_server_bots;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO group_sonar;-- Clear any existing function defaults from each schema.ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON FUNCTIONS FROM group_sonar;-- Set default to give each group the right to execute functions in any schema they can reach.ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT EXECUTE ON FUNCTIONS TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT EXECUTE ON FUNCTIONS TO group_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO rdsadmin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO rds_super;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO user_admin;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO user_backup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO user_bender;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO user_change_structure;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA dba TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA event_triggers TO user_cleanup;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_domo_pull;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_iceberg;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_iceberg_remote;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_saws;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_reporting;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA api_queries TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA domains TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA extensions TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA tools TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA types_plus TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA passthrough TO user_sonar;GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA ascendco TO user_sonar;-------------------------------------------------------------------------------- REGRANT tables/views.-------------------------------------------------------------------------------- REVOKE ALL on tables/views.REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA api_queries FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA analytics FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA ascendco FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA dba FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA domains FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA extensions FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA event_triggers FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA passthrough FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA tools FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types FROM group_sonar;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM PUBLIC;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_admins;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_api_users;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_cleanup;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_developers;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_iceberg;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_leviathan;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_reporting_super;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_saws;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_server_bots;REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA types_plus FROM group_sonar;-- GRANT rights that can be applied to all tables/views in a schema.GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA api TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA api TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA api TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA api TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA api TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA api TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA api TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA api TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA api TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA api TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA api_queries TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA api_queries TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA api_queries TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA api_queries TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA api_queries TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA api_queries TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA api_queries TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA api_queries TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA api_queries TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA api_queries TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA analytics TO group_admins;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA analytics TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA analytics TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA ascendco TO group_admins;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA ascendco TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA ascendco TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA ascendco TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA ascendco TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA ascendco TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA ascendco TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA ascendco TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA ascendco TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA dba TO group_admins;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA dba TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA dba TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA dba TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA dba TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA dba TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA dba TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA dba TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA dba TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA domains TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA domains TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA domains TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA domains TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA domains TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA domains TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA domains TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA domains TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA domains TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA domains TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA extensions TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA extensions TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA extensions TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA extensions TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA extensions TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA extensions TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA extensions TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA extensions TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA extensions TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA extensions TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA event_triggers TO group_admins;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA event_triggers TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA event_triggers TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA event_triggers TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA event_triggers TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA event_triggers TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA event_triggers TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA event_triggers TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA event_triggers TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA passthrough TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA passthrough TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA passthrough TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA passthrough TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA passthrough TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA passthrough TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA passthrough TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA passthrough TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA passthrough TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA passthrough TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA tools TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA tools TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA tools TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA tools TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA tools TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA tools TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA tools TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA tools TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA tools TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA tools TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA types TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA types TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA types TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA types TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA types TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA types TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA types TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA types TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA types TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA types TO group_sonar;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON ALL TABLES IN SCHEMA types_plus TO group_admins;GRANT SELECT ON ALL TABLES IN SCHEMA types_plus TO group_api_users;GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA types_plus TO group_cleanup;GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON ALL TABLES IN SCHEMA types_plus TO group_developers;GRANT SELECT ON ALL TABLES IN SCHEMA types_plus TO group_iceberg;GRANT SELECT ON ALL TABLES IN SCHEMA types_plus TO group_leviathan;GRANT SELECT ON ALL TABLES IN SCHEMA types_plus TO group_reporting_super;GRANT SELECT ON ALL TABLES IN SCHEMA types_plus TO group_saws;GRANT SELECT ON ALL TABLES IN SCHEMA types_plus TO group_server_bots;GRANT SELECT ON ALL TABLES IN SCHEMA types_plus TO group_sonar;-- GRANT full CRUD rights selectively by table.-- Note: group_admins and group_developers are granted full CRUD rights on all tables above.-- ascendco.analytic_productivity.GRANT INSERT, UPDATE, DELETE ON analytic_productivity TO group_sonar;-- ascendco.analytic_scan.GRANT INSERT, UPDATE, DELETE ON analytic_scan TO group_sonar;-- ascendco.analytic_sterilizer_load.GRANT INSERT, UPDATE, DELETE ON analytic_sterilizer_load TO group_sonar;-- ascendco.analytic_sterilizer_loadinv.GRANT INSERT, UPDATE, DELETE ON analytic_sterilizer_loadinv TO group_sonar;-- ascendco.assembly.GRANT INSERT, UPDATE, DELETE ON assembly TO group_sonar;-- ascendco.assembly_prods.GRANT INSERT, UPDATE, DELETE ON assembly_prods TO group_sonar;-- ascendco.data_file_info.GRANT INSERT, UPDATE, DELETE ON data_file_info TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON data_file_info TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON data_file_info TO group_saws;GRANT INSERT, UPDATE, DELETE ON data_file_info TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON data_file_info TO group_sonar;-- ascendco.deletion_log.GRANT INSERT, UPDATE, DELETE ON deletion_log TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON deletion_log TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON deletion_log TO group_saws;GRANT INSERT, UPDATE, DELETE ON deletion_log TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON deletion_log TO group_sonar;-- ascendco.domo_dataset.GRANT INSERT, UPDATE, DELETE ON domo_dataset TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON domo_dataset TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON domo_dataset TO group_server_bots;-- ascendco.domo_passthrough.GRANT INSERT, UPDATE, DELETE ON domo_passthrough TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON domo_passthrough TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON domo_passthrough TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON domo_passthrough TO group_sonar;-- ascendco.facility.GRANT INSERT, UPDATE, DELETE ON facility TO group_iceberg;-- ascendco.facility_location.GRANT INSERT, UPDATE, DELETE ON facility_location TO group_iceberg;-- ascendco.focus.GRANT INSERT, UPDATE, DELETE ON focus TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON focus TO group_sonar;-- api.hour_bin.-- ascendco.hsys.GRANT INSERT, UPDATE, DELETE ON hsys TO group_iceberg;-- ascendco.inv.GRANT INSERT, UPDATE, DELETE ON inv TO group_iceberg;-- ascendco.item.GRANT INSERT, UPDATE, DELETE ON item TO group_iceberg;-- ascendco.item_type.GRANT INSERT, UPDATE, DELETE ON item_type TO group_iceberg;-- ascendco.need.GRANT INSERT, UPDATE, DELETE ON need TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON need TO group_sonar;-- ascendco.outlier_change.-- ascendco.outlier_rule.-- ascendco.push_log.GRANT INSERT, UPDATE, DELETE ON push_log TO group_api_users;GRANT INSERT, UPDATE, DELETE ON push_log TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON push_log TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON push_log TO group_reporting_super;GRANT INSERT, UPDATE, DELETE ON push_log TO group_saws;GRANT INSERT, UPDATE, DELETE ON push_log TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON push_log TO group_sonar;-- ascendco.record_changes_log.GRANT INSERT, UPDATE, DELETE ON record_changes_log TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON record_changes_log TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON record_changes_log TO group_saws;GRANT INSERT, UPDATE, DELETE ON record_changes_log TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON record_changes_log TO group_sonar;-- ascendco.record_changes_log_detail.GRANT INSERT, UPDATE, DELETE ON record_changes_log_detail TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON record_changes_log_detail TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON record_changes_log_detail TO group_saws;GRANT INSERT, UPDATE, DELETE ON record_changes_log_detail TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON record_changes_log_detail TO group_sonar;-- ascendco.row_compare.GRANT INSERT, UPDATE, DELETE ON row_compare TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON row_compare TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON row_compare TO group_saws;GRANT INSERT, UPDATE, DELETE ON row_compare TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON row_compare TO group_sonar;-- ascendco.specialty.GRANT INSERT, UPDATE, DELETE ON specialty TO group_iceberg;-- ascendco.stat_facility.GRANT INSERT, UPDATE, DELETE ON stat_facility TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON stat_facility TO group_leviathan;GRANT INSERT, UPDATE, DELETE ON stat_facility TO group_saws;GRANT INSERT, UPDATE, DELETE ON stat_facility TO group_server_bots;GRANT INSERT, UPDATE, DELETE ON stat_facility TO group_sonar;-- ascendco.sterilize_method.GRANT INSERT, UPDATE, DELETE ON sterilize_method TO group_iceberg;-- ascendco.sterilize_params.GRANT INSERT, UPDATE, DELETE ON sterilize_params TO group_sonar;-- ascendco.sterilizer.GRANT INSERT, UPDATE, DELETE ON sterilizer TO group_sonar;-- ascendco.sterilizer_load.GRANT INSERT, UPDATE, DELETE ON sterilizer_load TO group_sonar;-- ascendco.sterilizer_log.GRANT INSERT, UPDATE, DELETE ON sterilizer_log TO group_iceberg;GRANT INSERT, UPDATE, DELETE ON sterilizer_log TO group_sonar;-- ascendco.web_user.GRANT INSERT, UPDATE, DELETE ON web_user TO group_sonar;-- Clear any existing table defaults from each schema.ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA dba REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA domains REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA tools REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM PUBLIC;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus REVOKE ALL PRIVILEGES ON TABLES FROM group_sonar;--  ALTER DEFAULT PRIVILEGES that can be applied to all tables/views in a schemaALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA api_queries GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA analytics GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA ascendco GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA dba GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA domains GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA extensions GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA event_triggers GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA passthrough GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA tools GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types GRANT SELECT ON TABLES TO group_sonar;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER, TRUNCATE ON TABLES TO group_admins;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT ON TABLES TO group_api_users;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT, DELETE ON TABLES TO group_cleanup;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT, INSERT, UPDATE, DELETE, REFERENCES, TRIGGER ON TABLES TO group_developers;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT ON TABLES TO group_iceberg;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT ON TABLES TO group_leviathan;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT ON TABLES TO group_reporting_super;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT ON TABLES TO group_saws;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT ON TABLES TO group_server_bots;ALTER DEFAULT PRIVILEGES IN SCHEMA types_plus GRANT SELECT ON TABLES TO group_sonar;------------------------------------------- Seeds-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:calendar_seed_data:calendar.seed.sql-------------------------------------------------------------------------- USA Sunday-Saturday------------------------------------------------------------------------select * from calendar_add ('21C272773AA443969293C342CC693ADC','USA Sunday-Saturday','Sunday','Week 1 is the earliest Sunday in the week with Jan 1');select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2015','2015','2014-12-28'::date,'2015-12-26'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2016','2016','2015-12-27'::date,'2016-12-31'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2017','2017','2017-01-01'::date,'2017-12-30'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2018','2018','2017-12-31'::date,'2018-12-29'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2019','2019','2018-12-30'::date,'2019-12-28'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2020','2020','2019-12-29'::date,'2020-12-26'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2021','2021','2020-12-27'::date,'2021-12-25'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2022','2022','2021-12-26'::date,'2022-12-31'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2023','2023','2023-01-01'::date,'2023-12-30'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2024','2024','2023-12-31'::date,'2024-12-28'::date);select * from calendar_year_add('21c27277-3aa4-4396-9293-c342cc693adc'::uuid,'FY 2025','2025','2024-12-29'::date,'2025-12-27'::date);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:tables:ascendco:iceberg_table.seed.sql-------------------------------------------------------- Seed records. See PgBuild_InsertIceBergTables------------------------------------------------------BEGIN;DELETE FROM iceberg_table; -- Start from scratch, no extra ON CONFLICT syntax needed below this way.INSERT INTO iceberg_table (table_number,table_name) VALUES (1, 'Preference');INSERT INTO iceberg_table (table_number,table_name) VALUES (2, 'Users');INSERT INTO iceberg_table (table_number,table_name) VALUES (3, 'Logit');INSERT INTO iceberg_table (table_number,table_name) VALUES (4, 'RecordChangesLog');INSERT INTO iceberg_table (table_number,table_name) VALUES (5, 'User_PrivGroups');INSERT INTO iceberg_table (table_number,table_name) VALUES (6, 'User_PrivGroupMembers');INSERT INTO iceberg_table (table_number,table_name) VALUES (7, 'ConcurrencyIDs');INSERT INTO iceberg_table (table_number,table_name) VALUES (8, 'R2D2');INSERT INTO iceberg_table (table_number,table_name) VALUES (9, 'ErrorLog');INSERT INTO iceberg_table (table_number,table_name) VALUES (10, 'ErrorDefinitions');INSERT INTO iceberg_table (table_number,table_name) VALUES (11, 'EmailQ');INSERT INTO iceberg_table (table_number,table_name) VALUES (12, 'EmailQ_Attachments');INSERT INTO iceberg_table (table_number,table_name) VALUES (13, 'Item');INSERT INTO iceberg_table (table_number,table_name) VALUES (14, 'ItemArch');INSERT INTO iceberg_table (table_number,table_name) VALUES (15, 'Assembly');INSERT INTO iceberg_table (table_number,table_name) VALUES (16, 'Facility');INSERT INTO iceberg_table (table_number,table_name) VALUES (17, 'PicSizes');INSERT INTO iceberg_table (table_number,table_name) VALUES (18, 'Prod');INSERT INTO iceberg_table (table_number,table_name) VALUES (19, 'SupProdType');INSERT INTO iceberg_table (table_number,table_name) VALUES (20, 'SupProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (21, 'Sup');INSERT INTO iceberg_table (table_number,table_name) VALUES (22, 'Specialty_Prod');INSERT INTO iceberg_table (table_number,table_name) VALUES (23, 'Pic');INSERT INTO iceberg_table (table_number,table_name) VALUES (24, 'eDocs');INSERT INTO iceberg_table (table_number,table_name) VALUES (25, 'SupProd_SupSpecialty');INSERT INTO iceberg_table (table_number,table_name) VALUES (26, 'SupSpecialty');INSERT INTO iceberg_table (table_number,table_name) VALUES (27, 'SupPriceList_SupProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (28, 'SupPriceList');INSERT INTO iceberg_table (table_number,table_name) VALUES (29, 'Specialty');INSERT INTO iceberg_table (table_number,table_name) VALUES (30, 'ProdType');INSERT INTO iceberg_table (table_number,table_name) VALUES (31, 'SyncTransferTracking_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (32, 'SyncTransfers_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (33, 'SyncSettings_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (34, 'SyncLog_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (35, 'SyncDocTransfers_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (36, 'SyncDocErrors_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (37, 'SyncConflictLog_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (38, 'DocumentTracking');INSERT INTO iceberg_table (table_number,table_name) VALUES (39, 'Sync_Versions_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (40, 'R2D2_Audit');INSERT INTO iceberg_table (table_number,table_name) VALUES (41, 'FacilitySpecialty');INSERT INTO iceberg_table (table_number,table_name) VALUES (42, 'ItemProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (43, 'ItemHist');INSERT INTO iceberg_table (table_number,table_name) VALUES (44, 'FacilityDepartment');INSERT INTO iceberg_table (table_number,table_name) VALUES (45, 'People');INSERT INTO iceberg_table (table_number,table_name) VALUES (46, 'Facility_People');INSERT INTO iceberg_table (table_number,table_name) VALUES (47, 'SupProdAttr');INSERT INTO iceberg_table (table_number,table_name) VALUES (48, 'InstProp');INSERT INTO iceberg_table (table_number,table_name) VALUES (49, 'InstProp_Prod');INSERT INTO iceberg_table (table_number,table_name) VALUES (50, 'SonarUI');INSERT INTO iceberg_table (table_number,table_name) VALUES (51, 'Proc');INSERT INTO iceberg_table (table_number,table_name) VALUES (52, 'PrefCard');INSERT INTO iceberg_table (table_number,table_name) VALUES (53, 'PrefCard_Equip');INSERT INTO iceberg_table (table_number,table_name) VALUES (54, 'Equip');INSERT INTO iceberg_table (table_number,table_name) VALUES (55, 'SurveyMerges');INSERT INTO iceberg_table (table_number,table_name) VALUES (56, 'Inv');INSERT INTO iceberg_table (table_number,table_name) VALUES (57, 'ItemType');INSERT INTO iceberg_table (table_number,table_name) VALUES (58, 'FacilityKeyType');INSERT INTO iceberg_table (table_number,table_name) VALUES (59, 'Key');INSERT INTO iceberg_table (table_number,table_name) VALUES (60, 'Pic_Link');INSERT INTO iceberg_table (table_number,table_name) VALUES (61, 'Stat');INSERT INTO iceberg_table (table_number,table_name) VALUES (62, 'SyncDataFiles_Old');INSERT INTO iceberg_table (table_number,table_name) VALUES (63, 'ItemMasterLink');INSERT INTO iceberg_table (table_number,table_name) VALUES (64, 'Prod_Fuzzy');INSERT INTO iceberg_table (table_number,table_name) VALUES (65, 'Case');INSERT INTO iceberg_table (table_number,table_name) VALUES (66, 'Case_Doc');INSERT INTO iceberg_table (table_number,table_name) VALUES (67, 'CaseDoc_PrefCard');INSERT INTO iceberg_table (table_number,table_name) VALUES (68, 'Case_Equip');INSERT INTO iceberg_table (table_number,table_name) VALUES (69, 'CaseType');INSERT INTO iceberg_table (table_number,table_name) VALUES (70, 'CaseType_Prod');INSERT INTO iceberg_table (table_number,table_name) VALUES (71, 'Case_Prod');INSERT INTO iceberg_table (table_number,table_name) VALUES (72, 'Viz');INSERT INTO iceberg_table (table_number,table_name) VALUES (73, 'SurveyProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (74, 'SurveyProdProc');INSERT INTO iceberg_table (table_number,table_name) VALUES (75, 'Survey');INSERT INTO iceberg_table (table_number,table_name) VALUES (76, 'SurveyRequest');INSERT INTO iceberg_table (table_number,table_name) VALUES (77, 'SurveyRound');INSERT INTO iceberg_table (table_number,table_name) VALUES (78, 'DocProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (79, 'DocProdProc');INSERT INTO iceberg_table (table_number,table_name) VALUES (80, 'PeopleObjects');INSERT INTO iceberg_table (table_number,table_name) VALUES (81, 'ObOpCart');INSERT INTO iceberg_table (table_number,table_name) VALUES (82, 'ObOpCartItem');INSERT INTO iceberg_table (table_number,table_name) VALUES (83, 'PrefCard_Proc');INSERT INTO iceberg_table (table_number,table_name) VALUES (84, 'Web_Request_Log');INSERT INTO iceberg_table (table_number,table_name) VALUES (85, 'FormTemplate');INSERT INTO iceberg_table (table_number,table_name) VALUES (86, 'FacilityLocation');INSERT INTO iceberg_table (table_number,table_name) VALUES (87, 'WebUser');INSERT INTO iceberg_table (table_number,table_name) VALUES (88, 'Old_AssemblyProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (89, 'DocProdProcItem');INSERT INTO iceberg_table (table_number,table_name) VALUES (90, 'Facility_Clinic');INSERT INTO iceberg_table (table_number,table_name) VALUES (91, 'Clinic');INSERT INTO iceberg_table (table_number,table_name) VALUES (92, 'Hsys');INSERT INTO iceberg_table (table_number,table_name) VALUES (93, 'ItemMasterName');INSERT INTO iceberg_table (table_number,table_name) VALUES (94, 'Opt_SurveyFact');INSERT INTO iceberg_table (table_number,table_name) VALUES (95, 'SupPriceList_Facility');INSERT INTO iceberg_table (table_number,table_name) VALUES (96, 'EntitySet');INSERT INTO iceberg_table (table_number,table_name) VALUES (97, 'Facility_FacilityGroup');INSERT INTO iceberg_table (table_number,table_name) VALUES (98, 'FacilityGroup');INSERT INTO iceberg_table (table_number,table_name) VALUES (99, 'FacilityPrintOptions');INSERT INTO iceberg_table (table_number,table_name) VALUES (100, 'InvItemProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (101, 'SyncSettings');INSERT INTO iceberg_table (table_number,table_name) VALUES (102, 'SyncTables');INSERT INTO iceberg_table (table_number,table_name) VALUES (103, 'SyncTablesConIDs');INSERT INTO iceberg_table (table_number,table_name) VALUES (104, 'SyncLog');INSERT INTO iceberg_table (table_number,table_name) VALUES (105, 'SyncConflictLog');INSERT INTO iceberg_table (table_number,table_name) VALUES (106, 'SyncLockedRecords');INSERT INTO iceberg_table (table_number,table_name) VALUES (107, 'DeletedRecords');INSERT INTO iceberg_table (table_number,table_name) VALUES (108, 'LargeOrder');INSERT INTO iceberg_table (table_number,table_name) VALUES (109, 'LargeOrderItem');INSERT INTO iceberg_table (table_number,table_name) VALUES (110, 'SyncDataFiles');INSERT INTO iceberg_table (table_number,table_name) VALUES (111, 'SyncTableSets');INSERT INTO iceberg_table (table_number,table_name) VALUES (112, 'Opt_DocItemProc');INSERT INTO iceberg_table (table_number,table_name) VALUES (113, 'Opt_PrefCard');INSERT INTO iceberg_table (table_number,table_name) VALUES (114, 'Opt_EquipCombo');INSERT INTO iceberg_table (table_number,table_name) VALUES (115, 'Opt_PrefCardNotes');INSERT INTO iceberg_table (table_number,table_name) VALUES (116, 'SyncAppVersion');INSERT INTO iceberg_table (table_number,table_name) VALUES (117, 'Job');INSERT INTO iceberg_table (table_number,table_name) VALUES (118, 'LargeOrderProdsToIdentify');INSERT INTO iceberg_table (table_number,table_name) VALUES (119, 'LargeOrderProdsToIdentifySup');INSERT INTO iceberg_table (table_number,table_name) VALUES (120, 'LargeOrderProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (121, 'LargeOrderProdCrossQuote');INSERT INTO iceberg_table (table_number,table_name) VALUES (122, 'Opt_DocProc');INSERT INTO iceberg_table (table_number,table_name) VALUES (123, 'Opt_DocProcCase');INSERT INTO iceberg_table (table_number,table_name) VALUES (124, 'Opt_DocProcCaseEquip');INSERT INTO iceberg_table (table_number,table_name) VALUES (125, 'Test');INSERT INTO iceberg_table (table_number,table_name) VALUES (126, 'Relation');INSERT INTO iceberg_table (table_number,table_name) VALUES (127, 'Patch_Log');INSERT INTO iceberg_table (table_number,table_name) VALUES (128, 'FacilityPrinter');INSERT INTO iceberg_table (table_number,table_name) VALUES (129, 'SQL_Browser_History');INSERT INTO iceberg_table (table_number,table_name) VALUES (130, 'Opt_ItemDemand_Summary');INSERT INTO iceberg_table (table_number,table_name) VALUES (131, 'InvFlow');INSERT INTO iceberg_table (table_number,table_name) VALUES (132, 'Opt_ItemDemand_Detail');INSERT INTO iceberg_table (table_number,table_name) VALUES (133, 'LargeOrderSnapshot');INSERT INTO iceberg_table (table_number,table_name) VALUES (134, 'SupAlias');INSERT INTO iceberg_table (table_number,table_name) VALUES (135, 'SupProd_Rollups');INSERT INTO iceberg_table (table_number,table_name) VALUES (136, 'Pin');INSERT INTO iceberg_table (table_number,table_name) VALUES (137, 'Barcode');INSERT INTO iceberg_table (table_number,table_name) VALUES (138, 'Scan');INSERT INTO iceberg_table (table_number,table_name) VALUES (139, 'InvScanLast');INSERT INTO iceberg_table (table_number,table_name) VALUES (140, 'ProdAuthor');INSERT INTO iceberg_table (table_number,table_name) VALUES (141, 'FacilityDeconMethods');INSERT INTO iceberg_table (table_number,table_name) VALUES (142, 'ProdBrand');INSERT INTO iceberg_table (table_number,table_name) VALUES (143, 'AssemblyTime');INSERT INTO iceberg_table (table_number,table_name) VALUES (144, 'Item_DeconMethod');INSERT INTO iceberg_table (table_number,table_name) VALUES (145, 'SterilizeMethod');INSERT INTO iceberg_table (table_number,table_name) VALUES (146, 'Sterilizer');INSERT INTO iceberg_table (table_number,table_name) VALUES (147, 'SterilizeParams');INSERT INTO iceberg_table (table_number,table_name) VALUES (148, 'Item_SterilizeMethods');INSERT INTO iceberg_table (table_number,table_name) VALUES (149, 'Item_SterilizeParams');INSERT INTO iceberg_table (table_number,table_name) VALUES (150, 'SterilizerLoad');INSERT INTO iceberg_table (table_number,table_name) VALUES (151, 'SterilizerLoad_Inv');INSERT INTO iceberg_table (table_number,table_name) VALUES (152, 'HTTPDLog_Failure_Cache');INSERT INTO iceberg_table (table_number,table_name) VALUES (153, 'DebugDump');INSERT INTO iceberg_table (table_number,table_name) VALUES (154, 'AssemblyProds');INSERT INTO iceberg_table (table_number,table_name) VALUES (155, 'WebUserMem');INSERT INTO iceberg_table (table_number,table_name) VALUES (156, 'Workstation');INSERT INTO iceberg_table (table_number,table_name) VALUES (157, 'Facility_SterilizeParams');INSERT INTO iceberg_table (table_number,table_name) VALUES (158, 'ItemSignature');INSERT INTO iceberg_table (table_number,table_name) VALUES (159, 'Opt_ItemDemand_Quick');INSERT INTO iceberg_table (table_number,table_name) VALUES (160, 'SupParent');INSERT INTO iceberg_table (table_number,table_name) VALUES (161, 'HsysTag');INSERT INTO iceberg_table (table_number,table_name) VALUES (162, 'DDTable');INSERT INTO iceberg_table (table_number,table_name) VALUES (163, 'DDRelation');INSERT INTO iceberg_table (table_number,table_name) VALUES (164, 'DDField');INSERT INTO iceberg_table (table_number,table_name) VALUES (165, 'HsysConfig');INSERT INTO iceberg_table (table_number,table_name) VALUES (166, 'AutoReport');INSERT INTO iceberg_table (table_number,table_name) VALUES (167, 'AutoReportOrg');INSERT INTO iceberg_table (table_number,table_name) VALUES (168, 'AutoReportOrgRecipient');INSERT INTO iceberg_table (table_number,table_name) VALUES (169, 'AutoReportRecipient');INSERT INTO iceberg_table (table_number,table_name) VALUES (170, 'AutoReportOrgAudit');INSERT INTO iceberg_table (table_number,table_name) VALUES (171, 'PrintJob');INSERT INTO iceberg_table (table_number,table_name) VALUES (172, 'ET');INSERT INTO iceberg_table (table_number,table_name) VALUES (173, 'WebUserHours');INSERT INTO iceberg_table (table_number,table_name) VALUES (174, 'BiType');INSERT INTO iceberg_table (table_number,table_name) VALUES (175, 'BiReader');INSERT INTO iceberg_table (table_number,table_name) VALUES (176, 'BiReader_BiType');INSERT INTO iceberg_table (table_number,table_name) VALUES (177, 'Sterilizer_BiReader');INSERT INTO iceberg_table (table_number,table_name) VALUES (178, 'BiControl');INSERT INTO iceberg_table (table_number,table_name) VALUES (179, 'BiTest');INSERT INTO iceberg_table (table_number,table_name) VALUES (180, 'SoftwareSystem');INSERT INTO iceberg_table (table_number,table_name) VALUES (181, 'MsgType');INSERT INTO iceberg_table (table_number,table_name) VALUES (182, 'Msg');INSERT INTO iceberg_table (table_number,table_name) VALUES (183, 'MsgStatus');INSERT INTO iceberg_table (table_number,table_name) VALUES (184, 'MsgAttempt');INSERT INTO iceberg_table (table_number,table_name) VALUES (185, 'Notification');INSERT INTO iceberg_table (table_number,table_name) VALUES (186, 'NotificationRead');INSERT INTO iceberg_table (table_number,table_name) VALUES (187, 'Media');INSERT INTO iceberg_table (table_number,table_name) VALUES (188, 'Feature');INSERT INTO iceberg_table (table_number,table_name) VALUES (189, 'Feature_Link');INSERT INTO iceberg_table (table_number,table_name) VALUES (191, 'ItemSyncHist');INSERT INTO iceberg_table (table_number,table_name) VALUES (192, 'Loaner');INSERT INTO iceberg_table (table_number,table_name) VALUES (193, 'LoanerCase');INSERT INTO iceberg_table (table_number,table_name) VALUES (194, 'Loaner_Item');INSERT INTO iceberg_table (table_number,table_name) VALUES (195, 'Rep');INSERT INTO iceberg_table (table_number,table_name) VALUES (196, 'Rep_Sup');INSERT INTO iceberg_table (table_number,table_name) VALUES (197, 'LocScanLast');INSERT INTO iceberg_table (table_number,table_name) VALUES (198, 'WebUserLogins');INSERT INTO iceberg_table (table_number,table_name) VALUES (199, 'Node');INSERT INTO iceberg_table (table_number,table_name) VALUES (200, 'FromToNode');INSERT INTO iceberg_table (table_number,table_name) VALUES (201, 'Loaner_ItemInv');INSERT INTO iceberg_table (table_number,table_name) VALUES (202, 'Collection');INSERT INTO iceberg_table (table_number,table_name) VALUES (203, 'CollectionInv');INSERT INTO iceberg_table (table_number,table_name) VALUES (204, 'Washer');INSERT INTO iceberg_table (table_number,table_name) VALUES (205, 'WasherLoad');INSERT INTO iceberg_table (table_number,table_name) VALUES (206, 'WasherLoad_Inv');INSERT INTO iceberg_table (table_number,table_name) VALUES (207, 'SterilizerLog');INSERT INTO iceberg_table (table_number,table_name) VALUES (208, 'SmartExport_Preset');INSERT INTO iceberg_table (table_number,table_name) VALUES (209, 'CloudBucket');INSERT INTO iceberg_table (table_number,table_name) VALUES (210, 'CloudDoc');INSERT INTO iceberg_table (table_number,table_name) VALUES (211, 'PrinterStatus');INSERT INTO iceberg_table (table_number,table_name) VALUES (212, 'SmartExport_Field');INSERT INTO iceberg_table (table_number,table_name) VALUES (213, 'FacilityActivities');INSERT INTO iceberg_table (table_number,table_name) VALUES (214, 'Activity');INSERT INTO iceberg_table (table_number,table_name) VALUES (215, 'Standardization');INSERT INTO iceberg_table (table_number,table_name) VALUES (216, 'StandardizationItem');INSERT INTO iceberg_table (table_number,table_name) VALUES (217, 'SterilizerLoad_InvRef');INSERT INTO iceberg_table (table_number,table_name) VALUES (218, 'AssemblyRef');INSERT INTO iceberg_table (table_number,table_name) VALUES (219, 'CollectionRef');INSERT INTO iceberg_table (table_number,table_name) VALUES (220, 'StandardizationProd');INSERT INTO iceberg_table (table_number,table_name) VALUES (221, 'StandardizationProdPerItem');INSERT INTO iceberg_table (table_number,table_name) VALUES (222, 'ProductionRef');INSERT INTO iceberg_table (table_number,table_name) VALUES (223, 'Temp_ProductivityDetail');INSERT INTO iceberg_table (table_number,table_name) VALUES (224, 'Temp');INSERT INTO iceberg_table (table_number,table_name) VALUES (225, 'Stat_Facility');INSERT INTO iceberg_table (table_number,table_name) VALUES (226, 'Chart');INSERT INTO iceberg_table (table_number,table_name) VALUES (227, 'sCase');INSERT INTO iceberg_table (table_number,table_name) VALUES (228, 'sCaseInv');INSERT INTO iceberg_table (table_number,table_name) VALUES (229, 'sCaseNo');INSERT INTO iceberg_table (table_number,table_name) VALUES (230, 'Edge');INSERT INTO iceberg_table (table_number,table_name) VALUES (231, 'ToolsUI');INSERT INTO iceberg_table (table_number,table_name) VALUES (232, 'WasherParam');INSERT INTO iceberg_table (table_number,table_name) VALUES (233, 'Facility_WasherParam');INSERT INTO iceberg_table (table_number,table_name) VALUES (234, 'StandardizationVersion');INSERT INTO iceberg_table (table_number,table_name) VALUES (235, 'sCaseCart');INSERT INTO iceberg_table (table_number,table_name) VALUES (236, 'HL7');INSERT INTO iceberg_table (table_number,table_name) VALUES (237, 'InvRepairs');COMMIT;------------------------------------------- Seeds------------------------------------------------------------------------------------ Statistics-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:statistics:analytic_productivity_stats.sqlCREATE STATISTICS IF NOT EXISTS    dba.analytic_productivity_dependencies_facility_hsys (dependencies)    ON facility_id, hsys_id    FROM ascendco.analytic_productivity;CREATE STATISTICS IF NOT EXISTS    dba.analytic_productivity_dependencies_facility_location_facility (dependencies)    ON facility_location_id, facility_id    FROM ascendco.analytic_productivity;CREATE STATISTICS IF NOT EXISTS    dba.analytic_productivity_dependencies_facility_location_hsys (dependencies)    ON facility_location_id, hsys_id    FROM ascendco.analytic_productivity;CREATE STATISTICS IF NOT EXISTS    dba.analytic_productivity_dependencies_hsys_facility_facility_locat (dependencies)    ON hsys_id, facility_id, facility_location_id    FROM ascendco.analytic_productivity;CREATE STATISTICS IF NOT EXISTS    dba.analytic_productivity_dependencies_user_name_facility (dependencies)    ON user_name, facility_id    FROM ascendco.analytic_productivity;CREATE STATISTICS IF NOT EXISTS    dba.analytic_productivity_dependencies_user_name_hsys (dependencies)    ON user_name, hsys_id    FROM ascendco.analytic_productivity;ANALYZE ascendco.analytic_productivity;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:statistics:analytic_scan_stats.sqlCREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_facility_hsys (dependencies)    ON facility_id, hsys_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_ndistinct_facility_hsys (ndistinct)    ON facility_id, hsys_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_facility_location_facility (dependencies)    ON facility_location_id, facility_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_associated_to_facilty (dependencies)    ON associated_to, facility_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_associated_to_hsys (dependencies)    ON associated_to, hsys_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_facility_location_hsys (dependencies)    ON facility_location_id, hsys_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_hsys_facility_facility_location (dependencies)    ON hsys_id, facility_id, facility_location_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_user_name_facility (dependencies)    ON user_name, facility_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_dependencies_user_name_hsys (dependencies)    ON user_name, hsys_id    FROM ascendco.analytic_scan;CREATE STATISTICS IF NOT EXISTS    dba.analytic_scan_ndistinct_hsys (ndistinct)    ON hsys_id, facility_id    FROM analytic_scan;ANALYZE ascendco.analytic_scan;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:statistics:analytic_sterilizer_load_stats.sqlCREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_load_dependencies_sterilizer_facility (dependencies)    ON sterilizer_id, facility_id    FROM ascendco.analytic_sterilizer_load;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_load_dependencies_web_user_facility (dependencies)    ON web_user_id, facility_id    FROM ascendco.analytic_sterilizer_load;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_load_dependencies_sterilize_params_facility (dependencies)    ON sterilize_params_id, facility_id    FROM ascendco.analytic_sterilizer_load;ANALYZE ascendco.analytic_sterilizer_load;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:statistics:analytic_sterilizer_loadinv_stats.sqlCREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_loadinv_dependencies_sterilizer_facility (dependencies)    ON sterilizer_id, facility_id    FROM ascendco.analytic_sterilizer_loadinv;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_loadinv_dependencies_sterilizer_hsys (dependencies)    ON sterilizer_id, hsys_id    FROM ascendco.analytic_sterilizer_loadinv;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_loadinv_dependencies_facility_hsys (dependencies)    ON facility_id, hsys_id    FROM ascendco.analytic_sterilizer_loadinv;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_loadinv_dependencies_web_user_facility (dependencies)    ON web_user_id, facility_id    FROM ascendco.analytic_sterilizer_loadinv;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_loadinv_dependencies_web_user_hsys (dependencies)    ON web_user_id, hsys_id    FROM ascendco.analytic_sterilizer_loadinv;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_loadinv_dependencies_sterilize_params_hsys (dependencies)    ON sterilize_params_id, hsys_id    FROM ascendco.analytic_sterilizer_loadinv;CREATE STATISTICS IF NOT EXISTS    dba.analytic_sterilizer_loadinv_nDistinct_item_speciality (nDistinct)    ON item_id, speciality_id    FROM ascendco.analytic_sterilizer_loadinv;ANALYZE ascendco.analytic_sterilizer_loadinv;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:statistics:analytic_work_stats.sqlCREATE STATISTICS IF NOT EXISTS    dba.analytic_work_dependencies_facility_hsys (dependencies)    ON facility_id, hsys_id    FROM ascendco.analytic_work;CREATE STATISTICS IF NOT EXISTS    dba.analytic_work_dependencies_facility_user (dependencies)    ON facility_id, user_id    FROM ascendco.analytic_work;CREATE STATISTICS IF NOT EXISTS    dba.analytic_work_dependencies_hsys_user (dependencies)    ON hsys_id, user_id    FROM ascendco.analytic_work;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:statistics:domo_passthrough_stats.sqlCREATE STATISTICS IF NOT EXISTS    dba.domo_passthrough_dependencies_facility_hsys (dependencies)    ON facility_id, hsys_id    FROM ascendco.domo_passthrough;ANALYZE ascendco.domo_passthrough;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:statistics:stat_facility_stats.sqlCREATE STATISTICS IF NOT EXISTS    dba.stat_facility_dependencies_facility_hsys (dependencies)    ON facility_id, hsys_id    FROM ascendco.stat_facility;ANALYZE ascendco.stat_facility;------------------------------------------- Setting Adjustments-------------------------------------------Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:setting_adjustments:set_default_statistics.sqlALTER DATABASE squid SET default_statistics_target = 200;ANALYZE;--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:activity_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','activity_v1','','View column strict check for types_plus.activity_v1','select * from types_plus.activity_v1 limit 0;','id	facility_id	facility_activities_id	web_user_id	other_desc	start_dts	done_dts	last_updated_by_data_file_id	created_by	created_dts	updated_by	updated_dts	duration_seconds','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','activity_v1','','View column orderless check for types_plus.activity_v1','select * from types_plus.activity_v1 limit 0;','created_by	created_dts	done_dts	duration_seconds	facility_activities_id	facility_id	id	last_updated_by_data_file_id	other_desc	start_dts	updated_by	updated_dts	web_user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:activity_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','activity_v2','','View column strict check for types_plus.activity_v2','select * from types_plus.activity_v2 limit 0;','id	facility_id	facility_activities_id	web_user_id	last_updated_by_data_file_id	updated_dts	created_dts	done_dts	start_dts	duration_seconds	marked_for_deletion	other_desc	created_by	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','activity_v2','','View column orderless check for types_plus.activity_v2','select * from types_plus.activity_v2 limit 0;','created_by	created_dts	done_dts	duration_seconds	facility_activities_id	facility_id	id	last_updated_by_data_file_id	marked_for_deletion	other_desc	start_dts	updated_by	updated_dts	web_user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:analytic_productivity_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_productivity_v1','','View column strict check for types_plus.analytic_productivity_v1','select * from types_plus.analytic_productivity_v1 limit 0;','id	data_file_id	marked_for_deletion	hsys_id	facility_id	facility_location_id	specialty_id	item_type_id	user_name	inv_name	item_name	tray_or_pack	num_inst	assembly_minutes	pause_minutes	points	points_per_hour	assembly_hour	pause_hour	start_utc	start_local	end_utc	end_local','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_productivity_v1','','View column orderless check for types_plus.analytic_productivity_v1','select * from types_plus.analytic_productivity_v1 limit 0;','assembly_hour	assembly_minutes	data_file_id	end_local	end_utc	facility_id	facility_location_id	hsys_id	id	inv_name	item_name	item_type_id	marked_for_deletion	num_inst	pause_hour	pause_minutes	points	points_per_hour	specialty_id	start_local	start_utc	tray_or_pack	user_name','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:analytic_scan_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_scan_v1','','View column strict check for types_plus.analytic_scan_v1','select * from types_plus.analytic_scan_v1 limit 0;','id	data_file_id	marked_for_deletion	hsys_id	facility_id	facility_location_id	specialty_id	scanned_type	associated_to	user_name	inv_name	num_inst	tray_or_pack	item_name	scan_time_utc_dts	scan_time_local_dts	location_description','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_scan_v1','','View column orderless check for types_plus.analytic_scan_v1','select * from types_plus.analytic_scan_v1 limit 0;','associated_to	data_file_id	facility_id	facility_location_id	hsys_id	id	inv_name	item_name	location_description	marked_for_deletion	num_inst	scan_time_local_dts	scan_time_utc_dts	scanned_type	specialty_id	tray_or_pack	user_name','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:analytic_sterilizer_load_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_sterilizer_load_v1','','View column strict check for types_plus.analytic_sterilizer_load_v1','select * from types_plus.analytic_sterilizer_load_v1 limit 0;','id	marked_for_deletion	data_file_id	sterilize_method_id	sterilize_params_id	sterilizer_id	facility_id	web_user_id	status_building_dts	status_building_local_dts	status_done_dts	status_done_local_dts	status	is_iuss	instruments_count	packs_count	trays_count','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_sterilizer_load_v1','','View column orderless check for types_plus.analytic_sterilizer_load_v1','select * from types_plus.analytic_sterilizer_load_v1 limit 0;','data_file_id	facility_id	id	instruments_count	is_iuss	marked_for_deletion	packs_count	status	status_building_dts	status_building_local_dts	status_done_dts	status_done_local_dts	sterilize_method_id	sterilize_params_id	sterilizer_id	trays_count	web_user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:analytic_sterilizer_loadinv_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_sterilizer_loadinv_v1','','View column strict check for types_plus.analytic_sterilizer_loadinv_v1','select * from types_plus.analytic_sterilizer_loadinv_v1 limit 0;','id	data_file_id	marked_for_deletion	facility_id	hsys_id	inv_id	item_id	item_type_id	speciality_id	sterilize_method_id	sterilize_params_id	sterilizer_id	sterilizerload_id	web_user_id	inv_name_provided	is_iuss	num_inst	qty	category	clinic_dept_name	processing_seconds	done_dts	done_local_dts','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_sterilizer_loadinv_v1','','View column orderless check for types_plus.analytic_sterilizer_loadinv_v1','select * from types_plus.analytic_sterilizer_loadinv_v1 limit 0;','category	clinic_dept_name	data_file_id	done_dts	done_local_dts	facility_id	hsys_id	id	inv_id	inv_name_provided	is_iuss	item_id	item_type_id	marked_for_deletion	num_inst	processing_seconds	qty	speciality_id	sterilize_method_id	sterilize_params_id	sterilizer_id	sterilizerload_id	web_user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:analytic_sterilizer_loadinv_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_sterilizer_loadinv_v2','','View column strict check for types_plus.analytic_sterilizer_loadinv_v2','select * from types_plus.analytic_sterilizer_loadinv_v2 limit 0;','id	data_file_id	marked_for_deletion	facility_id	hsys_id	inv_id	item_id	item_type_id	speciality_id	sterilize_method_id	sterilize_params_id	sterilizer_id	sterilizerload_id	web_user_id	inv_name_provided	is_iuss	num_inst	qty	category	clinic_dept_name	processing_seconds	done_dts	done_local_dts	status','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_sterilizer_loadinv_v2','','View column orderless check for types_plus.analytic_sterilizer_loadinv_v2','select * from types_plus.analytic_sterilizer_loadinv_v2 limit 0;','category	clinic_dept_name	data_file_id	done_dts	done_local_dts	facility_id	hsys_id	id	inv_id	inv_name_provided	is_iuss	item_id	item_type_id	marked_for_deletion	num_inst	processing_seconds	qty	speciality_id	status	sterilize_method_id	sterilize_params_id	sterilizer_id	sterilizerload_id	web_user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:analytic_work_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_work_v2','','View column strict check for types_plus.analytic_work_v2','select * from types_plus.analytic_work_v2 limit 0;','id	key_supplement	hsys_id	facility_id	inv_id	user_id	activity_id	assembly_id	q_event_id	scan_id	scase_id	scase_inv_id	sterilizer_load_id	sterilizer_loadinv_id	start_dts	end_dts	start_local_dts	end_local_dts	date_time	duration	missing_inst	num_inst	num_items	points	num_packs	num_trays	activity	description	marked_for_deletion','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','analytic_work_v2','','View column orderless check for types_plus.analytic_work_v2','select * from types_plus.analytic_work_v2 limit 0;','activity	activity_id	assembly_id	date_time	description	duration	end_dts	end_local_dts	facility_id	hsys_id	id	inv_id	key_supplement	marked_for_deletion	missing_inst	num_inst	num_items	num_packs	num_trays	points	q_event_id	scan_id	scase_id	scase_inv_id	start_dts	start_local_dts	sterilizer_load_id	sterilizer_loadinv_id	user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:assembly_prods_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','assembly_prods_v1','','View column strict check for types_plus.assembly_prods_v1','select * from types_plus.assembly_prods_v1 limit 0;','id	data_file_id	assembly_id	item_prod_id	created_dts	updated_dts	target	found_	repair	backup	actual	assembly_pos	marked_for_deletion	created_by	updated_by	prod_alert_text_ack	audit_events','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','assembly_prods_v1','','View column orderless check for types_plus.assembly_prods_v1','select * from types_plus.assembly_prods_v1 limit 0;','actual	assembly_id	assembly_pos	audit_events	backup	created_by	created_dts	data_file_id	found_	id	item_prod_id	marked_for_deletion	prod_alert_text_ack	repair	target	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:assembly_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','assembly_v1','','View column strict check for types_plus.assembly_v1','select * from types_plus.assembly_v1 limit 0;','id	data_file_id	marked_for_deletion	created_by_user_id	done_by_user_id	facility_location_id	inv_id	last_updated_by_data_file_id	updated_by_user_id	is_complete	is_quick_turn	con_id	created_by	difficulty	quantity	sequence_no	num_inst	points	done_dts	created_dts	updated_dts	missing_list	priority	status	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','assembly_v1','','View column orderless check for types_plus.assembly_v1','select * from types_plus.assembly_v1 limit 0;','con_id	created_by	created_by_user_id	created_dts	data_file_id	difficulty	done_by_user_id	done_dts	facility_location_id	id	inv_id	is_complete	is_quick_turn	last_updated_by_data_file_id	marked_for_deletion	missing_list	num_inst	points	priority	quantity	sequence_no	status	updated_by	updated_by_user_id	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:clinic_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','clinic_v1','','View column strict check for types_plus.clinic_v1','select * from types_plus.clinic_v1 limit 0;','id	hsys_id	created_dts	updated_dts	marked_for_deletion	receive_at_clinic	name_	created_by	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','clinic_v1','','View column orderless check for types_plus.clinic_v1','select * from types_plus.clinic_v1 limit 0;','created_by	created_dts	hsys_id	id	marked_for_deletion	name_	receive_at_clinic	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:domo_dataset_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','domo_dataset_v1','','View column strict check for types_plus.domo_dataset_v1','select * from types_plus.domo_dataset_v1 limit 0;','id	dataset_name	rows_count	columns_count	created_at_dts	updated_at_dts','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','domo_dataset_v1','','View column orderless check for types_plus.domo_dataset_v1','select * from types_plus.domo_dataset_v1 limit 0;','columns_count	created_at_dts	dataset_name	id	rows_count	updated_at_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:domo_passthrough_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','domo_passthrough_v1','','View column strict check for types_plus.domo_passthrough_v1','select * from types_plus.domo_passthrough_v1 limit 0;','source_id	hsys_id	facility_id	view_version	dataset_name	data','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','domo_passthrough_v1','','View column orderless check for types_plus.domo_passthrough_v1','select * from types_plus.domo_passthrough_v1 limit 0;','data	dataset_name	facility_id	hsys_id	source_id	view_version','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:domo_passthrough_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','domo_passthrough_v2','','View column strict check for types_plus.domo_passthrough_v2','select * from types_plus.domo_passthrough_v2 limit 0;','key_supplement	source_id	hsys_id	facility_id	view_version	dataset_name	data	from_dts	to_dts','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','domo_passthrough_v2','','View column orderless check for types_plus.domo_passthrough_v2','select * from types_plus.domo_passthrough_v2 limit 0;','data	dataset_name	facility_id	from_dts	hsys_id	key_supplement	source_id	to_dts	view_version','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:facility_activities_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_activities_v1','','View column strict check for types_plus.facility_activities_v1','select * from types_plus.facility_activities_v1 limit 0;','id	facility_id	last_updated_by_data_file_id	created_dts	updated_dts	marked_for_deletion	name_	created_by	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_activities_v1','','View column orderless check for types_plus.facility_activities_v1','select * from types_plus.facility_activities_v1 limit 0;','created_by	created_dts	facility_id	id	last_updated_by_data_file_id	marked_for_deletion	name_	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:facility_department_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_department_v1','','View column strict check for types_plus.facility_department_v1','select * from types_plus.facility_department_v1 limit 0;','id	facility_id	their_id	created_dts	updated_dts	marked_for_deletion	is_available_in_sonar	receive_at_dept	is_from_emr	name_	created_by	updated_by	label_name	inv_audit','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_department_v1','','View column orderless check for types_plus.facility_department_v1','select * from types_plus.facility_department_v1 limit 0;','created_by	created_dts	facility_id	id	inv_audit	is_available_in_sonar	is_from_emr	label_name	marked_for_deletion	name_	receive_at_dept	their_id	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:facility_location_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_location_v1','','View column strict check for types_plus.facility_location_v1','select * from types_plus.facility_location_v1 limit 0;','id	marked_for_deletion	facility_id	type_	name_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_location_v1','','View column orderless check for types_plus.facility_location_v1','select * from types_plus.facility_location_v1 limit 0;','facility_id	id	marked_for_deletion	name_	type_','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:facility_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_v1','','View column strict check for types_plus.facility_v1','select * from types_plus.facility_v1 limit 0;','id	marked_for_deletion	hsys_id	name_	tz_name','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_v1','','View column orderless check for types_plus.facility_v1','select * from types_plus.facility_v1 limit 0;','hsys_id	id	marked_for_deletion	name_	tz_name','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:facility_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_v2','','View column strict check for types_plus.facility_v2','select * from types_plus.facility_v2 limit 0;','id	hsys_id	production_label_form_id	permanent_label_form_id	missing_inst_label_form_id	facility_location_label_form_id	sterilizer_label_form_id	user_badge_label_form_id	workstation_label_form_id	default_spd_facility_id	created_dts	updated_dts	sonar_auto_logout_minutes	sonar_auto_logout_dialog_minutes	num_ors	sonar_go_live_date	marked_for_deletion	is_count_sheet_source_truth	hide_doc_names_for_stats	is_item_master_live	is_sonar_live	sterilizer_print_at_sterilizing	sterilizer_print_at_cooling	sterilizer_print_at_released	can_set_all_found_in_assembly	name_	their_id	created_by	updated_by	reporting_name	label_name	tz_name	sonar_name_full	sonar_count_sheet_form_name	sterilize_alert_level	sonar_scanner_stop_char	emr_location_name	sonar_features	interfaces	needs_scheduling	analytics_prefs','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','facility_v2','','View column orderless check for types_plus.facility_v2','select * from types_plus.facility_v2 limit 0;','analytics_prefs	can_set_all_found_in_assembly	created_by	created_dts	default_spd_facility_id	emr_location_name	facility_location_label_form_id	hide_doc_names_for_stats	hsys_id	id	interfaces	is_count_sheet_source_truth	is_item_master_live	is_sonar_live	label_name	marked_for_deletion	missing_inst_label_form_id	name_	needs_scheduling	num_ors	permanent_label_form_id	production_label_form_id	reporting_name	sonar_auto_logout_dialog_minutes	sonar_auto_logout_minutes	sonar_count_sheet_form_name	sonar_features	sonar_go_live_date	sonar_name_full	sonar_scanner_stop_char	sterilize_alert_level	sterilizer_label_form_id	sterilizer_print_at_cooling	sterilizer_print_at_released	sterilizer_print_at_sterilizing	their_id	tz_name	updated_by	updated_dts	user_badge_label_form_id	workstation_label_form_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:focus_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','focus_v2','','View column strict check for types_plus.focus_v2','select * from types_plus.focus_v2 limit 0;','scase_id	hsys_id	facility_id	sched_dts	facility_name	or_name	case_seq	desc_	status	transport_from	surgeon_name	proc_name	when_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','focus_v2','','View column orderless check for types_plus.focus_v2','select * from types_plus.focus_v2 limit 0;','case_seq	desc_	facility_id	facility_name	hsys_id	or_name	proc_name	scase_id	sched_dts	status	surgeon_name	transport_from	when_','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:form_template_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','form_template_v1','','View column strict check for types_plus.form_template_v1','select * from types_plus.form_template_v1 limit 0;','id	created_dts	updated_dts	marked_for_deletion	name_	comments_	updated_by	created_by	form_definition','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','form_template_v1','','View column orderless check for types_plus.form_template_v1','select * from types_plus.form_template_v1 limit 0;','comments_	created_by	created_dts	form_definition	id	marked_for_deletion	name_	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:hsys_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','hsys_v1','','View column strict check for types_plus.hsys_v1','select * from types_plus.hsys_v1 limit 0;','id	marked_for_deletion	name_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','hsys_v1','','View column orderless check for types_plus.hsys_v1','select * from types_plus.hsys_v1 limit 0;','id	marked_for_deletion	name_','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:hsys_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','hsys_v2','','View column strict check for types_plus.hsys_v2','select * from types_plus.hsys_v2 limit 0;','id	marked_for_deletion	name_	sonar_client_version	sonar_server_version	sonar_browser_version','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','hsys_v2','','View column orderless check for types_plus.hsys_v2','select * from types_plus.hsys_v2 limit 0;','id	marked_for_deletion	name_	sonar_browser_version	sonar_client_version	sonar_server_version','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:inv_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','inv_v2','','View column strict check for types_plus.inv_v2','select * from types_plus.inv_v2 limit 0;','id	item_id	item_arch_id	facility_location_id	standard_faclity_id	store_at_facility_id	created_dts	updated_dts	serial_no_as_of_dts	qty	flow	flow_long	par	last_seen_date	their_next_repair_date	last_sterilized_date	repair_last_repair_date	is_searched_but_not_found	marked_for_deletion	is_found	is_go_live_perm_printed	is_sleeping	is_handwritten_label	is_wrong_loc	is_facility_loc_inherited	needs_repair	is_deactivated	is_contents_incomplete	their_location	category	their_name	their_id	created_by	updated_by	their_id_scrubbed	crossing_status	inv_no	their_raw_name	comments_	their_bar_code	loc_rack	loc_row	loc_bin	loc_note	serial_no	data_cleanse_classification	repair_next_due	repair_last_repaired_by	msgs','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','inv_v2','','View column orderless check for types_plus.inv_v2','select * from types_plus.inv_v2 limit 0;','category	comments_	created_by	created_dts	crossing_status	data_cleanse_classification	facility_location_id	flow	flow_long	id	inv_no	is_contents_incomplete	is_deactivated	is_facility_loc_inherited	is_found	is_go_live_perm_printed	is_handwritten_label	is_searched_but_not_found	is_sleeping	is_wrong_loc	item_arch_id	item_id	last_seen_date	last_sterilized_date	loc_bin	loc_note	loc_rack	loc_row	marked_for_deletion	msgs	needs_repair	par	qty	repair_last_repair_date	repair_last_repaired_by	repair_next_due	serial_no	serial_no_as_of_dts	standard_faclity_id	store_at_facility_id	their_bar_code	their_id	their_id_scrubbed	their_location	their_name	their_next_repair_date	their_raw_name	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:item_arch_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','item_arch_v1','','View column strict check for types_plus.item_arch_v1','select * from types_plus.item_arch_v1 limit 0;','id	facility_id	clinic_id	created_dts	updated_dts	previous_as_of	marked_for_deletion	is_current	name_	type_	created_by	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','item_arch_v1','','View column orderless check for types_plus.item_arch_v1','select * from types_plus.item_arch_v1 limit 0;','clinic_id	created_by	created_dts	facility_id	id	is_current	marked_for_deletion	name_	previous_as_of	type_	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:item_type_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','item_type_v1','','View column strict check for types_plus.item_type_v1','select * from types_plus.item_type_v1 limit 0;','id	marked_for_deletion	name_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','item_type_v1','','View column orderless check for types_plus.item_type_v1','select * from types_plus.item_type_v1 limit 0;','id	marked_for_deletion	name_','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:item_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','item_v2','','View column strict check for types_plus.item_v2','select * from types_plus.item_v2 limit 0;','id	item_arch_id	facility_specialty_id	item_uu_id_across_item_archs	inv_responsible_user_id	facility_department_id	specialty_id	sup_id	dr_people_id	item_type_id	item_master_link_id	facility_location_id	clinic_id	hsys_tag_id	name_copied_from_prod_id	created_dts	updated_dts	named_dts	needs_sched_sync_as_of_dts	weight_lb	qty	flow	flow_long	max_processed_one_day	par	assembly_difficulty	num_inst	repair_every_x	their_qty	replace_every_x_cycles	hide_specialty_in_name	marked_for_deletion	is_assembly_critical	requires_leak_test	is_not_tracked_by_inv_no	is_imlink_locked	is_robotic	is_flexible_scope	is_generic_pack	dont_print_count_sheet	is_conflict_check	is_small_set	hide_hsys_tag_in_name	is_name_finalized	is_in_data_cleanse_scope	is_label_abbr	has_implants	sync_to_other_software_systems	inv_has_implants	is_custom_sort	is_name_copied_from_prod	is_deactivated	is_vendor_data	name_needs_review	ignore_for_optimization	inv_status	their_name	opt_status	created_by	updated_by	old_names	their_serial_no	name_desc	name_	their_id	decon_special_instructions	named_by	needs_review_notes	vendor_tray_type	sterilization_method	priority	category	packaging_type	packaging_notes	their_packaging_type	assembly_special_instructions	sterilize_special_instructions	label_name_abbr	their_location	count_sheet_status	requested_by	rack_row_bin_note	standardization_status	repair_every_x_type	their_base_barcode	their_key	stuff','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','item_v2','','View column orderless check for types_plus.item_v2','select * from types_plus.item_v2 limit 0;','assembly_difficulty	assembly_special_instructions	category	clinic_id	count_sheet_status	created_by	created_dts	decon_special_instructions	dont_print_count_sheet	dr_people_id	facility_department_id	facility_location_id	facility_specialty_id	flow	flow_long	has_implants	hide_hsys_tag_in_name	hide_specialty_in_name	hsys_tag_id	id	ignore_for_optimization	inv_has_implants	inv_responsible_user_id	inv_status	is_assembly_critical	is_conflict_check	is_custom_sort	is_deactivated	is_flexible_scope	is_generic_pack	is_imlink_locked	is_in_data_cleanse_scope	is_label_abbr	is_name_copied_from_prod	is_name_finalized	is_not_tracked_by_inv_no	is_robotic	is_small_set	is_vendor_data	item_arch_id	item_master_link_id	item_type_id	item_uu_id_across_item_archs	label_name_abbr	marked_for_deletion	max_processed_one_day	name_	name_copied_from_prod_id	name_desc	name_needs_review	named_by	named_dts	needs_review_notes	needs_sched_sync_as_of_dts	num_inst	old_names	opt_status	packaging_notes	packaging_type	par	priority	qty	rack_row_bin_note	repair_every_x	repair_every_x_type	replace_every_x_cycles	requested_by	requires_leak_test	specialty_id	standardization_status	sterilization_method	sterilize_special_instructions	stuff	sup_id	sync_to_other_software_systems	their_base_barcode	their_id	their_key	their_location	their_name	their_packaging_type	their_qty	their_serial_no	updated_by	updated_dts	vendor_tray_type	weight_lb','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:loaner_case_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_case_v1','','View column strict check for types_plus.loaner_case_v1','select * from types_plus.loaner_case_v1 limit 0;','id	loaner_id	last_updated_by_data_file_id	updated_dts	created_dts	case_dts	marked_for_deletion	desc_	surgeon	updated_by	created_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_case_v1','','View column orderless check for types_plus.loaner_case_v1','select * from types_plus.loaner_case_v1 limit 0;','case_dts	created_by	created_dts	desc_	id	last_updated_by_data_file_id	loaner_id	marked_for_deletion	surgeon	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:loaner_item_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_item_v1','','View column strict check for types_plus.loaner_item_v1','select * from types_plus.loaner_item_v1 limit 0;','id	loaner_id	item_id	last_updated_by_data_file_id	updated_dts	created_dts	left_behind_qty	qty	pickup_qty	marked_for_deletion	updated_by	created_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_item_v1','','View column orderless check for types_plus.loaner_item_v1','select * from types_plus.loaner_item_v1 limit 0;','created_by	created_dts	id	item_id	last_updated_by_data_file_id	left_behind_qty	loaner_id	marked_for_deletion	pickup_qty	qty	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:loaner_iteminv_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_iteminv_v1','','View column strict check for types_plus.loaner_iteminv_v1','select * from types_plus.loaner_iteminv_v1 limit 0;','id	loaner_item_id	inv_id	last_updated_by_data_file_id	created_dts	updated_dts	marked_for_deletion	created_by	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_iteminv_v1','','View column orderless check for types_plus.loaner_iteminv_v1','select * from types_plus.loaner_iteminv_v1 limit 0;','created_by	created_dts	id	inv_id	last_updated_by_data_file_id	loaner_item_id	marked_for_deletion	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:loaner_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_v1','','View column strict check for types_plus.loaner_v1','select * from types_plus.loaner_v1 limit 0;','s_case_id	id	sup_id	rep_id	facility_id	last_updated_by_data_file_id	pickup_dts	created_dts	updated_dts	datetime_local	drop_off_dts	num_items	marked_for_deletion	is_printed	created_by	updated_by	status	notes','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','loaner_v1','','View column orderless check for types_plus.loaner_v1','select * from types_plus.loaner_v1 limit 0;','created_by	created_dts	datetime_local	drop_off_dts	facility_id	id	is_printed	last_updated_by_data_file_id	marked_for_deletion	notes	num_items	pickup_dts	rep_id	s_case_id	status	sup_id	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:need_v5__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','need_v5','','View column strict check for types_plus.need_v5','select * from types_plus.need_v5 limit 0;','id	hsys_id	facility_id	item_id	percent_down	next_case_dts	flow	qty_circulation	qty_ready_everywhere	qty_ready_here	qty_sched_everywhere	qty_sched_here	qty_sterile_everywhere	qty_sterile_here	qty_suggest_sterilize	qty_total	ready_vs_need_defecit	sched_sort	sort_rank	suggest_transport	next_needed	or_name	status	status_sort	when_	qty_here','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','need_v5','','View column orderless check for types_plus.need_v5','select * from types_plus.need_v5 limit 0;','facility_id	flow	hsys_id	id	item_id	next_case_dts	next_needed	or_name	percent_down	qty_circulation	qty_here	qty_ready_everywhere	qty_ready_here	qty_sched_everywhere	qty_sched_here	qty_sterile_everywhere	qty_sterile_here	qty_suggest_sterilize	qty_total	ready_vs_need_defecit	sched_sort	sort_rank	status	status_sort	suggest_transport	when_','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:productivity_detail_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','productivity_detail_v1','','View column strict check for types_plus.productivity_detail_v1','select * from types_plus.productivity_detail_v1 limit 0;','id	source_record_row_counter	start_time_dts	source_table_number	data_file_id	user_id	facility_id	assembly_inst	assembly_pack	assembly_tray	assembly_points	assembly_seconds_trays	assembly_seconds_overall	pause_seconds	duration_seconds	placeholder_row	description	year_and_month	start_date	time_label	duration	pause_time	activity	user_label','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','productivity_detail_v1','','View column orderless check for types_plus.productivity_detail_v1','select * from types_plus.productivity_detail_v1 limit 0;','activity	assembly_inst	assembly_pack	assembly_points	assembly_seconds_overall	assembly_seconds_trays	assembly_tray	data_file_id	description	duration	duration_seconds	facility_id	id	pause_seconds	pause_time	placeholder_row	source_record_row_counter	source_table_number	start_date	start_time_dts	time_label	user_id	user_label	year_and_month','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:push_audit_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','push_audit_v1','','View column strict check for types_plus.push_audit_v1','select * from types_plus.push_audit_v1 limit 0;','schema_name	target_name	unique_path	target_type	data_file_id	duration_seconds	records_count	version_number	start_local_dts	end_local_dts	end_utc_dts	error_occurred	client_user_name	push_method_name	error_text','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','push_audit_v1','','View column orderless check for types_plus.push_audit_v1','select * from types_plus.push_audit_v1 limit 0;','client_user_name	data_file_id	duration_seconds	end_local_dts	end_utc_dts	error_occurred	error_text	push_method_name	records_count	schema_name	start_local_dts	target_name	target_type	unique_path	version_number','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:q_audit_step_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_audit_step_v1','','View column strict check for types_plus.q_audit_step_v1','select * from types_plus.q_audit_step_v1 limit 0;','id	hsys_id	qsub_type_id_audit	step	marked_for_deletion	last_updated_by_data_file_id	created_dts	updated_dts	created_by	updated_by	sort	qsub_type_id_event','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_audit_step_v1','','View column orderless check for types_plus.q_audit_step_v1','select * from types_plus.q_audit_step_v1 limit 0;','created_by	created_dts	hsys_id	id	last_updated_by_data_file_id	marked_for_deletion	qsub_type_id_audit	qsub_type_id_event	sort	step	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:q_event_audit_step_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_event_audit_step_v1','','View column strict check for types_plus.q_event_audit_step_v1','select * from types_plus.q_event_audit_step_v1 limit 0;','id	qevent_id	qaudit_step_id	last_updated_by_data_file_id	updated_dts	created_dts	sort	marked_for_deletion	is_coached	notes	created_by	updated_by	step	qsub_type_id_event	status','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_event_audit_step_v1','','View column orderless check for types_plus.q_event_audit_step_v1','select * from types_plus.q_event_audit_step_v1 limit 0;','created_by	created_dts	id	is_coached	last_updated_by_data_file_id	marked_for_deletion	notes	qaudit_step_id	qevent_id	qsub_type_id_event	sort	status	step	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:q_event_person_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_event_person_v1','','View column strict check for types_plus.q_event_person_v1','select * from types_plus.q_event_person_v1 limit 0;','id	web_user_id	last_updated_by_data_file_id	qevent_id	created_dts	updated_dts	marked_for_deletion	is_accountable	send_email	updated_by	role_	created_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_event_person_v1','','View column orderless check for types_plus.q_event_person_v1','select * from types_plus.q_event_person_v1 limit 0;','created_by	created_dts	id	is_accountable	last_updated_by_data_file_id	marked_for_deletion	qevent_id	role_	send_email	updated_by	updated_dts	web_user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:q_event_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_event_v1','','View column strict check for types_plus.q_event_v1','select * from types_plus.q_event_v1 limit 0;','or_surgeon_people_id	id	qtype_id	qsub_type_id	inv_id	scan_id	assembly_id	status_when_user_id	facility_id	last_updated_by_data_file_id	status_reported_by_user_id	status_done_user_id	status_investigating_user_id	datetime_local	status_done_dts	status_when_dts	status_investigating_dts	status_reported_dts	updated_dts	created_dts	or_delay_minutes	marked_for_deletion	is_data_problem	is_process_problem	assembly_audit_prods	is_coached	updated_by	or_room	status_done_name	status	status_when_name	desc_	status_investigating_name	or_delay_type	status_reported_by_name	notes	created_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_event_v1','','View column orderless check for types_plus.q_event_v1','select * from types_plus.q_event_v1 limit 0;','assembly_audit_prods	assembly_id	created_by	created_dts	datetime_local	desc_	facility_id	id	inv_id	is_coached	is_data_problem	is_process_problem	last_updated_by_data_file_id	marked_for_deletion	notes	or_delay_minutes	or_delay_type	or_room	or_surgeon_people_id	qsub_type_id	qtype_id	scan_id	status	status_done_dts	status_done_name	status_done_user_id	status_investigating_dts	status_investigating_name	status_investigating_user_id	status_reported_by_name	status_reported_by_user_id	status_reported_dts	status_when_dts	status_when_name	status_when_user_id	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:q_level_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_level_v1','','View column strict check for types_plus.q_level_v1','select * from types_plus.q_level_v1 limit 0;','id	hsys_id	last_updated_by_data_file_id	created_dts	updated_dts	level_	marked_for_deletion	created_by	updated_by	name_	ascendco_name','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_level_v1','','View column orderless check for types_plus.q_level_v1','select * from types_plus.q_level_v1 limit 0;','ascendco_name	created_by	created_dts	hsys_id	id	last_updated_by_data_file_id	level_	marked_for_deletion	name_	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:q_subtype_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_subtype_v1','','View column strict check for types_plus.q_subtype_v1','select * from types_plus.q_subtype_v1 limit 0;','id	qtype_id	qlevel_id	facility_group_id	facility_id	hsys_id	last_updated_by_data_file_id	created_dts	updated_dts	is_available_in_assembly	is_available_in_decon	marked_for_deletion	is_for_inv	is_active	ascendco_name	updated_by	type_	available_for	created_by	name_	item_type_ids','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_subtype_v1','','View column orderless check for types_plus.q_subtype_v1','select * from types_plus.q_subtype_v1 limit 0;','ascendco_name	available_for	created_by	created_dts	facility_group_id	facility_id	hsys_id	id	is_active	is_available_in_assembly	is_available_in_decon	is_for_inv	item_type_ids	last_updated_by_data_file_id	marked_for_deletion	name_	qlevel_id	qtype_id	type_	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:q_type_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_type_v1','','View column strict check for types_plus.q_type_v1','select * from types_plus.q_type_v1 limit 0;','id	hsys_id	last_updated_by_data_file_id	created_dts	updated_dts	marked_for_deletion	is_active	updated_by	created_by	ascendco_name	name_	type_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','q_type_v1','','View column orderless check for types_plus.q_type_v1','select * from types_plus.q_type_v1 limit 0;','ascendco_name	created_by	created_dts	hsys_id	id	is_active	last_updated_by_data_file_id	marked_for_deletion	name_	type_	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:rep_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','rep_v1','','View column strict check for types_plus.rep_v1','select * from types_plus.rep_v1 limit 0;','id	user_id	hsys_id	sup_id	created_dts	updated_dts	marked_for_deletion	name_	phone	email	created_by	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','rep_v1','','View column orderless check for types_plus.rep_v1','select * from types_plus.rep_v1 limit 0;','created_by	created_dts	email	hsys_id	id	marked_for_deletion	name_	phone	sup_id	updated_by	updated_dts	user_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:specialty_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','specialty_v1','','View column strict check for types_plus.specialty_v1','select * from types_plus.specialty_v1 limit 0;','id	data_file_id	marked_for_deletion	name_	name_short','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','specialty_v1','','View column orderless check for types_plus.specialty_v1','select * from types_plus.specialty_v1 limit 0;','data_file_id	id	marked_for_deletion	name_	name_short','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:stat_facility_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','stat_facility_v1','','View column strict check for types_plus.stat_facility_v1','select * from types_plus.stat_facility_v1 limit 0;','id	facility_id	hsys_id	date_	category	item_type	stat_type	is_most_recent	in_data_cleanse_scope	items_inactive	items_count	items_qty	items_inventoried	items_to_inventory	items_named	items_to_name	inst_qty	items_has_loc	items_missing_locs	item_prods_count	item_prods_missing_part_nos_thier	item_prods_missing_vendors_thier	item_prods_dr_pref	item_prods_critical	item_prods_not_linked	item_prods_missing_part_nos	item_prods_missing_vendors	item_prods_cant_determine	item_prods_linked	sup_prods_count	sups_count	prods_count	prods_with_pic	prods_without_pic	item_prods_verified	item_prods_expert_linked	item_prods_dup_names_their	item_prods_dup_names	prods_named	part_nos_fixed	invs_inactive	invs_count	invs_found	emr_items_count	emr_items_linked	emr_items_matches_their_name	emr_items_matches_our_name	emr_items_no_match_their_name	emr_items_no_match_our_name	emr_items_dups','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','stat_facility_v1','','View column orderless check for types_plus.stat_facility_v1','select * from types_plus.stat_facility_v1 limit 0;','category	date_	emr_items_count	emr_items_dups	emr_items_linked	emr_items_matches_our_name	emr_items_matches_their_name	emr_items_no_match_our_name	emr_items_no_match_their_name	facility_id	hsys_id	id	in_data_cleanse_scope	inst_qty	invs_count	invs_found	invs_inactive	is_most_recent	item_prods_cant_determine	item_prods_count	item_prods_critical	item_prods_dr_pref	item_prods_dup_names	item_prods_dup_names_their	item_prods_expert_linked	item_prods_linked	item_prods_missing_part_nos	item_prods_missing_part_nos_thier	item_prods_missing_vendors	item_prods_missing_vendors_thier	item_prods_not_linked	item_prods_verified	item_type	items_count	items_has_loc	items_inactive	items_inventoried	items_missing_locs	items_named	items_qty	items_to_inventory	items_to_name	part_nos_fixed	prods_count	prods_named	prods_with_pic	prods_without_pic	stat_type	sup_prods_count	sups_count','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sterilize_method_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilize_method_v1','','View column strict check for types_plus.sterilize_method_v1','select * from types_plus.sterilize_method_v1 limit 0;','id	data_file_id	marked_for_deletion	name_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilize_method_v1','','View column orderless check for types_plus.sterilize_method_v1','select * from types_plus.sterilize_method_v1 limit 0;','data_file_id	id	marked_for_deletion	name_','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sterilize_params_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilize_params_v1','','View column strict check for types_plus.sterilize_params_v1','select * from types_plus.sterilize_params_v1 limit 0;','id	data_file_id	marked_for_deletion	hsys_id	sterilize_method_id	name_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilize_params_v1','','View column orderless check for types_plus.sterilize_params_v1','select * from types_plus.sterilize_params_v1 limit 0;','data_file_id	hsys_id	id	marked_for_deletion	name_	sterilize_method_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sterilizer_load_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_load_v1','','View column strict check for types_plus.sterilizer_load_v1','select * from types_plus.sterilizer_load_v1 limit 0;','id	data_file_id	marked_for_deletion	sterilize_method_id	sterilizer_id	sterilize_params_id	created_dts	load_no	status_building_dts	status_sterilizing_dts	status_cooling_dts	status_done_dts	notes	failed_notes	utcoffset_seconds','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_load_v1','','View column orderless check for types_plus.sterilizer_load_v1','select * from types_plus.sterilizer_load_v1 limit 0;','created_dts	data_file_id	failed_notes	id	load_no	marked_for_deletion	notes	status_building_dts	status_cooling_dts	status_done_dts	status_sterilizing_dts	sterilize_method_id	sterilize_params_id	sterilizer_id	utcoffset_seconds','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sterilizer_load_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_load_v2','','View column strict check for types_plus.sterilizer_load_v2','select * from types_plus.sterilizer_load_v2 limit 0;','id	data_file_id	marked_for_deletion	sterilize_method_id	sterilizer_id	sterilize_params_id	created_dts	load_no	status_building_dts	status_sterilizing_dts	status_cooling_dts	status_done_dts	notes	failed_notes	utcoffset_seconds','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_load_v2','','View column orderless check for types_plus.sterilizer_load_v2','select * from types_plus.sterilizer_load_v2 limit 0;','created_dts	data_file_id	failed_notes	id	load_no	marked_for_deletion	notes	status_building_dts	status_cooling_dts	status_done_dts	status_sterilizing_dts	sterilize_method_id	sterilize_params_id	sterilizer_id	utcoffset_seconds','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sterilizer_log_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_log_v1','','View column strict check for types_plus.sterilizer_log_v1','select * from types_plus.sterilizer_log_v1 limit 0;','id	data_file_id	log_type	summary_json	log_xml','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_log_v1','','View column orderless check for types_plus.sterilizer_log_v1','select * from types_plus.sterilizer_log_v1 limit 0;','data_file_id	id	log_type	log_xml	summary_json','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sterilizer_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_v1','','View column strict check for types_plus.sterilizer_v1','select * from types_plus.sterilizer_v1 limit 0;','id	data_file_id	marked_for_deletion	facility_id	sterilize_method_id	name_','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sterilizer_v1','','View column orderless check for types_plus.sterilizer_v1','select * from types_plus.sterilizer_v1 limit 0;','data_file_id	facility_id	id	marked_for_deletion	name_	sterilize_method_id','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sup_parent_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sup_parent_v1','','View column strict check for types_plus.sup_parent_v1','select * from types_plus.sup_parent_v1 limit 0;','id	created_dts	updated_dts	marked_for_deletion	name_	created_by	updated_by','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sup_parent_v1','','View column orderless check for types_plus.sup_parent_v1','select * from types_plus.sup_parent_v1 limit 0;','created_by	created_dts	id	marked_for_deletion	name_	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:sup_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sup_v2','','View column strict check for types_plus.sup_v2','select * from types_plus.sup_v2 limit 0;','id	custom_facility_id	sup_parent_id	created_dts	updated_dts	is_custom_by_facility	marked_for_deletion	is_available_for_loaners	name_	created_by	updated_by	short_name','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','sup_v2','','View column orderless check for types_plus.sup_v2','select * from types_plus.sup_v2 limit 0;','created_by	created_dts	custom_facility_id	id	is_available_for_loaners	is_custom_by_facility	marked_for_deletion	name_	short_name	sup_parent_id	updated_by	updated_dts','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:text_collection_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','text_collection_v1','','View column strict check for types_plus.text_collection_v1','select * from types_plus.text_collection_v1 limit 0;','id	collection_name	added_dts	retain	facility_id','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','text_collection_v1','','View column orderless check for types_plus.text_collection_v1','select * from types_plus.text_collection_v1 limit 0;','added_dts	collection_name	facility_id	id	retain','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:web_user_v1__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','web_user_v1','','View column strict check for types_plus.web_user_v1','select * from types_plus.web_user_v1 limit 0;','id	data_file_id	marked_for_deletion	hsys_id	username	role_	name_first	name_last	name_full','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','web_user_v1','','View column orderless check for types_plus.web_user_v1','select * from types_plus.web_user_v1 limit 0;','data_file_id	hsys_id	id	marked_for_deletion	name_first	name_full	name_last	role_	username','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);--Coyote:Users:dpadams2:Resilio Sync:DPA:nautilus:generated_tests:views:types_plus:web_user_v2__tests.sql------------------------------------------------------------------- Test that the column list has not changed: Strict.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','web_user_v2','','View column strict check for types_plus.web_user_v2','select * from types_plus.web_user_v2 limit 0;','id	data_file_id	hsys_id	is_sonar_ascendco_support	marked_for_deletion	name_first	role_	username	name_full	name_last','','text','{"case_sensitvity":"sensitive","column_order":"strict"}','Pass','{user_change_structure}',false);------------------------------------------------------------------- Test that the column list has not changed: Orderless.-----------------------------------------------------------------select null from test_case_setup('View','types_plus','web_user_v2','','View column orderless check for types_plus.web_user_v2','select * from types_plus.web_user_v2 limit 0;','data_file_id	hsys_id	id	is_sonar_ascendco_support	marked_for_deletion	name_first	name_full	name_last	role_	username','','text','{"case_sensitvity":"sensitive","column_order":"orderless"}','Pass','{user_change_structure}',false);