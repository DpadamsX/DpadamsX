If (False)  // ===========================================	^method_name^		  // DESCRIPTION: Push records from the ^4d_table_name^ table to Nautilus.		  // Add the following lines to 	Compiler_PgIO 	C_BOOLEAN(^method_name^;$0)	C_OBJECT(^method_name^;$1)		  // CREATED BY: David Adams	  // DATE: ^created_on^	  // LAST MODIFIED: End if   // ============================================Code_Start (Current method name)C_BOOLEAN($0;$ran_okay)C_OBJECT($1;$connection_object)$connection_object:=$1  // Pass a good connection ID or you're toast.C_LONGINT($connection_id)C_TEXT($table_name_in_postgres_text)$connection_id:=$connection_object.connection_id$table_name_in_postgres_text:="^pg_table_name^"If ($connection_id<1)	$ran_okay:=FalseElse 	$ran_okay:=True		  //-------------------------------------------------------	  // Find the unsent data	  //-------------------------------------------------------	C_LONGINT($table_number)	C_LONGINT($first_conid_to_send_l)	C_LONGINT($last_conid_to_send_l)	C_LONGINT($records_count)	$table_number:=pgIO_GetConIDsForTable (->^4d_table_name^;->$first_conid_to_send_l;->$last_conid_to_send_l)	$records_count:=pgIO_LoadConIDRange (->^4d_table_name^;->^4d_table_name^ConID;$first_conid_to_send_l;$last_conid_to_send_l)	ORDER BY(^4d_table_name^;^4d_table_name^ConID)  // Important! Since we're chunking and bail if there's an error, it's important to keep track of the highest successful ConID sent.		  //-------------------------------------------------------	  // Prepare and push the data	  //-------------------------------------------------------	If ($records_count=0)		$ran_okay:=True	Else 				C_TEXT($cr)		C_TEXT($tab)		C_TEXT($sq)		$cr:=Char(Carriage return)		$tab:=Char(Tab)		$sq:=Char(Quote)				C_TEXT($insert_text)		$insert_text:=""		$insert_text:=$insert_text+"BEGIN;"+$cr		$insert_text:=$insert_text+"INSERT INTO ^pg_table_name^ ("+$cr		^insert_block^		$insert_text:=$insert_text+"VALUES"+$cr				  // $values_text+$cr  goes in here for the push. The VALUES statements are built in the loop below.				C_TEXT($on_conflict_text)		$on_conflict_text:=$on_conflict_text+$cr		$on_conflict_text:=$on_conflict_text+"ON CONFLICT(id) DO UPDATE SET "+$cr		^on_conflict_block^				C_LONGINT($maximum_push_bytes)		C_LONGINT($overhead_bytes)  // How many bytes are we using for the declarative bits?		C_OBJECT($insert_object)		$maximum_push_bytes:=Iam_GetPGMaximumPushKB *1024  // We want bytes to compare to the results from calling Length($values_text)		$overhead_bytes:=Length($insert_text)+Length($on_conflict_text)  // How many bytes are consumed by the declarative bits?		$insert_object:=PgQuery_New ($connection_object;"";"^method_name^")  // The same query object is used for each push in this method. The SQL payload gets reset for each push.				  // Fold the data into values statements.		C_BLOB($values_blob)  // Accumulate in a BLOB, crazy faster than accumulating in a text var.		SET BLOB SIZE($values_blob;0)				^data_file_id_assignment^				C_LONGINT($record_index)		For ($record_index;1;$records_count)						  // GOTO SELECTED RECORD. Yeah, it rules. See:			  // https://ascendco.atlassian.net/wiki/spaces/SON/pages/572817462/Loading+Data+Efficiently+for+Pushing+to+Postgres			GOTO SELECTED RECORD(^4d_table_name^;$record_index)						C_TEXT($clause_text)			$clause_text:=""						  // Convert the current row to a properly escaped and formatted value row. We're doing multi-row inserts, to this is a ("parens","sort","of","deal",5)			^values_block^			C_LONGINT($push_data_size_bytes)			C_BOOLEAN($push_now)			$push_data_size_bytes:=BLOB size($values_blob)+Length($clause_text)+$overhead_bytes						Case of 				: ($record_index=$records_count)  // We've gone through all of the records.					$push_now:=True									: ($push_data_size_bytes>=$maximum_push_bytes)  // We've filled the buffer.					$push_now:=True									Else   // Keep on building the VALUES.					$push_now:=False			End case 						If ($push_now=False)				$clause_text:=$clause_text+","+$cr  // We now *know* that we're going to add another value (statement), so we also know that we need a comma. The last (value) does *not* have a comma.			End if 						TEXT TO BLOB($clause_text;$values_blob;UTF8 text without length;*)						If ($push_now)  // We've filled our buffer (based on max KB from IAM) or reached the last record. Push! 								  // This doubles memory consumption briefly. I asked Rob about a command that accepts a BLOB instead of text.				  // He said "no" as it would require a text copy internally anyway, so it won't help. If memory is an issue,				  // write to disk instead of text or BLOB and then use Document to text to load the block in one go.				C_TEXT($values_text)  // The VALUES are built up in the loop below. When we've got all the records, or have filled our self-defined buffer, a push is sent.				$values_text:=BLOB to text($values_blob;UTF8 text without length)				SET BLOB SIZE($values_blob;0)  // Free up the RAM.								If (False)					SET TEXT TO PASTEBOARD($insert_text+$values_text+$on_conflict_text)				End if 								  // Jam the text right into the object...not calling PgQuery_SetSQLStatement here in case text is built (doubled) by for 4D for the parameter.				OB SET($insert_object;PgQuery_Statement_SQL;$insert_text+$values_text+$on_conflict_text)				$values_text:=""  // Clear this now! It frees up memory before the push and makes sure that we don't keep resending old rows.								$ran_okay:=PgQuery_Run ($insert_object)								PgQuery_SetSQLStatement ($insert_object;"")  // Free up the memory taken by the SQL statement.								If ($ran_okay=False)					PgSQL_Execute ($connection_id;"ROLLBACK;")					$record_index:=$records_count+1  // Break the loop. 				Else 					PgSQL_Execute ($connection_id;"COMMIT;")										  //-------------------------------------------------------					  // Update the last sent ConID					  //-------------------------------------------------------					  // This is why we sort by ConID up at the top. We're chunking through the number line and at each success, we plant a flag saying, "got this far!"					If (SyncTables_SetLastConIDSentToPG ($table_number;^4d_table_name^ConID)=False)						  // Fails if record is locked or pushed value is lower than existing max value. Never decrement the max!						  // Not bailing. We'll end up resending records in the future, but no harm should come of it.					End if 									End if 								  // IceBerg records with [DeletedRecordDate] # !00/00/00! get pushed up as marked_for_deletion (boolean) to Nautilus.				  //  So, we push every change by ConID and then go back and hard-delete in Nautilus any records soft-deleted in IceBerg.				pgIO_ClearDeletedRecordsInTable ($connection_id;$table_name_in_postgres_text)							End if 					End for 			End if 		UNLOAD RECORD(^4d_table_name^)	End if $0:=$ran_okayIf ($ran_okay)  // Push an entry even if no records need to be sent.	pgio_Push_PushLogEntry ($connection_object;$table_number;$table_name_in_postgres_text;$records_count)End if Code_End (Current method name)